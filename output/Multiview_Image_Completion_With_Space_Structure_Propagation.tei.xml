<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multiview Image Completion with Space Structure Propagation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seung-Hwan</forename><surname>Baek</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inchang</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
							<email>minhkim@vclab.kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Multiview Image Completion with Space Structure Propagation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a multiview image completion method that provides geometric consistency among different views by propagating space structures. Since a user specifies the region to be completed in one of multiview photographs casually taken in a scene, the proposed method enables us to complete the set of photographs with geometric consistency by creating or removing structures on the specified region. The proposed method incorporates photographs to estimate dense depth maps. We initially complete color as well as depth from a view, and then facilitate two stages of structure propagation and structure-guided completion. Structure propagation optimizes space topology in the scene across photographs, while structure-guide completion enhances, and completes local image structure of both depth and color in multiple photographs with structural coherence by searching nearest neighbor fields in relevant views. We demonstrate the effectiveness of the proposed method in completing multiview images.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Digital photography has been stimulated from the perspective of collaboration, yielding casual multiview photographs of a scene. Even though multiview images are getting popular from the recent advances of digital imaging devices such as mobile cameras and light field cameras, consistent image editing of multiview photographs rarely has been discussed. For instance, most traditional image completion methods focus on an individual photograph <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b1">2]</ref>; hence, applying such single image completion methods is not able to retain the geometric consistency of space structures in images.</p><p>Traditional inpainting <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b27">28]</ref> focuses on preserving coherency of structure in an image. In contrast, we propose a novel solution that allows for geometric coherency, socalled space structure, while completing multiview images. Multiview photographs allow us to estimate depth, utilized * Corresponding author as geometric constraints. While completing multiview images, our method accounts for not only structure in an image, but also space structure across multiview images.</p><p>Our method first receives a target region from a user in one of the multiview photographs. The region is then completed by three steps: (1) the preprocessing step estimates dense depth maps and camera parameters using structure from motion, and completes the color and the depth of a reference view, (2) the structure propagation step conveys the space structure of the previous completions to the next image to be completed, and (3) the structure-guided completion enhances the quality of completion by incorporating the transferred space structure, searching for local similarity via the nearest neighbor field across multiview photographs. We perform the structure propagation and structure-guided completion steps for all images, resulting in multiple completed images for the first iteration. To enhance the image completion, our iterative approach repeats these two steps until we reach to the final completed images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Image completion synthesizes image structure to fill in larger missing areas using exemplar <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b16">17]</ref>. Our work is a branch of image completion, focusing on image completion of multiple photographs.</p><p>Single Image Completion Criminisi et al. <ref type="bibr" target="#b8">[9]</ref> prioritized patches to be filled, and greedily propagated the patches from the known source region to the target region. Wexler et al. <ref type="bibr" target="#b30">[31]</ref> solved the image completion problem with an expectation-maximization (EM) optimization using an image pyramid. Since the nearest neighbor field (NNF) search is the computational bottleneck of image completion, <ref type="bibr">Barnes et</ref> al. accelerated the process by introducing an approximated search algorithm <ref type="bibr" target="#b1">[2]</ref>. Darabi et al. <ref type="bibr" target="#b9">[10]</ref> considered the gradients of images for patch-based synthesis and also introduced alpha-blending of multiple patches. Our method is based on the framework of Wexler et al. <ref type="bibr" target="#b30">[31]</ref> with the main difference that our approach simultaneously completes the color and the depth of multiview photographs with structural coherence. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-image completion</head><p>Completed multiple photographs Output Guided-vote <ref type="figure">Figure 1</ref>. We take multiview photographs and a target region mask as input. (a) Preprocessing: per-view information is estimated such as camera parameters and depth maps. A color image and its depth map are completed as reference from a view (see Section 4). (b) Structure propagation: the space structure of the previously completed view is transferred to the next view to be completed. The target region is estimated with consideration of the space structure (Section 3.2). (c) Structure-guided completion: the local structure in each image is iteratively refined for color as well as depth (Section 3.3). We iterate structure propagation and structure-guided completion, resulting in multiple color images completed with geometric consistency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stereo Image Completion</head><p>Since the disparity of similar colors depends on depth, completing the color and the depth on a target region in stereo images is a chicken-andegg problem. Wang et al. <ref type="bibr" target="#b29">[30]</ref> jointly synthesized the color and the depth using a greedy search <ref type="bibr" target="#b8">[9]</ref>. They executed the image completion independently on left and right images and then evaluated them to constrain the perspective consistency. However, the consistency of image completion is not always guaranteed, particularly when processing a large holes. Morse et al. <ref type="bibr" target="#b22">[23]</ref> initially inpainted the depth via a simple interpolation with a PDE solver, and exploited the inpainted depth to complete the color. Since PDE-based inpainting of the depth is even more challenging than completing the color due to lack of clues, the inaccurate depth completion in this method tends to reduce the quality of image inpainting significantly. Similar to traditional imagebased rendering methods <ref type="bibr" target="#b31">[32]</ref>, the goal of these stereo inpainting methods is merely to remove target foreground objects by filling in the occlusion region, which is caused by the objects, using patches from the background. Note that large-scale structures in image completion cannot be accounted for the previous stereo completion methods; e.g., the synthesized structure in one image could be outside of the target region on other images due to perspective projection. Alternatively, Luo et al. <ref type="bibr" target="#b21">[22]</ref> asked users to manually complete the target depth map and then performed image completion on the color images only. While this method can complete the target region with foreground objects, users need to manually correct the target region of both views considering the visibility of completed depth. <ref type="bibr" target="#b15">[16]</ref> embedded scene semantics into target regions by using millions of prior Internet photographs. Darabi et al. <ref type="bibr" target="#b9">[10]</ref> considered a mixture of two patches from different images in applying a random correspondence search method <ref type="bibr" target="#b1">[2]</ref>. Barnes et al. <ref type="bibr" target="#b2">[3]</ref> proposed a 3D data structure for efficient NNF search from multiple source images. Wexler et al. <ref type="bibr" target="#b30">[31]</ref> introduced a video completion method that propagates image completion with a smoothness constraint of consecutive frames. Even though these methods accounted for multi-ple images or patches, they presumed that the camera view point does not change significantly. Multiple images are merely employed to improve the quality of image completion. They all disregard the three-dimensional space structure of image completion. To the best of our knowledge, our method is the first work that accounts for the geometric consistency of space structure in image completion of multiple photographs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiple Image Completion Hays and Efros</head><p>Depth-Image-Based Rendering Image-based rendering (IBR) is a traditional method that synthesizes a novel view from multiple photographs <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b4">5]</ref>. IBR has been extended as depth-image-based rendering (DIBR) by adding depth information from multiview stereo <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b5">6]</ref>. DIBR is used for synthesizing viewpoint with interpolation and extrapolation by means of direct and inverse projection on the segmented pixels from a novel viewpoint. The typical problems in DIBR viewpoint synthesis are completing the missing regions such as occlusions and cracks. In recent works of DIBR <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b6">7]</ref>, small or uniform regions can be restored by diffusion-based methods, such as <ref type="bibr" target="#b3">[4]</ref>. Largely missing regions are restored by patch-based approaches <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b28">29]</ref>. The ultimate goal of image completion in DIBR is to reconstruct missing regions using the background information, while keeping projected region intact. In contrast, we incorporate our patch-based approach to complete not only background but also foreground objects with geometric consistency in multiple photographs. Also, we complete the projected region as well as the missing region, in order to handle the artifacts of projected region arising from inaccurate depth values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Multiple Image Completion</head><p>Our pipeline consists of three steps: preprocessing, structure propagation, and structure-guided completion. See <ref type="figure">Figure 1</ref> for an overview.</p><p>Input We use multiview unstructured photographs I i containing a static scene from different views v i ∈ V as input, where V is the set of every view. A user specifies an original image I o , and give an original mask M o indicating the  completion region Ω o to be completed on the original image I o . Note that our method automatically completes the corresponding target region Ω i on the i-th image, resulting in a consistent completed imageÎ i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preprocessing</head><p>Since we target casually taken multiple photographs for image completion, preprocessing starts to estimate dense depth maps using structure from motion (SfM). See </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Structure Propagation</head><p>Subsequent to estimating the camera parameters from SfM, we first select relevant views, where the initial completion is visible in multiple photographs. The completed color and depth in a target region of v o is propagated to guide the completions of the selected views to preserve geometric consistency. See <ref type="figure" target="#fig_3">Figure 3</ref> for overview.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inverse &amp; Direct Projection</head><p>LetV be the set of completed multiviews, where v i ∈V is progressively completed from the original view v o ∈V . In order to determine next view to be completed v j / ∈V , we compare the lastly completed view v i and other remaining views v j / ∈V in terms of the Euclidean distance of the camera positions and the orientation difference.</p><p>Once the most similar view v j is selected, the completed colorÎ i and depthD i of the homogeneous pixel coordinateṡ p i ∈ v i are projected inversely to the homogenous global coordinates p via perspective projections of each view v i ∈ V :</p><formula xml:id="formula_0">p =D i (p i )E −1 i K −1 iṗ i ,<label>(1)</label></formula><p>where K and E are the intrinsic and extrinsic parameters of each view v i in relation toṗ i and p. Now we can accumulate each completionṗ i in the global coordinates of a 3D point p, thus project image completion ofṗ i toṗ j in the next view v j directly:</p><formula xml:id="formula_1">p j = K j E j p.<label>(2)</label></formula><p>This mechanism of inverse and direct projection allows us to preserve geometric consistency in multiple photographs although this results in cracks due to perspective projection and occlusion. These cracks are handled in the stage of structure-guided completion (see Section 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Identifying Completion Regions</head><p>Traditional stereo completion methods <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b22">23]</ref> complete target region using background only; therefore, no additive structures are allowed in completion. In contrast, our structure propagation allows for introduction of additive structures in completion.</p><p>To do so, we separate the target region Ω j into two associated regions of addition and subtraction, Ω + j and Ω − j in the new view v j . We need two steps to identify the complete regions in the new view. First, we should identify the subtractive regions Ω − j to be removed in v j . We inversely project each pixelṗ j ∈ v j to correspondingṗ o ∈ v o using Equations <ref type="formula" target="#formula_0">(1)</ref>  Second, we identify the additive regions Ω + j where some additive structure to be introduced in completion. Note that this Ω + j could be different from Ω − j depending on which structure is completed. Since the space structure exists only in the original view v i , we project the completed pixel region Ω i to v j via inverse and direct projection. This Ω + j therefore results in cracks and discontinuity. We expand the region to a convex hull that surrounds Ω + j to solve these artifacts using patch-based synthesis (see Section 3.3). Finally, we define a union region of these two regions as follows:</p><formula xml:id="formula_2">Ω j = Conv(Ω + j ) ∪ Ω − j .</formula><p>Note that this process does not account for a new structure to be completed in Ω − j in the next step. We solve this problem by iterating this completion workflow rounding the series of photographs.</p><p>Compared to DIBR methods <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b6">7]</ref>, we synthesize missing regions as well as structure-guide regions in or- (a) Color structure guide at low frequency (b) Color structure guide at high frequency <ref type="figure">Figure 5</ref>. We use the low frequency shape (a) as structure guide.</p><p>Since the projected guide includes severe corruption with cracks and missing details, we fix it with our multi-view patch synthesis.</p><p>der to to handle depth errors inevitably induced by completion. DIBR methods maintain I ′ j and D ′ j for Ω + j , and complete the remaining target region Ω C j = {p ∈ Ω − j |p / ∈ Ω + j }. However, as the structure-guide region Ω + j spreads over the image sparsely and contains artifacts due to the inaccurate depth values, this approach yields poor results as shown in <ref type="figure" target="#fig_6">Figure 6</ref>(c).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Structure-Guided Multiple Completion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Space Structures</head><p>Contrary to state-of-the-art methods <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b9">10]</ref>, we have additive completion regions Ω + j in addition to subtractive completion regions Ω − j . Prior to synthesizing the completion regions Ω j , we first transfer the pre-completed color I i and depth D i on Ω i to Ω + j using Equations (1) and (2) as structure guide. We utilize this transferred information while synthesizing Ω j as guide. We denote the structure guides of color and depth as I ′ j and D ′ j , respectively. The traditional patch-based completion frameworks <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b1">2]</ref> build an image pyramid that includes the target regions from coarse to fine levels. These methods search for a similar patch in the source region per the target patch centered at target pixel p j , in order to substitute the color of p j with that of the similar source pixel, so-called search. Now we have a source patch matched with target pixel p j . As source patches corresponding to the neighbor pixels of p j could have pixels that lie on the pixel position p j , they interpolate the colors of those pixels to determine the final color of p j , so-called vote. For each level, search and vote are performed iteratively, and this approach results in a completed image at the finest level.</p><p>Our proposed approach imposes the structure guides through this optimization problem. We synthesize the target region Ω j while maintaining the projected structure guides of I ′ j and D ′ j on Ω + j . Our intuition is that the structure guide is roughly correct while the details are crisp (see <ref type="figure">Figure 5</ref>). Our approach harmonizes patch-based synthesis with space-structure guide in order to achieve geometric consistency in multi-image completion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Coherence vs. Structure Guide</head><p>Our goal is to synthesize the target region Ω j using the source regions of every view Ψ</p><formula xml:id="formula_3">∀ = Ψ k = A k \ Ω −1 k |k ∈ V ,</formula><p>where A k is the set of every pixel in view k. Our energy function consists of two terms, a coherence and a guidance term:</p><formula xml:id="formula_4">E = pj ∈Ωj min q ∀ ∈Ψ ∀ {E coherence (p j , q ∀ ) + E guide (p j )},</formula><p>where p j is a target pixel on the target region Ω j , and q ∀ is a source pixel on the source region Ψ ∀ .</p><p>The coherence term E coherence describes the similarity of the target and source patch in terms of color in CIELAB <ref type="bibr" target="#b7">[8]</ref> and depth gradients, defined by:</p><formula xml:id="formula_5">E coherence (p j , q ∀ ) =C Ī j (p j ) ,Ī ∀ (q ∀ ) + αC ∇D j (p j ) , ∇D ∀ (q ∀ ) ,<label>(3)</label></formula><p>where C is the L2 norm of the difference of two values, and α is the weighting constant.Ī j (p j ) ∇D j (p j ) are the color patches and the depth gradient patches centered at pixel p j . Note that this function resembles that one from Darabi et al. <ref type="bibr" target="#b9">[10]</ref> with the following difference. While Darabi et al. took both color and color gradients in their coherence term, we take both color and depth gradients for evaluating space-structure coherence. Our principal intuition for examining depth gradients is that, if we evaluate the difference of the depths directly, we cannot utilize many patches of the same shape but in a different distance to complete a depth map. Our light-weight shape representation of depth gradients allows us to evaluate the shape similarity of depth patches to synthesize depth information in missing regions, whereas traditional stereo completion methods <ref type="bibr" target="#b29">[30]</ref> examined direct depth information. α varies depending on the level of quality of the reconstructed depth maps. The guidance term E guide accounts for the similarity of the target patch and the structure guide for pixel p j ∈ Ω + j :</p><formula xml:id="formula_6">E guide (p j ) = βC I j (p j ) , I ′ j (p j ) + γC D j (p j ) , D ′ j (p j ) ,<label>(4)</label></formula><p>where β and γ are the weighting factors for color and depth differences, respectively. The overall scales of β and γ balance the local image structure and the space structure guide. In order to solve this objective function, we complete the color image first by our patch-based completion considering structure guide I ′ j . We then complete the depth using the completed color as well as the structure guide D ′ j . This guide energy term is mainly handled by the guided voting stage. See Section 3.3.3 for detail on optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Color and Depth Optimization</head><p>Our optimization is originated from Darabi et al. <ref type="bibr" target="#b30">[31]</ref> with the main difference for structure-guided image completion. Our optimization consists of two steps: search and guided vote. Here we mainly describe the differences from the base algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Guide Initialization</head><p>We first construct color and depth image pyramids of the original data and the structure-guide, I j,l , D j,l and I ′ j,l , D ′ j,l , respectively, using a Lanczos kernel following Darabi et al. <ref type="bibr" target="#b9">[10]</ref>. Here let l ∈ [1, L] be the level of the pyramid and L be the number of levels (I j,L = I j ). Accordingly, target completion region Ω j and sub-region with structure guide Ω + j are transformed into each level l, resulting in Ω j,l and Ω + j,l . Then, the structure guide I ′ j,1 at the coarsest level is initially copied to the additive completion region Ω + j,1 ∈ I j,1 to impose the coarse image completion resemble the structure guide. The rest of completion region Ω j \Ω + j is filled in by interpolating the gradients of the boundary pixels with a PDE solver. See Algorithm 1 for an overview.</p><p>Search For this search stage, we mainly use Equation <ref type="formula" target="#formula_5">(3)</ref> to find the NNF of the closest patch at pixel q ∀ ∈ Ψ ∀ to N N F j,l ← SEARCH(Î j,l , I ∀,l , ∇D j,l , ∇D ∀,l ) 5:Î j,l ,D j,l ← VOTE(N N F j,l , I ∀,l , I ′ p j ,l , ∇D ∀,l , D ′ p j ,l ) 6: end for match patch at pixel p j ∈ Ω j . Here we are motivated to adopt a popular search method, proposed by Barnes et al. <ref type="bibr" target="#b1">[2]</ref>, which is based on random search and propagation. Since our method takes multiple images as input, we extend the search range from a single to multiple photographs, by concatenating them as one, similar to Barnes et al. <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Guided Vote</head><p>Our guided vote is the main difference from the state-of-the-art methods. From the search process, we collect colors and depth gradients of the patches from the NNF of neighbor pixels. We estimate initial color and depth gradients from the NNF, I * j,l (p j ) and ∇D * j,l (p j ), centered at target pixel p j using the weighted sum approach, proposed by Wexler et al. <ref type="bibr" target="#b30">[31]</ref>. These coherent color and depth values are updated with a guidance of space structure, as described in Equations <ref type="formula" target="#formula_5">(3)</ref> and <ref type="formula" target="#formula_6">(4)</ref>, as follows.</p><p>Since we obtain the initial colors I * j,l from coherence search, to account for space structure, we update color at pixel p j by linearly interpolating the coherent color I * j,l (p j ) and structure guide I ′ j,l (p j ), where p j is on the additive completion region Ω + j :</p><formula xml:id="formula_7">I j,l (p j ) ← (1 − β(l)) × I * j,l (p j ) + β (l) × I ′ j,l (p j ) ,<label>(5)</label></formula><p>where β(l) is the frequency-dependent weight. We define β(l) as a truncated function that interpolates the level of weighting linearly:</p><formula xml:id="formula_8">β (l) =    1, l ≤ l s (l e − l)/(l e − l s ), l s &lt; l ≤ l e 0, l e &lt; l ,<label>(6)</label></formula><p>where l s and l e are the user parameters that control the influence of structure guide I ′ j . Although we compare depth gradients in NNF search, our goal is to complete depthD j,l rather than ∇D * j,l on the target region Ω j,l and to achieve geometric consistency with structure guide D ′ j,l . For the region Ω C j,l = Ω j,l \ Ω + j,l , we want to complete depthD j,l from the voted depth gradients ∇D * j,l . Also, we should preserve space structure D ′ j,l projected from the previous view, for the other region. Finally, the optimalD j,l can be estimated by minimizing the following objective function:</p><formula xml:id="formula_9">min D j,l Ω C j,l ||∇D j,l − ∇D * j,l || 2 ,<label>(7)</label></formula><p>with boundary conditionsD j,l | δΩ C j,l = D ′ j,l | δΩ C j,l . We optimize this objective equation with a constraint term of the boundary conditions:</p><formula xml:id="formula_10">γ D j,l | δΩ C j,l − D ′ j,l | δΩ C j,l 2</formula><p>, where a constant γ is a weighting constant that appears in Equation (4). By applying the Euler-Lagrange equation, the opti-malD j,l satisfies the Poisson equation: ∇ 2D j,l = ∇ · D * j,l . Algorithm 2 summarizes our completion method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Implementation Details</head><p>Preprocessing Point clouds and camera parameters are estimated by using SfM methods <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b12">13]</ref> from multiple photographs. We then project the point clouds into each view, resulting in a sparse depth map per a view using Equation (1) (see <ref type="figure" target="#fig_1">Figure 2b</ref>). We propagate sparse depth estimates to every pixel, yielding a dense depth map D i per view <ref type="figure" target="#fig_1">(Figure 2c)</ref>. Once we build depth information in photographs, for the target region Ω o of input view v o , we perform our completion method (Section 3.3) without any structure guide, resulting in a completed color imageÎ o and the completed depth mapD o . Multiple Source Images We complete each view of multiple photographs with consideration of space structure, as described in Section 3. Different from traditional completion methods, we use multiple images as input, and therefore we extend the patch search range from a single to multiple photographs, by concatenating them as one following Barnes et al. <ref type="bibr" target="#b2">[3]</ref>. When we complete view v j , we select M source views uniformly on the sorted views w.r.t. the pose difference with view v j , for computational efficiency. The concatenated image is used for our structureguide completion (Section 3.3). whereas previous stereo completion methods <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref> utilize one of the left and right images to complete the selected image.</p><p>Depth Denoising In general, a depth map reconstructed from the Poisson equation suffers from severe noise. We therefore conduct an additional process of depth denoising that smooths out the estimated depth in the target region. We first segment the initially-estimated depth map into superpixels <ref type="bibr" target="#b0">[1]</ref> by using the color information in the completed color image. We then perform median filtering per each depth superpixel to clean noise. Matting Laplacian <ref type="bibr" target="#b19">[20]</ref> is applied to remove quantization error over superpixel edges in the depth map.</p><p>Parameters We use a 7 × 7 patch for color and depth. Parameter α in Equation <ref type="formula" target="#formula_5">(3)</ref> controls the balance between color and depth gradients in calculating individual coherence within each image. α is set to a lower value to weight the color similarity for local coherence of each image. Parameter β in Equation <ref type="formula" target="#formula_6">(4)</ref> is determined by l s and l e in Equation <ref type="bibr" target="#b5">(6)</ref>, which controls the balance between individual coherence and global geometric consistency. Parameter γ in Equation (4) controls the inaccurate depths in propagated structure guides. A higher value of γ suppresses the depth errors more, which is originated from Poisson reconstruction. In this experiment, we set the values of α, l s , l e and γ as 0.01, 0.3, 0.6, and 100. See <ref type="figure" target="#fig_11">Figure 9</ref>. In addition, we use ten levels of the image pyramid and the number of source views is set to three. We found that two iterations are enough for satisfying geometric consistency across multiple views. We complete three to six images selected from three to twenty images used for SfM, considering computational feasibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>Our Matlab and C++ implementation took approx. 300 seconds to complete color and depth of a 680 × 900 image with 2.5 × 10 4 target pixels. Computing time increases linearly proportional to the number of input images in general, taking 25 minutes for the multiple images with five photographs. To validate the performance of our method, we applied our method to three types of input data: stereoscopic images, a single RGB-D image and multiple images.   <ref type="bibr" target="#b29">[30]</ref> for a stereo image. Our method reconstructs the left and the right image with geometric consistency while completing the connection of left-most pipe naturally, while Wang et al. <ref type="bibr" target="#b29">[30]</ref> fills the target region with background objects, inhibiting natural completion of the complex structure. <ref type="figure">Figure 8</ref> shows the result of completing color and depth in a single RGB-D image. Our method can achieve geometric consistency of not only color but also depth. Note that depth patches cannot be compared directly for shape similarity due to depth value differences. Our gradient-based depth synthesis allows us to compare shape similarity in terms of gradients through the NNF search.</p><p>To the best of our knowledge, multiple image completion has not been studied before. For evaluation, we therefore applied a stereo completion algorithm of Wang et al. <ref type="bibr" target="#b29">[30]</ref> on a pair of stereo images consequently to process multiple images. Wang et al. <ref type="bibr" target="#b29">[30]</ref> impose geometric consistency by comparing the colors of corresponding pixels in completed left and right images. <ref type="figure">Figure 10</ref> demonstrates that our method can synthesize new structures consistently across multiple photographs, while maintaining coherence of each image. In contrast, Wang et al. <ref type="bibr" target="#b29">[30]</ref> cannot account for large structures and fail to preserve both geometric consistency and coherence inside each image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion and Conclusions</head><p>Propagated depth maps could be unstable due to the errors originated from SfM (see <ref type="figure" target="#fig_6">Figure 6b</ref>). To solve this problem, we account for color and depth coherency in an image. The propagated space structure is simultaneously updated through iteration with consideration of spatial frequency. Nevertheless, the quality of depth maps could be degraded in case of dynamic or feature-less scenes, which potentially cause the failure of our method. Note that initial completion of the target image can be conducted by any other state-of-the-art single image completion methods <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b9">10]</ref>.</p><p>We have presented a novel multiple image completion method that preserves the geometric consistency among different views. The proposed method consists of structure propagation and structure-guided completion. Our structure-guided completion, which is designed as a single optimization framework, exhibits superior results in terms of coherency and consistency. Our versatile algorithm enables to complete not only multiple images, but also stereoscopic images. In addition it allows to fill the empty region with foreground as well as background objects, which has been challenging so far in the previous stereo completion methods <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b22">23]</ref>.  <ref type="figure">Figure 10</ref>. Multi-image completion. The first column shows input color and depth. Red color indicates completion regions. The second and the third column shows completed depth and color, respectively, compared with Wang et al. <ref type="bibr" target="#b29">[30]</ref>. The fourth and the fifth column presents completions from different views. Refer to the supplemental materials for more results. Image courtesy of Olsson and Enqvist <ref type="bibr" target="#b24">[25]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>For given photographs (a), we estimate camera parameters and point clouds. A sparse depth map (b) is estimated by projecting the point clouds into each view. We propagate the sparse depth values using Matting Laplacian<ref type="bibr" target="#b19">[20]</ref>, resulting in a dense depth map per a view (c). Image courtesy of Olsson et al.<ref type="bibr" target="#b24">[25]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 2 for example. We then conduct initial color and depth image completion on a reference view v o . See Sections 3.3 and 4 for details on structure-guided image completion and SfM implementation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Schematic diagram of our multiview patch-based synthesis. Structure propagation: after completing the current view (a), we select a next nearest target view (b), and propagate the previous completion to (b). Structure-guided completion: we utilize multiple photographs (a), (b) and (c) to complete a target view.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>and (2). We then determine if the corresponding pixelṗ o belongs to the original region Ω o . See Figures 4(a) and (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>(a) We complete the target region Ωi from the current view vi. (b) Corresponding to Ωi of the view vi, we estimate the subtractive region Ω − j on a new view vj. (c) &amp; (d) Completion of view vi introduces additive target region Ω + j on the new view vj.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>(a) shows an initial completion of the original view using our RGB-D completion method. (b) presents our intermediate projection of the completed structure to a new view. Note that the distorted space structure is caused by inaccurate depth. (c) shows the result of our completion. The distorted color and depth are updated iteratively through patch-based synthesis with structure guide. (d) compares our result with a traditional DIBR method, which complete the missing region with background and is incapable of handling depth inaccuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Create image pyramids I j,l , I ′ j,l , D j,l ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Input: I ∀ , Ωo Output:Î ∀ ,D ∀ 1: Estimate per-view information K ∀ , E ∀ and D ∀ . 2:Îo,Do ← COMPLETION(Io, ∅, Do, ∅) 3:V ← {vo} 4: for iter = [1, ..., N ] Îj ,Dj ← COMPLETION(Ij , I ′ j , Dj, D ′ j ) 10:V ←V ∪ {vj} 11: end while 12:V ← {vo} 13: end for</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .Figure 8 .</head><label>78</label><figDesc>Stereo image completion. Our method completes the stereo image (a) with complex structures, resulting in the completed images (b) and (c) with geometric consistency by creating or removing objects. Wang et al.<ref type="bibr" target="#b29">[30]</ref> utilize background patches only in turn. They cannot preserve the structure of the scene, such as the pipe in the left-side of the scene (d) and (e). Also note that there are some notable artifacts in (d) and (e), which are originated from the individual completion of each view. Image courtesy of Scharstein et al.<ref type="bibr" target="#b25">[26]</ref>. For a single RGB-D image data (a), our method completes the target region (red area), resulting in a consistent RGB-D image (b). Image courtesy of Kim et al.<ref type="bibr" target="#b17">[18]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7</head><label>7</label><figDesc>compares our method with Wang et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 .</head><label>9</label><figDesc>(a) We investigate the effects of parameters: (b) α (orange box), (c) β(ls, le) (purple) and (d) γ (yellow). We fix other parameters while varying only one of them, with the following values: α = 0.01, ls = 0.3, le = 0.6 and γ = 100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>View #1</head><label>View</label><figDesc>View #2View #3 Input of view #1: Image &amp; depth map[Wang et al.]    Ours[Wang et al.]    Ours[Wang et al.]    </figDesc><table>Ours 

Completed depth of 
view #1 

[Wang et al.] 

Ours 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Min H. Kim gratefully acknowledges Korea NRF grants (2013R1A1A1010165 and 2013M3A6A6073718) and additional support by Samsung Electronics (G01140381) and an ICT R&amp;D program of MSIP/IITP (10041313) in addition to Sung-Hyun Choi (Samsung) for helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SLIC superpixels compared to state-of-the-art superpixel methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Süsstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2274" to="2282" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Goldman. PatchMatch: A randomized correspondence algorithm for structural image editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="24" to="25" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">PatchTable: Efficient patch queries for large datasets and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-M</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="97" to="98" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Image inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bertalmio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Caselles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ballester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH &apos;00</title>
		<meeting>ACM SIGGRAPH &apos;00</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="417" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unstructured lumigraph rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcmillan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gortler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH &apos;01</title>
		<meeting>ACM SIGGRAPH &apos;01</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="425" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Depth synthesis and local warps for plausible image-based navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chaurasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Duchêne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Drettakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Space-time hole filling with random walks in view extrapolation for 3D video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing (TIP)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2429" to="2441" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Colorimetry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Region filling and object removal by exemplar-based image inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing (TIP)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1200" to="1212" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Image melding: combining inconsistent images using patch-based synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Darabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Depth-aided image inpainting for novel view synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Daribo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pesquet-Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop on Multimedia Signal Processing (MMSP)</title>
		<meeting>IEEE Int. Workshop on Multimedia Signal essing (MMSP)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="167" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Depth-image-based rendering (DIBR), compression, and transmission for a new approach on 3D-TV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5291</biblScope>
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Accurate, dense, and robust multiview stereopsis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1362" to="1376" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Depth-based image completion for view synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gautier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">L</forename><surname>Meur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guillemot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3DTV Conference: The True Vision -Capture, Transmission and Display of 3D Video (3DTV-CON)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The lumigraph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gortler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grzeszczuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH &apos;96</title>
		<meeting>ACM SIGGRAPH &apos;96</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="43" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Scene completion using millions of photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="4" to="5" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Image completion using planar structure guidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="129" to="130" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Scene reconstruction from high spatioangular resolution light fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pritch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Image-based rendering in the gradient domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Langguth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goesele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="199" to="200" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Colorization using optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="689" to="694" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Light field rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH &apos;96</title>
		<meeting>ACM SIGGRAPH &apos;96</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="31" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Geometrically consistent stereoscopic image editing using patch-based synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Chuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics. (TVCG)</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="56" to="67" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Patchmatchbased content completion of stereo image pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Morse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT) &apos;12</title>
		<meeting>3D Imaging, Modeling, essing, Visualization and Transmission (3DIMPVT) &apos;12</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="555" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hole filling method using depth based in-painting for view synthesis in free viewpoint television and 3-D video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Picture Coding Symposium (PCS) &apos;09</title>
		<meeting>Picture Coding Symposium (PCS) &apos;09</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Stable structure from motion for unordered image collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Enqvist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th Scandinavian Conference on Image Analysis</title>
		<meeting>17th Scandinavian Conference on Image Analysis</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="524" to="535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">High-resolution stereo datasets with subpixel-accurate ground truth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hirschmüller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kitajima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Krathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nešić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Westling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition: 36th German Conference</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="31" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Photo tourism: Exploring photo collections in 3D</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="835" to="846" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Image completion with structure propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="861" to="868" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Seamless view synthesis through texture optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">C</forename><surname>Au</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing (TIP)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="342" to="355" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Stereoscopic inpainting: Joint color and depth completion from stereo images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Space-time completion of video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wexler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="463" to="476" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">High-quality video view interpolation using a layered representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Uyttendaele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Winder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="600" to="608" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
