<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Heterogeneous Light Fields</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Diebold</surname></persName>
							<email>maximilian.diebold@iwr.uni-heidelberg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Heidelberg Collaboratory for Image Processing</orgName>
								<orgName type="institution">Sony Deutschland GmbH</orgName>
								<address>
									<addrLine>Speyerer Str 6, Hedelfinger Strae 61</addrLine>
									<postCode>69115, 70327</postCode>
									<settlement>Heidelberg, Stuttgart</settlement>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Jähne</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Heidelberg Collaboratory for Image Processing</orgName>
								<orgName type="institution">Sony Deutschland GmbH</orgName>
								<address>
									<addrLine>Speyerer Str 6, Hedelfinger Strae 61</addrLine>
									<postCode>69115, 70327</postCode>
									<settlement>Heidelberg, Stuttgart</settlement>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gatto</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Heidelberg Collaboratory for Image Processing</orgName>
								<orgName type="institution">Sony Deutschland GmbH</orgName>
								<address>
									<addrLine>Speyerer Str 6, Hedelfinger Strae 61</addrLine>
									<postCode>69115, 70327</postCode>
									<settlement>Heidelberg, Stuttgart</settlement>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Heterogeneous Light Fields</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In contrast to traditional binocular or multi-view stereo approaches, the adequately sampled space of observations in light-field imaging allows, to obtain dense and high quality depth maps. It also extends capabilities beyond those of traditional methods. Previously, constant intensity has been assumed for estimating disparity of orientation in most approaches to analyze epipolar plane images (EPIs). Here, we introduce a modified structure tensor approach which improves depth estimation. This extension also includes a model of non-constant intensity on EPI manifolds. We derive an approach to estimate high quality depth maps in luminance-gradient light fields, as well as in color-filtered light fields. Color-filtered light fields pose particular challenges due to the fact that structures can change significantly in appearance with wavelength and can completely vanish at some wavelength. We demonstrate solutions to this challenge and obtain a dense sRGB image reconstruction in addition to dense depth maps.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The basis of light-field <ref type="bibr" target="#b7">[8]</ref> imaging is the plenoptic function as introduced in <ref type="bibr" target="#b0">[1]</ref>. It represents a multi-dimensional function describing all the information available of light reflected from a scene. This comprises the direction and spectral radiance of the light. To capture light fields, the plenoptic function is simplified in its dimensionality to a four dimensional subspace, at times termed the lumigraph. This light field representation was first introduced in computer graphics by both Gortler et al. <ref type="bibr" target="#b8">[9]</ref> and Levoy et al. <ref type="bibr" target="#b15">[16]</ref>. The lumigraph describes the ray path as parameterized by two parallel planes. Along the ray path, the radiance remains constant. That means that all rays leaving a surface point and intersecting the two parallel planes have equal intensity in the resulting light field. Due to that constraint, most methods to compute disparities such as <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b3">4]</ref> relate only to light fields with this property. Even for binocular or multi-view stereo approaches, as proposed in <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b19">20]</ref> correspondence between points is modeled on their having the same intensity value. Thus, current cameras such as Raytrix <ref type="bibr" target="#b18">[19]</ref> and Lytro <ref type="bibr" target="#b6">[7]</ref> focus on reconstruction from input images having similar color information. A violation, in case of images captured with different color filters or illuminations, needs sophisticated preprocessing algorithms to adapt the data for the depth estimation, as in the work of Yong et al. <ref type="bibr" target="#b9">[10]</ref>. In that approach, the input image data is mapped to a log-chromaticity color space to obtain an illumination-independent color space to find corresponding points in the input data. Thus the direct computation of depth maps on heterogeneous input data is made in neither multi-view stereo nor current light field imaging. Hyper-spectral images may be generated using a single camera with revolving color filters before the objective, as described in Tominaga <ref type="bibr" target="#b21">[22]</ref>. Unfortunately with this setup, it is not possible to make depth estimates on the underlying scene. In this paper we present heterogeneous light fields which have changing properties between the captured images -such as with the presence of illumination gradients or application of colored filters. We demonstrate that a modified structure tensor is able to process heterogeneous light fields. We analyze the limits of both illumination gradients and randomly illuminated light fields. Furthermore, we show that even for color filtered light fields the structure tensor approach computes locally highly reliable depth information which can be merged to a dense depth map. With this dense depth map it is possible to compute a hyper-spectral image with respect to a reference view out of the used color filtered light field. To visualize the obtained hyper-spectral image we introduce a method to approximate the sRGB color space from the hyper-spectral information and display the final RGB reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Light field disparity estimation</head><p>A light field may be defined as a lumigraph <ref type="bibr" target="#b8">[9]</ref> having two parallel planes Π and Ω. While the Ω -plane addresses the image coordinates (x, y) ∈ Ω of each taken image, the Πplane defines the location of the focal points (s, t) ∈ Π of each camera. A 3D light field as used to capture hetero- <ref type="figure">Figure 1</ref>. Shows synthetically generated EPIs. For each orientation (angle) several EPIs are analyzed to determine the overall precision. The overall precision is computed by using the equation <ref type="bibr">23.</ref> geneous light fields is given by</p><formula xml:id="formula_0">L : Ω × Π → R (s, x, y) → L(s, x, y),<label>(1)</label></formula><p>where L(s, x, y) denotes the pixel intensity value of the ray intersecting (x, y) of the image plane and s of the focal plane (in our case, just a focal line). 2D slices from L are termed epipolar plane images Σ. Ignoring issues of calibration and rectification, an epipolar plane image can be extracted from a 3D light field by setting the y axis to a fixed value y * . The addressed epipolar plane image can be described by the equation</p><formula xml:id="formula_1">S y * : Σ y * → R (2) (x, s) → S y * (x, s) := L(s, x, y * ).<label>(3)</label></formula><p>To compute disparity maps of a given scene, the structure tensor is used in determining the underlying orientations within an EPI. This structure tensor J 1 , used in Wanner <ref type="bibr" target="#b24">[25]</ref>, is defined by the equation</p><formula xml:id="formula_2">J 1 = τ *    ∂Ŝ ∂x 2 ∂Ŝ ∂x · ∂Ŝ ∂s ∂Ŝ ∂s · ∂Ŝ ∂x ∂Ŝ ∂s 2    =: J xx J xs J xs J ss<label>(4)</label></formula><p>with the abbreviationŜ</p><formula xml:id="formula_3">:= σ * S,<label>(5)</label></formula><p>where σ defines an inner Gaussian smoothing and τ an outer Gaussian smoothing applied over each of the structure tensors components. The underlying disparity d is achieve, as introduced in Wanner et al. <ref type="bibr" target="#b22">[23]</ref>, by using the structure tensor components. This reduces disparity estimation to the equation</p><formula xml:id="formula_4">d = tan 1 2 arctan 2J xs J xx − J ss .<label>(6)</label></formula><p>This formula demonstrates the advantage of the structure tensor approach. In contrast to binocular or multi-view stereo, where a correspondence search between several images is necessary, the structure tensor simply computes the disparity map by analyzing orientation in epipolar plane images. Aside from the disparity, a reliability measure is also computed to indicate confidence of the underlying orientation This reliability measure is termed coherence c and was first introduced in Bigun et al. <ref type="bibr" target="#b1">[2]</ref> c := (J xx − J ss ) 2 + 4(J xs ) 2 (J xx + J ss ) 2 .</p><p>3. The modified structure tensor</p><p>To derive a robust structure tensor for heterogeneous light-field processing we analyze the second order structure tensor introduced by Mülich et al. <ref type="bibr" target="#b17">[18]</ref>. This structure tensor is used to separate two transparent overlaying orientations, as introduced in Wanner et al. <ref type="bibr" target="#b23">[24]</ref>. Thus, it already describes an improved structure tensor that can separate two different depth layers. In heterogeneous light fields, an illumination gradient or color-filtered images result in EPI structures with properties similar to two overlaying orientations. For illumination gradient light fields, the first orientation describes the scene disparity while the second orientation indicates the orientation of the illumination gradient. In color-filtered light fields, we have a similar orientation separation, unfortunately the a priori knowledge for the second orientation, while necessary, is not known. For the disparity estimation of the underlying scene, only the first orientation is important since this orientation describes the underlying disparity and, for the depth computation, there is no benefit in using the second orientation. We use the second order structure tensor to derive a new structure tensor to process robust single orientation in heterogeneous light fields without processing the negligible second orientation. Next, we introduce the canonical-correlation analysis (CCA) to derive a new structure tensor. The CCA is used in statistics to analyze the correlation between base vectors in a given evaluation window E. To determine the underlying orientation for a given evaluation window E, we first define the base vectors which are given by the derivatives ofŜ. Thus the base space H becomes</p><formula xml:id="formula_6">H = E * δ(Ŝ) δx , E * δ(Ŝ) δy =: (H x , H y ) .<label>(8)</label></formula><p>Derived from this, the needed covariance matrix 1 computes as and</p><formula xml:id="formula_7">C(H x , H y ) = var(H x , H x ) cov(H x , H y ) cov(H y , H x ) var(H y , H y ) (9) with var(H x , H x ) = 1 n n i=1 (H x,i − H x,µ ) 2<label>(10)</label></formula><formula xml:id="formula_8">cov(H x , H y ) = 1 n n i=1 (H x,i − H x,µ )(H y,i − H y,µ ). (11)</formula><p>where H x,µ is the computed mean value of all values n ∈ E. The given covariance matrix can also be expressed in vector notation and becomes</p><formula xml:id="formula_9">C(H x , H y ) = 1 n H * x H x H * x H y H * y H x H * y H y = 1 n H * H (12)</formula><p>Next we replace the evaluation window with a Gaussian filter which transforms the covariance matrix to the already defined structure tensor as shown in equation 4. With this method, to derive the structure tensor we analyze the second order structure tensor introduced by Mülich et al. <ref type="bibr" target="#b17">[18]</ref>, defined by </p><formula xml:id="formula_10">J = τ * JxxJxx</formula><p>with</p><formula xml:id="formula_12">J xx = δ 2 (σ * S) δx 2 (14) J yy = δ 2 (σ * S) δy 2 (15) J xy = δ 2 (σ * S) δxδy<label>(16)</label></formula><p>where the base space of the second order structure tensor is given by</p><formula xml:id="formula_13">H 3D = J xx , J xy , J xy .<label>(17)</label></formula><p>To analyze the behavior of this structure tensor we generate, for all possible orientations, synthetic EPIs as shown in <ref type="figure">figure 1</ref>. For a better understanding of the correlation between the structure tensor components J xx , J xy and J yy , each 3D point of the base space H is plotted in a 3D coordinate system as shown in <ref type="figure" target="#fig_0">figure 2</ref>. This 3D visualization shows all 3D points of H 3D , for all defined orientations between −45 • and 45 • , as red dots. The derived orientation estimates are plotted as blue lines in the J xx , J xy subspace. As one can see, beside the separation of two transparent overlaying orientations, a single orientation estimate is encoded in the second order structure tensor. A closer look shows that the single orientation estimation is independent of the third structure tensor component J yy . That leads to a new base space for the single orientation</p><formula xml:id="formula_14">H 2D = J xx , J xy ,<label>(18)</label></formula><p>which results by using the introduced procedure to a structure tensor representation defined by</p><formula xml:id="formula_15">J 2 = τ * J xx J xx J xx J xy J xx J xy J xy J xy .<label>(19)</label></formula><p>The shape of this structure tensor is similar to the first introduced structure tensor from equation 4. The only difference is an additional derivative filtering in the x direction of each component. Taking this into account, we select a derivative filter with (2R−1) elements. The advantage of an odd symmetry filter, like 1 2 [−1 0 1], is shown by its transfer function as describe by Jähne <ref type="bibr" target="#b10">[11]</ref>. Thus, the transfer function for the smallest possible derivative filter (R = 2) becomes</p><formula xml:id="formula_16">1 2 [−1 0 1] s ❝ cos(πk)<label>(20)</label></formula><p>wherek ≤ 1 denotes the normalized wave number. As one can see, this filter not only attenuates low frequencies but also high frequencies. With this understanding, the usage of an inner Gaussian filter becomes obsolete, because its main purpose was for anti-aliasing, noise removal and value averaging. All of this, aside from the averaging, is now done by <ref type="figure">Figure 3</ref>. This EPI has a linear illumination gradient in vertical direction. The first row of the shown EPI related to the first captured image of the heterogeneous light field while the last row is related to the last captured image. As one can see increases the illumination continuously. The red line shows the position where the shown EPI is extracted.</p><p>the additional derivative filter. The averaging is transferred to the outer Gaussian filter, which has negligible effect on its value, and its shape doesn't change by the defined offset. This makes the entire processing not only faster, due to the removal of the inner Gaussian filter, but also applicable to heterogeneous light fields. Thus the new derived structure tensor becomes</p><formula xml:id="formula_17">J 3 = τ *    ∂Ŝ ∂x 2 ∂Ŝ ∂x · ∂Ŝ ∂s ∂Ŝ ∂s · ∂Ŝ ∂x ∂Ŝ ∂s 2    =: Ĵ xxĴxŝ J xsĴss<label>(21)</label></formula><p>with the abbreviationŜ</p><formula xml:id="formula_18">:= ∂S ∂x .<label>(22)</label></formula><p>Next we analyze the resulting precision of the new defined structure tensor for different derivative filters in contrast to the traditional structure tensor. Thus we compute the precision as described in Diebold et al. <ref type="bibr" target="#b4">[5]</ref> and generate several synthetic EPIs for a discretized angular space between [−45 • , 45 • ] as shown in <ref type="figure">figure 1</ref>. The resulting overall precision for all evaluated orientations i ∈ N becomes</p><formula xml:id="formula_19">σ d = 1 N N i (µ i ) 2 + 4 N N i (σ i ) 2 .<label>(23)</label></formula><p>where σ i defines the standard deviation of the evaluated estimations and µ i denotes the mean values, to additionally  <ref type="bibr" target="#b24">[25]</ref> in comparison to the new structure tensor with applied inner Gaussian filter J2, and without additional inner Gaussian Filter J3. The evaluation is made for different possible derivative filters of the same shape. As one can see, the new structure tensor outperforms in the Scharr filter implementation the traditionally structure tensor by far.</p><p>consider appearing systematic error. The results of the precision analysis are shown in table 1. As one can see, the achievable precision of the new derived structure tensor J 3 increases with respect to the traditional structure tensor J 1 which was introduced by Wanner et al. <ref type="bibr" target="#b24">[25]</ref>. But the question remains of how the precision changes under luminance gradient light fields.</p><p>In luminance-gradient light fields, the illumination changes from image to image, which is termed illumination gradient ∆I in the following. To analyze these kinds of heterogeneous structures, we apply illumination gradient ∆I to synthetically rendered light fields as shown in <ref type="figure" target="#fig_4">figure 4</ref>. An example of a luminance gradient light field and the resulting appearance of an EPI are shown in <ref type="figure">figure 3</ref>. To compare the reliability of the structure tensor for different illumination     gradients we compute for each evaluation scene the PSNR with respect to the ground truth disparity map. The results for different ∆I are shown in <ref type="figure" target="#fig_4">figure 4</ref>. As one can see, the new structure tensor keeps an almost constant PSNR until the illumination gradient reaches a limiting value. From there, the PSNR immediately decreases. The entire evaluation is made with 16bit images because we must avoid saturation. In the event of saturated regions, the PSNR will decrease due to missing orientation information, and not because of the applied gradient. Thus, 16 bit images allow isolating the influence of the illumination gradient on the estimation result. Aside from the PSNR of the improved structure tensor J 3 , the PSNR of the traditional structure tensor J 1 of the Buddha scene is shown in <ref type="figure" target="#fig_4">figure 4</ref>. As one can directly see, the traditional structure tensor is not able to process a heterogeneous light field. Furthermore, we analyze synthetically generated heterogeneous light fields having random illumination distributions. Here, we randomly shuffle the image related multiplier which was used to achieve the illumination gradient in the EPI. The results of this evaluation are shown in <ref type="figure" target="#fig_7">figure 6</ref>, illustrating the applicability to acquired light fields. Aside small illumination variations invariably occur in acquired light fields. Illumination differences appear due to flickering of the light source or because of varying camera properties such as arise from exposure jitter across the light field array. Thus, the designed structure tensor not only improves the estimation result in homogeneous light fields but also makes it possible to process heterogeneous light fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Color-filtered light fields</head><p>In this section we introduce color-filtered light fields as shown in <ref type="figure" target="#fig_5">figure 5</ref>. Color-filtered light fields are captured with color filters of different wavelengths so that image of the light field contains differing color information. The used band-pass filters have a full-width half-mean of 10 nm and are uniformly distributed in the color spectrum between 400 nm and 700 nm. This means the color-filtered light field contains spectral information of the underlying scene. After generating synthetic color-filtered light fields, we apply the introduced structure tensor J 3 to test scenes such as the rain-bow textured scene shown in <ref type="figure" target="#fig_8">figure 7(a)</ref>. Due to its breadth of color, this scene illustrates that the structure tensor is able to locally estimate the underlying orientation with respect to the visible wavelength. The local estimation results for 500 nm, 600 nm and 700 nm are seen in <ref type="figure" target="#fig_8">figure 7</ref>(b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Color merge and total variation</head><p>It is necessary to merge the local disparity estimations into a reference view r ∈ Π to obtain a dense disparity map. Thus the measured disparity needs to be transferred in the reference view. To select single disparity values, we use examine coherence order and replace estimations in the reference view with smaller coherence value. For the entire merging, we select each row s ∈ Π\r in the EPI and transfer the local disparity estimation of each pixel x onto the addressed position y s in the reference view r which is given by the equation    where the absolute value ensures only even pixel values are addressed in the reference view. That is important to consider since two or more local disparity estimates d s (x) at different positions x can address the same pixel in the reference view. This can happen when one object occludes another. The disparity merge can finally be described by</p><formula xml:id="formula_20">y s = |x + s · d s (x)|<label>(24)</label></formula><formula xml:id="formula_21">d r (y s ) = d s (x) | c s (x) &gt; c r (y s ), d s (x) &gt; d r (y s ) (25)</formula><p>where d r and c r are initialized with the local result of the reference view. Rounding of the applied pixel position introduces error in the resulting disparity map. To minimize this error we determine the actual shift positionx in row s.</p><p>The new position becomeŝ</p><formula xml:id="formula_22">x = y s − s · d s (x).<label>(26)</label></formula><p>When the disparity value at the new position d s (x) is within an epsilon environment ǫ with respect to the initial disparity value d s (x), it replaces the initial disparity value at location x. A reverse disparity value checks whether the rounding has caused an object boundary to be crossed and, if so, rejects (in this case the selected disparity d s ). The final merged disparity map for a reference view of the rainbow textured scene is shown in <ref type="figure" target="#fig_8">figure 7</ref>(c). Unfortunately, it still contains some small patches with undefined disparity value. For the further processing, it is necessary to have a dense disparity map. Thus we apply a second-order total variation as introduced by F. Lenzen et al. <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref> on the merged disparity map. The proposed second order total variation approach minimizes the functional</p><formula xml:id="formula_23">F T V2 (u) := 1 2 u − f 2 2 + αT V (u) + βT V 2 (u) (27)</formula><p>where α, β &gt; 0 denote regularization parameters. The result after the applied second order total variation is shown in <ref type="figure" target="#fig_8">figure 7(d)</ref>. The final hyper-spectral image can now be determined by addressing all color values along the orientations whose direction is given by the achieved disparity map.  <ref type="table">Table 2</ref>. Shows the PSNR of the disparity estimation result with respect to the ground truth for synthetically generated color-filtered light fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PSNR [dB]</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">sRGB reconstruction</head><p>For an RGB color reconstruction from the spectral images we need to find a method to determine the (R, G, B) values from the pixel values S i of the captured spectral images i ∈ N . For this, we use the approach of Tominaga <ref type="bibr" target="#b21">[22]</ref>. That proposes that the CIE color space (X, Y, Z) can be determined by the pixel values S i multiplied by a weighting</p><formula xml:id="formula_24">function M .   X Y Z   = M ·    S ′ 1 . . . S ′ N   <label>(28)</label></formula><p>The weighting function to approximate the CIE color space can be determined by approximating the CIE color matching functions. Thus the camera quantum efficiency QE cam (λ) and the spectral sensitivity functions BP i (λ) of the image i related band pass filter as well as the spectral color distribution LS(λ) of the light source need to be known. Then the CIE-color matching function (x(λ),ȳ(λ),z(λ)) can be estimated by the formula</p><formula xml:id="formula_25"> x (λ) y(λ) z(λ)   = M ·    QE ′ 1 (λ) . . . QE ′ N (λ)    + e<label>(29)</label></formula><p>with For the best possible approximation of the CIE color matching function we introduce the functional F M which minimizes the area difference between the color matching function and the obtained approximation of M for the entire frequency domain Λ with λ ∈ Λ. The proposed functional becomes</p><formula xml:id="formula_26">QE ′ i (λ) = BP i (λ) · QE cam (λ) · LS(λ)<label>(30)</label></formula><formula xml:id="formula_27">F M = min k Λ  x (λ) y(λ) z(λ)   − M 3xN · QE ′ cam (λ) dλ (31)</formula><p>After determining the weighting function M , we can transfer the spectral information to the CIE color space using equation 28. Next we convert the CIE color space as proposed by Tominaga <ref type="bibr" target="#b21">[22]</ref> to sRGB color space <ref type="bibr" target="#b20">[21]</ref>  For the final visualization we also apply a gamma correction of γ = 0.68 to the linear RGB-space which transforms the linear values into sRGB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>As result for homogeneous light fields, we show the comparison of the new structure tensors J 3 with respect to the traditional structure tensor J 1 . The traditional structure tensor leads to the result shown in <ref type="figure" target="#fig_9">figure 8(b)</ref>, while our proposed method shows a full coverage of the captured metal test part as demonstrated in <ref type="figure" target="#fig_9">figure 8(c)</ref>. Next, we want to show the applicability of the proposed structure tensor to color-filtered light fields and the RGB reconstructions. To acquire heterogeneous light fields properly it is important to use linear-ordered color filters. They provide a more stable estimation for intensity gradients, as shown for linear luminance gradient light fields in contrast to random distributed filters configurations. Due to that, a constant quality in the orientation estimation of colorfiltered light fields is guaranteed as long as the gradient is not reaching the critical maximum. Furthermore, considering a color distributions of objects placed in the scene, as shown in <ref type="figure">figure 10 (c)</ref>, it becomes important to select the filter respectively, to ensure that color dependent orientations appear in the underlying EPI. To estimate orientation for colors only seen by one camera is not possible. Thus we can derive two constraints • For broad color spectra of target object, the used band pass filter can have a narrow bandwidth to obtain analyzable orientation.</p><p>• For narrow color spectra of target objects, the used band pass filter needs to be chosen that a orientations are visible in at least 5 neighboring images to guarantee a valid estimation.</p><p>As shown in <ref type="figure" target="#fig_5">figure 5</ref>, the EPI contains local orientation information while black transitions illustrate vanishing color content. <ref type="figure">Figure 9</ref>(a) shows the center view image of the initial synthetic homogeneous light field. This light field contains 31 images which get converted to a color-filtered light field as shown in <ref type="figure" target="#fig_5">figure 5</ref>. Each image is filtered with a band-pass filter having a full-width half-mean of 10 nm. The filters are uniformly distributed in 10 nm steps between 400 nm and 700 nm. The resulting RGB images of the synthetic light field is seen in <ref type="figure">figure 9</ref>(c). The real color-filtered light fields are captured with a PCOedge 5.5 camera, mounted on a high-precise translation stage. For the heterogeneous data we have a symmetric light-field configuration starting from 400 nm to 700 nm and back to 400 nm while each filter has a full-width halfmean of 10 nm. The filters employed are 400 nm, 450 nm, 500 nm, 515 nm, 532 nm, 550 nm, 560 nm, 589 nm, 600 nm, 650 nm, 700 nm and back down to 400 nm. The processing results of the acquired color-filtered light fields are shown in <ref type="figure">figure 10</ref>(c). Input data and additional images are provided in the additional material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>Since the traditional structure tensor suffered from the restriction of a constant intensity along the orientation, the new designed structure tensor overcomes this problem and makes it suitable for an even larger field of applications. The new structure tensor approach introduced in this paper significantly reduces the error in the estimate of orientation compared to the traditional structure tensor. We demonstrate that the modified structure tensor has the advantage of a high reliability in processing heterogeneous light fields. This makes it possible to better analyze acquired light fields, since varying camera properties cause illumination variations. Here we have seen that due to the high reliability of the computed disparity, the color reconstruction matches the object boundaries perfectly. Color-filtered light fields hold a more densely sampled spectra as it is possible for a single camera. Thus, an advanced analysis in the spectral domain is possible. A continuation of this work will be the comparison to other existing depth estimation methods and a transfer of the current approach to camera arrays systems for capturing color-filtered light fields. Possible applications are in food surveillances, e.g to distinguish different cheeses by comparing their spectra, or to determine if food is still eatable or not. Another application is the study about defects in skin, where bacteria or chemical changes influencing the color spectra. It also opens the possibility to use the structure tensor for other types of heterogeneous light fields like for light fields with applied polarization filters to obtain BRDF information. The large variety of new application scenarios and the fast processing to achieve depth information makes it also suitable for movie analysis in near future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>The first image shows the 3D visualization of the base space of the second order structure tensor. All derivative values of J for all possible orientations are plotted. The blue lines show the respectively underlying orientation estimation solution. The top view of the 3D graph shows that the 2D projection of the data matches with the single orientation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Shows the PSNR of the shown scenes (a) for different applied illumination gradients ∆I.Figure (b)shows the PSNR applied on the entire disparity map as well as only to coherence thresholded θ = 0.8 values. For the Buddha scene the traditional implementation of the structure tensor is shown as black dashed line. As one can see keeps the PSNR almost constant until a gradient limit is reached. In contrast, the PSNR of the traditional structure tensor one drops down instantly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Shows an example of an linear heterogeneous light field. Each image is captured with a different color filter having a full width half mean of 10nm. The red line shows the position, where the shown EPI is extracted. In color filtered light fields the intensity changed in orientation direction with respect to the underlying color content.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .</head><label>6</label><figDesc>Illustrates the PSNR for different applied randomly shuffled illuminations defined by an underlying illumination gradient ∆I. The figure shows the PSNR applied on the entire disparity map as well as only to coherence thresholded θ = 0.8 values. For the Buddha scene the traditional implementation of the structure tensor is shown as black dashed line. As one can see keeps the PSNR quiet constant while the PSNR of the traditional structure tensor drops down instantly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>(a) shows the reference image of the light field which become transformed into an color filtered light field. (b) are the local disparity estimations. (c) shows the merged disparity map out of the local disparity maps. (d) shows the final disparity map after an applied total variation. (e) shows the final disparity estimation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 .</head><label>8</label><figDesc>(a) shows a real captured metal test part with not saturated specular highlights. (b) shows the estimated disparity map using the traditional structure tensor as introduced in equation 4. (c) shows the disparity estimation result after applying our proposed structure tensor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 .Figure 10 .</head><label>910</label><figDesc>(a shows the original RGB image of the Buddha scene. (b) shows the final disparity result of the color filtered light field after the applied second order total variation. (c) shows the RGB reconstruction of the computed hyper-spectral image. The left column shows the merged disparity maps. The central column shows the result after the applied second order total variation. The right column shows the RGB reconstruction of the real captured light fields.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In the variance and covariance equation, we have a zero mean assumption Hµ = (Hx,µ, Hy,µ) = (0, 0). Thus the nominator of the variance is n instead of n − 1 not known mean values.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The plenoptic function and the elements of early vision. Computational models of visual processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Optimal orientation detection of linear symmetry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bigün</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Granlund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision</title>
		<meeting>International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="page" from="433" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Epipolar-plane image analysis: An approach to determining structure from motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marimont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="7" to="55" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Extracting layers and analyzing their specular properties using epipolar-plane-image analysis. Computer vision and image understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Anandan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="51" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Epipolar Plane Image Refocusing for Improved Depth Estimation and Occlusion Handling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Diebold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goldluecke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision, Modeling and Visualization Workshop VMV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Efficient Large-Scale Stereo Matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conf. on Computer Vision</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lytro camera technology: theory, algorithms, performance analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lumsdaine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1J1-1J10. International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">8667</biblScope>
		</imprint>
	</monogr>
	<note>IS&amp;T/SPIE Electronic Imaging</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Light Field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gershun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. and Physics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="51" to="151" />
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Lumigraph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gortler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grzeszczuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH</title>
		<meeting>SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="43" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mutual Informationbased Stereo Matching Combined with SIFT Descriptor in Log-chromaticity Color Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">S</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">U</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jähne</surname></persName>
		</author>
		<title level="m">Digital Image Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Handling occlusions in dense multi-view stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2001), with CD-ROM</title>
		<meeting><address><addrLine>Kauai, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-12-14" />
			<biblScope unit="page" from="103" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Scene Reconstruction from High Spatio-Angular Resolution Light Field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pritch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH</title>
		<meeting>SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adaptive Second-Order Total Variation: An Approach Aware of Slope Discontinuities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lenzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lellmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Scale Space and Variational Methods in Computer Vision SSVM</title>
		<meeting>the 4th International Conference on Scale Space and Variational Methods in Computer Vision SSVM</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">7893</biblScope>
			<biblScope unit="page" from="61" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Denoising Time-Of-Flight Data with Adaptive Total Variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lenzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Garbe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings ISVC</title>
		<meeting>ISVC</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="337" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Light field rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH</title>
		<meeting>SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="31" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A New Three-Step Search Algorithm for Block Motion Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Trans. Circuits And Systems For Video Technology</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Theory for Multiple Orientation Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mühlich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings European Conference on Computer Vision</title>
		<editor>H. Bischof and A. Leonardis</editor>
		<meeting>European Conference on Computer Vision</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">3952</biblScope>
			<biblScope unit="page" from="69" to="82" />
		</imprint>
	</monogr>
	<note>II</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The Next Generation of Photography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Perwass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wietzke</surname></persName>
		</author>
		<ptr target="www.raytrix.de" />
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Global Solutions of Variational Models with Convex Regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A standard default color space for the internet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stokes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chandrasekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Motta</surname></persName>
		</author>
		<ptr target="http://www.w3.org/Graphics/Color/sRGB.html" />
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Color Imaging: Device-Independent Color, Color Hardcopy, and Graphic Arts IV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tominaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">3648</biblScope>
		</imprint>
	</monogr>
	<note>Spectral imaging by a multichannel camera</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generating EPI representations of 4D Light fields with a single lens focused plenoptic camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fehr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jähne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Visual Computing</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="90" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Reconstructing Reflective and Transparent Surfaces from Epipolar Plane Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goldluecke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. German Conference on Pattern Recognition</title>
		<meeting>German Conference on Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Variational Light Field Analysis for Disparity Estimation and Super-Resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goldluecke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
