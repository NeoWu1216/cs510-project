<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cataloging Public Objects Using Aerial and Street-Level Images -Urban Trees</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">D</forename><surname>Wegner</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">California Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Branson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">California Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hall</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">California Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Schindler</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">California Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">California Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eth</forename><surname>ZÃ¼rich</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">California Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Cataloging Public Objects Using Aerial and Street-Level Images -Urban Trees</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Each corner of the inhabited world is imaged from multiple viewpoints with increasing frequency. Online map services like Google Maps or Here Maps provide direct access to huge amounts of densely sampled, georeferenced images from street view and aerial perspective. There is an opportunity to design computer vision systems that will help us search, catalog and monitor public infrastructure, buildings and artifacts. We explore the architecture and feasibility of such a system. The main technical challenge is combining test time information from multiple views of each geographic location (e.g., aerial and street views). We implement two modules: det2geo, which detects the set of locations of objects belonging to a given category, and geo2cat, which computes the fine-grained category of the object at a given location. We introduce a solution that adapts state-ofthe-art CNN-based object detectors and classifiers. We test our method on "Pasadena Urban Trees", a new dataset of 80,000 trees with geographic and species annotations, and show that combining multiple views significantly improves both tree detection and tree species classification, rivaling human performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In this very moment thousands of geo-tagged images of almost any location of the populated world are being captured and shared on the web. There are two main sources of publicly available images, user-contributed photographs and imagery from online mapping services. While userprovided photographs cover mostly popular sites, systematic commercial efforts provide a homogeneous and dense coverage of the populated parts of the world, especially urban areas. This includes overhead imagery captured by satellite and aircraft, and high-resolution ground panoramas that are regularly distributed along the road network <ref type="bibr" target="#b2">[3]</ref>. Browser-based interfaces such as Google Maps provide free and well-structured access to this rich, up-to-date and geocoded treasure trove.</p><p>Publicly available imagery has already found its use in * joint first authorship Aerial Images Map Data Street View Images Southern Magnolia</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiview Detection &amp; Recognition</head><p>Fine-Grained Geographic Tree Catalog <ref type="figure">Figure 1</ref>. Overview of proposed automated public tree cataloguing system from online maps. Aerial images and street view panoramas along with semantic map data are downloaded for some geographical region. Category detection and fine-grained classification algorithms are trained from human-annotated exemplars.</p><p>Detection, classification and geolocation information is computed automatically from multiple street view images and aerial images and combined with map data to achieve a geolocated fine-grained catalog. The image shows a catalog of location and species of trees in a medium-sized city. a great number of applications and circumstances. To cite a few: navigation and geo-localization <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b34">34]</ref>, virtual tourism <ref type="bibr" target="#b1">[2]</ref>, urban planning and evaluation of the quality of public spaces <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b17">17]</ref>. However, the process of cataloguing and classifying visible objects in the public space (e.g. street signs, building facades, fire hydrants, solar panels and mail boxes) is still carried out 'by hand', often by inperson inspection or from expensive ad-hoc imagery such as LiDAR. Due to the cost, time, and organizational headache it involves, such information is rarely collected and analyzed. Harvesting such information automatically from online maps will provide inexpensive ready-to-use and reliable information to the public, to administrators, and to scientists which would greatly improve the quality and timeliness of public resource management.</p><p>We present a vision-based system that systematically detects and classifies publicly visible objects. Overhead and street-view imagery are combined to populate and update a public inventory of trees with GPS position and fine-grained species at virtually no cost. Our methods were motivated by a large-scale tree mapping project called Opentreemap 1 aiming to build a centralized, publicly available, and frequently updated tree inventory for each city in the world. The project is stifled by the significant amount of human labor required to catalogue trees. We speculated that Computer Vision may make it viable and explored the question of which combination of geometry and recognition would be most appropriate. Our main contributions are: 1. det2geo: a method to generate a geographic catalog of objects belonging to a given category using multiple aerial and street-level views of each location. 2. geo2cat: a method to compute the fine-grained class label of the 3D object at a given geographical coordinate using multiple aerial and street-level views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Pasadena Urban Trees:</head><p>A dataset of about 80,000 trees tagged with species labels and geographic locations, along with a comprehensive set of aerial, street view, and map images downloaded from Google Maps (&gt;100,000 images).</p><p>To build geo2cat and det2geo, we created methods to automatically download and mutually register aerial and street view images from Google maps. We document the appropriate geometric routines needed to register each type of Google maps image, such that they can easily be integrated with computer vision algorithms (Section 3). We believe that, compared to most prior work, we have gone more in depth to integrate modern, learning-based methods for detection (Section 4) and recognition (Section 5) with multiview geometry and maps data to obtain multi-view visual detection and recognition. We find that multi-view recognition of 3D objects provides significant empirical gains over the customary single view approach: mean average precision increases from 42% to 71% for tree detection, and tree species recognition accuracy is improved from 70% to 80% (Section 7). We motivate and test our algorithms with an important real life application and a new dataset (Section 6). Our methods are already working well enough to have practical impact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>During the past ten years a number of creative and potentially useful ideas have emerged, how to make use of publicly available geo-referenced imagery. Amongst these are the analysis of social networks <ref type="bibr" target="#b6">[7]</ref>, the identification of popular landmarks <ref type="bibr" target="#b29">[29,</ref><ref type="bibr" target="#b7">8]</ref>, scene reconstruction, 3D models and visualizations <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b10">11]</ref> and 4D models that capture changes over time <ref type="bibr" target="#b35">[35]</ref>. Many of these studies are based on images shared by individual users, whose uneven spatial distribution has been recognized as a fundamental limitation <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b1">2]</ref>. Regularly sampled street-level and satellite pictures have been used to obtain more complete coverage and reconstructions <ref type="bibr" target="#b45">[45]</ref>. Researchers have proposed visual recognition and classification methods for inferring Geolocalization from single images <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b31">31]</ref> for applications like land cover classification <ref type="bibr" target="#b28">[28]</ref> or to build large-scale maps of snow coverage or bird species distribution <ref type="bibr" target="#b46">[46]</ref>.</p><p>A number of studies have proposed methods for automating the detection of publicly visible objects. These methods make use of ad-hoc special-purpose imagery <ref type="bibr" target="#b42">[42]</ref> or laser scans <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b26">26]</ref>. One recent approach to tree detection in cities with aerial RGB images is <ref type="bibr" target="#b48">[48]</ref>. They first classify aerial images into tree and background pixels with a CRF under the standard Potts prior. Single trees are extracted by matching a template to candidate tree regions, followed by a set of rules that greedily selects best matches while minimizing overlap of adjacent templates. It is not yet clear whether that method will scale up to entire cities with many different tree shapes since the experiments are carried out on limited datasets. The study focusses on detection and does not address species classification.</p><p>Tree species classification from remote sensing data usually relies either on species-specific spectral signatures in hyperspectral data <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b39">39]</ref> or on dense full-waveform Li-DAR returns that capture the distinctive reflectance patterns of the laser beam penetrating the canopy <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b49">49]</ref>; or on a combination of LiDAR data and aerial imagery, to exploit both the height distribution of the LiDAR returns and the image radiometry and texture <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b22">22]</ref>. Classifiers are mostly trained for a relatively small number of species <ref type="bibr">(3 in [27, 21, 24]</ref>, 4 in <ref type="bibr" target="#b22">[22]</ref>, 7 in <ref type="bibr" target="#b47">[47,</ref><ref type="bibr" target="#b37">37]</ref>).</p><p>An alternative to remote sensing is to acquire images of tree details (e.g., of leafs, bark) in situ, and match them to a reference database <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b13">14]</ref>. If turned into a smart-phone app like Pl@ntNet <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b13">14]</ref> or Leafsnap <ref type="bibr" target="#b25">[25]</ref> they enable anyone to recognize the species of a particular plant. The main goal of such apps has been to educate users about plants. It seems difficult to collect a complete and homogeneous tree inventory with them due to the fact that each tree must be visited by at least one person.</p><p>Recent work tries to establish correspondence between street-view data and oblique aerial imagery with a learned matching function <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref>. We are not aware of any prior work that combines aerial and street view images as different cues that can be used with modern learning-based detection and fine-grained recognition algorithms. We also do not know of any work that recognizes more than a handful of species without dedicated sensor data like hyper-spectral images or high-density LiDAR.</p><p>Unlike previous studies we approach the detection and classification of urban objects, trees in this paper, by using exclusively images that are publicly available. We find that the two points of view, aerial and street-view, complement each other well. The trick is to do late fusion of category labels: the outputs of state-of-the-art CNN detectors and clas- sifiers are combined in a probabilistic framework. In this way, one circumvents the difficult problem of establishing sparse (let alone dense) correspondence across very wide (â 90 â¢ ) baselines and scale differences. Note also that, unlike most other methods, our formulation does not require any prior segmentation into superpixels, hierarchies of adhoc rules, or pre-designed top-down tree models. In many cases it is not even necessary to annotate training data, because geo-referenced tree inventories already exist in many regions of the worldi.e., our training data was generated by downloading publicly available resources from the web.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Online map data</head><p>As a data source we use publicly available images of Google maps, including aerial imagery, street view imagery, and map data (see <ref type="figure">Figure 1</ref>). Given a geographic region of interest (e.g., the city of New York), we first densely download all relevant images from static URLs. For each type of image modality v (e.g., street view or aerial view), we computed the function â â² = P v (â, c) that projects a geographic latitude/longitude location â = (lat, lng) to its corresponding image location â â² = (x, y) given camera parameters c. These projection functions will provide a building block for using Google maps data with different types of computer vision algorithms in subsequent sections of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Street view images:</head><p>We can estimate geographic coordinates of an object from a single street view panorama under the assumption of known camera height and locally flat terrain. We first represent the object in Local east, north, up (ENU) coordinates with respect to the position of the camera. This means that if we position a plane tangent to the surface of the earth at lat(c), lng(c) and define a coordinate system where the x-axis points east, the y-axis points north, and the z-axis points up <ref type="figure" target="#fig_0">(Fig. 2)</ref>, then the ENU position of an object sitting on the ground at (lat, lng) is</p><formula xml:id="formula_0">(e x , e y , e z ) = R cos[lat(c)] sin[lng â lng(c)], R sin[lat â lat(c)], âh (1)</formula><p>where h is the height that the Google street view camera is mounted above the ground and R is the radius of the earth. The object is then at a distance z = e 2</p><p>x + e 2 y from the camera (measured on the ground plane). It sits at a clockwise angle of arctan(e x , e y ) from north, and a tilt of arctan(âh, z) <ref type="figure" target="#fig_0">(Fig. 2)</ref>. The ENU coordinate can be converted into cylindrical coordinates using the camera's heading to obtain image coordinates â â² = (x, y). The resulting image projection (x, y) = P sv (lat, lng, c) is computed as</p><formula xml:id="formula_1">x = (Ï + arctan(e x , e y ) â yaw(c)) W/2Ï y = (Ï/2 â arctan(âh, z)) H/Ï (2)</formula><p>where the panorama image is W Ã H pixels.</p><p>Aerial images: Due to space limitations, we include the form of â = P â1 v (â â² , c) and further information about geometric transformations in the supplementary results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">det2geo: Multi-view detection</head><p>The goal of det2geo is to process image sets and map layers downloaded from Google maps and automatically generate a catalog of all geographic locations of an object of interest. We introduce methods to augment state-of-the-art learning based object detection systems with multi view geometry and maps such as the location of roads.</p><p>A minor complication to using conventional object detection methods is that our target outputs and training annotations are geographic coordinates (latitude/longitude)-they are points rather than bounding boxes. A simple solution is to interpret boxes as regions of interest for feature extraction rather than as physical bounding boxes around an object. At train time we can convert geographic coordinates to pixel coordinates using the appropriate projection function P v (â, c) and create boxes with size inversely proportional to the distance of the object to the camera. At test time, we can convert the pixel location of the center of a bounding box back to geographic coordinates using P â1 v (â â² , c). Doing so makes it possible to train single-image detectors. In the next section, we show how to build a multi-view detector that combines multiple images and other sources of information probabilistically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Multi-view detection</head><p>As a base detection system, we use the publicly available implementation of Faster R-CNN <ref type="bibr" target="#b38">[38]</ref>. Faster R-CNN is a recent state-of-the-art method that significantly improves the speed of R-CNN <ref type="bibr" target="#b12">[13]</ref> and Fast R-CNN <ref type="bibr" target="#b11">[12]</ref>, all of which are based on convolutional neural networks (CNNs) and region proposals.  In our approach, we allow promising detection regions in one view to augment the region proposal set of the other views. The multiview detection score of a geographic coordinate is obtained by combining the corresponding detection scores in each view, and thresholding and non-maximal suppression occurs over regions represented in geographic coordinates rather than in pixel coordinates of any one view. We use the following procedure:</p><p>1. For each view v, generate region proposals R v by running a detector with a liberal detection threshold 2. Compute a combined multi view region proposal set R by taking the union of all view proposals R v after warping them into geographic coordinates R =</p><formula xml:id="formula_2">{P â1 v (â vj , c v )} |Rv| j=1</formula><p>, where â vj is the pixel location of the jth region center.</p><p>3. For each view v, evaluate detection scores on the combined multi view proposal set R after converting each region â k into image coordinates P v (â k , c).</p><p>4. Compute a combined detection score by adding together the detection scores of each view. Apply a detection threshold Ï 2 and suppress overlapping regions to obtain geographic detections. <ref type="figure" target="#fig_1">Figure 3</ref> shows a visualization of the approach. It is designed to be able to always combine information from each view, even when the region proposal or detection system fails in a subset of the views. Additionally, we attempt to minimize computation time by keeping the combined proposal set R as small as possible. Note that although we use Faster R-CNN, our method can work with any major object detection algorithm, including methods that use region proposals or methods that compute detection scores in sliding window fashion. A limitation though is that simply adding the detection scores together is suboptimal when some views are more reliable sources of information than others. In the next section, we describe a procedure to learn how to combine them probabilistically and also include other sources of information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Probabilistic model</head><p>Let T be a candidate set of object detections, where each t i â T represents an object location in geographic coordinates. Let lat(t) and lng(t) be shorthand for the latitude and longitude of t. Our goal is to choose the best set of objects T that factors in different sources of information, including aerial view imagery, street view imagery, semantic map data (e.g., the location of roads), and spatial context of neighboring objects. We combine these sources of information using a conditional random field:</p><formula xml:id="formula_3">log p(T ) = tâT Î(t, T ; Î±) spatial context + â¦(t, mv(t); Î²) map image + Î¨(t, av(t); Î³) aerial view image + sâsv(t) Î¦(t, s; Î´) street view images â Z<label>(3)</label></formula><p>where Î(), â¦(), Î¨(), and Î¦() are potential functions with learned parameters Î±, Î², Î´, Î³, av(t) and mv(t) are the IDs of aerial and map view images that contain object t, sv(t) is the ID of the set of street view images where t is visible (with associated meta data defining the camera position), and Z is a normalization constant. We define these terms below: Aerial View Potential: We define the aerial view potential to be the detection score evaluated at the appropriate region:</p><p>Î¨(t, av(t); Î³) = CNN (X(av(t)), P av (t); Î³)</p><p>where X(av(t)) is the aerial image, Î³ encodes the weights of the aerial view detection CNN, and P av (t) transforms between pixel location and geographic coordinates.See supplementary material for details. Street View Potential: Similarly, we define the potential function for a street view image s â sv(t) as Î¦(t, s; Î´) = CNN (X(s), P sv (t, c(s)); Î´)</p><p>where X(s) is a street view image, Î´ encodes the weights of the street view detection CNN, and P sv (t, c) is defined in Equation 2. Note that each object t might be visible in multiple street view images. We tried two approaches for defining the set sv(t) of relevant images: 1) We select a single street view image that is closest to the proposed object location t, or 2) We select all images that were taken within a prespecified distance threshold Ï sv between t and the camera location c(s). We empirically found the first approach to give better results, probably due to lower likelihood of occlusion and effect of camera heading error 2 . Spatial Context Potential: The purpose of the spatial context potential is to impose a prior on the distance between neighboring objects. For example, two trees cannot physically grow in the same location and are unlikely to be planted in very close proximity. At the same time, neighboring trees are often planted in regularly spaced intervals parallel to the road. Let d s (t, T ) = min t â² âT tât â² 2 be the distance to the closest neighboring object, and Q s (d s (t, T )) be a quantized version of d s . That is, Q s () is a vector in which each element is 1 if d s lies within a given distance range and 0 otherwise. We then learn a vector of weights Î± (see <ref type="figure">Fig.8</ref> in supplementary material), where each element Î± i can be interpreted as the likelihood that the closest object is within the appropriate distance range. Thus</p><formula xml:id="formula_6">Î(t, T ; Î±) = Î± Â· Q s (d s (t, T ))<label>(6)</label></formula><p>In our experiments, we compare this to a term that forbids neighboring objects to be closer than Ï nms</p><formula xml:id="formula_7">Î nms (t, T ; Î±) = ââ if d s (t, T ) &lt; Ï nms 0 otherwise<label>(7)</label></formula><p>This is analagous to a traditional non-maximal suppression term that suppresses overlapping bounding boxes. The learned approach has the advantage that it can learn to softly penalize objects from being too close. It can also learn that it is unlikely for an object such as a tree to be completely isolated from other trees. Map Potential: Google maps offer additional semantic information that may provide useful priors for detection. Intuitively, an object such as a tree cannot lie in the middle of the road. Moreover, trees are often planted alongside roads at a fixed distance. We download Google maps images and use simple image processing techniqes to compute the distance from each pixel to the nearest road <ref type="bibr" target="#b2">3</ref> . Let d m (t) be the distance in meters between an object t and the closest road. Similar to the spatial context term, we quantize this distance into geometrically increasing intervals and learn a prior Î² i (see <ref type="figure">Fig.8</ref> in supplementary material) on each interval:</p><formula xml:id="formula_8">â¦(t, mv(t); Î²) = Î² Â· Q m (d m (t))<label>(8)</label></formula><p>Inference: At test time, our goal is to choose a catalog of object detections T * = arg max T log(p(T )) that maximizes <ref type="bibr">Equation 3</ref>. This is in general a challenging problem; however, a widely used procedure is to iteratively add new detections using a greedy algorithm. That is, we begin with T = â, and iteratively append a new detection</p><formula xml:id="formula_9">t â² = arg max t log(p(T âª t))<label>(9)</label></formula><p>stopping when no new object can be found that increases log p(T ). This is efficient to compute because we can precompute the combined detection score â¦(t, mv(t); Î²) + Î¨(t, av(t); Î³) + sâsv(t) Î¦(t, s; Î´) for each location t in our combined multi view region proposal set R, then update our computation of the spatial term Î(t, T ; Î±) every time we add a new detection t â² . This greedy procedure is a very commonly used procedure in object detection and is a well known probabilistic interpretation of non-maximal suppression that has known approximation guarantees for some choices of Î() <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b43">43]</ref>. Learning: At training time, our goal is to learn parameters Î± * , Î² * , Î´ * , Î³ * = arg max Î±,Î²,Î´,Î³ log(p(T )) that maximizes <ref type="bibr">Equation 3</ref>, where T is the set of objects in our training set.</p><p>For practical reasons, we use piecewise training, which is known to work well for these types of CRFs <ref type="bibr" target="#b41">[41]</ref> and offers convenience in terms of optimization and modularity. Here, we subdivide the training set into a validation set D v and training set D t , then learn each parameter vector Î±, Î², Î´, Î³ separately over their respective potential terms. Next, we learn a weighted combination of each potential term on the validation set. For details see the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">geo2cat: Fine-grained classification</head><p>geo2cat aims to predict the fine-grained category of an object that has already been geolocated (e.g., using det2geo). We propose to apply state-of-the-art CNNs, and combine their outputs on aerial and street view imagery.</p><p>The method first obtains cropped versions of each object at different zoom levels using the appropriate projection function P v (â, c) defined in Section 3. Each cropped region is then fed through a CNN feature extractor. After testing several models we found that the GoogLeNet CNN model <ref type="bibr" target="#b44">[44]</ref> offered the best compromise in terms of recognition performance, run-time, and memory consumption. We train one CNN model per viewpoint and zoom level using a log-logistic loss via stochastic gradient descent. We finetune the weights of each model after initializing them to weights pre-trained on ImageNet <ref type="bibr" target="#b40">[40]</ref>. The learning rate is initially set to 0.001. After every ten epochs, it is decreased by a factor ten for 30 epochs in total. We then discard the top, fully-connected layer per model and extract features from the pool/7 Ã 7 layer of the GoogLeNet model. The resulting feature vector per model has 1024 dimensions. We concatenate all feature vectors of all models (views and zooms) per tree to a single feature vector 4 which we then use to train a standard linear SVM 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">The Pasadena Urban Trees Dataset</head><p>We apply det2geo and geo2cat to a new dataset, motivated by a collaboration with Opentreemap-a large-scale project to build and maintain a geographic catalog of tree species. We collected the dataset by downloading publicly available aerial and street view images from Google Maps at city-scale. As test area, we chose Pasadena because 1) an up-to-date tree inventory (as of 2013) with annotated species is publicly available and 2) image data are as of October 2014 (street view) and March 2015 (aerial images). The Pasadena tree inventory is publicly available as a kmlfile that contains rich information for â 80,000 trees on public ground. We estimate that these constitute â 20% of all trees in Pasadena. <ref type="figure" target="#fig_2">Figure 4 (top)</ref> shows an overview of all trees in the Pasadena city center that were used for experiments. Each tree is mapped with its geo-location, street address, species, and trunk diameter. Detection data set: We densely downloaded all street view, aerial, and map images for Pasadena. This included 1) 46,321 street view panorama images of size 1664 Ã 832 px and their associated camera locations and meta data, 2) 28,678 aerial view images of size 256 Ã 256 px (at â 0.15 m resolution), and 3) 28,678 map view images of size 256 Ã 256 px. We converted the geographic locations of the 80, 000 Pasadena trees to the appropriate pixel locations in each image. Since the inventory does not include trees on private land, we densely labeled all tree locations in a subset of 1,000 aerial view images and 1,000 street view images using Mechanical Turk, which we used to train object detectors. Species recognition data set: We downloaded four dif- <ref type="bibr" target="#b3">4</ref> to form a vector of 4096 dimensions in our case with one aerial image and street views at three different zoom levels per tree. A (probably more elegant) alternative to simple feature concatenation would be to explicitly encode the three panorama zoom levels in a single CNN architecture. <ref type="bibr" target="#b4">5</ref> experiments with Neural Nets decrease performance by 2 percent ferent images per tree from Google Maps around the appropriate geographic position for 18 different species (see <ref type="figure" target="#fig_3">Fig. 5</ref>, 5205 trees in total) that have between 100 and 600 instances: one aerial image and street view images at three different zoom levels 40, 80, and 110 ( <ref type="figure" target="#fig_2">Fig. 4 (bottom)</ref>). While automated downloads facilitated data collection for thousands of trees within a few hours, the images are subject to some noise (e.g., a tree may be occluded by a truck, or it has been removed after the inventory date). Manual evaluation of a dataset subset showed that &lt; 5% of images were affected. We did not manually filter data, so as to keep the processing pipeline fully automatic. Rather, we rely on the learning algorithm to cope with label noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Experiments</head><p>We evaluate the proposed approach in terms of detection accuracy and species classification accuracy separately on the dataset described in Section 6. We split the dataset into 16 geographically separated rectangular regions (9 for training, 6 for testing, and 1 for validation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">det2geo: Tree detection</head><p>Evaluation: We evaluated detection performance in terms of average precision (precision averaged over all levels of recall), which is the standard metric used in the VOC Pascal Detection Challenge <ref type="bibr" target="#b9">[10]</ref>. Here, candidate trees were ranked by their score combining aerial, streetview, and map imagery and spatial context (the 4 terms in Eq. 3 for a given tree t) and enumerated in order <ref type="bibr" target="#b5">6</ref>   dict the latitude and longitude of trees rather than bounding boxes, predictions within a threshold of 4 meters from ground truth were considered to be valid matches. Note that the typical difference of our system from ground truth is 1 â 2 m, equal to ground truth accuracy 7 . We plot our results in <ref type="figure" target="#fig_5">Figure 6</ref> and summarize our results below: Significant improvement combining multiple views: Our full model obtained .706 mAP, a significant gain over the .42 mAP achieved from a pure aerial view detector using the same Faster R-CNN detection system <ref type="bibr" target="#b38">[38]</ref>. This baseline is perhaps the most straightforward way to apply a current state-of-the-art detector to Google maps imagery without developing a way of combining multiple views. A pure street view detector achieves better performance (.581 mAP). This is a stronger baseline because it requires using geometry to combine multiple street view images-we implemented it by omitting non-streetview terms from Eq. 3 and applying non-maxima suppression (Eq. 7). We found that many penalized detections were in fact trees located on private land, which weren't included in our inventory <ref type="bibr" target="#b7">8</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">geo2cat: Tree species classification</head><p>First, we compare single view recognition (aerial or street view) to the combination of all four images per tree. If classifying tree species based on only one image per tree (instead of three zoom levels and one aerial view), we achieve â .66 average precision for aerial images, and â .70 per zoom level 40, 80, and 110. Combining features of all four models per tree, we see a significantly higher performance of .80 average precision and .79 average recall over all species. According to collaborators at TreePeople 9 , our recognition performance is comparable to that achievable using citizen scientists, due to the significant amount of expertise required.</p><p>Close inspection of per species results <ref type="figure" target="#fig_5">(Fig. 6</ref>) reveals that not all tree species can be recognized equally well. Shamel Ashes (SA) are the most error prone (.46 precision, .35 recall) whereas American Sweetgums are recognized almost perfectly (1.0 precision, .93 recall). Note that the number of occurrences per tree is quite unevenly distributed (only 113 Yew Pines vs. 593 Canary Island Date Palms). Generally, strongly varying lighting conditions (cf. <ref type="figure" target="#fig_3">Fig. 5</ref>), partial occlusions, and differing size, shape, and general appearance per species make fine-grained classification challenging. We also observe that some species tend to be located in a few larger clusters in very different contexts (e.g., Shamel Ashes), while others are evenly distributed across the city. This makes generalization challenging.</p><p>We visualize the confusion matrix of tree species recognition in <ref type="figure">Fig. 7</ref>. We see that most tree species are recognized well (dominant, most orange values on main diagonal). We can also observe that there is hardly any dominant confusion <ref type="bibr" target="#b8">9</ref> www.treepeople.org  between two particular species for any possible combination. For example, out of all tree species Shamel Ash (SA) has highest confusion with other species, but confusion is more or less evenly distributed across alternate species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>The picture of all that may be visible outdoors in the populated world is sampled with increasing temporal and spatial resolution. This 'World-Wide Light Field (WWLF)' allows machines to discover, catalogue and monitor public objects in the real 3D world. We built and tested two primitives that help automate the exploration of what is visible in the WWLF: geo2cat given GPS coordinates it computes <ref type="bibr">Figure 7</ref>. Confusion matrix of tree species recognition results. More orange indicates higher values (see <ref type="figure" target="#fig_5">Fig. 6</ref> for abbreviations) the fine-grained class of the object at that location, while det2geo produces the list of GPS coordinates of objects that belong to a chosen category.</p><p>We have tested our algorithms on a specific benchmark: detecting trees of the urban forest and classifying their species. geo2cat distinguishes 18 different species using state-of-the-art CNNs on RGB aerial and street view images at multiple zooms. det2geo finds the locations of urban trees (on public land), with the help of probabilistic CRF-based fusion on CNN detector scores across views.</p><p>Our experiments suggest that publicly available imagery supports both accurate detection, and accurate fine-grained classification of publicly visible objects. This is good news because cataloguing of publicly visible objects is currently carried out with specialized imagery (LiDAR, hyperspectral) that is collected ad-hoc, and/or with in-person visits.</p><p>Our next goal is to explore how well our algorithms scale to planet-wide exploration. We are planning to engage in a US-wide tree catalog of the urban forest, which is highly valuable for city planners. We will also attempt to estimate further parameters like the trunk diameter of trees. Another interesting challenge will be to combine automated methods, such as geo2cat and det2geo with crowdsourcing to fill in missing objects. To this end we will explore how to engage citizen scientists to carry out image-based and inperson verification of the data.</p><p>Our method is not limited to trees, and we expect it to generalize to other types of urban objects, for example, lamp posts, mailboxes, traffic lights. And it should become even more relevant as more city-scale imagery becomes available (e.g., videos from driver assistance systems).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>(a) Geometry of the street view acquisition system. The Google car sits on the surface of the earth at coordinate (lat,lng). A tree is represented in ENU coordinates formed by a plane tangent to the earth at the location of the camera. The heading of the car rotates this point to determine the tree's location in a panorama image. (b) An example of a 360 â¢ street view panorama image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Multi View Detection: We begin with an input region (left image), where red dots show available street view locations. Per view detectors are run in each image (top middle), and converted to a common geographic coordinate system. The combined proposals are converted back into each view (bottom middle), such that we can compute detection scores with known alignment between each view. Multi-view scores are combined with semantic map data and spatial reasoning to generate combined detctions (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Top: Overview of the Pasadena 2013 public tree inventory data set. Bottom: Aerial image and street view panorama examples from Google maps at zoom levels 40, 80, and 110.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Examples of the 18 species for GPS2Cat and their number of occurrences (5205 trees in total, see abbreviations inFig. 6).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Top: Comparison of the full tree detection model to single view aerial and street view detectors and lesioned models. center, bottom: Tree species recognition results left to right: American Sweetgum (AS), Bottle Tree (BT), Brisbane Box (BB), Brush Cherry (BC), California Fan Palm (CF), Canary Island Date Palm (CI), Carob (CA), Carrotwood (CW), Chinese Elm (CE), Date Palm (DP), Fern Pine (FP), Guadalupe Palm (GP), Incense Cedar (IC), Indian Laurel Fig (IF), Italian Cypress (IP), Jacaranda (JA), Shamel Ash (SA), Yew Pine (YP).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Multi View Proposal ScoresSingle View Detections / Proposals Input Region Aerial</figDesc><table>Aerial 

Streetview 
15 

Streetview 
15 

Streetview 
4 

Streetview 
4 

Combined Detections 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>. Since our goal is to pre-</figDesc><table>AS: 155 

BT: 566 
BB: 309 
BC: 313 
CF: 522 
CI: 593 
CA: 314 
CW: 305 
CE: 330 

DP: 170 
FP: 160 
GP: 129 
IC: 140 
IF: 335 
IP: 270 
JA: 315 
SA: 166 
YP: 113 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>â .462 mAP) or aerial images (.706 â .619 mAP). Dropping the map term results in a smaller drop in performance (.706 â .667 mAP). Replacing the learned spatial context potential with non-maximal suppression results in only a small drop (.706 â .69 mAP). For each lesioned version of the system we re-learn an ap-propriate weight for each potential function on the validation set. The method "No CRF Learning" shows results if we use the full model but omitted learning these scaling factors and set them all to 1 (results in a .706 â .66 mAP drop). Additional analysis, visualizations, and qualitative examples are included in the supplementary material.</figDesc><table>. 
Thus performance in practice was better than what .706 
mAP would indicate. 
Each component of the model is useful: To validate our 
model, we performed additional lesion studies. In Fig-
ure 6 top, "No Aerial", "No Streetview", and "No Map" 
remove the applicable potential term from the full model in 
Eq. 3. "No Spatial" replaces the learned spatial context term 
(Eq. 8) with a more conventional non-maximal suppression 
term (Eq. 7). We see the biggest loss in performance if we 
drop street view images (.706 </table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://www.opentreemap.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Future extensions could better exploit multiple views by inversely weighting their influence with distance from the object, for example.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Roads are distinguishable as pixels with value 255. Morphological opening removes other small symbols that also have value 255. Morphological closing removes text written on roads. A distance transform computes per pixel distances to road.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">A current limitation of the system is that it does not detect objects at the wrap-around of street view panoramas, which could be fixed by padding images from the other side of the panorama.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">We are currently initiating a field campaign with high-accuracy dGPS to quantify these errors.<ref type="bibr" target="#b7">8</ref> This is a limitation of the current ground truth and obtaining public/private land boundaries is an important next step.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Building rome in a day</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="105" to="112" />
			<date type="published" when="2011" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Building Rome in a Day</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Google street view: Capturing the world at street level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dulong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Filip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Frueh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lafon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ogale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weaver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="32" to="38" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Branch and bound strategies for non-maximal suppression in object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blaschko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Energy Minimization Methods in Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Classifying individual tree species under leafoff and leaf-on conditions using airborne lidar. ISPRS Journal of Photogrammetry and Remote Sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brandtberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="325" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hyperspectral discrimination of tropical rain forest tree species at leaf to crown scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing of Environment</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="375" to="398" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Inferring social ties from geographic coincidences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Backstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cosley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">52</biblScope>
			<biblScope unit="page" from="22436" to="22441" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mapping the world&apos;s photos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Backstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th international conference on World wide web</title>
		<meeting>the 18th international conference on World wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="761" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Leaf shape based plant species recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="883" to="893" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Building Rome on a Cloudless Day</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fite-Georgel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gallup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raguram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Jen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Clipp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="368" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Pl@ntNet mobile 2014: Android port and new features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>GoÃ«au</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Affouard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>BakiÄ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dufour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vignau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>BarthÃ©lÃ©my</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Multimedia Retrieval</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>GoÃ«au</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>BakiÄ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>CarrÃ©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>BarthÃ©lÃ©my</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-F</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pl@ntNet mobile app</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>DuchÃ©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>PÃ©ronnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Multimedia</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Shape-based Recognition of 3D Point Clouds in Urban Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Golovinskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improving public transit accessibility for blind riders by crowdsourcing bus stop landmark locations with google street view: An extended analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Azenkot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pannella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Minckler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Froehlich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Accessible Computing (TACCESS)</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Combining crowdsourcing and google street view to identify street-level accessibility problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Froehlich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="631" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">im2GPS: estimating geographic information from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Scene completion using millions of photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An SVM Classification of Tree Species Radiometric Signatures Based on the Leica ADS40 Sensor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Heikkinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Korpela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tokola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Honkavaara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Parkkinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4539" to="4551" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Investigating multiple data sources for tree species classification in temperate forest and use for single tree delineation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heinzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Applied Earth Observation and Geoinformation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="101" to="110" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Using google street view to audit the built environment: inter-rater reliability results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schootman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Behavioral Medicine</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="112" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Variation and directional anisotropy of reflectance at the crown scale -implications for tree species classification in digital aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Korpela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Heikkinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Honkavaara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tokola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing of Environment</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="2062" to="2074" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Leafsnap: A computer vision system for automatic plant species identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kress</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Soares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="502" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Geometric Feature Extraction by a Multi-Marked Point Process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lafarge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gimel&amp;apos;farb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Descombes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1597" to="1609" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automated tree recognition in old growth conifer stands with high resolution digital imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Leckie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Gougeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tinis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">N</forename><surname>Burnett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Paradine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing of Environment</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="311" to="326" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Proximate sensing: Inferring what-is-where from georeferenced photo collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Newsam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2955" to="2962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Landmark classification in large-scale image collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th international conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1957" to="1964" />
		</imprint>
	</monogr>
	<note>Computer vision</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Location Recognition using Prioritized Feature Matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Worldwide Pose Estimation Using 3D Point Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning deep representations for Ground-to-Aerial geolocalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Cross-View Image Geolocalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Mav urban localization from google street view data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Majdik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Albers-Schoenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Scaramuzza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">telligent Robots and Systems (IROS), 2013 IEEE/RSJ International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3979" to="3986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Scene Chronology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Matzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Combining Leaf Salient Points and Leaf Contour Descriptions for Plant Species Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mouine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Verroust-Blondet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Image Analysis and Recognition</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="205" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A comparative analysis of high spatial resolution IKONOS and WorldView-2 imagery for mapping urban tree species</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Landry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing of Environment</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="516" to="533" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Differentiating plant species within and across diverse ecosystems with imaging spectroscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Dennison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alonzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing of Environment</title>
		<imprint>
			<biblScope unit="volume">167</biblScope>
			<biblScope unit="page" from="135" to="151" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Imagenet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="1" to="42" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Textonboost: Joint appearance, shape and context modeling for multi-class object recognition and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2006</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Detection and 3d reconstruction of traffic signs from multiple view color images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Soheilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Paparoditis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Vallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Journal of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Submodboxes: Near-optimal search for a set of diverse object proposals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">From google street view to 3d city models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Havlena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer vision workshops (ICCV Workshops)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2188" to="2195" />
		</imprint>
	</monogr>
	<note>IEEE 12th international conference on</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Observing the natural world with Flickr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Korayem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision Workshop</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="452" to="459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Semi-automatic classification of tree species in different forest ecosystems by spectral and geometric variables derived from Airborne Digital Sensor (ADS40) and RC30 data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Waser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ginzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kuechler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Baltsavias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hurni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing of Environment</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="76" to="85" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Tree detection from aerial imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Praun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM GIS&apos;09</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Tree species classification and estimation of stem volume and DBH based on single tree extraction by exploiting airborne full-waveform LiDAR data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krzystek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heurich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing of Environment</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="368" to="380" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
