<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ambiguity Helps: Classification with Disagreements in Crowdsourced Annotations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktoriia</forename><surname>Sharmanska ⋆</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">SMiLe CLiNiC</orgName>
								<orgName type="institution">University of Sussex</orgName>
								<address>
									<settlement>Brighton</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hernández-Lobato</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universidad Autónoma de Madrid</orgName>
								<address>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Miguel Hernández-Lobato</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Harvard University</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>Massachusetts, US</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Novi</forename><surname>Quadrianto</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">SMiLe CLiNiC</orgName>
								<orgName type="institution">University of Sussex</orgName>
								<address>
									<settlement>Brighton</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Ambiguity Helps: Classification with Disagreements in Crowdsourced Annotations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Imagine we show an image to a person and ask her/him to decide whether the scene in the image is warm or not warm, and whether it is easy or not to spot a squirrel in the image. For exactly the same image, the answers to those questions are likely to differ from person to person. This is because the task is inherently ambiguous. Such an ambiguous, therefore challenging, task is pushing the boundary of computer vision in showing what can and can not be learned from visual data. Crowdsourcing has been invaluable for collecting annotations. This is particularly so for a task that goes beyond a clear-cut dichotomy as multiple human judgments per image are needed to reach a consensus. This paper makes conceptual and technical contributions. On the conceptual side, we define disagreements among annotators as privileged information about the data instance. On the technical side, we propose a framework to incorporate annotation disagreements into the classifiers. The proposed framework is simple, relatively fast, and outperforms classifiers that do not take into account the disagreements, especially if tested on high confidence annotations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>There exists an anecdote in the computer vision community that every graduate student has to annotate at least one dataset during the graduate school life. With a rise of crowdsourcing platforms, such as Amazon Mechanical Turk (MTurk), Microworkers, and CrowdFlower, it becomes possible instead to crowdsource annotations from people everywhere in the world. One might expect that the graduate life becomes more of an easy and manageable ride. However, the ambitions and visions in the community evolve together with the possibility afforded by the crowdsourcing platforms. With MTurk, now it becomes possible to collect annotations for large datasets such as ImageNet <ref type="bibr" target="#b25">[26]</ref>, TinyImages <ref type="bibr" target="#b30">[31]</ref>, COCO <ref type="bibr" target="#b13">[14]</ref>, and Places <ref type="bibr" target="#b37">[38]</ref>. More-over, it becomes prevalent to collect task-specific datasets, for example for studying the attributes and their strength <ref type="bibr" target="#b19">[20]</ref> and for determining the easiness or hardness of a particular classification task <ref type="bibr" target="#b21">[22]</ref>. Those task-specific datasets often require annotations that are more ambiguous than typical object annotations 'present' or 'not present'.</p><p>Working with a crowdsourcing platform has its own positive and negative aspects. On the positive side, we could mass collect annotations within a short period of time. The annotations come from people with a diverse background, therefore to some degree it reflects on an unbiased process of data collection. On the other hand, this process requires a tight control over the quality of annotations. It is common that we get noisy or even random annotations by the inexperienced and distrusted MTurk annotators. Escaping from a task to annotate a dataset ourselves, we are confronted with a task to master a whole collection of tricks on the quality control in a crowdsourcing scenario <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b0">1]</ref>. This paper focuses on: a) the case that the quality control has been successfully applied and the annotations are collected from those highly reputed annotators, and b) the annotation task goes beyond a clear-cut dichotomy such as, for example, a squirrel is 'present' or 'not present' in the given image. In the ambiguous task, such as determining 'how easy' it is to spot a squirrel in an image, or deciding whether the scene is 'warm' or 'not warm' from the image, the necessity of obtaining multiple human judgments for each image data grows. A confidence in the label annotations, ranging from a simple percentage agreement to the kappa statistic, is then computed from the multiple annotations at each data point. For sufficiently high confidence annotations, a majority voting scheme is then widely adopted as the ground-truth label <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>It is now worth highlighting the following two observations regarding disagreements in multiple annotations. The first is that the removal of disputed cases results in a reduced size of datasets; those datasets are typically already moderate in size. The second is that the notion of a true groundtruth label might not be available, at least for a subset of the data, given that the task is ambiguous and the annotations are all human judgments. We propose to incorporate annotation disagreements into the learning process of a classifier. Our method will utilize all data points with varying degree of confidence and will follow the commonly used rules to define a ground-truth label, for example, using maximum voting. We propose a classifier which uses the confidence in the label annotations to determine the level of influence of each data point in the training process. Data points with high level of disagreements will have less influence during training hopefully improving the performance. We instantiate this classifier in the form of Support Vector Classifier as well as Gaussian Process Classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The problem of learning a classifier from data points annotated with multiple noisy labels per instance dates back to at least the work of <ref type="bibr" target="#b28">[29]</ref> in 1990s. The work adopts the latent variable modeling of <ref type="bibr" target="#b2">[3]</ref>. Fast forward to 2008 and beyond, the needs for learning with multiple noisy annotations are further exemplified by the advent of crowdsourcing platforms <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b14">15]</ref>. Prior work ranges from a simple majority voting where all annotators are weighted equally <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26]</ref> to a weighted voting by quantifying the expertise of the annotators <ref type="bibr" target="#b7">[8]</ref>. Work that actively selects both the informative instances and the high-quality annotators also exists <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b14">15]</ref>. However, the expertise of the annotators is not readily quantifiable and the notion of true label might not exist. In this paper, we focus on data annotated by highly reputed annotators, therefore they should have an equal weight, and we will not attempt to infer a true ground-truth label. Moreover, we are not in the active setting where we can control what and how much labeled data to be generated by annotators. Related to this, we are not trying to redefine a new task that aims to disambiguate the ambiguous task (e.g. <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b10">11]</ref>). Instead, we are in a passive mode where we are given data sources consisting of data instances, their associated labels, and an additional information per data instance capturing the level of label disagreement, for example, in the forms of average annotator response for that label. This additional information could be readily available in most vision datasets.</p><p>There are two general perspectives in addressing the learning model of classification: probabilistic and nonprobabilistic. We will focus on models that use the maxmargin principle (SVM-based) as a representative of nonprobabilistic approach and models that exploit Gaussian Process framework (GP-based) as a prototypical example of probabilistic method. Probabilistic methods output a probability distribution over labels, in contrast to nonprobabilistic methods that only output the most likely label for a particular data point. Consequently, we would expect that the GP method will be better in capturing the model uncertainty over labels and can inherently steer this model uncertainty based on the confidence in label annotations. In the next sections, we will first continue our description of related work discussing how to incorporate disagreements in label annotations into the SVM-based models and then we will describe our proposed GP-based approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Instillation of Disagreements into Classifiers</head><p>We will now restrict our attention to the typical computer vision dataset: images and their annotations including the class labels based on, for example, the majority voting scheme over MTurk responses and the agreement scores among annotators defined as confidence.</p><p>3.1. SVM-based methods: state-of-the-art overview Perhaps, the most frequently used classification setup is an SVM model trained on crowdsourced data with labels defined by majority voting among annotators. This means all data points are equally important without considering the size of the majority. We can instead use this majority size, i.e. the disagreement level in the label annotation, to distinguish between easy and difficult data points. One approach will be to instill this additional information as an upper bound to the hinge loss function in the SVM, resulting in a state-of-the-art method called SVM+ <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b31">32]</ref>. First, let us define the learning setup. We assume that there are some image data in the form of a matrix X = (x 1 , . . . , x n ) T of observed features and a vector of associated class labels y = (y 1 , . . . , y n ) T , y n ∈ {−1, 1}. However, besides X and y, there is also another set of attributes associated with each training data point. Namely, the crowdsourcing confidence in label annotations X conf = (x conf 1 , . . . , x conf n ) T . The goal of learning is to infer a classifier f that will output a label y new for an un-seen data point x new , given the labeled training data plus the crowdsourcing confidence level for each data point. It is important to note that f cannot use X conf as the input argument because it will not be available at test time. This label confidence is privileged information <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b32">33]</ref> (available during training but not at test time).</p><p>The method SVM+ tries to predict the slack variables ξ n of the data using X conf . Intuitively, we try to predict the difficulty of each data point based on the label disagreement among annotators for that particular instance, thereby creating a data dependent upper bound on the hinge loss. SVM+ sets ξ n = w conf , x conf n +b conf in the SVM, where w conf and b conf are some parameters. The SVM+ objective function is:</p><formula xml:id="formula_0">minimize w,w conf b,b conf w 2 +α w conf 2 + β N n=1 w conf , x conf n + b conf</formula><p>subject to, for all n = 1, . . . , N ; w conf , x conf</p><formula xml:id="formula_1">n + b conf ≥ 0 1 − y n [ w, x n + b] ≤ w conf , x conf n + b conf .<label>(1)</label></formula><p>The scalar parameters α and β are the trade-off parameters. The model in (1) assumes a linear functional form for f and ξs. This can be relaxed via the kernel trick <ref type="bibr" target="#b33">[34]</ref>. Gaussian kernels are often used in the X and X conf domains, but with different bandwidths. Theoretically, SVM+ exploits that if one had access to the optimal slack variables, the convergence to the Bayes' error would be faster than the standard SVM, i.e., O(1/n) convergence versus O(1/ √ n) <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">GP-based methods: Our proposed GPC with annotation disagreements</head><p>In a probabilistic approach to binary classification, the goal is to model probabilities of a data point x n belonging to one of two classes. These probabilities must lie in the interval [0, 1], however, a Gaussian process defines a probability over real-valued functions. GPC model turns the output of a Gaussian process into a class probability using a non-linear activation function.</p><p>GPC: Consider that the class label y n ∈ {−1, 1} of x n is generated as y n = sign(f (x n )), where f (·) is a latent function and sign(0) = 1. For GPC, a zero-mean Gaussian process prior is assumed for f <ref type="bibr" target="#b22">[23]</ref>. To model a noisy class label generation process, the class membership probability can be written as p(y n = 1|x n , ǫ n , f ) = Θ([f (x n ) + ǫ n ]) with a zero-mean and σ 2 -variance Gaussian noise ǫ n . We have used Θ(·) to denote the Heaviside step function. In this paper, we will use this explicit noise representation 1 . Given N training data points, the latent function for those training points can be written as f = (f (x 1 ), . . . , f (x N )) T . Invoking the Gaussian marginalization property, the prior on f will then simply be an N -variate Gaussian distribution i.e., p(f ) = N (f |0, C), where N (·|µ, Σ) is a multivariate Gaussian with mean µ and covariance matrix Σ. Each entry in C, C nm , is k(x n , x m ), with k(·, ·) being a covariance function. A typical covariance function is the squared exponential k(x n , x m ) = θ exp(−0.5 ||xn−xm|| 2 /ℓ), where θ controls the amplitude and ℓ controls the smoothness of f .</p><p>Assuming i.i.d. noise, the likelihood of the latent function f given N data points is <ref type="bibr" target="#b1">2</ref> </p><formula xml:id="formula_2">: p(y|X, f , ǫ 1,...,N ) = = N n=1 p(y n |x n , ǫ n , f ) = N n=1 Θ(y n f (x n )) .<label>(2)</label></formula><p>We have absorbed the noise term ǫ n into the covariance function of f and re-defined C nm = k(x n , x m ) + σ 2 δ nm where δ nm = 1 if n = m and 0 otherwise and σ 2 is the variance of the additive Gaussian noise around f . Bayes' rule is then used to compute p(f |X, y) = p(y|X, f )p(f )/p(y|X), which can be used for prediction. Moreover, p(y|X) may be maximized to estimate the parameters of k(·, ·) and the noise variance σ 2 <ref type="bibr" target="#b22">[23]</ref>. Computing p(f |X, y) is intractable, and several methods can be used for approximate inference <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18]</ref> with expectation propagation (EP) as the preferred method.</p><p>GPC conf : To instill the confidence in the label annotation into the GPC framework, there exists GPC+ model <ref type="bibr" target="#b6">[7]</ref>. The GPC+ is a heteroscedastic Gaussian process classification model that considers additive Gaussian noise around f with data-dependent variance given by exp(g(x ⋆ n )), where g is another Gaussian process evaluated on the privileged information x ⋆ n . Similarly to the SVM+, the GPC+ can also be used to incorporate user agreement scores. The main drawback of the GPC+ model comes with an expensive inference procedure. This motivates us to propose a fast and scalable version of the GPC+ method. In the EP algorithm suggested in <ref type="bibr" target="#b6">[7]</ref>, the updates have no closed form expression and they must be approximated using numerical quadratures. Our proposed model admits an inference technique via EP algorithm which is quadrature-free (Section 4.2), therefore much faster than <ref type="bibr" target="#b6">[7]</ref> (see <ref type="table" target="#tab_2">Table 3</ref>) with no sacrifice in the predictive performance.</p><p>We follow the same intuition as in Section 3.1, but instead of using the additional information to upper bound the hinge loss, we will use it to modify the likelihood function. For this, we consider, besides f , another function g evaluated in the X conf domain. The following properties of g are assumed. Whenever g is negative, the data point is easy-toclassify and the likelihood in (2) is considered. Whenever g is positive, the data point is difficult-to-classify and the influence of this data point towards the likelihood function on f should be reduced. For the difficult instance, we will consider a constant likelihood of 1 /2 in f , i.e. the probability that minimizes an impurity measure for a binary label. During the EP inference, the difficult instance will have either the constant likelihood (being ignored) or a mixture of constant and step likelihood (reduced influence); refer to Section 5.1-Analysis of the confidence in annotations.</p><p>Let g = (g(x conf 1 ), . . . , g(x conf n )) T . Given y, X and X conf , the likelihood for f , g is now:</p><formula xml:id="formula_3">p(y|X, X conf , f , g) = = N n=1 p(y n |x n , x conf n , f , g) = = N n=1 Θ y n f (x n ) 1−Θ(g(x conf n )) 1 /2 Θ(g(x conf n )) . (3)</formula><p>A similar likelihood is used for multi-class classification in <ref type="bibr" target="#b5">[6]</ref>. However, the likelihood in <ref type="bibr" target="#b5">[6]</ref> does not consider correlations through the function g about the classification difficulty of each data point.</p><p>We assume independence between f and g, p(f ) = N (f |0, C f ) and p(g) = N (g|1m g , C g ), where each entry in C f and C g is equal to k(x n , x m ) + σ 2 f δ nm and k(x conf n , x conf m ) + σ 2 g δ nm respectively. We denote the set of different parameters in k(·, ·) for f and g along with noise variances as</p><formula xml:id="formula_4">Ω = {θ f , σ 2 f , ℓ f , θ g , σ 2 g , ℓ g }.</formula><p>The posterior for f and g is:</p><formula xml:id="formula_5">p(f , g|y, X, X conf ) = p(y|X, X conf , f , g)p(f )p(g) p(y|X, X conf ) ,<label>(4)</label></formula><p>where p(y|X, X conf ) can be maximized with respect to Ω to find good hyper-parameter values <ref type="bibr" target="#b22">[23]</ref>. The posterior is used to compute a predictive distribution for the label y new of a new data point x new : p(y new |y, X, X conf ,</p><formula xml:id="formula_6">x new ) = = Θ(y new f new (x new ))p(f new |f )p(f , g|y, X, X conf ) df dgdf new ,<label>(5)</label></formula><p>where p(f new |f ) is a Gaussian conditional distribution. Note that <ref type="formula" target="#formula_6">(5)</ref> is approximate because we do not consider the label confidence x conf new associated to x new . However, if we are only interested in the label being predicted, i.e., the one with the largest probability, (5) may be treated as exact.</p><p>We refer to the model specification described above as GPC conf . Nevertheless, the computation of (4) and <ref type="formula" target="#formula_6">(5)</ref> is not feasible. These quantities must be approximated in the next section using expectation propagation (EP) <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Optimization</head><p>In this section, we will review an optimization method for the SVM+ problem in (1). Moreover, we will propose a quadrature-free EP algorithm for computing the posterior (4) and the predictive (5) distributions of GPC conf .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">SVM+ optimization</head><p>The optimization problem in (1) can be written as a quadratic programming problem and in <ref type="bibr" target="#b20">[21]</ref> a sequential minimal optimization (SMO) algorithm is derived to find its solution. The SVM+ is more difficult to train than the SVM since it has more hyper-parameters to adjust, i.e., the bandwidths of the two kernels and trade-off parameters α and β. These parameters are typically tuned using a grid search guided by cross-validation, which is very expensive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">GPC conf approximate inference</head><p>We briefly describe here a quadrature-free EP algorithm for GPC conf . Full details can be found in the supplementary material. In EP each likelihood factor in p(y|X, X conf , f , g)p(f )p(g), i.e., the numerator in the r.h.s. of (4), is approximated by an un-normalized Gaussian <ref type="bibr" target="#b15">[16]</ref>. We note that p(f ) and p(g) are a Gaussian distribution, therefore no approximation is needed for those two terms. Let f n = f (x n ) and g n = g(x conf n ). Then, we can approximate the n-th likelihood term as follows: p(y n |x n , x conf n , f , g) ≡ h n (f n , g n ) ≈ ≈s n · N (f n |m n ,ṽ n ) · N (g n |μ n ,ν n ) ≡h n (f n , g n ) , wheres n ,m n ,ṽ n ,μ n andν n are to be estimated by EP, and we have assumed independence between f and g. The EP approximation of the numerator in the r.h.s. of <ref type="bibr" target="#b3">(4)</ref> </p><formula xml:id="formula_7">isq(f , g) = p(f )p(g) N n=1h n (f (x n ), g(x conf</formula><p>n )), where each h n has been replaced by the correspondingh n . After normalization,q becomes the EP posterior approximation. Namely,</p><formula xml:id="formula_8">q(f , g) =q(f , g)Z −1 q = N (f |µ f , Σ f )N (g|µ g , Σ g ),</formula><p>which is a product of two multivariate Gaussians since the Gaussian distribution is closed under the product operation <ref type="bibr" target="#b26">[27]</ref>. Furthermore, the normalization constant Z q can be readily computed. Moreover, Z q is used to approximate the denominator in the r.h.s. of (4).</p><p>EP updates until converge each factorh n . We will denoteh old n as the value of this approximate factor at current iteration. The updated value at next iteration will be denoted ash new n . First, we remove the n-th approximate factor from the q approximate posterior, that is q −n ∝ q old /h old n . The term q −n is a Gaussian because both q andh n are. Next, an updated posterior distribution q new is obtained by minimizing the Kullback-Leibler divergence between h n q −n and q new , i.e. KL( hnq −n /Z hn ||q new ) with the normalization constant Z hn . Minimizing the KL term involves moment matching between h n q −n and q new . The moments of h n q −n can be obtained from the derivatives of log Z hn with respect to the (natural) parameters of q −n <ref type="bibr" target="#b26">[27]</ref>. Let m −n , v −n , µ −n and ν −n be the mean and variance under q −n for f n and g n , respectively. Then, Z hn has a closed-form <ref type="bibr" target="#b2">3</ref> </p><formula xml:id="formula_9">, i.e., Z hn = = Φ( m −n / √ v −n )Φ( −µ −n / √ ν −n ) + Φ( µ −n / √ ν −n )/2, where Φ(·)</formula><p>is the c.d.f. of a standard Gaussian distribution. The updated n-th approximate factor is nowh new n = Z hn q new /q −n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">FITC approximation for scalable GPC conf</head><p>EP requires the inverses of C f and C g , i.e., the covariance matrices of p(f ) and p(g). This scales like O(N 3 ), which can be expensive if number of data points N is large. To reduce this cost, we employ the full independent training conditional (FITC) approximation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17]</ref>. Under the FITC, the covariance matrix C is replaced by an approximation Q given by the sum of a low-rank matrix and a diag-</p><formula xml:id="formula_10">onal matrix. Q is parameterized by M ≤ N pseudo-inputs X = (x 1 , . . . , x M ) T . That is, Q = diag(C − K) + K, with K = C xx C −1 xx C T xx , where diag(C − K)</formula><p>is a diagonal matrix with the diagonal entries of C−K and C xx is a N ×M matrix whose entries are given by k(x i , x j ), with k(·, ·) the covariance function. Similarly, for C xx . The cost of com-</p><formula xml:id="formula_11">puting Q −1 is O(N M 2 ), if M ≪ N .</formula><p>We approximate both C f and C g using the FITC approximation. For this, we use M pseudo-inputs, X and X conf , with the locations optimized by maximizing Z q .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In the first experiment, we address the task of recognizing various scene attributes whether they are 'present' or 'not present' in the images. We use a publicly available SUN Attribute dataset (SUNAttribute) <ref type="bibr" target="#b3">4</ref>  <ref type="bibr" target="#b19">[20]</ref> that comes with the averaged score over MTurk annotations of attribute being present in the image. In the second experiment, we focus on differentiating between 'easy' and 'hard' images of animal classes. We use a subset of Animals with Attributes dataset (AwA) <ref type="bibr" target="#b4">5</ref>  <ref type="bibr" target="#b12">[13]</ref> for which the annotation of easy-hard scores is available 6 <ref type="bibr" target="#b21">[22]</ref>. For each class the annotation specifies ranking scores of its images from easiest to hardest.</p><p>Methods. We compare the performance of the proposed method GPC conf with baselines including the standard GPC (with the likelihood in <ref type="formula" target="#formula_2">(2)</ref>), the heteroscedastic model GPC+ <ref type="bibr" target="#b6">[7]</ref>, and the SVM-based methods, SVM and SVM+. GPC conf , GPC+, and SVM+ methods utilize user agreement scores for each image label, whereas GPC and SVM do not. In GPC, for f , and in GPC conf and GPC+, for both f and g, we use a squared exponential covariance function. All hyper-parameters, i.e., Ω = {θ, σ 2 , ℓ} are found by optimizing the marginal likelihood p(y|X, X conf ); this is called type-II maximum likelihood. All GPC-based methods use the FITC approximation and the number of pseudo-inputs M is set to 100, which is smaller than the total number of training instances, 400 and 520 on average. The pseudo-inputs are initially chosen randomly from X, in the case of the f function, and from X conf , in the case of the g function. Then, they are also optimized via type-II maximum likelihood. Finally, in SVM and SVM+ we use Gaussian RBF kernels, and a grid search coupled with 5 fold cross-validation to find all hyper-parameters. SVM has 2 hyper-parameters (kernel bandwidth and regularization) and SVM+ has 4 hyper-parameters (2 kernel bandwidths and 2 regularization parameters) to be tuned. The R code of all the methods is available at the authors' homepage.</p><p>Evaluation metric. We use the classification accuracy as the performance measure. We repeat each experiment 10 times using random train/test splits of the data and report mean and standard error across repeats. At each split, we take 80% of the data to train and 20% to test the models. Additionally we also provide the results using average precision as the performance metric (in the supplementary).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Ambiguity in recognizing semantic attributes</head><p>We focus on the Amazon MTurk study carried out on the SUNAttribute dataset. This dataset consists of 14, 340 scene images taken from the SUN dataset <ref type="bibr" target="#b35">[36]</ref> annotated with 102 scene attributes such as sunny, natural, man-made easyhardscore.zip among others. The main task of this MTurk study is to annotate whether an attribute is 'present' or 'not present' in the image. The difficulty of this annotation task is multifaceted: (i) some attributes are rare e.g. smoke, scary, and others are rather common, e.g. natural, man-made; (ii) some attributes are visually obvious, e.g. ice, fire, and others are not, e.g. natural light, warm, cold; and (iii) images typically have only few attributes that are present.</p><p>In this dataset, presence of the attribute is measured as an average score of three binary user responses. The score is 1.00, 0.66, 0.33, or 0.0 when three, two, one, or zero workers accordingly decide that the attribute is 'present' in the image. In the description of the dataset <ref type="bibr" target="#b19">[20]</ref>, an attribute is considered 'present' if it receives at least two votes and 'not present' if it receives zero votes of three trusted workers. The authors mentioned that a single positive vote (average score equals 0.33) happens in a transition state between the attribute being present or not, so those images were excluded from the experiments. Our framework can automatically take this transition state into account and therefore does not discard any valuable annotations. The attribute label 'present'(+1) or 'not present'(-1) is defined via the maximum voting scheme (or in this case thresholding at 0.5) as it is widely adopted in crowdsourcing studies. Finally, the additional privileged data in terms of annotation confidence is 1.0 if all three MTurk users agree, and 0.66 if two out of three users agree on the label.</p><p>Setup. In <ref type="bibr" target="#b19">[20]</ref>, the authors consider two scenarios to study the attribute learning performance. We follow closely the first scenario, where the train and test sets are half positive and half negative so that recognizing each attribute is not influenced by the attribute popularity. We randomly select 500 samples with different confidence values to train/test the attribute classifiers. In total we train 83 binary attribute classifiers 7 . Additionally we study a balanced case of images with confidence 1.00 and 0.66 for training/testing the attribute classifiers. The results of this setting with 57 attributes in total 8 can be found in the supplementary material (entitled 57 attributes case). As our feature representation, we use 4096 dimensional deep CNNs features extracted from the fc7 activation layer in Caf-feNet <ref type="bibr" target="#b8">[9]</ref> pretrained on the large scene recognition database Places <ref type="bibr" target="#b37">[38]</ref>. We normalize the features to have zero mean and unit variance for each dimension.</p><p>Results. We report the results of this experiment in Table 1. To ease the presentation of our results, we also visualize the pairwise differences between the performance of our proposed GPC conf method and four other methods, GPC, GPC+, SVM and SVM+, in the form of bar plots located The numbers are mean and standard error of the accuracy over 10 runs of the 83 attribute classifiers. GPC conf , GPC+ and SVM+ methods utilize user agreement scores for each image label, whereas GPC and SVM do not. The best result is highlighted in boldface with an extra blue for GPC conf and GPC+. We consider GPC conf as a faster variant of GPC+ (please refer to <ref type="table" target="#tab_2">Table 3</ref> for running time comparison). Bottom: To summarize the full results in the above table, we also provide a pairwise comparison of the proposed GPC conf and four other methods in terms of difference in accuracies. The length of the bar corresponds to relative improvement of the accuracy for each of the 83 attributes. Finally, we also include statistical summary of the results based on Demšar <ref type="bibr" target="#b3">[4]</ref> analysis (bottom right). Average rank of the methods (x axis) is computed based on accuracy over all repeats (the higher the better). A critical distance measures significant differences between methods based on their ranks. We link two methods with a solid line if they are not statistically different (p-value &gt; 5%). Best viewed in color. at the bottom of the table. Additionally we also analyzed our experimental results using the multiple dataset statistical comparison method of <ref type="bibr" target="#b3">[4]</ref> (bottom right). A bird's eye view of <ref type="table">Table 1</ref> and its figures tells that it is certainly beneficial to incorporate label confidence information into the learning process. Overall, the GPC-based LUPI methods, GPC conf and GPC+, outperform other baselines in the majority of cases. We counted 30 wins for GPC conf , 28 wins for GPC+, 9 for GPC, 10 for SVM+, and 15 for SVM including 9 draws. GPC conf is superior to the standard GPC in 56 out of 83 cases, whereas SVM+ performs on par with the standard SVM baseline. Furthermore, GPC conf is able to utilize the label confidence better than SVM+ in this experiment. We suspect the SVM+ does not perform well due to the difficulty in finding suitable values for the four hyperparameters. The statistical analysis based on Demšar test <ref type="bibr" target="#b3">[4]</ref> further supports these claims, as well as the fact that there is no significant difference between the GPC conf and GPC+ methods.</p><p>Analysis of the predictive performance. Additionally we perform the analysis using a balanced case of images with confidence 1.00 and 0.66 for training/testing the attribute classifiers (the results are in the supplementary material). We report the performance on test images with both 1.0 and 0.66 agreement scores (test scenario A), and when using test images with 1.0 agreement scores only (test scenario B). GPC conf shows an advantage over other baselines, particularly in B, verifying its robustness against label noise. As a practical note, we can see that there is a clear difference when testing the methods in A and B, i.e. the overall performance of the methods in B is higher than those in A. Hence, it is important to take into account the information about MTurk users agreement when collecting new datasets and designing the evaluation setup.</p><p>Analysis of the confidence in annotations. The main principled advantage of the GPC-based over SVM-based methods is that the label confidence is inherently encoded in the probabilistic output of the GPC-based methods. Given that we have confidence of the MTurk annotations during training (X conf ), we analyze confidence in labels produced by the GPC conf method in two ways. First, we visualize few representative examples of the learned function g that acts on MTurk confidence X conf in <ref type="figure" target="#fig_4">Figure 1</ref>-right (thick blue line, left y-axis shows function values). This function is designed to reflect the value of the MTurk confidence: instances with low confidence in annotations receive less emphasis in the training process (g is positive) and instances with high confidence receive more emphasis (g is negative). On this plot one can also see the probability p(g(x conf n ) &gt; 0) as a function of MTurk confidence (thick red line, right yaxis shows probability scores). For samples where MTurk confidence was equal to 1, p(g(x conf n ) &gt; 0) is almost 0 (our design enforces instances with high confidence to have  Posterior mean of g(·) Probability of g(·)&gt;0</p><formula xml:id="formula_12">Confidence in X conf Label Confidence in the Model x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x 0.90 0.95 1.00 x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x</formula><formula xml:id="formula_13">1.0 x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x 0</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Probability</head><p>Confidence in X conf</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Value of the g function</head><p>Confidence in X conf Label Confidence in the Model Probability Confidence in X conf</p><formula xml:id="formula_14">x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x 0.90 0.95 1.00 x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x 0.65 0.70 0.5 0.6 0.7 0.8 0.9 1.0 x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x 0</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Value of the g function</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Confidence in X conf</head><p>Label Confidence in the Model  negative g). However, for samples with MTurk confidence 0.66, we have 3 scenarios 9 : a) p(g(x conf n ) &gt; 0) = 1.0 corresponds to low confidence data points being ignored with likelihood contributions of 1/2 <ref type="figure" target="#fig_4">(Figure 1-middle)</ref>, b) p(g(x conf n ) &gt; 0) = 0.0 corresponds to low confidence data points being as informative as any data point with the step likelihood contributions <ref type="figure" target="#fig_4">(Figure 1-bottom)</ref>, and c) 0.0 &lt; p(g(x conf n ) &gt; 0) &lt; 1.0 corresponds to influence of low confidence data points being reduced with a mixture of 1/2 and the step likelihood contributions <ref type="figure" target="#fig_4">(Figure 1-top)</ref>.</p><formula xml:id="formula_15">x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x 0.90 0.95 1.00 x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x 0.65 0.70 0.5 0.6 0.7 0.8 0.9 1.0 x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x</formula><p>Second, we also show the scatter plots how label confidence scores p(y|X, X conf ) produced by the classifier (in the training split) reflect the MTurk agreement scores in <ref type="figure" target="#fig_4">Figure 1</ref>-left. The scatter plot shows similar trends between the MTurk confidence and the classifier confidence of GPC conf . When MTurk confidence is 1, the GPC conf classifier confidence tends to be high (in the top right corner), and if MTurk score is 0.66, the classifier confidence stays low (in the bottom left corner). <ref type="bibr" target="#b8">9</ref> For a particular instance xn, x conf n , yn the associated term in the likelihood function of f and g in Eq. 3 is: p(yn|xn, x conf n , f, g) = 1/2 Θ(g(x conf n )) × Θ(ynf (xn)) 1−Θ(g(x conf n )) . By marginalizing g, the likelihood term of f given the instance is: p(g(x conf n ) &gt; 0) × 1 2 + (1 − p(g(x conf n ) &gt; 0)) × Θ(ynf (xn)).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Ambiguity to distinguish easy from hard images</head><p>We focus on the Amazon MTurk study carried out on 8 classes of the AwA dataset: chimpanzee, giant panda, leopard, persian cat, hippopotamus, raccoon, rat and seal. In this study, a worker is shown a set of images of one class and is asked to rank the images from the easiest to the hardest to spot the animal. Finally, each image gets an easy-hard score in the range from 1 (hardest) to 16 (easiest) as the average score over all worker responses across multiple sets of images.</p><p>Setup. This task mimics human learning to classify easy and hard samples. For each class, we label half of the images as 'easy'(+1) and half of the images as 'hard'(-1) with respect to the easy-hard scores, and solve a binary classification problem. The important information about the easyhard score can be encoded in the label confidence. We iteratively assign the highest confidence, i.e., 1.0 to the top 10% of the easiest images and bottom 10% of the hardest images. Next, we assign a less confident score equal to 0.9 to the 10% of the remaining data from the top and from the bottom, and repeat. Images with an average score slightly above/below the threshold get a confidence score of 0.6. We use all available data per class to form the train/test splits, ranging from 300 (rat) to 900 images (giant panda). As our feature representation, we use 4096 dimensional deep CNNs features extracted from the fc7 activation layer in CaffeNet <ref type="bibr" target="#b8">[9]</ref> pretrained on ImageNet (ILSVRC12) <ref type="bibr" target="#b25">[26]</ref>. We normalize the features to have zero mean and unit variance for each dimension.</p><p>Results. We present the results of this experiment in <ref type="table" target="#tab_1">Table 2</ref>. First we would like to point out that in all cases but seal the overall performance of the methods is better than chance. This means that there is a difference between easy and hard instances and we can learn a classifier to cap-ture this difference. In case of seal, majority of the images are indifferent, i.e. easy-hard score is homogeneously distributed in the middle range, so the image is as easy as it is hard. Since there is no signal for classifier to learn we exclude this class from further analysis. From the table with the results we can conclude that it is certainly beneficial to incorporate label confidence information into the learning process. Overall, the methods that utilize confidence information, GPC conf and SVM+, outperform their counterparts, GPC and SVM, in all cases but rat, which has the least amount of train/test data available. In this experiment, the proposed GPC conf performs on par with the SVM+ method, which shows the benefits of both GPC-based and SVMbased frameworks for LUPI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion and Conclusion</head><p>All you need in this life is ignorance and confidence, and then success is sure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mark Twain</head><p>We studied learning using privileged information (LUPI) as a framework to incorporate annotation disagreements into the classifiers. In this framework, there is extra information (in our case confidence in annotations) for each data sample that is only accessible at training time. We exploit this extra information as the way to discriminate between easy and difficult examples. We proposed a model based on Gaussian Process framework in which the influence of difficult instances in the training process is reduced, retained, or even ignored. The proposed method uses an efficient quadrature-free expectation propagation algorithm for approximate inference therefore it is faster to train than existing LUPI methods: 42m for ours v. 1h13m for GPC+ and 4h12m for SVM+, the two baseline LUPI methods. We showed that classifiers could benefit from incorporating annotation ambiguities into the learning process. There are emerging research trends in coupling kernel methods/Gaussian processes and deep CNNs models (see for example: <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b34">35]</ref>). The main idea is to learn the convolutional layers as in deep CNNs and replace fully connected layers with the nonparametric kernel functions. Coupling our GPC conf model and the deep-er kernels concept is an attractive future direction. To achieve this in practice, we will need a large dataset with confidence annotations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 .</head><label>1</label><figDesc>Label confidence analysis. Left: Scatter plot of MTurk confidence versus marginal likelihood p(y|X, X conf ) at training time. Right: Representative posterior mean of the g function and 1-standard-deviation confidence interval (solid blue curve) alongside with the probability of g &gt; 0 (solid red curve) for three different cases. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Table 1. Recognizing 83 scene attributes. Top:</figDesc><table>GPC 

GPC conf 
GPC+ [7] 
SVM+ [34] 
SVM 
image 
image+conf 
image+conf 
image+conf 
image 
sailing 
79.70 ± 0.79 
80.70 ± 0.71 
79.90 ± 0.85 
80.00 ± 0.84 
79.30 ± 0.88 
driving 
77.20 ± 1.78 
78.70 ± 1.67 
78.50 ± 1.63 
77.90 ± 1.47 
77.70 ± 1.61 
biking 
75.00 ± 1.39 
76.80 ± 1.24 
76.70 ± 1.29 
75.60 ± 1.71 
76.80 ± 1.19 
transport 
81.20 ± 0.58 
80.60 ± 1.03 
80.90 ± 1.09 
81.10 ± 1.02 
80.00 ± 1.13 
vacation 
76.50 ± 1.63 
76.10 ± 1.67 
75.70 ± 1.55 
74.20 ± 1.41 
75.10 ± 1.12 
hiking 
78.20 ± 2.11 
80.10 ± 1.68 
79.60 ± 1.74 
78.70 ± 1.93 
78.30 ± 1.56 
climbing 
82.20 ± 1.29 
83.30 ± 1.18 
82.90 ± 1.14 
81.80 ± 1.21 
81.70 ± 1.10 
camping 
75.10 ± 1.25 
76.40 ± 1.33 
76.10 ± 1.37 
75.10 ± 1.42 
76.10 ± 1.31 
reading 
78.40 ± 0.94 
78.70 ± 1.13 
78.30 ± 1.15 
77.70 ± 0.99 
78.10 ± 1.22 
teaching 
75.80 ± 0.95 
76.10 ± 1.35 
76.80 ± 1.26 
76.20 ± 1.30 
76.10 ± 1.58 
diving 
75.70 ± 1.32 
75.60 ± 1.04 
76.10 ± 0.98 
76.60 ± 0.80 
74.40 ± 0.74 
swimming 
76.20 ± 0.82 
78.00 ± 1.00 
78.40 ± 1.01 
78.00 ± 0.65 
78.20 ± 0.86 
eating 
79.40 ± 1.00 
80.40 ± 0.78 
80.10 ± 0.94 
77.30 ± 1.42 
80.60 ± 0.80 
socializing 
76.20 ± 1.00 
76.70 ± 1.43 
77.30 ± 1.23 
78.10 ± 1.47 
77.30 ± 1.50 
congregat. 
80.00 ± 1.17 
81.20 ± 1.11 
80.60 ± 1.13 
77.80 ± 1.04 
79.90 ± 1.19 
queuing 
71.30 ± 1.15 
71.10 ± 1.20 
71.20 ± 1.19 
70.10 ± 1.07 
71.60 ± 1.37 
competing 
78.30 ± 1.61 
80.30 ± 1.40 
80.00 ± 1.48 
79.60 ± 1.63 
80.90 ± 1.46 
sports 
80.90 ± 1.10 
81.60 ± 0.84 
81.50 ± 0.86 
79.90 ± 1.27 
81.40 ± 1.06 
exercise 
77.70 ± 1.48 
80.40 ± 1.14 
79.90 ± 1.43 
79.00 ± 0.80 
78.90 ± 1.10 
playing 
76.70 ± 0.88 
77.00 ± 1.32 
77.10 ± 1.29 
76.60 ± 1.66 
76.90 ± 1.55 
spectating 
81.90 ± 1.45 
83.20 ± 0.90 83.20 ± 0.86 
81.10 ± 1.20 
82.20 ± 1.00 
farming 
79.00 ± 0.76 
79.20 ± 1.08 
79.20 ± 1.11 
79.30 ± 0.94 
77.80 ± 0.96 
shopping 
81.50 ± 0.74 
81.20 ± 0.94 
81.10 ± 0.98 
80.20 ± 1.58 
81.00 ± 1.07 
working 
76.90 ± 1.62 
76.80 ± 1.59 
77.00 ± 1.60 
76.30 ± 1.50 
75.70 ± 1.66 
us.tools 
75.20 ± 1.17 
74.80 ± 1.26 
75.30 ± 1.35 
73.20 ± 1.16 
75.10 ± 1.18 
business 
71.20 ± 1.48 
71.50 ± 1.51 
70.90 ± 1.63 
68.60 ± 1.54 
71.50 ± 1.58 
praying 
78.60 ± 0.60 
78.70 ± 1.02 
79.20 ± 1.08 
78.40 ± 0.55 
77.20 ± 1.21 
fencing 
69.40 ± 0.87 
69.40 ± 0.99 
69.80 ± 1.00 
68.30 ± 1.71 
69.30 ± 1.09 
railing 
65.70 ± 1.71 
69.60 ± 1.12 
69.70 ± 1.30 
68.00 ± 1.26 
68.20 ± 1.77 
wire 
70.80 ± 1.55 
70.20 ± 1.85 
70.50 ± 1.80 
72.10 ± 1.24 
71.00 ± 1.26 
trees 
76.20 ± 1.35 
76.00 ± 1.22 
76.00 ± 1.29 
74.40 ± 1.18 
75.20 ± 0.94 
grass 
77.90 ± 1.51 
79.10 ± 1.14 
79.00 ± 1.22 
79.30 ± 1.67 
77.70 ± 1.05 
vegetation 
78.30 ± 1.26 
78.90 ± 1.47 
78.50 ± 1.54 
77.40 ± 1.23 
76.70 ± 1.10 
shrubbery 
78.50 ± 1.68 
79.50 ± 1.31 
79.70 ± 1.43 
77.10 ± 1.63 
76.20 ± 1.69 
foliage 
76.20 ± 0.91 
77.30 ± 0.96 
77.10 ± 0.97 
76.20 ± 0.69 
76.80 ± 1.27 
leaves 
75.50 ± 1.55 
76.60 ± 1.59 
77.40 ± 1.46 
76.80 ± 1.16 
77.20 ± 1.08 
asphalt 
80.90 ± 1.25 
81.30 ± 1.32 
81.20 ± 1.60 
80.30 ± 0.85 
80.90 ± 1.16 
pavement 
73.70 ± 0.88 
73.70 ± 1.10 
73.90 ± 0.88 
73.90 ± 1.10 
74.30 ± 0.68 
shingles 
83.60 ± 0.89 
83.50 ± 0.82 
83.90 ± 0.98 
82.90 ± 1.26 
82.20 ± 1.33 
carpet 
74.60 ± 1.27 
74.40 ± 1.10 
74.90 ± 1.08 
74.40 ± 0.98 
73.20 ± 1.36 
brick 
79.10 ± 1.57 
78.50 ± 1.46 
78.30 ± 1.36 
80.10 ± 1.27 
78.70 ± 1.56 
concrete 
66.40 ± 1.45 
65.70 ± 1.10 
67.40 ± 1.34 
65.80 ± 1.33 
67.30 ± 1.15 

GPC 
GPC conf 
GPC+ [7] 
SVM+ [34] 
SVM 
image 
image+conf 
image+conf 
image+conf 
image 
metal 
71.50 ± 1.57 
72.00 ± 1.33 
71.70 ± 1.51 
71.90 ± 1.45 
70.40 ± 0.70 
paper 
72.90 ± 1.33 
74.00 ± 1.00 
73.70 ± 0.85 
72.80 ± 1.29 
72.80 ± 1.00 
wood 
72.00 ± 1.15 
72.30 ± 1.21 
72.40 ± 1.25 
71.90 ± 2.09 
72.20 ± 1.55 
vinyl 
69.80 ± 1.70 
69.10 ± 1.68 
69.20 ± 1.64 
67.30 ± 1.48 
70.60 ± 1.34 
rubber 
77.40 ± 1.08 
78.20 ± 1.16 
77.80 ± 1.21 
77.20 ± 1.42 
77.80 ± 1.21 
cloth 
74.10 ± 1.53 
75.70 ± 1.09 
76.00 ± 1.10 
74.30 ± 1.18 
75.10 ± 1.11 
sand 
78.50 ± 1.39 
77.80 ± 1.59 
77.40 ± 1.46 
77.70 ± 1.52 
78.20 ± 1.36 
rock 
74.70 ± 1.31 
75.50 ± 1.37 75.50 ± 1.53 
74.20 ± 1.27 
75.30 ± 1.69 
dirt/soil 
76.10 ± 1.34 
77.70 ± 1.30 
77.30 ± 1.38 
75.50 ± 1.74 
75.60 ± 1.31 
glass 
67.70 ± 1.10 
68.20 ± 0.91 
68.00 ± 1.17 
65.80 ± 1.39 
67.90 ± 1.03 
ocean 
81.00 ± 0.51 
80.60 ± 0.71 
80.90 ± 0.77 
80.60 ± 0.78 
79.60 ± 0.97 
run.water 
79.80 ± 1.33 
80.20 ± 0.87 
80.10 ± 0.99 
80.80 ± 1.03 
80.30 ± 1.41 
stillwater 
76.30 ± 1.51 
76.00 ± 1.26 
76.40 ± 1.31 
75.40 ± 0.98 
75.60 ± 1.11 
snow 
84.40 ± 0.89 
85.50 ± 0.85 
85.40 ± 0.78 
85.00 ± 0.96 
85.40 ± 0.99 
clouds 
71.80 ± 1.68 
70.50 ± 1.50 
71.90 ± 1.20 
70.80 ± 1.41 
69.40 ± 1.10 
nat.light 
78.80 ± 1.26 
81.50 ± 1.00 
81.60 ± 1.07 
79.70 ± 1.18 
81.30 ± 1.23 
sunny 
71.90 ± 1.20 
72.20 ± 0.81 
72.70 ± 1.04 
69.30 ± 1.35 
71.90 ± 1.36 
el.lighting 
73.20 ± 0.99 
73.00 ± 1.17 
73.20 ± 1.09 
73.80 ± 1.12 
72.10 ± 0.95 
aged/worn 
72.70 ± 1.18 
73.50 ± 0.95 
73.10 ± 1.10 
72.70 ± 1.08 
73.70 ± 0.93 
glossy 
74.40 ± 1.56 
75.00 ± 1.81 
74.10 ± 1.69 
72.60 ± 1.52 
72.40 ± 1.71 
matte 
69.40 ± 1.02 
67.70 ± 0.99 
67.90 ± 1.00 
68.80 ± 1.04 
69.80 ± 0.96 
moist 
73.80 ± 1.65 
75.30 ± 1.62 
74.20 ± 1.56 
72.70 ± 1.64 
75.70 ± 1.42 
dry 
75.80 ± 1.60 
75.70 ± 1.50 
76.20 ± 1.59 76.20 ± 0.90 76.20 ± 1.26 
dirty 
77.40 ± 1.09 
76.70 ± 1.47 
77.10 ± 1.40 
75.70 ± 1.31 
75.70 ± 1.20 
rusty 
69.60 ± 1.24 
70.10 ± 1.14 
70.30 ± 1.16 
69.40 ± 1.10 
69.50 ± 1.31 
warm 
71.50 ± 1.63 
72.20 ± 2.08 
71.90 ± 2.02 
70.60 ± 1.46 
70.20 ± 1.55 
cold 
86.90 ± 1.27 
87.20 ± 1.19 
87.10 ± 1.17 
87.30 ± 0.83 
87.00 ± 0.99 
natural 
82.80 ± 1.16 
82.20 ± 1.10 
82.40 ± 0.93 
81.90 ± 1.40 
81.70 ± 1.25 
man-made 
71.40 ± 1.14 
71.80 ± 0.99 
71.70 ± 1.15 
71.70 ± 0.81 
73.90 ± 1.14 
open 
78.00 ± 0.72 
79.60 ± 1.10 
79.50 ± 1.12 
78.60 ± 0.74 
79.30 ± 1.19 
semi-encl. 
76.90 ± 1.14 
77.30 ± 1.01 
77.60 ± 0.98 
77.10 ± 1.86 
77.80 ± 1.37 
enclosed 
80.60 ± 1.14 
81.90 ± 1.34 
82.10 ± 1.25 
80.80 ± 1.08 
82.10 ± 1.05 
far-horizon 
80.40 ± 1.52 
81.00 ± 1.31 
80.20 ± 1.35 
79.90 ± 1.39 
79.70 ± 1.24 
nohorizon 
79.10 ± 1.28 
79.60 ± 1.43 79.60 ± 1.43 
78.60 ± 1.43 
78.60 ± 1.44 
rugged 
81.20 ± 0.87 
81.30 ± 0.60 
81.30 ± 0.57 
80.80 ± 1.26 
81.90 ± 0.83 
vertical 
72.50 ± 0.93 
75.10 ± 1.53 
74.40 ± 1.39 
71.80 ± 1.38 
73.60 ± 1.23 
horizontal 
72.40 ± 1.27 
73.60 ± 0.94 73.60 ± 0.91 
71.70 ± 1.47 
70.90 ± 1.25 
symmetr. 
73.30 ± 1.24 
73.10 ± 1.27 
73.40 ± 1.23 
70.60 ± 1.58 
72.30 ± 1.66 
cluttered 
79.30 ± 1.18 
78.90 ± 1.20 
78.70 ± 1.18 
78.20 ± 1.35 
78.40 ± 0.98 
soothing 
71.90 ± 1.16 
73.70 ± 1.14 
73.20 ± 1.17 
73.00 ± 1.32 
73.10 ± 1.35 
stressful 
72.90 ± 1.58 
73.70 ± 1.70 
73.80 ± 1.72 
72.80 ± 1.23 
72.70 ± 1.64 

2.1 
2.1 

• 

2 
3 
4 

GPC+ 

GPC conf 
SVM+ 

GPC image 

SVM 

Critical Distance 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 .</head><label>2</label><figDesc>Distinguishing easy from hard images on AwA dataset. The numbers are mean and standard error of the accuracy over 10 runs. To define confidence of image label, GPC conf and SVM+ methods utilize easy-hard score annotation available per image.</figDesc><table>GPC 
GPC conf (ours) GPC+[7] SVM SVM+[34] 
SUNAttribute 
27m. 
32m. 
51m. 
6m. 
106m. 
AwA 
32m. 
42m. 
73m. 
10m. 
252m. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 .</head><label>3</label><figDesc>Average training time in minutes for SUNAttribute with ≈ 400 tr. samples and AwA experiments with ≈ 520 tr. samples.</figDesc><table></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">By integrating out the noise ǫn, we end up at the familiar form of probit classifiers where the class membership probability is simply p(yn = 1|xn, f ) = Φ (0,σ 2 ) (f (xn))<ref type="bibr" target="#b22">[23]</ref> with Φ(·) as the probit function.<ref type="bibr" target="#b1">2</ref> We will drop the conditional notation on ǫ to avoid clutter.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Please, refer to the Eq. (11) in the supplementary material.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://cs.brown.edu/˜gen/sunattributes.html 5 http://attributes.kyb.tuebingen.mpg.de/ 6 http://smileclinic.alwaysdata.net/lupi/AwA_</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">In<ref type="bibr" target="#b19">[20]</ref>, 87 attributes are learned with 350 samples for training/testing. Since we use more samples, we account for 83 out of 87 of attributes.<ref type="bibr" target="#b7">8</ref> The number of attributes is restricted by the amount of positive samples available with confidence 1.00 and 0.66.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>VS and NQ thank AWS Cloud Credits for Research. DHL acknowledges support from Plan Nacional I+D+i, grants TIN2013-42351-P and TIN2015-70308-REDT, and from Comunidad de Madrid, grant S2013/ICE-2845 CASI-CAM-CM. JMHL acknowledges support from the Rafael del Pino foundation. VS and DHL contributed equally.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Amazon&apos;s mechanical turk: A new source of inexpensive, yet high-quality, data?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Buhrmester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Gosling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3" to="5" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Modelling annotator bias with multitask gaussian processes: An application to machine translation quality estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Maximum likelihood estimation of observer error-rates using the EM algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Dawid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Skene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Statistics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="20" to="28" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Statistical comparisons of classifiers over multiple data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Demšar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2006" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sparse Gaussian processes using pseudo-inputs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Snelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Robust multi-class Gaussian process classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dupont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Mind the nuisance: Gaussian process classification using privileged noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sharmanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Quadrianto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Repeated labeling using multiple noisy labelers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Provost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="402" to="441" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5093</idno>
		<title level="m">Caffe: Convolutional architecture for fast feature embedding</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Worker types and personality traits in crowdsourcing relevance labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kazai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Milic-Frayling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Attribute adaptation for personalized image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kovashka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Assessing approximate inference for binary Gaussian process classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kuss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2005" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Attributebased classification for zero-shot visual object categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Trans. on Pattern Analysis and Machine Intelligence (T-PAMI)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="453" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Microsoft COCO: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-class multi-annotator active learning with robust Gaussian Process for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A Family of Algorithms for Approximate Bayesian Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Minka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The generalized FITC approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Naish-Guzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Holden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Approximations for binary Gaussian process classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2008" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Relative attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The SUN Attribute database: Beyond categories for deeper scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="page" from="59" to="81" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fast optimization algorithms for solving SVM+</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pechyony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical Learning and Data Science</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Curriculum learning of multiple tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pentina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sharmanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Gaussian Processes for Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>The MIT Press</publisher>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning from crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">C</forename><surname>Raykar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Valadez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1297" to="1322" />
			<date type="published" when="2010" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">GP classification and active learning with multiple annotators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="page" from="1" to="42" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Expectation propagation for exponential families</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seeger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep-er kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPRAM</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Inferring ground truth from subjective labelling of venus images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">M</forename><surname>Fayyad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Burl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Utility data annotation with amazon mechanical turk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sorokin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshop</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">80 million tiny images: a large database for non-parametric object and scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Trans. on Pattern Analysis and Machine Intelligence (T-PAMI)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1958" to="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Estimation of Dependences Based on Empirical Data: Springer Series in Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning using privileged information: Similarity control and knowledge transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Izmailov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2023" to="2049" />
			<date type="published" when="2015" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A new learning paradigm: Learning using privileged information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vashist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep kernel learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">SUN database: Large-scale scene recognition from abbey to zoo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ehinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Modeling annotator expertise: Learning when everybody knows a bit of something</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rosales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Valadez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bogoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Moy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Dy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AISTATS</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning deep features for scene recognition using places database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
