<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visual Path Prediction in Complex Scenes with Crowded Moving Objects</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Yoo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of ECE</orgName>
								<orgName type="laboratory">Perception and Intelligence Lab</orgName>
								<orgName type="institution" key="instit1">ASRI</orgName>
								<orgName type="institution" key="instit2">Seoul National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Yun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of ECE</orgName>
								<orgName type="laboratory">Perception and Intelligence Lab</orgName>
								<orgName type="institution" key="instit1">ASRI</orgName>
								<orgName type="institution" key="instit2">Seoul National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonghee</forename><surname>Hong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of ECE</orgName>
								<orgName type="laboratory">Perception and Intelligence Lab</orgName>
								<orgName type="institution" key="instit1">ASRI</orgName>
								<orgName type="institution" key="instit2">Seoul National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hawook</forename><surname>Jeong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of ECE</orgName>
								<orgName type="laboratory">Perception and Intelligence Lab</orgName>
								<orgName type="institution" key="instit1">ASRI</orgName>
								<orgName type="institution" key="instit2">Seoul National University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Samsung Electronics Co</orgName>
								<address>
									<settlement>Ltd</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><forename type="middle">Young</forename><surname>Choi</surname></persName>
							<email>jychoi@snu.ac.kr2hawook.jeong@samsung.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of ECE</orgName>
								<orgName type="laboratory">Perception and Intelligence Lab</orgName>
								<orgName type="institution" key="instit1">ASRI</orgName>
								<orgName type="institution" key="instit2">Seoul National University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Visual Path Prediction in Complex Scenes with Crowded Moving Objects</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper proposes a novel path prediction algorithm for progressing one step further than the existing works focusing on single target path prediction. In this paper, we consider moving dynamics of co-occurring objects for path prediction in a scene that includes crowded moving objects. To solve this problem, we first suggest a two-layered probabilistic model to find major movement patterns and their cooccurrence tendency. By utilizing the unsupervised learning results from the model, we present an algorithm to find the future location of any target object. Through extensive qualitative/quantitative experiments, we show that our algorithm can find a plausible future path in complex scenes with a large number of moving objects.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Scene understanding is an essential topic in the computer vision area, but lots of challenges remain in scene understanding research. In particular, the prediction of the future behavior of an object requires a highly intellectual inference regarding a scene structure and the objects' dynamics in a scene. The research on the visual prediction problem is in an initial stage because the problem requires a high level of inference on visual scenes, but the current scene understanding algorithms do not have the capability to infer a complex scene like a human. The current research is limited to specific problems such as occluded part prediction and future path prediction of an object in a scene, etc., as will be described in the related works in section 2. This paper aims to progress in the research on the future path prediction problem. Recently, a couple of works on the future path prediction problem have been presented <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b20">21]</ref>. Kitani et al. <ref type="bibr" target="#b20">[21]</ref> defined their specific prediction problem as finding the future trajectory of an object in an arbitrary location given the semantic structure of the scene. Walker et al. <ref type="bibr" target="#b42">[43]</ref> proposed an algorithm to infer the shape and location changes of the representative patches considering the semantic structures of the scene after detecting the essential patches. The existing prediction works do not consider the reciprocal actions among moving objects in a scene. To predict the future location of a target object at blue x point, finding the co-occurring movement pattern is required. The blue line shows the future trajectory of the object at blue x point and red line denotes the co-occurring movement patterns of other objects at the moment. If the turn right pattern (red) is dominant as in (a), the object of our interest will goes right and it will goes straight or left if straight pattern (red) occurs as in (b).</p><p>Even though their works pioneer the visual prediction field, the algorithms do not show satisfactory results in complex scenes, like cross-streets, where many objects interact with each other. In a cross-street, objects moves differently depending on the traffic light, even when they start from the same location in the cross-street. <ref type="figure" target="#fig_0">Figure 1</ref> is an example of this type of scene, which includes diverse movement patterns such as going straight and turning left. To predict the future location of a target object in this kind of scene, it is necessary to consider the movement patterns that occur at the prediction moment. For example, the object at the blue 'x' point will go to different destinations with respect to the co-occurring movement patterns (red line). If other objects (red) move right, as in (a), the object (blue) should go right in order to avoid collision. The target object (blue), likewise, will go straight or turn left when the co-occurring movement pattern (red) is straight as in (b). This example indicates that if we do not consider the dynamics of other co-occurring objects, we may get an inadequate predicted path, which may give rise to a collision.</p><p>In this paper, for one step of progress beyond the existing works, we propose a novel path prediction algorithm, which considers the moving dynamics of co-occurring objects. To the best of our knowledge, this is the first attempt in the path prediction research field. We develop a new unsupervised Bayesian learning model that extracts typical movement patterns of objects and relationships from among the patterns to solve the prediction problem. The proposed model combines a topic mixture model <ref type="bibr" target="#b3">[4]</ref> and the Gaussian mixture <ref type="bibr" target="#b29">[30]</ref> hierarchically, which learns movement patterns as well as their interactions by utilizing the feature tracking results. However, the hierarchical combination of these two mixture models is not mathematically straightforward because the Guassian distribution is not a conjugate prior <ref type="bibr" target="#b7">[8]</ref> of multinomial (topic) distribution, and so the posterior distribution of the combined model cannot be derived. Hence, this kind of combination has not been utilized despite its effectiveness. To resolve the problem, we introduce a mathematical trick to formulate a hierarchical topic-Gaussian mixture with satisfying the conjugate prior relation through an augmented variable. Then, we develop a deterministic path prediction algorithm utilizing the moving dynamics inferred by the proposed hierarchical topic-Gaussian mixture model. In this algorithm, we predict the future path of the target object by inferring the most plausible movement pattern for the object through analysis of the previous location of the object and moving dynamics of other co-occurring objects. We show that our algorithm finds a suitable future path of the target object through quantitative/qualitative experiments with widely used datasets <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b4">5]</ref>. In particular, it is shown that, as expected, our method could predict the future path of objects and avoid collision with other cooccurring objects in the scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Prediction capability is one of the essential indicators to measure the intellectual power and is extensively used to analyze intelligent behaviors of human <ref type="bibr" target="#b34">[35]</ref> and animals <ref type="bibr" target="#b37">[38]</ref>. Likewise, a variety of visual prediction research in computer vision has been conducted to measure the performance of scene understanding algorithms.</p><p>The existing visual prediction research includes many subcategories, such as predicting occluded parts <ref type="bibr" target="#b16">[17]</ref>, actions <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b26">27]</ref>, object dynamics <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b0">1]</ref> and future path prediction <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b42">43]</ref>. Recent path prediction research can be categorized into two approaches: path-planningbased approach and patch-appearance-based approach.</p><p>The first approach utilizes a path planning algorithm <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b25">26]</ref>. The approach uses statistical techniques such as inverse reinforcement learning <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b33">34]</ref> to find the optimal future path. Kitani et al. <ref type="bibr" target="#b20">[21]</ref> first utilized the robot path planning algorithm to infer a point-wise future location of an object in a visual scene. The goal of this algorithm is to find a well-planned path for a target object with given scene structures such as roads, buildings, and so on. The object passes the appropriate area such as the pavement or road and avoids static obstacles in its way by following the induced path to reach the destination. To infer the predicted path, the algorithm first finds the cost for accessing each lo-cation in a scene and describes the cost via the reward map by utilizing the semantic segmentation result <ref type="bibr" target="#b31">[32]</ref>. Then the algorithm extracts the optimal path which minimizes the overall cost by using inverse optimal control <ref type="bibr" target="#b32">[33]</ref> and Markov decision process <ref type="bibr" target="#b1">[2]</ref>. This approach is designed for single object movement prediction and does not consider possible collisions with other moving objects in a scene.</p><p>The second approach induces future changes of notable patches instead of locations of the target. In this case, inferring the representative patches is also a subproblem to be solved. Walker et al. <ref type="bibr" target="#b42">[43]</ref> found the salient patches by applying recent mid-level patch-finding algorithms <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b36">37]</ref>. Then, they generated the weighted graph explaining the changes of the patches. The nodes of the graph represent the future locations and shapes of the patch. The weight is defined as a transition cost. The algorithm then finds the minimal weighted path by using Dijkstra's algorithm <ref type="bibr" target="#b8">[9]</ref>. This path, starting from the initial node to termination, describes the changes of both shape and location. However, this algorithm has also been designed for single patches and does not reflect the dynamics of other moving objects in the scene.</p><p>Unlike the existing approaches, we propose a path prediction algorithm that reflects the movements of other cooccurring objects by using the novel hierarchical topic Gaussian mixture model. In the other research field, pattern analysis algorithms based on the probabilistic topic model <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b39">40]</ref> also learn object dynamics in a scene to detect abnormal events. We highlight that our path prediction and motion pattern inference algorithms basically solve different problems. The existing topic model-based algorithms learns the regional patterns in a form appropriate to judge whether or not the target is moving in the typical regions. Meanwhile, the proposed HTGMM learns the object moving dynamics in the form of moving patterns together with their co-occurrences in a way that is adequate for future path prediction. Even the new model still provides the inference result in a quantized form because of the common limitations of the topic mixture <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6]</ref>. Therefore, we propose an efficient algorithm that induces the continuous future path from the quantized movement patterns and their relationship. To get the continuous path prediction, this paper transforms the quantized result into an energy potential map depicting the plausible paths in the form of valleys and predicts the future path by using the potential map. This prediction method is an essential contribution of the work together with the proposed HTGMM for the inference of moving object dynamics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>The overall scheme of the proposed method is depicted in <ref type="figure" target="#fig_1">Figure 2</ref>. By analyzing the KLT trajectories <ref type="bibr" target="#b38">[39]</ref>, notable movement patterns are extracted from the scene by the proposed HTGMM. These patterns imply the semantic moving</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Movement Patterns and Groups</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test Points</head><p>Prediction Results dynamics of objects in a scene, such as going straight or turning right. Therefore, it is natural to expect that some patterns will occur at the same time according to their semantics. For example, we know that straight patterns going right and left in the separated lanes may usually occur simultaneously, as shown in the red lines in <ref type="figure" target="#fig_1">Figure 2</ref>. In this work, we divide the patterns into groups by considering the co-occurrence tendency among them. Each group, therefore, includes the patterns that may occur in the same time span. Utilizing this information, we predict the future trajectory of a target. As seen in <ref type="figure" target="#fig_1">Figure 2</ref>, depending on the dominant group at the prediction time, the predicted path can be different, even if the target starts from the same location. In the below sections, we give a detailed explanation of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>KLT Trackers Training Video</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Conversion of Input Trajectories</head><p>First, we convert KLT trajectories <ref type="bibr" target="#b38">[39]</ref> into a set of words to be used as input features for the proposed probabilistic model. The sets of KLT trajectories are denoted by</p><formula xml:id="formula_0">T l = {(x lt ,y lt ) | t =1 , ..., N T },l =1 , ..., N . The term words, w = {w i | i =1 , .</formula><p>.., N w }, are defined as indices of the grids dividing a given scene. Then, each point (x lt ,y lt ) in a trajectory T l is mapped to the word w lt which indicates the grid including the point. N, N T , and N w respectively denote the total number of trajectories, the number of points in each trajectory, and the total number of the words w. Consequently, we can convert the trajectory T l into the quantized form T</p><formula xml:id="formula_1">(w) l = {w lt | t =1, ..., N T }.</formula><p>In the below sections, we will write the quantized trajectory T (w) l as T l for convenience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Hierarchical Topic-Gaussian Mixture Model</head><p>In this section, we introduce the unsupervised Hierarchical Topic-Gaussian Mixture Model (HTGMM). This model induces typical movement patterns and their co-occurrence types for a given quantized trajectory T l . <ref type="figure" target="#fig_2">Figure 3</ref> illustrates the proposed HTGMM in graphical representation. In a nutshell, the model learns K number of movement patterns into the topic mixture {φ k ,q k },k =1 , ..., K, by utilizing the quantized KLT trajectories. Then, the patterns are clustered is an indexing variable indicating the pattern type of the l-th trajectory in the d-th chunk, ranging from 1 to K. That is, it points out the pattern {φ k ,q k } including T (d) l among K patterns. φ k is defined as the N w dimensional random vector with multinomial distribution. The i-th element of φ k indicates the probability that k−th pattern includes the i-th grid location, i.e., i-th word. φ k learns the regional information of the k-th pattern. q k ∈ R Nw×Nw denotes the word to word transition, i.e., direction, probability of k-th pattern. Consequently, given z</p><formula xml:id="formula_2">(d) l = k, the probability that k-th pattern includes T (d) l = {w (d) l1 ,w (d) l2 , ..., w (d) lN (d) l } ,isgivenby p(T (d) l | φ k ,q k )= N (d) l j=1 φ k (w (d) lj ) N (d) l −1 j=1 q k (w (d) lj ,w (d) l(j+1) ). (1) Indexing variable z (d) l is assigned by the multinomial distri- bution with parameter θ (d) ∈ R K as z (d) l ∼ mult(θ (d) ), (2) where ∼ means that the random variable z (d) l has multi- nomial distribution with parameter of θ (d) , whereas θ (d)</formula><p>represents the occurrence frequencies of the patterns in dth chunk. In θ (d) , the entries with relatively high values give an information that the corresponding patterns have high tendency to occur simultaneously. It means that all θ (d) ,d =1, ..., D, give essential clues to find co-occurrence relationship of patterns. Therefore, we obtain M number of co-occurrence types by grouping θ (d) into M clusters. To cluster the θ (d) , we set the mixture of M Gaussians {μ m ,S m },μ m ∈ R K ,S m ∈ R K×K ,m =1 , ..., M . Accordingly, the entries of μ m with high value represents major patterns in m-th group. The patterns in each group will occur at the same time with high probability. The example of obtained co-occurrence types is shown in <ref type="figure" target="#fig_3">Figure 4</ref>. c (d) is the indexing variable indicating one of Gaussian mixture, ranging from 1 to M . The indexing variable c (d) is assigned by multinomial distribution with parameter π as c (d) ∼ mult(π).</p><p>(3) However, since {μ m ,S m } for the given c (d) = m is not a conjugate prior of θ (d) <ref type="bibr" target="#b7">[8]</ref>, the posterior distribution of θ (d) cannot be easily induced by using {μ m ,S m } as a Gaussian prior of θ (d) . To resolve the difficulty, we additionally introduce an augmented variableθ</p><formula xml:id="formula_3">(d) = f (θ (d) ) where f (·)</formula><p>is a deterministic mapping. It means that θ (d) is converted tō θ (d) with probability one. The performance depending on the choice of the mapping f (·) will be discussed in section 4. The Gaussian distribution can be the prior ofθ (d) with any f (·) becauseθ (d) is not connected to z (d) l as shown in <ref type="figure" target="#fig_2">Figure 3</ref>. After that, one of the Gaussian mixture selected by c (d) = m is defined as a prior ofθ (d) i.e.,</p><formula xml:id="formula_4">θ (d) ∼N(μ m ,S m ).<label>(4)</label></formula><formula xml:id="formula_5">Note that p(θ (d) | μ m ,S m ,θ (d) )=p(θ (d) | μ m ,S m ) given p(θ (d) |θ (d) )=1.</formula><p>The procedure in the below is designed to let original θ (d) assign z </p><p>Since Dirichlet prior τμ m is pseudo count <ref type="bibr" target="#b2">[3]</ref> of θ (d) , the entry of θ (d) has higher value as the corresponding entry value of μ m is larger. Furthermore, it is easy to induce the marginal distribution of θ (d) because μ m is conjugate prior of θ (d) . Hyper-parameters α, β, γ ∈ R in <ref type="figure" target="#fig_2">Figure 3</ref> are Dirichlet prior and μ o ∈ R M ,κ o ∈ R,S o ∈ R M ×M are Nomral-Invert-Wishart prior <ref type="bibr" target="#b2">[3]</ref> of Gaussian mixture {μ m ,S m }. These all parameters are conjugate priors of the corresponding random variables. Joint pdf of the whole model is induced by combining the equations (1)-(5) altogether. However, it is impossible to get the exact posterior distribution of each variables because integral of the joint pdf is intractable due to the indexing variables z and c. Therefore, approximated inference methods are required to solve the problem. We use Gibbs sampling method <ref type="bibr" target="#b28">[29]</ref> for inference of all the hidden variables in the proposed HTGMM. See the supplementary material for the detailed inference procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Deterministic Method for Path Prediction</head><p>This section presents the path prediction method using the movement patterns and their co-occurrence groups learned by the proposed HTGMM. For this, we have to resolve two main problems. The first problem is that the movement patterns are described in quantized space. The other problem is that transition probability among words are defined only in the area of learned patterns. Therefore, we first suggest a method to expand the transition information of q k into the entire word pairs. Then, we propose the final path prediction method inducing the future location x t+1 at time t in continuous domain given a previous target path x t = {x 1 ,x 2 , ..., x t } in an iterative manner. Relaxation of word to word transition: The word to word transition q k (w i ,w j ) indicates the direction of k-th move- ment pattern from i-th grid to j-th grid. The (w i ,w j ) is a word pair in a scene where the condition q k (w i ,w j ) =0 is satisfied. Since we do not have the transition information for all the word pairs, the total number of trained word pairs (w i ,w j ) is less then whole possible number of word pairs N w 2 . To expand the word to word transitions to whole word pairs, we employ an energy potential vector y =[ y 1 ,y 2 , ..., y Nw ] T . The y i ,y j are defined so that y i − y j = q k (w i ,w j ). If we know the transition probabilities for R pairs of words, we can set R equations for each (y i ,y j ). The set of the equations can be expressed by sparse</p><formula xml:id="formula_7">matrix form Ay = b, A ∈ R R×Nw ,b ∈ R R which holds A[r, i]=1 ,A[r, j]=−1 and b[r]=q k (w i ,w j ). A[r, i]</formula><p>and A[r, j] are (r, i) and (r, j) element of matrix A. Also, b[r] is the r-th element of vector b. In most cases, A is not a full rank matrix. Accordingly, we can find a solution as y =( A T A) −1 A T b by using pseudo inverse. Using the y, we induce transition probabilities of whole word pairs in a scene. <ref type="figure" target="#fig_5">Figure 5</ref> is an example illustrating the y. The difference between y i and y j at each location denotes the possibility that the target moves from high potential position w i to low potential position w j . The <ref type="figure" target="#fig_5">Figure 5</ref> shows that the potential value decreases as the target moves to the future locations. Path Prediction in Continuous Domain: After finding the potential map y, we iteratively update x t . The overall path prediction procedure has three steps. In the first step, we find the movement patterns adequate to the target object by using the inference results from HTGMM. The second step is the updating procedure for y t . In this step, we modify y to reflect the past trajectory of the target, x t . We denote y at time t as y t . In the last step, we estimate future location x t+1 of the target using the updated y t+1 .  </p><formula xml:id="formula_8">p({φ k ,q k }|x (q) t ,μ c ) ∝ p(x (q) t |{φ k ,q k })p(z = k | μ c ).</formula><p>(6) The first term in the right-hand side of the equation can be obtained from the equation <ref type="bibr" target="#b0">(1)</ref>. It represents the probability that k-th movement pattern includes the target trajectory x t . The second term is a Dirichlet multinomial distribution over μ c . The distribution is induced by marginalizing θ of p(z = k | θ)p(θ | μ c ) where p(z = k | θ) and p(θ | μ c ) can be obtained from the equations <ref type="formula">(2)</ref> and <ref type="formula" target="#formula_6">(5)</ref>. It is a tractable calculation because μ c is a conjugate prior for θ. The second term leads to the selection of z indicating the frequently occurring pattern in the group c. The group c is determined by the maximum value of the posterior probability for μ c in the HTGMM with given co-occurring KLT trajectories.</p><p>(2). Energy potential map update step: After selecting the pattern k, we update y k t+1 using y k t and x t . We denote y k t as the potential vector y for k-th pattern at time t. To estimate y k t+1 reflecting the trace x t , we first define t − 1 terms in equation <ref type="formula" target="#formula_9">(7)</ref> from the x (q) t , where y i is the energy potential assigned for the word w i in x t . y wi+1 − y wi = p, i =1, ..., t − 1.</p><p>Then, we add them into the rows of the matrix A, b used previously for calculating the potential vector. By solving the linear equation Ay = b with modified A and b, we obtain a new vector y c containing the future dynamics estimated from the past movements. We set p as a mean value of all q k (w u ,w v ) ≥ 0 in a scene. The vector y k t+1 is updated by reflecting the y c to the present state as</p><formula xml:id="formula_10">y k t+1 =(1− α)y k t + αy c ,<label>(8)</label></formula><p>where term α is a design parameter.</p><p>(3) Path prediction step: Now we finally find x t+1 using the y k t+1 . As seen in <ref type="figure" target="#fig_5">Figure 5</ref>, the map y k t+1 forms a valleylike shape going down to the destination of the pattern k. Therefore, we find x t+1 by following the slope of the valley. To find new x t+1 in a continuous domain, we expand y k t+1 into continuous space using bi-linear mapping <ref type="bibr" target="#b35">[36]</ref>. F k t+1 refers the continuous energy potential map obtained from y k t+1 . Then, we find the sink point x s of the F k t+1 which indicates the destination of the pattern k. The optimization formulation to find x t+1 is given by</p><formula xml:id="formula_11">x t+1 =min x F k t+1 (x), s.t. x − x t 2 = x t − x t−1 2 , x − x s 2 ≤ x t − x s 2 .<label>(9)</label></formula><p>To find the minimal point in (9), we only need to navigate the points x lying in the circle C(R, θ) which R = x t − x t−1 2 and −π ≤ θ ≤ π with center x t . To find x with minimal F k t+1 (x), we find inflection points by calculating θ satisfying the gradient ∇ θ F k t+1 (C(R, θ)) = 0 and choose the point with the minimum field value as the future location x t+1 . By increasing the time index t, we predict the future location of target recursively and we terminate the recursive iteration when the distance between predicted point x t+1 and x s is smaller than x t − x t−1 2 or x t+1 goes over the boundary of the scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head><p>To validate the proposed algorithm, we compared the performance against the existing path prediction algorithms <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b20">21]</ref>. Through the comparison, we have confirmed that the existing path prediction algorithms <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b20">21]</ref> are not adequate for the crowded scenes which have a temporal pattern co-occurrence tendency. Also, to check our method's applicability to pedestrian moving patterns, we compared it with Yi's method <ref type="bibr" target="#b44">[45]</ref>. In addition, to check the effects of the components of the proposed HTGMM model, we conducted extensive experiments to evaluate our algorithm by self-comparing its performance with that of three baseline algorithms designed by naive combinations of the existing topic and Gaussian models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset</head><p>For the experiments, we first used QMUL <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b4">5]</ref>, including cross road scenes and our own complex intersection (CI) dataset captured in a wide-intersection. These scenes include diverse moving object patterns and cooccurrence types governed by traffic signals. Furthermore, these scenes are very crowded, and it is hard to utilize semantic scene segmentation information as in the previous works <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b42">43]</ref>. In addition, for the pedestrian data set, we adopted PWPD <ref type="bibr" target="#b44">[45]</ref> which does not have explicit temporal groups among the movement patterns. The dataset captures a crowded indoor plaza scene in a subway station, and the movement of the objects is far less ordered compared to the QMUL, CI datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison Methods</head><p>First, we compared the prediction performance with two major existing path prediction algorithms <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b20">21]</ref> for the QMUL, CI datasets. Walker's method <ref type="bibr" target="#b42">[43]</ref> learns the transition probability among representative mid-level patches and predicts the shape and future position of the patch. Kitani's method <ref type="bibr" target="#b42">[43]</ref> trains the reward function for each location given semantic segmentation results and finds the predictive path which minimizes the cost. For comparison, we measured the error between ground truth trajectory and predicted trajectories of each algorithms using modified Hausdorff distance (denoted by MHD in tables) <ref type="bibr" target="#b11">[12]</ref> and Euclidean distance (denoted by ECD in tables). Since Walker's method automatically determines the patches for prediction, we generated ground truth trajectories for the selected patches. For the PWPD dataset, we compared the performance with Yi's method <ref type="bibr" target="#b44">[45]</ref> which marks the stateof-the-art performance to the PWPD dataset. This method does not explicitly focus on predicting trajectories but can predict the possible destination region of objects in the scene by seeing half of the entire paths.</p><p>Second, in addition to the existing algorithms <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b44">45]</ref>, we employed our own three baseline algorithms. In the first baseline algorithm, utilizing the movement patterns {φ k ,q k } and θ (d) obtained by the HTGMM, we simply inferred the co-occurrence of the movement patterns by clustering θ (d) with a Gaussian mixture model. This baseline algorithm refers to 'B(1)'. The method naively breaks the proposed HTGMM into two independent models and infers the hidden variables in a greedy manner. The second baseline algorithm is designed with the same concept as the first baseline algorithm except for usingθ (d) instead of θ (d) . The purpose of the second baseline is to show that only the simple mappingθ (d) = f (θ (d) ) does not give significant improvement of performance without the prior design as in the proposed HTGMM. The second baseline algorithm refers to 'B(2)'. The other baseline algorithm 'B(3)' assumes just one group. This means that the third baseline algorithm does not consider co-occurrence information. In addition, we added the prediction result obtained by humans to evaluate the prediction performance relative to human ability. Five human participants saw the training video three times repeatedly to learn the movement dynamics. They then predicted the future path from the same points given in the experiments for the proposed algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Qualitative Evaluation</head><p>To evaluate the robustness of design parameters, we tested our work with different parameters, namely the number of patterns K and the number of groups M . As seen in the left graph in <ref type="figure" target="#fig_8">Figure 6</ref>, our method is robust in relation to K unless the number is too small. M is a more sensitive parameter than K. In the traffic scenario, we observed that selecting three to five groups achieves the best performance. It is noticeable that the performance gap is less severe if we choose a value larger than the fitted parameters. <ref type="figure" target="#fig_9">Figure 7</ref> shows the patterns and their co-occurrence types extracted by the proposed algorithm. Each pattern is illustrated by utilizing regional probability φ k and the potential energy map F (k) . The co-occurrence groups of the patterns are illustrated in the right four images in each row of <ref type="figure" target="#fig_9">Figure 7</ref>. By utilizing the results, we measured the patterntrajectory matching accuracy, indicating whether a trajectory is matched to an appropriate pattern in the situation at the prediction time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CI Dataset:</head><p>We set the number of patterns, K, and the number of groups, M , to 15 patterns and three co-   occurrence groups, respectively, to learn the CI dataset. As shown in the right three images of <ref type="figure" target="#fig_9">Figure 7</ref>-(a), the proposed model can successfully make three groups with cooccurring patterns depending on the major co-occurrence types generated by traffic signals: horizontal straight, turning left with vertical straight, and vertical straight. By utilizing those patterns and groups, we conducted a prediction task and evaluated the prediction performance with 189 ground truth trajectories. As illustrated in <ref type="figure" target="#fig_10">Figure 8</ref>-(a), we can see that the predicted trajectories do not go toward moving objects (green arrow direction) considering co-occurrence group and arrive at the destination by following the valley obtained by the energy potential map and are matched to the ground truth. Conversely, as in <ref type="figure" target="#fig_11">Figure 9</ref>, the predicted path by <ref type="bibr" target="#b42">[43]</ref> for CI data set guides cars to avoid other cars, which results in an erroneous prediction in crowded traffic conditions. QMUL Dataset: For this dataset, we set K and M to 24 patterns and four co-occurrence groups, respectively, because the scene structure is more complicated. <ref type="figure" target="#fig_9">Figure 7-(b)</ref> represents the patterns and co-occurrence groups, extracted from the QMUL dataset. In <ref type="figure" target="#fig_9">Figure 7-(b)</ref>, it is worth highlighting that the vertical straight patterns depicted by red circles in the first two groups are included in different cooccurrence groups even though they are passing the same region. Hence, their future paths will be different from each other depending on the movements of other objects. In other words, the object in the first pattern will keep going according to the vertical straight pattern, but the object in the second pattern will stop near the crosswalk region to avoid a collision with the horizontal movements. <ref type="figure">Figure</ref> 8-(b) shows the prediction results given the groups. We executed the prediction experiment and evaluated the performance with 246 ground truth trajectories. In this scene, there are many locations too complicated for choosing the pattern, but our algorithm successfully selects adequate patterns for prediction. For example, the trajectory in the first image and int the second image in <ref type="figure" target="#fig_10">Figure 8</ref>-(b) start from almost the same location, but the predicted path is completely different depending on the co-occurrence group that is dominant at the prediction time. PWPD Dataset: We tested our method in the pedestrian walking path dataset <ref type="bibr" target="#b44">[45]</ref> which captures complex dynamic crowd movements. The experimental results in the PWPD dataset <ref type="bibr" target="#b44">[45]</ref> shows that the applicability of the proposed algorithm is not restricted to cross-road traffic scenes, but can be used for a more disordered situation. Since this scene does not include the temporal group, such as traffic controlled by traffic signals, we set the number of group M  <ref type="bibr" target="#b11">[12]</ref> and ECD denotes Euclidean distance. W14 refers to Walker's method <ref type="bibr" target="#b42">[43]</ref> and K12 refers to Kitani's method <ref type="bibr" target="#b20">[21]</ref>. B1,B2 and B3 indicates Baseline algorithms in section 4.2. W14(1) is mean value of the top 10% lowest error. W14(2) represents error of the path which has the highest probability. The result K12 is from the same configuration as W14 <ref type="formula">(2)</ref>. to 1 and the number of patterns K to 40 via experiments which were not sensitive. We used the object trajectories given by the author <ref type="bibr" target="#b44">[45]</ref>. As shown in <ref type="figure" target="#fig_0">Figure 10</ref>-(a), our model successfully learned movement patterns. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Quantitative Evaluation</head><p>First, we conducted a quantitative comparison of the algorithms <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b42">43]</ref> with the videos proposed in the paper. <ref type="table">Table 1</ref> shows the comparison results. For Walker's method <ref type="bibr" target="#b42">[43]</ref>, we used the mid-level features trained by the car chase dataset and the CI, QMUL datasets. For Kitani's work <ref type="bibr" target="#b20">[21]</ref>, manual ground truth segmentation results were adopted. Although the conditions of the experiment were advantageous to them, our method yielded superior performance because the two methods are designed to avoid obstacles such as cars and lawns.</p><p>We also measured the performance of the algorithm and compared the results with the baseline methods as well as with human prediction. As shown in <ref type="table">Table 1</ref>, the proposed algorithm outperformed the other baseline algorithms in both datasets. The result implies that the proposed method has a meaningful contribution compared to the naive use of the existing topic and Gaussian mixture models. The baseline algorithm 'B(1)' achieved better performance than the baseline algorithm 'B(3)' which does not group the patterns. However, since the group information learned by the first baseline algorithm was inaccurate, the performance improvement by GMM was insufficient. Considering that the baseline algorithm uses the same θ (d) learned by the proposed HTGMM, we conclude that the performance jump of the proposed method in comparison with the baseline algorithm 'B(1)' validates our model's superior ability to group co-occurring patterns. The result of 'B(2)' implies Video measure Y15(1) Y15(2) Y15(3) Ours PWPD Precision 48% 38% 33% 43.2% <ref type="table">Table 2</ref>. Pedestrian destination results. Y15(1) <ref type="bibr" target="#b44">[45]</ref> is the result which uses the stationary crowd factor. Y15(2),(3) are the baselines which do not, or naively use the factor. that utilizing sigmoid function without the proposed conjugate prior design in HTGMM does not yield a good performance. Furthermore, the prediction result (MHD, ECD) from humans and 'Proposed(2)' shows that our algorithm has a comparable prediction ability to that of humans in view of distance error. The result of 'Human' in <ref type="table">Table 1</ref> is the average value for the five humans. Interestingly, even humans were confused in predicting the path of the target, which can go in multiple directions depending on the cooccurrence dynamics. Also, as shown in <ref type="table">Table 2</ref>, our method achieved destination predicting performance comparable to the newest method <ref type="bibr" target="#b44">[45]</ref> without employing the stationary crowd information, claimed to be the essential feature by Yi et al. <ref type="bibr" target="#b44">[45]</ref> for analyzing a crowded scene like the PWPD dataset. It is noted that our method outperforms the other baselines of <ref type="bibr" target="#b44">[45]</ref>: Y15(2), Y15(3), which do not utilize that factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we have proposed a novel path prediction algorithm that considers the moving dynamics of cooccurring objects. To solve the problem, we first designed two-layered probabilistic model to extract the major movement patterns and their co-occurrence groups in a scene. Utilizing the result from the proposed model, we have presented an effective path prediction method. By extensive qualitative/quantitative experiments, we have shown that our algorithm can predict the future paths of objects in complex scenes including many moving objects and changing situations such as cross streets with traffic lights. This paper explores a meaningful progress in path prediction research in that the proposed algorithm considers the other co-occurring objects as well as the target itself. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgment</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Cross-street which includes diverse movement patterns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Overall scheme of the proposed method. The arrow in the scenes refers the movement pattern. Each pattern which occurs at the same time are located in colored boxes. Yellow x point is the location of the target object of which future path be predicted. Depending on the dominant group at prediction time, we induce different predicted paths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>The proposed HTGMM. Each circle represents random variable. Empty circle denotes hidden variable and gray circle is an observed variable. Directed line represents conditional dependency between the circles and rectangle box means that the random variables and their dependency in the box are repeated with the number below the box.into the mixture of M Gaussians, {μ m ,S m },m =1, ..., M , to infer M co-occurrence groups. The following gives the detailed description of the proposed HTGMM. First of all, to use overall quantized trajectories as input features to the model, we sort all the trajectories in order of ending times of the trajectories and evenly divide them into D number of chunks with N number of trajectories for each chunk. Through this procedure, the trajectories in a chunk occur in similar time span. The whole trajectories T (d) l ,d =1 , ..., D, l =1 , ..., N, are used for the observed variables and clustered by the sets of random variables {φ k ,q k },k =1 , ..., K, which indicates K number of patterns. z(d) l</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>PatternFigure 4 .</head><label>4</label><figDesc>Explanation of proposed graphical model. The figure describes the generative procedure of the HTGMM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>dominant pattern in the group, c (d) = m. To induce θ (d) which reflects the cooccurring pattern information μ m given c (d) = m, τ and μ m is defined as Dirichlet prior of θ (d) i.e., θ (d) ∼ Dir(τμ m ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>The result of expanded word to word transition. We obtain energy potential map in (a) by expanding word to word transition of the pattern in bottom of (a). The potential goes down from yellow to blue. We induce the potential map in continuous domain by bi-lnear interpolation in (b). Therefore, the sink point of the map (red 'x') indicates the destination of the pattern. The points at purple 'x' represent xt+1 and xt. The figure (c) shows the example path prediction result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>( 1 )</head><label>1</label><figDesc>Pattern selection step: This step begins with converting the past trajectoryx t = {x i | i =1 , ..., t} into a quantized form x (q) t = {w i | i =1 , ..., t} where w i is a word including x i . Then we select the pattern including x</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>to the probability of selecting k-th pattern {φ k ,q k } given the dominant pattern group c by employing the results from HTGMM as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 .</head><label>6</label><figDesc>Precision Graph with respect to number of patterns K and number of groups M .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .</head><label>7</label><figDesc>The inferred movement patterns and their co-occurrence groups. In each rows, three images in the left indicates the examples of movement patterns. Other images in the rightside depict their groups. The color of each pattern indicates the direction of the pattern, from red to blue. The bar in each picture in the rightside of each rows represents the µm of each Gaussian group. The gray-scaled color in the bar indicates the occurrence probability of a pattern, where a white color shows a high probability. It means that the white entries of the bar show the major patterns of the group in the corresponding picture. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 .</head><label>8</label><figDesc>Illustration of diverse path prediction results in different groups. The solid lines indicate the ground truth trajectories and dot lines denote the predicted paths. The green arrows indicate the other possible directions if the co-occurrence groups are changed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 .</head><label>9</label><figDesc>Path prediction results of Walkers'<ref type="bibr" target="#b42">[43]</ref> for CI dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 .</head><label>10</label><figDesc>Qualitative Prediction Results for PWPD dataset<ref type="bibr" target="#b44">[45]</ref>. (a) Extracted patterns of ours, (b) Our prediction results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 10 -</head><label>10</label><figDesc>(b) describes examples of path prediction results. The results show that our model successfully predicts the future when the object(human) does not loiter, as in Figure 10-(b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>This work was partly supported by the ICT RD program of MSIP/IITP[B0101-15-0552, Development of Predictive Visual Intelligence Technology] and the Brain Korea 21 Plus Project.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Table 1. Quantitative results of cross-street dataset. MHD indicates modified Hausdorff distance</figDesc><table>Video 

measure 
Human Proposed Proposed(2) W14(1) W14(2) K12 
B(1) 
B(2) 
B(3) 
QMUL Precision 
99.37 
92.14% 
-
-
-
-
67.36% 73.14% 49.58% 
MHD [12] 23.32 
23.38 
11.65 
49.36 
76.20 
86.73 
41.90 
35.34 
65.70 
ECD 
45.71 
50.19 
36.80 
85.5 
115.29 
107.43 71.47 
59.51 
88.05 
CI 
Precision 
99.20 
91.49% 
-
-
-
-
63.29% 65.42% 55.31% 
MHD 
21.22 
27.89 
14.72 
62.03 
115.51 
127.62 45.04 
43.91 
49.68 
ECD 
40.15 
44.95 
28.60 
92.50 
150.43 
143.60 63.29 
56.15 
68.59 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Human motion prediction considering environmental context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ardiyanto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Miura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th IAPR International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="390" to="393" />
		</imprint>
	</monogr>
	<note>Machine Vision Applications (MVA)</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A markovian decision process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bellman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1957" />
		</imprint>
		<respStmt>
			<orgName>DTIC Document</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Probabilistic topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="77" to="84" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Video anomaly detection and localization using hierarchical feature representation and gaussian process regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-W</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-H</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2909" to="2917" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Knowledge discovery through directed probabilistic topic models: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Daud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Muhammad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers of computer science in China</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="280" to="301" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Efficient samplingbased approaches to optimal path planning in complex cost spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Devaurs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Siméon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cortés</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Algorithmic Foundations of Robotics XI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="143" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Conjugate priors for exponential families</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ylvisaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of statistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="269" to="281" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A note on two problems in connexion with graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W</forename><surname>Dijkstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numerische mathematik</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="269" to="271" />
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mid-level visual element discovery as discriminative mode seeking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="494" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">What makes paris look like paris?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A modified hausdorff distance for object matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-P</forename><surname>Dubuisson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th IAPR International Conference on</title>
		<meeting>the 12th IAPR International Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1994" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="566" to="568" />
		</imprint>
	</monogr>
	<note>Pattern Recognition</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Extracting and locating temporal motifs in video scenes using a hierarchical non parametric bayesian model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Emonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Odobez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3233" to="3240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning collections of part models for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Endres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiaa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="939" to="946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Predicting object dynamics in scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Fouhey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2027" to="2034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A markov clustering topic model for mining behaviour in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1165" to="1172" />
		</imprint>
	</monogr>
	<note>Computer Vision</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Action-reaction: Forecasting the dynamics of human interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2014</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="489" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Model predictive path planning with time-varying safety constraints for highway autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jalalmaab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fidan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Falcone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Robotics (ICAR), 2015 International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="213" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Two-stage online inference model for traffic pattern analysis and anomaly detection. Machine vision and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Choi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1501" to="1517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Blocks that shout: Distinctive parts for scene classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Juneja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jawahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="923" to="930" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ziebart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<title level="m">Activity forecasting. Computer Vision-ECCV 2012</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="201" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning spatio-temporal structure from rgb-d videos for human activity detection and anticipation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Koppula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saxena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning (ICML-13)</title>
		<meeting>the 30th International Conference on Machine Learning (ICML-13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="792" to="800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Anomaly detection in extremely crowded scenes using spatio-temporal motion pattern models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kratz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nishino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1446" to="1453" />
		</imprint>
	</monogr>
	<note>CVPR 2009. IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">What&apos;s going on? discovering spatio-temporal dependencies in dynamic scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kuettel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Breitenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1951" to="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Planning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Lavalle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Randomized kinodynamic planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Lavalle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Kuffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="378" to="400" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Prediction of human activity by discovering temporal sequence patterns. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1644" to="1657" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adaptive informative path planning in metric spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">W</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Algorithmic Foundations of Robotics XI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="283" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The collapsed gibbs sampler in bayesian computations with applications to a gene regulation problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">427</biblScope>
			<biblScope unit="page" from="958" to="966" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Bayesian modelling and inference on mixtures of distributions. Handbook of statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mengersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="459" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Data-driven activity prediction: Algorithms, evaluation methodology, and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Minor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Doppa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="805" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Stacked hierarchical labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Munoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2010</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="57" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Algorithms for inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Icml</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="663" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Bayesian inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Amir</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page">61801</biblScope>
			<pubPlace>Urbana</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Remembering the past to imagine the future: the prospective brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Schacter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Addis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Buckner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="657" to="661" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Digital image processing and computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Schalkoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>Wiley</publisher>
			<biblScope unit="volume">286</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Unsupervised discovery of mid-level discriminative patches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2012</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="73" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Animal intelligence: an experimental study of the associative processes in animals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Thorndike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Psychological Review: Monograph Supplements</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1898</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Detection and tracking of point features. School of Computer Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon Univ. Pittsburgh</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Bridging the past, present and future: Modeling scene activities from event relationships and global rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Emonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Odobez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2096" to="2103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A sequential topic model for mining recurrent activities from long term video logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Emonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Odobez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="100" to="126" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Predicting actions from static scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2014</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="421" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Patch to the future: Unsupervised visual prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3302" to="3309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Unsupervised activity perception in crowded and complicated scenes using hierarchical bayesian models. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E L</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="539" to="555" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Understanding pedestrian behaviors from stationary crowd groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3488" to="3496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Maximum entropy inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Ziebart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1433" to="1438" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
