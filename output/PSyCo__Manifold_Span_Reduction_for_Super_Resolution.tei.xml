<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PSyCo: Manifold Span Reduction for Super Resolution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Pérez-Pellitero</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">TNT Lab</orgName>
								<orgName type="institution">Leibniz Universität Hannover</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Technicolor R&amp;I Hannover 3 Image Processing Group</orgName>
								<orgName type="institution">Universitat Politècnica de Catalunya</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordi</forename><surname>Salvador</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Technicolor R&amp;I Hannover 3 Image Processing Group</orgName>
								<orgName type="institution">Universitat Politècnica de Catalunya</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Ruiz-Hidalgo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">TNT Lab</orgName>
								<orgName type="institution">Leibniz Universität Hannover</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PSyCo: Manifold Span Reduction for Super Resolution</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The main challenge in Super Resolution (SR) is to discover the mapping between the low-and high-resolution manifolds of image patches, a complex ill-posed problem which has recently been addressed through piecewise linear regression with promising results. In this paper we present a novel regression-based SR algorithm that benefits from an extended knowledge of the structure of both manifolds. We propose a transform that collapses the 16 variations induced from the dihedral group of transforms (i.e. rotations, vertical and horizontal reflections) and antipodality (i.e. diametrically opposed points in the unitary sphere) into a single primitive. The key idea of our transform is to study the different dihedral elements as a group of symmetries within the high-dimensional manifold. We obtain the respective set of mirror-symmetry axes by means of a frequency analysis of the dihedral elements, and we use them to collapse the redundant variability through a modified symmetry distance. The experimental validation of our algorithm shows the effectiveness of our approach, which obtains competitive quality with a dictionary of as little as 32 atoms (reducing other methods' dictionaries by at least a factor of 32) and further pushing the state-of-the-art with a 1024 atoms dictionary.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The latest achievements in the research of examplebased SR have been possible thanks to the exploitation of the progressively deeper understanding of the structure of the natural image patch manifold. In recent years we have witnessed a shift from costly sparse coding techniques to more efficient models. In the latter, a relatively costly offline manifold learning enables light inference with various levels of efficacy in terms of complexity and accuracy <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b24">25]</ref>. The development of these two as-  <ref type="table" target="#tab_2">Table 1.</ref> pects is key for the pervasive adoption of SR, not only as an end application, but also as a pre-processing stage in vision applications where the resolution of the capture device is insufficient for scene understanding or feature detection. Within the sparse coding techniques <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b13">14]</ref>, the main idea is to enforce image pairs to have the same sparse representations over both the low resolution and the high resolution dictionaries. However, this sparsity constrain involves minimizing a L 1 norm function, both at the training and inference stage, leading to complex minimization procedures. Newer solutions to avoid sparse representations involve the use of a regression-based approach <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref>. In this case, the main goal is to infer a mapping between lowand high-resolution manifolds. This mapping, potentially complex and non-linear, is approximated by a piecewise linearization employing several linear regressors at specific anchor points. Sublinear search structures such as trees, hashing functions or forests <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b17">18]</ref> have been proposed in order to reduce the regressor search complexity. Other current light-inference solutions introduce deep neural net-works for SR with encouraging results <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. Although not necessarily light, single-image self-similarity SR have shown competitive results partly thanks to improved search strategies, such as <ref type="bibr" target="#b11">[12]</ref>. In a similar direction, there are several efforts in the literature to extend the available manifold samples. Most of the approaches aim to expand the search space by generating new data from the available one, e.g. multi-scale pyramids <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b21">22]</ref>, homographies <ref type="bibr" target="#b11">[12]</ref>, with the resultant increase in the number of search candidates.</p><p>In this paper we present PSyCo (Patch Symmetry Collapse), a method that improves the search without increasing its number of candidates. Our contributions include the use of the dihedral group (i.e. reflections and rotations) over more complex projective transformation models and the introduction of a collapsing transform κ that collapses the 16 redundant patch variations induced by the dihedral group and the antipodality. This transform has an inherently low complexity and therefore is specially suitable for fast SR algorithms and, by extension, to other patchbased methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>2.1. Problem formulation SR techniques aim to estimate a high-resolution (HR) image X from a low-resolution (LR) image Y which has an unsatisfactory pixel resolution, assuming the following generation model:</p><formula xml:id="formula_0">Y = (X * H) ↓ s,<label>(1)</label></formula><p>where H is a low-pass filter and ↓ s denotes downsampling operator for an s magnification factor. This inverse problem is usually addressed at a patch level, which we denote with small case (e.g. x, y, c) when in their original square shape and with bold small case (e.g. x, y, c) when vectorized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Dictionary learning</head><p>The usage of a pair of sparse dictionaries (D h and D l ) was popularized by the SR method of Yang et al. <ref type="bibr" target="#b26">[27]</ref>, in which they propose a sparse prior for SR. Sparse coding represents input vectors as a weighted linear combination of a small set of basis vectors, thus extracting high level patterns of the input unlabeled data and obtaining compact and meaningful dictionaries. In their sparse SR <ref type="bibr" target="#b26">[27]</ref>, the optimization of the dictionary is performed jointly for both D h and D l , resulting in great computational cost. During testing time, they minimize the following function:</p><formula xml:id="formula_1">min α y − D l α 2 2 + λ α 1 ,<label>(2)</label></formula><p>where the first term ensures a good LR reconstruction and the L 1 -norm regularization term enforces sparsity in the solution. The sparse decomposition α is then applied to D h to obtain the HR patch. Later work on sparse SR by Zeyde et al. <ref type="bibr" target="#b28">[29]</ref> introduced faster algorithms for dictionary optimization (e.g. k-SVD <ref type="bibr" target="#b0">[1]</ref>) and a different optimization scheme: the dictionaries are learned separately, obtaining first D l independently from D h , and afterwards the latter is generated with the sparse encoding of D l . The results improve both in time and quality those of the original work of Yang et al. <ref type="bibr" target="#b26">[27]</ref>. Despite alleviating some of the most time-consuming processing of its predecessor, the sparse decomposition in <ref type="bibr" target="#b28">[29]</ref> is still the bottleneck during inference time. As a natural solution for that, Timofte et al. proposed the Anchored Neighborhood Regression (ANR) <ref type="bibr" target="#b20">[21]</ref> where there is no sparse decomposition during inference time, but instead a selection within a discrete set of points (i.e. anchor points) for which a linear ridge regressor has been trained off-line. This method coincided with other similar regression-based SR algorithms such as <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>, and also triggered several follow-ups, e.g. <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b16">17</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Coarse to fine regression</head><p>Regression-based SR tackles the upscaling problem by estimating the mapping function between the LR and the HR manifolds, most commonly through an off-line learning stage. Under a locally linear assumption <ref type="bibr" target="#b3">[4]</ref>, this function can be split into several piecewise linear regression functions that are trained with a subset of the full training set, e.g. a cluster or neighborhood. For the sake of clarity, we introduce the regression framework using the opening work of ANR <ref type="bibr" target="#b20">[21]</ref>, as this is fundamentally the framework we use in our proposed method.</p><p>Let us denote by D l the set of k anchor points and D h the correspondent HR counterparts, both of them obtained with k-SVD as in the scheme of Zeyde et al. <ref type="bibr" target="#b28">[29]</ref>. For each atom d i in D l , a certain neighborhood or cluster N i l is found through a nearest neighbor (NN) search from a training pool of examples, which in ANR is the same D l . The associated ridge regressor R i is then trained with the closed form expression</p><formula xml:id="formula_2">R i = N i h (N i ⊺ l N i l + λI) −1 N i ⊺ l .</formula><p>During inference, the closest anchor point d * to the input features y F is obtained through NN search and the associated regressor R * is applied in the following form:</p><formula xml:id="formula_3">x = c + R * y F ,<label>(3)</label></formula><p>where c is a first coarse approximation of x (obtained by e.g. bicubic, Iterative Back Projection (IBP) <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b26">27]</ref>). In the later A + <ref type="bibr" target="#b21">[22]</ref> and the Dense Local Regressor <ref type="bibr" target="#b16">[17]</ref>, N l is obtained from a large pool of training samples (in the order of millions), which greatly improves quality results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Search space and manifold collapse</head><p>Finding meaningful examples for SR is crucial both for internal learning (where the search space is limited by the    image) and external learning. In this direction, Timofte et al. <ref type="bibr" target="#b21">[22]</ref> proposed to generate new training data from different multi-scale images, Zhu et al. <ref type="bibr" target="#b29">[30]</ref> proposed to deform patches based on optical flow and, more recently, Huang et al. <ref type="bibr" target="#b11">[12]</ref> incorporate 3D scene geometry for cross-scale selfsimilarity using a modified PatchMatch <ref type="bibr" target="#b1">[2]</ref>. Another approach to improve the NN search consists in reducing variability of the manifold through the knowledge of its redundancy. In the early work of Freeman et al. <ref type="bibr" target="#b8">[9]</ref>, the concept of improving the NN search through the collapse of the manifold's variability was already addressed. In their learning process, to predict the highest frequency band they only consider the mid-frequency band and discard the rest of low-frequencies (LF), thus collapsing the training data for all possible LF values into one value. Similarly in concept, when subtracting the mean to a patch, all possible means are mapped to a single 0-mean patch. The benefit of removing the undesired variability of the manifold versus generating more data is obvious as the first one obtains the same advantages while not increasing the number of search candidates. In this paper we further deepen the knowledge of natural image patch manifold, analyzing the redundancy present within the manifold due to the dihedral group of transforms (i.e. rotation, vertical and horizontal reflections), which are invariant across scales and easily invertible (i.e. a lossless f −1 (x) exists).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Reducing the manifold span</head><p>In this section we first overview two basic patch preprocessing steps (mean subtraction and normalization) and their effects within the manifold, followed by a geometric transformation model that can reduce the manifold span (extended in Section 4) and its analysis in the Discrete Cosine Transform (DCT) space. An overview of the presented transformation is shown in <ref type="figure" target="#fig_4">Fig. 2.</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Mean subtraction and normalization</head><p>Mean subtraction is an inexpensive process widely adopted in SR applications, as it is specially beneficial since the mean presents no variations across scales. Bevilaqua et I -I g 0 g 1 g 2 g 3 g 4 g 5 g 6 g 7 <ref type="figure">Figure 3</ref>: D 4 dihedral transforms applied to a 20x20 patch and its corresponding antipodal versions denoted with −I.</p><p>al. <ref type="bibr" target="#b2">[3]</ref> concluded in their feature analysis that the centered luminance patches are the best suited for their non-negative neighbor embedding SR. Within the manifold structure, mean subtraction collapses all the possible patches to lie on the hyperplane 1 ⊺ x = 0, as shown in <ref type="figure" target="#fig_4">Fig. 2b</ref>.</p><p>Patch normalization is also a simple yet effective process very present in low-level vision, often interpreted as an illumination normalization. Patch normalization removes the undesired variability derived from scalar multiplication: All positive scalar variations are represented by a single unitary vector (i.e. a certain patch structure). In terms of manifold transformation, normalization enforces the patches to lie in the unitary hypersphere, as we show in <ref type="figure" target="#fig_4">Fig. 2c</ref>. The combination of both mean subtraction and normalization limits the span of the manifold to the intersection of the mean hyperplane and the unitary hypersphere, a ring in the 3dimensional example of <ref type="figure" target="#fig_4">Fig. 2d.</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Antipodality</head><p>Antipodal points (i.e. points that are diametrically opposed in the unitary sphere: x A = −x) cannot be properly collapsed by patch normalization as norms are strictly positive, so any two normalized antipodal points are located at the furthest away Euclidean distance (the diameter of the hypersphere) while actually the structure of the patch is exactly the same (see <ref type="figure">Fig. 3</ref>). In our previous work we already introduced antipodal invariance for SR <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b14">15]</ref>. It is possible to collapse antipodal variability together with dihedral transformations as described in Section 4 and illustrated in <ref type="figure" target="#fig_4">Fig. 2e-2f.</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Transformation models</head><p>Within the space of patches, numerous 2D geometric transformations have been proposed in order to model physical displacements in the 3D world, improve invariance to those transforms (e.g. rotation for object detection) or expand the search space both in testing and training. A general model for such transformations is the projective transformation model, also referred as homography or collinearity.</p><p>The projective transformation properly describes the possible transformations of a pinhole camera when moving to an arbitrary viewpoint. Homographies are widely used in several applications involving multiple cameras or camera motion <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11]</ref>, and they have been also used recently in SR <ref type="bibr" target="#b11">[12]</ref> in order to increase the number of relevant patches in the NN search.</p><p>Homographies show two main drawbacks when applied to SR. Firstly, as small patches present a very scarcely sampled grid, transforming its geometry requires interpolating values, which leads to a high-frequency loss. Secondly, the homography transform has 8 degrees of freedom, therefore being computationally expensive to explore and estimate (e.g. Huang et al. <ref type="bibr" target="#b11">[12]</ref> use an affine transform enriched with some perspective deformation limited to a discrete set of detected planes).</p><p>In this paper, we propose the usage of the dihedral group D 4 (for polygons of 4 sides, e.g. patches) <ref type="bibr" target="#b22">[23]</ref>, which is a subset of affine transformations that only includes rotations and reflections. This finite group G = {g j } 7 j=0 contains 8 structure-preserving transforms which just re-distribute the elements within a patch and therefore do not require any interpolation. We can obtain the set of 8 dihedral transforms G via a combination of the following matrices in the 2D space:</p><formula xml:id="formula_4">gx = −1 0 0 1 , gy = 1 0 0 −1 , g⊺ = 0 1 1 0 ,<label>(4)</label></formula><p>where g x and g y denote the reflections along the x and y axis respectively, and g ⊺ denotes the transpose operation. All the transforms forming the dihedral group are linear and scale invariant, and a straightforward inverse function exists. In <ref type="figure">Fig. 3</ref> we show the behavior of the dihedral group of transforms and how they affect a given patch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Dihedral group in the DCT space</head><p>In this section we analyze the effect of the dihedral group G in the domain of the DCT, as there are some useful properties that lay the groundwork for our proposed method. x(m, n) cos π(m+ 1 2 )k M cos π(n+ 1 2 )l N .</p><p>As the DCT is linear, applying the transpose operator (i.e. g ⊺ in the 2D space) results in a transpose in the transformed space, i.e. b ⊺ = f DCT (x ⊺ ). As for the reflection operators (i.e. g x and g y in the 2D space), they result in a change of sign in some of its components:</p><formula xml:id="formula_6">b gx (k, l) = b(k, l) · (−1) l b gy (k, l) = b(k, l) · (−1) k .<label>(6)</label></formula><p>The behavior of the proposed dihedral transforms in the DCT space is therefore reduced to transpositions and sign changes in a defined set of coefficients. <ref type="figure">Fig. 5</ref> left shows which components of the DCT are expected to change whenever there is a reflection or transposing operator. This simple and predictable behavior in the DCT space facilitates the observation of mirror symmetries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Manifold symmetries</head><p>The transform group G presented in Section 3.3 defines 8 points in the M×N -dimensional manifold of natural patches for a given patch primitive x (see <ref type="figure">Fig. 5 right)</ref>. This is a dihedral symmetric shape within the manifold surface, since a symmetric structure is defined if there exists a non-trivial group of action that defines an isomorphism. Our goal is to exploit the symmetries defined by G together with antipodality in order to efficiently collapse redundant variability of our manifold span.</p><p>Our proposed Symmetry-Collapsing Transform (SCT) builds on the work of Zabrodsky et al. <ref type="bibr" target="#b27">[28]</ref>, where they proposed a continuous Symmetry Distance (SD) which measures how symmetric a given structure is. This metric δ is defined in the shape space Ω, where each shape is represented by a sequence of r points {P i } r−1 i=0 . The metric reads:</p><formula xml:id="formula_7">δ(P, Q) = 1 r r−1 i=0 P i − Q i 2 ,<label>(7)</label></formula><p>which is an averaged point to point Euclidean distance. In order to achieve invariance to symmetry, a Symmetry Transform (ST) of a shape P is defined as the symmetric shape closest to P in terms of Equation <ref type="formula" target="#formula_7">(7)</ref>, and thus SD is defined as SD = δ(P, ST (P )). The metric is therefore the point to point Euclidean distance of a given shape to its closest symmetric shape. Zabrodsky et al. <ref type="bibr" target="#b27">[28]</ref> present different ST depending on the type of symmetry to be accounted (e.g. rotational, mirror-symmetry). For the specific case of the mirror-ST, with a known mirror symmetry axis, the procedure for every pair of points {P 0 , P 1 } is: Fold by reflecting the point across the mirror symmetry axis obtaining P 0 ,P 1 (i.e. P 0 ≡P 0 ).</p><p>Average both points to obtain a new average point A 0 . Unfold the average point A 0 in order to obtain A 1 .</p><p>We show an overview of the original mirror-ST in <ref type="figure" target="#fig_0">Fig. 4  (steps 1 and 2a)</ref>. In the original algorithm, the ST aims to obtain a regular polygon which can be thereafter compared to the input shape in order to estimate its point to point distance. Our goal is to obtain a transform that reduces variability while respecting the SD. To achieve this reduction, we present a modified ST, which we denote as SCT, that moves all the possible symmetric points to a reference side of the mirror axis, thus reducing redundant variability. For that purpose, assuming a single mirror axis, all the points are fold into the reference side where P 0 lies, and the element of the applied symmetry group (i.e. g j ) is saved. This is similar to a mean subtraction , where all possible different means of a given patch are collapsed to a single 0-mean patch and the mean is saved in order to differentiate among them. We show an overview of our proposed SCT in <ref type="figure" target="#fig_0">Fig. 4 (steps 1 and 2b)</ref>, where we highlight that the resulting distances are conserved with respect to the original algorithm. Although folding the points back to their original position is not necessary for the distance calculation in our SCT, we can do it at any point as the inverse SCT.</p><p>The initial ST and SD extend to any finite pointsymmetry group G in any dimension, where the folding and unfolding are performed by applying the group elements <ref type="bibr" target="#b27">[28]</ref>. However, when extending to more than 3D, finding the symmetry axes that minimize SD is non-trivial.</p><p>In order to (a) keep the transform under a reasonable complexity, (b) easily and analytically find the mirror axes of G and (c) benefit from behavior of G in the DCT domain, we propose a representation based on the first vertical and horizontal harmonics b(1, 0) and b(0, 1). Each of these coefficients is affected only by one reflection and the transpose is plainly mapped to a coefficient switch. Semantically, b(1, 0) and b(0, 1) are the coefficients statistically containing more energy that represent the response to vertical and horizontal variations, resembling the original vertical and horizontal 2D space of Zabrodsky et al. <ref type="bibr" target="#b27">[28]</ref>. The three resulting mirror planes are straightforwardly obtained as b(1, 0) = 0, b(0, 1) = 0 and |b(1, 0)| − |b(0, 1)| = 0, as shown in <ref type="figure">Fig. 5</ref> right. At this stage, there is still ambiguity within this projected space as an antipodal point can be confused by a patch affected by vertical and horizontal reflections (as both vertical and horizontal coefficients have a sign change). In order to disambiguate, we include another dimension and a fourth mirror plane in b(3, 3) = 0 which is not affected by transpose, nor vertical or horizontal reflection (as it is a DCT base with inner dihedral symmetry). This fourth axis, which we fold in the first place, represents the negative unitary matrix −I (i.e. sign change) to be applied both patch-wise and within the DCT domain before collapsing the rest of symmetries.</p><p>The final proposed transformc = κ(c, ϕ(c)) produces  <ref type="figure">Figure 5</ref>: Left: Coefficients of a DCT that are affected by g x , g y (resulting in a sign change, Eq. 6) and g ⊺ (resulting in a transpose of coefficients). Right: Overview of our κ(x, ϕ(x) with real patches, highlighting the symmetry axes associated to each operator. collapsed patches (denoted by the ring accent) using the four defined axes, where g j = ϕ(c) retrieves the element within the group G together with the disambiguation of the sign (i.e. −I when b(3, 3) &lt; 0 ). The inverse c = κ −1 (c, ϕ(c)) applies the same elements of the symmetry group that were used in the collapse in a reverse order, restoring the patch to its original appearance.</p><formula xml:id="formula_8">g T g x g y -1 0 1 -1 0 1 o κ -1 (x, ϕ(x)) g y g x g T o κ(x, ϕ(x))</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Application to SR</head><p>In this section we propose a novel SR algorithm that makes use of our proposedc = κ(c, ϕ(c)), which we name PSyCo (Patch Symmetry Collapse). As briefly mentioned in the related work, we build on the ANR <ref type="bibr" target="#b20">[21]</ref> framework of anchored regression. We denote 0-mean patches with the line accent (e.g. c). The main idea is to train our regression ensemble (both k anchor points in D l and the associated regressors {R i }) with the ground truth and coarse collapsed patches {x,c} so that during training time the system is optimized for the reduced span of the manifold which is to be used. We obtain our coarsely approximated images C with IBP as presented in <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b14">15]</ref>. The k-SVD input is a matrix of 0-mean patches without symmetric redundancy which have  been stacked as columns, denoted byC. After that, a NN search with the angular similarity d⊺ ic is performed for each atom d i in D l to construct each neighborhood C i as a fixed-size subset of the whole training data C. Once the anchor points and neighborhoods have been defined, each regressor R i is trained with the following closed-form expression:</p><formula xml:id="formula_9">R i = (1 + λ)(X i −C i )C i ⊺ (C iCi ⊺ + λI) −1 . (8)</formula><p>During inference time, the NN search and regression is performed with d ,c and after regression the symmetric transformation needs to be reverted so that the patches recover their original orientation. The regression stage reads:</p><formula xml:id="formula_10">x = c + κ −1 (R * c , ϕ(c)),<label>(9)</label></formula><p>and the final imageX is obtained by an overlapping reconstruction strategy, as it is common in SR <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b18">19</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Configuration</head><p>In this section we validate the contributions of our proposed transform, assessing the impact of collapsing each of the axes separately, and also the combination of those exclusively corresponding to the dihedral group G and the impact of the complete system, which also tackles antipodal symmetries. <ref type="figure" target="#fig_7">Figure 6a</ref> shows PSyCo with several mirroraxes configurations and dictionary sizes. First, we would like to asses the benefits of our symmetric transform when compared to untransformed patches. The quality is around 0.4 dB higher for small dictionary sizes (e.g. 16, 32) and around 0.2 dB for 1024 atoms. We find remarkable the fact that our symmetry transform performs always slightly better than a ×16 times larger dictionary without any symmetry accounted. This supports the idea that with our manifold collapse we can effectively cover the 16 different appearances of a given primitive patch without increasing the search space, plus an additional quality gain as the training of the regressors is better (i.e. due to more meaningful patches in the neighborhoods).</p><p>When it comes to assess the incidence of each type of transform separately, we find that all have similar impact, being the antipodal symmetry slightly better-performing than the reflection or the transpose. We also note that each symmetry axis is roughly comparing equally to a ×2 − 4 times larger untransformed dictionary. The dihedral symmetries together surpass that of the antipodal, and we observe that its quality performance surpasses by a great margin that of the ×8 larger dictionary without any symmetry.</p><p>In <ref type="figure" target="#fig_7">Fig. 6b and 6c</ref> we show the behavior of the only two parameters to be selected in our SR algorithm. The neighborhood size has higher impact and its optimal value increases for smaller dictionary sizes (as each neighborhood covers more span within the manifold). The regularization weighting term λ has a lesser impact and its optimal value increases for big neighborhoods and small dictionaries. We also note that λ = 0.2 is a good compromise across all possible configurations, and thus we recommend its usage for a first approach when optimizing the neighborhood size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results</head><p>We perform several experiments comparing with current SR state of the art. The experimental set-up is:</p><p>Datasets: We perform our SR benchmarking with Set5, Set14, kodak and Urban100 ( <ref type="bibr" target="#b11">[12]</ref> used different resolutions for each s, we set the resolution corresponding to s = 4 for all s). Compared methods: We compare against the current SRCNN deep learning method presented by Dong et al. <ref type="bibr" target="#b6">[7]</ref> with their recommended 9-5-5 network (note the superior performance when compared to the 9-1-5 network of their earlier publication <ref type="bibr" target="#b5">[6]</ref>), the A + anchored regression algorithm of Timofte et al. <ref type="bibr" target="#b21">[22]</ref>, the recently published SR forest with alternative training ASRF of Schulter et al. <ref type="bibr" target="#b18">[19]</ref> and the Transformed Self-Exemplars Single-Image SR of Huang et al. <ref type="bibr" target="#b11">[12]</ref>. Conditions: We present two different configurations, with 32 and 1024 atoms. For the first one, we set a neighborhood size of 42000 and λ = 0.25; for the second one the neighborhood size is set to 2750 and λ = 0.18. We train A + , ASRF and PSyCo with Bicubic SRCNN <ref type="bibr" target="#b6">[7]</ref> ASRF <ref type="bibr" target="#b18">[19]</ref> A+ <ref type="bibr" target="#b21">[22]</ref> PSyCo (1024) Ground Truth <ref type="figure">Figure 7</ref>: Close-ups of the results for visual qualitative assessment of a ×4 magnification factor from the datasets in the benchmark. Best-viewed zoomed in.   <ref type="bibr" target="#b19">[20]</ref>, which has the highest correlation with perceptual scores for SR evaluation <ref type="bibr" target="#b23">[24]</ref>. Additionally, for those methods which depend on a dictionary, we test a ×2 upscaling factor on Set14 for several dictionary sizes and measure PSNR and times (see <ref type="figure" target="#fig_0">Fig. 1</ref>) to compare performances for equal dictionary sizes. Evaluation: In <ref type="table" target="#tab_2">Table 1</ref> we show the averaged PSNR, IFC and times of the benchmark. PSyCo with 1024 atoms obtains the best PSNR values, around 0.3dB higher across all s and datasets when compared to the most related algorithm A + . We also outperform the most competitive methods (SRCNN and ASRF) in PSNR by up to 0.3dB. In terms of time, both our configurations are the fastest of the benchmark, specially our proposed (32), which is an order of magnitude faster than any other method. We also note that our methods are trained in less than two hours, which contrasts with the SRCNN method trained with Ima-geNet. The measured IFC values are consistently the highest among the benchmark, and we highlight the fact that for most s, PSyCo with 32 atoms obtains the runner-up IFC, confirming the good performance of our time-and memoryeffective configuration. In <ref type="figure">Fig. 7</ref> we show some quantitative results. We highlight the generally sharper edges and the less proliferation of ringing and aliasing artifacts which results in better preserved structures (e.g. first row in <ref type="figure">Fig. 7</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>In this paper we present a new method for regressionbased SR that builds around a novel manifold collapsing transform κ. This transform eliminates the undesired variability of the manifold due to the dihedral group of symmetries (i.e. rotation, vertical and horizontal reflections) and the antipodal symmetry (i.e. points that are diametrically opposed in the unitary sphere). Our contributions are: (1) We recommend the use of the dihedral transformation group over more complex projective transformation models. The dihedral group is specially suitable for SR as it is scale invariant and easily invertible. Furthermore, we perform a frequency analysis of the dihedral group in the DCT domain, where the group members are mapped as a combination of transpose and sign changes. (2) We modify the ST of Zabrodsky et al. <ref type="bibr" target="#b27">[28]</ref> by skipping point averaging and unfolding, so that the resulting transform collapses the variability of the data while still preserving the original SD. (3) We select a set of projections for which we define symmetry axes corresponding to those of the dihedral and antipodal symmetries. The complexity of our proposed κ is inherently low, as it requires as little as 3 inner products and a matrix re-ordering (i.e. g j ). We exhaustively test our transform applied to SR, and also compare it with other recent state of the art. We consistently obtain ×16 − ×32 smaller dictionaries when aiming at a certain PSNR (see <ref type="figure" target="#fig_0">Fig 1)</ref>. For a fixed dictionary size, we greatly improve in terms of quality both objectively and qualitatively. Our method with 1024 atoms greatly surpasses the state of the art in terms of PSNR and IFC, and with a 32 atoms dictionary we achieve competitive quality while being an order of magnitude faster.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>PSNR vs time (s) of our algorithm compared to other SR methods for dictionary sizes from 16 to 2048, in power-of-two increments. Experiment run on Set14 and ×2 magnification factor. Circled points are found in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Reduction of the manifold's span and complexity by the procedures introduced in Section 3. The manifold is composed of three dimensional (i.e. 3 × 1) patches in the range of [−1, 1] extracted from images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>The DCT b of a patch x of size M ×N reads: b(k, l) =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Mirror-Symmetry Transform of a single pair of points as proposed by Zabrodsky et al.<ref type="bibr" target="#b27">[28]</ref> (1 and 2a) and our proposed SCT (1 and 2b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Different configurations of PSyCo. (a) Shows the PSNR performance for different mirror symmetries, (b) shows the impact of the neighborhood size and (c) the impact of the regularization weighting term λ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Performance of ×2, ×3 and ×4 magnification in terms of averaged PSNR (dB), IFC and execution time (s) on datasets Set5, Set14, Kodak and Urban100. Best results in bold and runner-up in blue.the same 91 images provided by Yang et al. in their sparse coding SR<ref type="bibr" target="#b26">[27]</ref>. As for SRCNN, we use the network provided by their authors which has been trained with the Im-ageNet dataset (in the order of hundred thousand images). Implementation: For the compared methods we used the code publicly available from the author's website. Our code is a MATLAB + MEX implementation. Experiments: We upscale images by the magnification factors ×2, ×3 and ×4 with the authors' recommended configurations and measure PSNR, time and Information Fidelity Criterion (IFC)</figDesc><table></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgment This work was supported in part by the project TEC2013-43935-R, financed by the Spanish Ministerio de Economía y Competitividad and the European Regional Development Fund; in part by the ERC-Starting Grant (Dynamic MinVIP) and the Cluster of Excellence rebirth.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An algorithm for designing overcomplete dictionaries for sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bruckstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>K-Svd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Patchmatch: A randomized correspondence algorithm for structural image editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Low-complexity single-image superresolution based on nonnegative neighbor embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bevilacqua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roumy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guillemot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-L</forename><surname>Alberi-Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Superresolution through neighbor embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep network cascade for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning a deep convolutional network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Image superresolution using deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>TPAMI</publisher>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">99</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Homography based multiple camera detection and tracking of people in a dense crowd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eshel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Moses</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning low-level vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Pasztor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">T</forename><surname>Carmichael</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Super-resolution from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Glasner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bagon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Auto-directed video stabilization with robust l1 optimal camera paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grundmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kwatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Essa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Single image super-resolution from transformed self-exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Improving resolution by image registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVGIP: Graphical Models and Image Processing</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Geometry constrained sparse coding for single image superresolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Antipodally invariant metrics for fast regression-based super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pérez-Pellitero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ruiz-Hidalgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Half hypersphere confinement for piecewise linear regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pérez-Pellitero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ruiz-Hidalgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast super-resolution via dense local training and inverse regressor search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pérez-Pellitero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ruiz-Hidalgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Naive Bayes Super-Resolution Forest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pérez-Pellitero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fast and accurate image upscaling with super-resolution forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leistner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An information fidelity criterion for image quality assessment using natural scene statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>De Veciana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Anchored neighborhood regression for fast examplebased super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">D</forename><surname>Smet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A+: Adjusted anchored neighborhood regression for fast super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">D</forename><surname>Smet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Geometric segmentation of perspective images based on symmetry groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Single-image super-resolution: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fast direct superresolution by simple functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fast image superresolution based on in-place example regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Image super-resolution via sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2861" to="2873" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Symmetry as a continuous feature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zabrodsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Avnir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="1995-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On single image scale-up using sparse-representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zeyde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Protter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conf. on Curves and Surfaces</title>
		<meeting>International Conf. on Curves and Surfaces</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Single image superresolution using deformable patches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
