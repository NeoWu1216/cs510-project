<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">When Naïve Bayes Nearest Neighbors Meet Convolutional Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilja</forename><surname>Kuzborskij</surname></persName>
							<email>kuzborskij@dis.uniroma1.it</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer</orgName>
								<orgName type="department" key="dep2">Control and Management Engineering</orgName>
								<orgName type="institution">Sapienza Rome University</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">3É cole Polytechnique Fédérale de Lausanne (EPFL)</orgName>
								<orgName type="institution">Idiap Research Institute</orgName>
								<address>
									<country>Switzerland, Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Maria</forename><surname>Carlucci</surname></persName>
							<email>fmcarlucci@dis.uniroma1.it</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer</orgName>
								<orgName type="department" key="dep2">Control and Management Engineering</orgName>
								<orgName type="institution">Sapienza Rome University</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
							<email>caputo@dis.uniroma1.it</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer</orgName>
								<orgName type="department" key="dep2">Control and Management Engineering</orgName>
								<orgName type="institution">Sapienza Rome University</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">3É cole Polytechnique Fédérale de Lausanne (EPFL)</orgName>
								<orgName type="institution">Idiap Research Institute</orgName>
								<address>
									<country>Switzerland, Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">When Naïve Bayes Nearest Neighbors Meet Convolutional Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Since Convolutional Neural Networks (CNNs) have become the leading learning paradigm in visual recognition, Naive Bayes Nearest Neighbor (NBNN)-based classifiers have lost momentum in the community. This is because (1) such algorithms cannot use CNN activations as input features;</head><p>(2) they cannot be used as final layer of CNN architectures for end-to-end training , and (3) they are generally not scalable and hence cannot handle big data. This paper proposes a framework that addresses all these issues, thus bringing back NBNNs on the map. We solve the first by extracting CNN activations from local patches at multiple scale levels, similarly to <ref type="bibr" target="#b12">[13]</ref>. We address simultaneously the second and third by proposing a scalable version of Naive Bayes <ref type="bibr" target="#b6">[7]</ref>). Results obtained using pre-trained CNNs on standard scene and domain adaptation databases show the strength of our approach, opening a new season for NBNNs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The current easy access to terabytes of visual data, combined with the impressive ability of deep learning algorithms to exploit them, has led to a paradigm shift in visual recognition over the last few years. The so called shallow architectures, i.e. learning algorithms consisting of 1-3 levels, have survived only when (a) they have been able to scale over very large amount of data and classes ( i.e. ≥ 10 6 and ≥ 10 3 respectively); (b) they could be used as the final layer of Convolutional Neural Network (CNN)s, allowing for end-to-end learning, and/or (c) they could use effectively the activation layers of pre-computed CNNs <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b2">3]</ref> as input features. All shallow architectures which do not comply with these requirements have started to fade away.</p><p>One of those fading algorithms is the Naïve Bayes Near-est Neighbour (NBNN) classifier <ref type="bibr" target="#b1">[2]</ref>. Indeed, the key requisites of NBNN-based approaches do not fit well with CNNs.</p><p>To begin with, they require local feature representations without any vector quantization, as opposed to the global feature representation derived from the CNN activation layers <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b2">3]</ref>. Moreover, NBNN-based algorithms rely on the Image-2-Class (I2C) paradigm: for every image, each local descriptor is considered as independently sampled from a class-specific feature distribution. Hence, each descriptor votes for the most probable class, and the collection of votes is used to label each image. As opposed to that, CNNs operate on another classification principle. These two intrinsic features of NBNN approaches led to a strong generalization ability, showcased by remarkable results in place classification <ref type="bibr" target="#b6">[7]</ref> and domain adaptation <ref type="bibr" target="#b41">[42]</ref>. Still, as of today no solution has been found for bridging these two approaches. This paper fills this gap. We propose a simple way to compute local features from whole images, using pretrained CNNs. Our starting point is the paper of Gong et al. <ref type="bibr" target="#b12">[13]</ref>, on which to a large extent we build. We extract CNN activations for local patches at multiple scale levels. As opposed to <ref type="bibr" target="#b12">[13]</ref>, we do not perform any pooling or concatenation. The resulting features can be used directly as input to any NBNN-based classifier. However, the total number of examples can be very large, especially when doing a dense sampling for the patches and tackling large scale problems. To deal with this, while at the same time maximizing the predictive power of NBNN-based approaches, we propose a scalable version of Naive Bayes Non-linear Learning (NBNL, <ref type="bibr" target="#b6">[7]</ref>). NBNL tries to circumvent limitations of NBNN through non-linear learning powered by Latent Locally-Linear SVM <ref type="bibr" target="#b7">[8]</ref>, that to our knowledge is the current state of the art among NBNN-based classifiers. Our stochastic algorithm retains the generality and robustness of the original method, yet it wins by having low memory footprint. At the same time, it considerably increases its scalability during training, making it applicable also to problems with hundreds of classes, where a dense sampling strategy might lead to 10 7 features or more. Moreover, we show that our smoothed version of NBNL could in principle be used as final layer for an end-to-end training of a CNN. <ref type="figure">Figure 1</ref> shows schematically the whole framework.</p><p>We assess our approach on scene recognition and domain adaptation datasets. These two research areas are those where NBNN-based algorithms showed more promise in the pre-CNN era. We show that on the Scene 15 <ref type="bibr" target="#b21">[22]</ref>, UIUC Sports <ref type="bibr" target="#b22">[23]</ref>, and MIT Indoor <ref type="bibr" target="#b32">[33]</ref> datasets we achieve the state of the art among single-features approaches. To the best of our knowledge, these are the first results reported where an NBNN-based method achieves the state of the art not only among other NBNN-based approaches, but also among traditional techniques. Regarding domain adaptation, experiments on the Office+Caltech256 <ref type="bibr" target="#b11">[12]</ref> dataset show that by just using our approach to build a source classifier and then testing it on the target, we achieve remarkable results in the unsupervised setting, and the state of the art in the semi-supervised one. This further underlines the current power and remarkable future potential of our contribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>NBNN <ref type="bibr" target="#b1">[2]</ref> is a learning-free non-parametric image classification scheme. It proved its robustness and generalization ability on many different tasks, from image recognition <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b39">40]</ref> to domain adaptation <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b41">42]</ref> to action recognition <ref type="bibr" target="#b47">[48]</ref>. A number of works went on to improve the generalization performance of NBNN by adding layers of learning. For example, in <ref type="bibr" target="#b44">[45]</ref> the authors included a metric learning procedure, thus altering the metric space of 1-nearest neigbour. A similar idea was also investigated by Tommasi and Caputo <ref type="bibr" target="#b41">[42]</ref>, demonstrating that a plain NBNN performs very well in the domain adaptation setting, and even better when tuned-up with metric learning. Another route was pursued by works focused on patch subset selection and weighting <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b45">46]</ref>. A somewhat orthogonal direction was explored by fusing NBNN with kernel methods, proposing NBNN kernels <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b33">34]</ref>, which could be used in conjunction with linear classifiers and ultimately combined with another kernels over traditional representations. All of these methods were proposed before the advent of modern features induced by CNN, and typically were evaluated on feature descriptors such as SIFT or SURF, extracted from very small image patches. Since the seminal paper of Donahue et al. <ref type="bibr" target="#b4">[5]</ref>, the state of the art has been provided by CNNs' activations. Building on this, Gong et al. <ref type="bibr" target="#b12">[13]</ref> proposed a multiscale orderless pooling of CNN features extracted from densely sampled patches. Later, Liu et al. <ref type="bibr" target="#b24">[25]</ref> proposed a similar pooling scheme, called cross-convolutional-layer pooling, which focuses on using different convolutional layers together.</p><p>In this work, we revisit NBNN considering its power in conjunction with CNN features, in both categorization and domain adaptation scenarios. Many proposed algorithms built on top of NBNNs were thoroughly empirically studied <ref type="bibr" target="#b39">[40]</ref>. However, the amount of training data hardly ever exceeded ≈ 10 4 images. This stems from the limitations of the nearest-neighbor search -the need to store all or most of training data, and the curse of dimensionality that is often suffered by non-parametric algorithms. Some variations have been proposed to improve the time and space complexity of NBNNs. McCann and Lowe <ref type="bibr" target="#b28">[29]</ref> proposed to build one single search structure for all the classes and to consider only neighboring descriptors, thus offering an increase in performance. In Naïve Bayes Non-linear Learning (NBNL) <ref type="bibr" target="#b6">[7]</ref>, the authors retained the idea of patchbased classification as in NBNN, but followed the way of non-linear parametric classification. This allowed them to achieve a compact representation of the classes by learning a set of prototypes, allowing fast testing and improved accuracy. Unfortunately, their method was confined to the batch setting without much improvement in scalability compared to NBNN. In this paper we further develop the idea of NBNL by proposing a scalable stochastic locally-linear formulation, drawing inspiration from <ref type="bibr" target="#b6">[7]</ref> and <ref type="bibr" target="#b7">[8]</ref>.</p><p>Many works in machine learning, such as <ref type="bibr" target="#b35">[36]</ref>, reside on the assumption that, although natural data live in a high-dimensional space, they are embedded into a low-dimensional manifold. Such algorithms try to learn about the manifold under the assumption that looking close enough, or locally, it appears approximately linear, thus can be captured by an hyperplane. A well-known stream of works on Local Coordinate Coding (LCC) <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b43">44]</ref> aims to learn the set of hyperplanes and weights that combine them locally. Often, this is done in the unsupervised way by minimizing the reconstruction error <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b51">52]</ref>. In these works a special attention is given to local weights of hyperplanes, or codes, which in visual learning problems are used as features. This approach was taken further by Locally-Linear Support Vector Machine <ref type="bibr" target="#b20">[21]</ref>, where codes are first found through clustering together with nearestneigbour search, and then hyperplanes are learned in a single optimization problem. As these methods use separate unsupervised learning stage, they are unaware of the underlying discriminative task and scalability depends on the efficiency of this pre-training. This limitation is countered in the literature on Latent SVM <ref type="bibr" target="#b5">[6]</ref> and Multiclass Latent Locally-Linear (ML3) SVM <ref type="bibr" target="#b7">[8]</ref>, where both, hyperplanes and codes are learned simultaneously through discriminative learning problem. Despite non-convexity, smart relaxations and optimization methods like Concave-Convex Procedure (CCCP), enable them to work well in practice. Unfortunately, these are typically batch algorithms with heuristical initialization <ref type="bibr" target="#b9">[10]</ref>, sometimes guided by in-domain knowledge, such as mining hard-negatives <ref type="bibr" target="#b5">[6]</ref>. Other works <ref type="figure">Figure 1</ref>: An example illustrating our framework bridging across NBNN-based methods and CNNs for the scene classification problem. Given a query image, we first compute CNN activations for local patches at different scales, from a pre-trained architecture. The resulting feature representation can be fed to any NBNN-based classifier, that will then output the image label. In the paper, we used <ref type="bibr" target="#b52">[53]</ref> as pre-trained CNNs, and a scalable version of NBNL <ref type="bibr" target="#b6">[7]</ref> as classifier. Note that the framework holds also for other choices of one or both of these two components.</p><p>proposed to scale up learning in this setting <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b30">31]</ref>, however, none of them demonstrated real scalability empirically. In this work we address these limitations proposing a simple scalable Stochastic Multiclass Latent Locally-Linear SVM, which does not require initialization tricks and easily handles the order of 10 6 training examples.</p><p>Our locally-linear formulation also conceptually reminds non-linearity used in Maxout Networks <ref type="bibr" target="#b13">[14]</ref>. However, unlike <ref type="bibr" target="#b13">[14]</ref>, the inputs are weighted and combined with controlled degree of smoothness, which allows us to use analytic form of non-linearity. Thus, Maxout non-linearity is a special case of the locally-linear rule we employ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Computing Local CNN Activations</head><p>As mentioned before, a key requirement for any NBNNbased framework is to deal with features that capture local information about the image. This concretely means to extract from each whole image a set of local patches at multiple scales, and compute feature descriptors from them. Following <ref type="bibr" target="#b12">[13]</ref>, we decide here to create orderless image representations from pre-trained CNN by extracting deep activation features from patches obtained at increasingly finer scales. The effectiveness of such features will depend on several designer choices, from the pre-trained CNN chosen, to the sampling rate for the patches, the patch size, and the computed CNN activations. In the following we discuss these points and our own designer choices. Pre-trained CNN. The first hyper-parameter to chose is the CNN architecture to be used for computing the activations. The current off-the shelf state of the art choice for this task on whole images is the Caffe implementation <ref type="bibr" target="#b16">[17]</ref>, pretrained on ILSVRC <ref type="bibr" target="#b36">[37]</ref>. We decided to follow this route here with respect to the architecture type. As one of our benchmarks is the scene classification problem, we decided to use their network trained on a hybrid dataset composed from Places-205 <ref type="bibr" target="#b52">[53]</ref> and ILSVRC <ref type="bibr" target="#b36">[37]</ref>. Note that other architectures like VGG <ref type="bibr" target="#b2">[3]</ref> or OverFeat <ref type="bibr" target="#b37">[38]</ref> could be used in the same framework. Note also that, for any given CNN ar-chitecture within this framework, fine tuning on a validation set might further improve results. Patch Extraction. The second set of hyper parameters to tune are those specifically related to the patch extraction, i.e. the sampling rate for the patches, the patches size and the number of scales. Regarding the sampling rate, we considered two patch sampling settings: (a) dense, with around 400 patches per image, and (b) sparse, with approximately 100 patches per image. Since each image has different proportions, the sampling stride was dynamically computed in order to approximately achieve the desired number of patches. Regarding the patches size and number of scales, we did set the size of the smallest patch from {16px, 32px, 64px}, and further doubled the size with each level. For example, if the size of the smallest patch is 16px and we consider 3 levels, we will extract patches of size 16 × 16px (level 1), 32 × 32px (level 2) and 64 × 64px (level 3). As level 0, we considered the whole image, where before extracting the patches, each image is resized to reduce its longest side to 200 pixels. CNN activations. Finally, we have to choose the fully connected layer of CNN, whose outputs will be used as features. The most popular choice in the literature, adopted also in <ref type="bibr" target="#b52">[53]</ref>, is to take the output of the seventh fully connected layer after ReLU transformation, that is setting all negative values to zero. We compared this setting with other possibilities, namely taking the output of the sixth layer, on some pilot experiments. We found that also in the NBNN framework the mainstream approach is the most effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Scalable Naïve Bayes Non-linear Learning</head><p>In this section we describe our main technical contribution, a novel Stochastic Multiclass Latent Locally-Linear (STOML3) SVM, designed to resolve the scalability issues of NBNN. Applied to the NBNN learning framework, it results in a scalable Naïve Bayes Non-linear Learning technique (sNBNL). First we introduce the background (sections 4.1-4.3), and present our algorithm in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Definitions</head><p>We first introduce the notation and technical definitions used in the rest of the paper. Denote with small and capital bold letters respectively column vectors and matrices, e.g. α = [α 1 , α 2 , . . . , α d ] T ∈ R d and A ∈ R d1×d2 . We will use a non-negative truncation function [x] + = max{0, x}, and for the vectors,</p><formula xml:id="formula_0">[x] + = [max{0, x 1 }, . . . , max{0, x d }] ⊤ .</formula><p>To denote the largest element of the vector, we will use notation max{x} = max{x 1 , . . . , x d }. We denote enumeration sets by [n] = {1, . . . , n} for n ∈ N. Denote by X and Y respectively the input and output space of the learning problem. Let the training instance I, w.l.o.g., be composed from n subinstances,</p><formula xml:id="formula_1">I = {x i } n i=1 . Then we denote the training set of size m by S = {(I i , y i )} m i=1</formula><p>, drawn from the probability distribution D over X n × Y. We will focus on the c-class classification problem so Y = [c], and, w.l.o.g.,</p><formula xml:id="formula_2">X = {x : x 2 ≤ 1, x ∈ R d }.</formula><p>To measure the accuracy of a learning algorithm, we have a non-negative convex loss function ℓ(f (x), y), which measures the cost incurred predicting f (x) instead of y. Finally we will denote a one nearest neighbor function w.r.t. the support set Z by π Z (x) = arg min z∈Z x − z 2 . Alternatively, for d × n neighbor matrices we will use the notation π Z (x) = arg min z∈{z1,...,zn} x − z 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Naïve Bayes Nearest Neighbor Classification</head><p>The idea behind NBNNs <ref type="bibr" target="#b1">[2]</ref> is to treat each image as a collection of uniformly or randomly sampled patches. Let I be the set containing visual descriptors of patches in the test image, let X 1 , . . . , X n be random variables taking values in the space of these descriptors, and let Y be taking values in the label set. Denoting by p Y (y|I) the unknown conditional probability density function, the NBNN predictor is,</p><formula xml:id="formula_3">f (I) = arg max y∈Y p Y (y | I) .<label>(1)</label></formula><p>The key statistical assumption made in NBNN is that patches are conditionally independent given the class. In addition, assuming that p Y (y) is uniform and switching to log-likelihood of p Y (y |I), we have that,</p><formula xml:id="formula_4">f (I) = arg max y∈Y n i=1 log(p Xi (x i | y)) .<label>(2)</label></formula><p>Since p Xi is unknown, NBNN resorts to the non-parametric Kernel Density Estimator (KDE) <ref type="bibr" target="#b15">[16]</ref> with Gaussian kernel function, and further lower-bounds the log-likelihood by Jensen's inequality, to make the predictor computationally efficient. In this form prediction involves nearest neighbor search, which can be very efficient when the intrinsic dimension of the data is small <ref type="bibr" target="#b3">[4]</ref>. Denoting the support of the class y by W y = ∪ (I ′ ,y ′ )∈S : y=y ′ I ′ , the approximated empirical NBNN predictor is then,</p><formula xml:id="formula_5">f (I) = arg min y∈Y x∈I x − π Wy (x) 2 .<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Naïve Bayes Non-Linear Learning</head><p>As NBNN is a nearest-neighbor-based approach, it shares its well-known scalability limits. Few works have explored the potential of NBNN-like schemes surpassing the order of 10 4 training examples. Here we review the recently proposed Naïve Bayes Non-linear Learning (NBNL) <ref type="bibr" target="#b6">[7]</ref> that scales NBNN through parametric learning. It will be the starting point for our scalable algorithm.</p><p>Let W = (W 1 , . . . , W c ) ∈ R d×k×c be the collection of k-sized supports of NBNN in matrix notation. Following <ref type="bibr" target="#b6">[7]</ref>, we will refer to the columns of any support W y as prototypes. We will also assume that all prototypes have bounded norm, that is w 2 ≤ τ . NBNL rests upon the observation that NBNN minimizes,</p><formula xml:id="formula_6">x∈I x − π W y (x) 2 2 = x∈I min i∈[k] x − w y,i 2 2 ≤ |I|(1 + τ ) − 2 x∈I max W ⊤ y x .<label>(4)</label></formula><p>The right hand side can be minimized over y ∈ Y, similarly as in <ref type="formula" target="#formula_5">(3)</ref>, which yields the NBNL predictor</p><formula xml:id="formula_7">f nbnl (I) = arg max y∈Y 1 |I| x∈I max W ⊤ y x .<label>(5)</label></formula><p>The key idea is that prototypes in such a predictor need not be fixed, but can be learned. Fornoni and Caputo <ref type="bibr" target="#b6">[7]</ref> proposed to learn prototypes through the regularized empirical risk minimization. Considering f nbnl , the problem would be to minimize the following over W ,</p><formula xml:id="formula_8">1 m m i=1 ℓ   1 n x∈I i max W ⊤ y i x , yi   + λ l∈Y W l 2 F .<label>(6)</label></formula><p>However, in <ref type="bibr" target="#b6">[7]</ref>, they ultimately proposed to solve a simpler relaxed problem (due to Jensen's inequality),</p><formula xml:id="formula_9">min W 1 mn mn i=1 ℓ max W ⊤ y i xi , yi + λ l∈Y W l 2 F .<label>(7)</label></formula><p>Problem <ref type="formula" target="#formula_9">(7)</ref> is generally addressed by the family of latent <ref type="bibr" target="#b5">[6]</ref> and locally-linear SVMs <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b7">8]</ref>. In particular, <ref type="bibr" target="#b6">[7]</ref> employed a non-linear ML3 Support Vector Machine (SVM) <ref type="bibr" target="#b7">[8]</ref>, which we briefly review next.</p><p>Multiclass Latent Locally-Linear (ML3) SVM. In ML3 SVM one aims to solve a problem similar to <ref type="bibr" target="#b6">(7)</ref>. ML3 SVM is a locally-linear parametric classification algorithm, where we assume that in a given small locality the optimal decision boundary is approximately linear <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19]</ref>. Usually, in locally-linear versions of SVM we consider score func-</p><formula xml:id="formula_10">tions f LL W (x) = x ⊤ W β(x), where β(x)</formula><p>is a function specifying local combination of hyperplanes W at a particular point of the input space. Typically one has to choose β(x) before solving the main optimization problem <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b20">21]</ref>. This amounts to the separate procedure dedicated just to learn and fix weights β(x). ML3 SVM addresses this by the score function with automatic weighting,</p><formula xml:id="formula_11">f ML3 W (x) = max α p ≤1,α 0 {x ⊤ W α} = [W ⊤ x] + q ,<label>(8)</label></formula><p>for any p ∈ [1; +∞] and q = p p−1 . Given a point x, this rule leads to the combination of hyperplanes, such that the margin of a combined linear classifier is maximized on x.</p><p>The objective function of ML3 SVM is non-convex, however, by posing it as a difference of convex functions, we can find a reasonably good solution by Concave-Convex Procedure (CCCP) <ref type="bibr" target="#b50">[51]</ref>. This essentially confines the algorithm to the batch setting, because we need to solve a separate convex optimization problem at every CCCP iteration. Besides its batch nature, ML3 heavily relies on heuristic weight initialization by first solving a linear SVM problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Stochastic ML3 SVM</head><p>In this section we fix the limitations of ML3 by introducing a novel scalable stochastic formulation, conceptually similar to the one of ML3. Namely, we propose a Stochastic Multiclass Latent Locally-Linear (STOML3) SVM which can run online, is free from any initialization tricks, and enjoys stationary point convergence guarantee. This stochastic formulation allows to use NBNL at scales out of reach for ML3 SVM and NBNN. We call this new version, the scalable NBNL (sNBNL).</p><p>Rather than solving a regularized empirical risk as in <ref type="formula" target="#formula_9">(7)</ref>, we will aim at minimizing a regularized risk directly, similarly as in the popular Stochastic Gradient Descent (SGD) approach to learning. More formally, our goal is to solve,</p><formula xml:id="formula_12">min W E (x,y)∼D [ℓ(W, (x, y))] + λ l∈Y W l 2 F ,<label>(9)</label></formula><p>where we chose a differentiable multiclass logistic loss,</p><formula xml:id="formula_13">ℓ(W, (x, y)) = log   1 + r =y exp f ML3 W r (x) − f ML3 W y (x)   .</formula><p>In practice we cannot solve (9) directly, since D is unknown, thus the gradient cannot be computed. However, we can still compute an unbiased estimate of the gradient given a point (x, y) ∼ D, and thus update the solution iteratively. Alike the batch formulation of ML3 SVM, the resulting objective function is non-convex. We approach (9) through the Stochastic Majorization-Minimization (SMM) framework <ref type="bibr" target="#b26">[27]</ref>, which unlike SGD, provides a stationary point convergence guarantee, and converges faster in practice <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b34">35]</ref>. We summarize the STOML3 SVM in pseudocode, and defer its technical derivation details to the following section. The computational complexity of every STOML3 SVM update is in O(|Y|kd), however in practice we bringing it down to O(|Y|) through GPU optimization.</p><p>Connection to Neural Network Learning. Latent locally-linear classification, ML3 SVM, and STOML3 SVM can be interpreted as a variant of a shallow artificial neural network, <ref type="figure" target="#fig_0">Figure 2</ref>. The main difference between ... ... ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>One-vs-All classifier</head><p>Function of Learned Input traditional models such as multilayer perceptrons, is that the hidden layer consists of linear units (z = w ⊤ x), whereas the weights of the output layer, α are adjusted automatically depending on the outputs of hidden layer z, thus for learned w, α is a function of input x. Specifically, these weights are adjusted to maximize the margin by combining outputs of hidden units. Clearly, for different regions of the input space, resulting combinations are different, yielding non-linear decision surface.</p><p>From the artificial neural network learning point of view, it would be interesting to consider deeper architectures of STOML3. Another possibility would be to combine it with convolutional layers to investigate end-to-end locally-linear classification. We leave these directions to the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Derivation</head><p>To derive STOML3 SVM we use the Stochastic Majorization-Minimization (SMM) framework proposed by Mairal <ref type="bibr" target="#b26">[27]</ref>. SMM deals with minimization of a differentiable function that has a form of expectation, by minimizing its simpler approximate convex upper-bound. Specifically, after we sample a training example, we minimize an upper bound on the term inside of expectation with realization fixed. In our case, the objective is (9), Stochastic Multiclass Latent Locally-Linear (STOML3) SVM Input: W 0 (initial prototypes), λ ∈ R + (regularization parameter), q ≥ 1 (boundary smoothness). Output: W (learned prototypes).</p><formula xml:id="formula_14">φ(z) := [z] + q 1: A 0 k ← 0, B 0 k ← 0,W 0 k ← 0, ∀k ∈ Y . 2: for t = 1, 2, . . . do 3: Draw example (x t , y t ) ∼ D . 4: γ t ← 1 − 1 √ t 5: s k ← W t−1 ⊤ k x t , ∀k ∈ Y 6: for k ∈ Y do 7: A t k ← γ t A t−1 k + 1 √ t exp(φ(s k )) j∈Y exp(φ(sj )) ∇φ(s k )x ⊤ t 8: B t k ← γ t B t−1 k + I{k=yt} √ t ∇φ(s yt )x ⊤ t 9:W t k ← γ tW t−1 k + 1 √ t W t−1 k 10: W t k ← 1 1+λ W t k − A t k + B t k 11:</formula><p>end for 12: end for and thus for a realization (x, y) ∼ D we need to specify a convex upper-bound of a regularized loss function,</p><formula xml:id="formula_15">g(W ) := ℓ(W, (x, y)) + λ l∈Y W l 2 F .<label>(10)</label></formula><p>More formally, in SMM such a convex upper-bound is called the surrogate function of an objective, defined as:</p><p>Strongly Convex First-Order Surrogate Functions <ref type="bibr" target="#b26">[27]</ref>. Fix V ∈ R d×k×c , and let h be a strongly convex function such that h ≥ g and h(V ) = g(V ). Let h − g be differentiable and the gradient ∇(h−g) be L-Lipschitz continuous. We will call h the first order surrogate function of g.</p><p>We can choose among many different surrogates, but we have to keep in mind that it should be easily minimized with every incoming training example. That said, we choose,</p><formula xml:id="formula_16">h(W ) = g1(V ) + ∇g1(V ) ⊤ (W − V ) + L 2 W − V 2 + g2(W ) ,</formula><p>where g 1 = ℓ, g 2 is the regularizer. This choice is motivated by efficiency, because we can find minimum of h(W ) analytically. It is also not hard to see that h is a strongly convex first-order surrogate function. Thus, given optimal W , the rest of the derivation follows the optimization template of Mairal <ref type="bibr" target="#b26">[27]</ref>, summarized in our pseudocode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In this section we test experimentally our framework. We considered two tasks, scene recognition and domain adaptation, where in the past NBNN methods showed promise. Our experiments aim to verify two claims: first, that such methods coupled with local CNN activations at multiple scales are able to achieve results competitive with, or even better than, end-to-end, fine tuned CNN architectures. Second, that scalable NBNL outperforms NBNN, thus paving the way for the use of our approach on large scale scenarios that have been so far prohibitive for NBNN methods. In the rest of the section we describe the datasets and experimental settings used, and the variants of our framework that were tested (Section 5.1). Section 5.2 describes the results obtained in scene recognition, exploring how the performance changes when varying the parameters relative to the patch extraction, and the scalability of the approach. Section 5.3 reports results obtained in the domain adaptation setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Settings</head><p>Datasets. For the scene recognition setting, we used the Scene 15 <ref type="bibr" target="#b21">[22]</ref>, UIUC Sports <ref type="bibr" target="#b22">[23]</ref>, and MIT Indoor <ref type="bibr" target="#b32">[33]</ref> databases. For Scene 15, we used 100 images per class for training and 100 for testing. For UIUC Sports, we used 70 images per class for training and 60 images for testing. For MIT Indoor, we used 80 images per class for training and 20 for testing. These choices are all consistent with the standard protocols reported in the literature. Each configuration is tested on 5 splits. For the large scale experiments, we used the SUN-397 database <ref type="bibr" target="#b46">[47]</ref> that totals 1.6 million image patches. We strictly followed the experimental procedure described in <ref type="bibr" target="#b46">[47]</ref>. For all scene experiments, we concatenated the CNN activations with the absolute position of every patch. For the domain adaptation scenario, we considered the Office + Caltech database <ref type="bibr" target="#b11">[12]</ref>, which contains a subset of ten classes shared between Office and Cal-tech256 <ref type="bibr" target="#b14">[15]</ref>. Here we keep 20 images per class for training (15 if the target is either Webcam or DSLR) and use the rest as test set. Each configuration was tested on 10 splits. Baselines For every scenario, for every setting, we always used the following three variants of our framework: (1) CNN-NBNN: this consists of using the NBNN classifier as originally proposed <ref type="bibr" target="#b1">[2]</ref> , combined with the local CNN activations. (2) CNN-NBNL: the same as (1), using NBNL as classifier <ref type="bibr" target="#b6">[7]</ref>. (3) CNN-sNBNL: the same as (1), (2), but using our scalable version of NBNL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Scene Classification Experiments</head><p>We performed extensive experiments over Scene 15, UIUC Sports and MIT Indoor for assessing how performance changes when varying the parameters of the CNN activation extraction. Specifically, we varied the sampling density, patch size and the number of levels. We also compared results when taking the activations before or after ReLU. As classifier, we always used NBNN (preliminary experiments using also NBNL and sNBNL did not show any significant variation in behaviors). <ref type="figure" target="#fig_1">Figure 4</ref> reports a representative set of our findings. We see that larger patch sizes generally yield better performance, but combining patches taken at different scales further improves accuracy. For ex- <ref type="figure">Figure 3</ref>: Top-scoring patches from "snowboarding" and "polo" categories of Sports 8 dataset.</p><p>ample, using only 64×64px patches gives a worse accuracy than using 32 × 32px and 64 × 64px patches. This shows that distinct scales hold complementary information. Dense sampling does not improve the accuracy significantly.</p><p>Overall, using together 32px, 64px, and 128px patches seems to be the best and most stable configuration. The stability of results breaks down when we supply smaller patches of 16px. We speculate that at this patch size there is not enough visual information for CNN to provide meaningful representation. Finally, we note that CNN features extracted before ReLU generally perform better. That said, in the rest of the paper we always use simultaneously 32px, 64px, and 128px patches, no ReLU and sparse sampling.</p><p>Next we compare sNBNL against NBNL in efficiency and effectiveness. Our goal is to confirm the ability of sNBNL to reach the same results as NBNL at a lower computational cost. <ref type="table" target="#tab_1">Table 2</ref> shows the results obtained using NBNL and sNBNL on the three databases, in terms of accuracy and training time. We see that the two algorithms achieve basically the same results, as confirmed by a signtest (p &lt; 0.05). Instead w.r.t. the training time these differences are remarkable, with sNBNL achieving on average a speed up of 25 times compared to NBNL. This is a first experimental confirmation of the scalability of our approach. <ref type="table" target="#tab_0">Table 1</ref> compares our results with previous work. We see that we achieve consistently the best accuracy among the single cue methods. This is impressive for an approach that uses an off-the-shelf pre-trained CNN, without any fine tuning. Moreover, on the Scene 15 database, our performance surpasses also that of multi-cue approaches.</p><p>We conclude this section by probing the potential of our framework on a larger scale experiment. We run experiments on the SUN-397 <ref type="bibr" target="#b46">[47]</ref> dataset. Note that this dataset is out of reach for NBNN, and prohibitive also for NBNL. We trained GPU-optimized implementation of STOML3 SVM  in minibatches of 2500 examples on 10 splits originally proposed in <ref type="bibr" target="#b46">[47]</ref>. As in the previous scene recognition experiments, we concatenated the absolute patch positions with the feature vector. We perform data standardization and we set the regularization parameter λ to 1 -note that even better results can be obtained by tuning it. CNN-sNBNL achieves a performance of 55.8 ± 0.29%, which surpasses recently reported results by Zhou et al. <ref type="bibr" target="#b52">[53]</ref> of 53.86 ± 0.21% and 54.32 ± 0.14%. These were obtained by training a linear SVM on Hybrid and Places-205 CNN features respectively. We also comment on the patch importance by showing the high-scoring patches in representative images. We focus on Sports-8 and select patches which have the highest score according to the STOML3 predictor <ref type="bibr" target="#b7">(8)</ref>. We highlight those and dim the rest of the image in <ref type="figure">Fig. 3</ref>. Notably, NBNL puts higher score on patches semantically related to the category.</p><p>We conclude that the reported results clearly showcase the power of our framework in the scene recognition setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Domain Adaptation Experiments</head><p>We report here experiments performed on the Of-fice+Caltech database, both in the unsupervised and semisupervised scenarios. Note that none of the three instantiations of our framework are a domain adaptation algorithm, hence we simply use each of them on the source data, and test the obtained classifier on the target. Concretely, in the unsupervised setting we simply train NBNN/NBNL/sNBNL on the source; for the semisupervised setting, we add three target images to the source and proceed as for the unsupervised case. A similar experiment was first presented in <ref type="bibr" target="#b41">[42]</ref>, showing that NBNN gener-  alizes well across the domains without DA-specific design in mind. As features, we use the same configuration employed in the scene recognition experiments, that is patches of size 32px, 64px and 128px without ReLU. We also performed experiments with sparse sampling. <ref type="table" target="#tab_2">Tables 3,4</ref> report the results obtained in the unsupervised and in the semi-supervised settings. We see that, in the unsupervised setting, our approach is powerful enough to outperform several learning-based baselines, in spite of its simplicity. Performance on the semi-supervised setting further improves, as we achieve the state of the art in all settings. We stress that this is accomplished by the methods that are not designed for domain adaptation scenario. Note that we could not run DA-NBNN, the only existing NBNN-based domain adaptation method on our local CNN multi scale activations because of its computational limitations. These results further confirm the power of the proposed framework, and its potential for future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>This paper provides a method for using CNN activation features combined with NBNN-based classifiers. The two key ingredients are: (1) extraction of CNN activations from local patches at different scales, and (2) a scalable NBNNbased algorithm that exploits the learning power of locally linear SVMs. We present an instantiation of this framework using a pre-trained Caffe architecture, applied to the scene classification and domain adaptation problems. Results are very strong: on scene classification we achieve the state of the art among single cue methods on three widely used benchmark databases. On domain adaptation, the simple use of the framework on the source only, leads to promising results, competitive against many learning methods proposed so far. Future work will further explore the framework in an end-to-end setting and domain adaptation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Latent locally-linear classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Results obtained by NBNN on CNN features computed with different patch sizes, sampling rates, on three datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Comparison of previous work with our approach. Legend: bold indicates the best performance among single feature methods, red bold indicates the overall best.</figDesc><table>Method 
Scene 15 
Sports 8 
MIT67 
NBNN (Surf)[7] 
72.8 
67.6 
− 
NBNL (Surf)[7] 
82.42 
85.54 
42.15 
CNN-NBNN 
88.24 ± 0.99 
94.46 ± 0.47 63.92 ± 1.63 
Lin. SVM(CNN) 
90 ± 0.63 
94.16 ± 1.13 64.62 ± 1.04 
CNN-NBNL 
92.42 ± 0.64 95.29 ± 0.61 
73 ± 0.36 
CNN-sNBNL 
92.88 ± 0.89 95.28 ± 0.68 72.79 ± 0.73 
Hybrid CNN[53] 
91.59 
94.22 
70.8 
LScSPM[9] 
89.78 
85.27 
− 
MOP-CNN[13] 
− 
− 
68.88 
DDSFL + CAFFE[54] 
92.81 
96.78 
76.23 
ISPR + IFV[24] 
91.06 
92.08 
68.50 
CNN Fusion[20] 
92.1 
94.8 
70.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>NBNL vs sNBNL in accuracy, training and testing 
time in seconds, over the three scene recognition databases. 

Sports 8 
Scenes 15 
ISR 67 
Acc. 
Train 
Test Acc. 
Train 
Test Acc. Train Test 
NBNL 
94.2 1024.4 13.9 91.5 5729.2 95.9 72.5 9690 63.2 
sNBNL 
95.2 
63.5 
0.4 91.6 210.3 
1.9 72.7 304.2 1.3 
Speed-up 
-
×16 
×34 
-
×27 
×50 
-
×32 ×49 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 :</head><label>3</label><figDesc>Unsupervised domain adaptation results</figDesc><table>Alg. \Dataset 
A→ W 
A→ C 
W→ A 
W→ C 
C→ A 
C→ W 
NBNN[42] 
31.8 
31.3 
37.4 
26.8 
41 
28.4 
DA-NBNN[42] 
35 
41 
42 
33 
55 
36 
CNN-NBNN 
60.23 ± 3.5 75.2 ± 1.0 66.87 ± 1.3 63.3 ± 1.2 79.03 ± 0.9 61.28 ± 4.6 
CNN-NBNL 
62.61 ± 3.5 71.61 ± 2.1 56.84 ± 2.6 50.08 ± 2.4 79.97 ± 2.3 61.05 ± 3.7 
CNN-sNBNL 
61.93 ± 3.7 
72 ± 2 
63.45 ± 1.9 55.81 ± 1.5 80.91 ± 2.0 64.84 ± 3.4 
GFK[12] 
35.7 
37.9 
35.5 
29.3 
40.4 
− 
SWAP[11] 
37.6 
41.3 
38.2 
32.2 
46.2 
46.1 
Landmark[11] 
46.1 
45.5 
40.2 
35.4 
56.7 
49.5 
LapCNN[26] 
− 
83.6 
− 
77.8 
92.1 
81.6 
DDC[26] 
− 
84.3 
− 
76.9 
91.3 
85.5 
DAN[26] 
− 
86 
− 
81.5 
92 
− 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Semi supervised domain adaptation results ± 2.9 76.93 ± 1.7 80.6 ± 1.5 70.5 ± 1.7 84.67 ± 1.2 90.03 ± 1.9 CNN-NBNL 84.87 ± 3.7 74.31 ± 1.1 77.14 ± 2.4 68.17 ± 2.8 83.77 ± 1.5 86.52 ± 3.6 CNN-sNBNL 87.54 ± 2.3 76.74 ± 1.9 79.38 ± 1.6 70.17 ± 1.6 85.62 ± 1.1 87.28 ± 2.5</figDesc><table>Alg. \Dataset 
A→ W 
A→ C 
W→ A 
W→ C 
C→ A 
C→ W 
NBNN[42] 
56.9 
34 
43.5 
31.6 
50.2 
57.7 
DA-NBNN[42] 
62 
46 
58 
42 
65 
61 
CNN-NBNN 
88.9 H-L2L[32] 
77.1 
38.6 
51.6 
34.0 
55.32 
− 
DASH-N[30] 
75.5 
54.9 
70.4 
50.2 
71.6 
− 
SDDL[39] 
72 
27.4 
49.4 
29.7 
49.5 
− 
HMP[1] 
70 
51.7 
61.5 
46.8 
67.7 
− 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. This work is supported by the ERC Starting Grant RoboExNovo.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hierarchical matching pursuit for image classification: Architecture and fast algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">In defense of nearest-neighbor based image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Boiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR). IEEE Conference on</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Return of the devil in the details: Delving deep into convolutional nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Nearest-neighbor searching and metric space dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Clarkson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nearest-neighbor methods for learning and vision: theory and practice</title>
		<editor>G. Shakhnarovich, T. Darrell, and P. Indyk</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="15" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A discriminatively trained, multiscale, deformable part model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), IEEE Conference On</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Scene recognition with naive bayes non-linear learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fornoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition (ICPR), International Conference on</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multiclass latent locally linear support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fornoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Machine Learning (ACML)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Laplacian sparse coding, hypergraph laplacian sparse coding, and applications. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.-H</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="92" to="104" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Training deformable part models with decorrelated features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Geodesic flow kernel for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), IEEE Conference on</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-scale orderless pooling of deep convolutional activation features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Maxout networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Caltech-256 object category dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<pubPlace>Caltech</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">The Elements Of Statistical Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Multimedia</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Local deep kernel learning for efficient non-linear SVM prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Aggrwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Large-margin convex polytope machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kantchelian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Tschantz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tygar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Convolutional network features for scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koskela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Laaksonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Multimedia</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Locally linear support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ladicky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition, IEEE Conference on</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">What, where and who? classifying events by scene and object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning important spatial pooling regions for scene classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), IEEE Conference on</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The treasure beneath convolutional layers: cross convolutional layer pooling for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), IEEE Conference on</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Stochastic majorization-minimization algorithms for large-scale optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Online learning for matrix factorization and sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="19" to="60" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Local naive bayes nearest neighbor for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), IEEE Conference on</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Non-Linear and Sparse Representations for Multi-Modal Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>University of Maryland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Partition-wise linear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Oiwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fujimaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning to learn, from transfer learning to domain adaptation: A unifying perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Patricia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), IEEE Conference on</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Recognizing indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Quattoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), IEEE Conference on</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The pooled nbnn kernel: Beyond image-to-class and image-to-image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rematas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision (ACCV)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A stochastic gradient method with an exponential convergence rate for finite training sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Nonlinear dimensionality reduction by locally linear embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="1" to="42" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Overfeat: Integrated recognition, localization and detection using convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Generalized domain-adaptive dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), IEEE Conference on</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Naive bayes image classification: beyond nearest neighbors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision (ACCV)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Iterative nearest neighbors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="60" to="72" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Frustratingly easy nbnn domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The nbnn kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Locality-constrained linear coding for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), IEEE Conference on</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Image-to-class distance metric learning for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-T</forename><surname>Chia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Optimizing 1-nearest prototype classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wohlhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kostinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Donoser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), IEEE Conference on</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Sun database: Large-scale scene recognition from abbey to zoo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Ehinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer vision and pattern recognition (CVPR), IEEE Conference on</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Eigenjoints-based action recognition using naive-bayes-nearest-neighbor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE Conference on</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Improved local coordinate coding using local tangents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Nonlinear learning using local coordinate coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The concave-convex procedure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="915" to="936" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning anchor planes for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ladicky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saffari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning deep features for scene recognition using places database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems, NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Exemplar based deep discriminative and shareable feature learning for scene image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3004" to="3015" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
