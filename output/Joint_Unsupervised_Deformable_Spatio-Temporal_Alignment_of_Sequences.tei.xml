<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Unsupervised Deformable Spatio-Temporal Alignment of Sequences</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lazaros</forename><surname>Zafeiriou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Epameinondas</forename><surname>Antonakos</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">⋆</forename><surname>Stefanos</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Center for Machine Vision and Signal Analysis</orgName>
								<orgName type="institution">University of Oulu</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zafeiriou</forename><forename type="middle">⋆</forename></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Pantic</surname></persName>
							<email>m.pantic@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Twente</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">⋆</forename></persName>
						</author>
						<title level="a" type="main">Joint Unsupervised Deformable Spatio-Temporal Alignment of Sequences</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Typically, the problems of spatial and temporal alignment of sequences are considered disjoint. That is, in order to align two sequences, a methodology that (non)-rigidly aligns the images is first applied, followed by temporal alignment of the obtained aligned images. In this paper, we propose the first, to the best of our knowledge, methodology that can jointly spatio-temporally align two sequences, which display highly deformable texture-varying objects. We show that by treating the problems of deformable spatial and temporal alignment jointly, we achieve better results than considering the problems independent. Furthermore, we show that deformable spatio-temporal alignment of faces can be performed in an unsupervised manner (i.e., without employing face trackers or building person-specific deformable models).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Temporal and spatial alignment are two very wellstudied fields in various disciplines, including computer vision and machine learning <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b15">16]</ref>. Temporal alignment is the first step towards analysis and synthesis of human and animal motion, temporal clustering of sequences and behaviour segmentation <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b35">36]</ref>. Spatial image alignment is among the main computer vision topics <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b0">1]</ref>. It is usually the first step towards many pattern matching applications such as face and facial expression recognition, object detection etc. <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b5">6]</ref>. It is also the first step towards temporal alignment of sequences <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>Typically, temporal and spatial alignment are treated as two disjoint problems. Thus, they are solved separately, usually by employing very different methodologies. This is more evident in the task of spatio-temporal alignment of sequences that contain deformable objects. For example, the typical framework for temporal alignment of two sequences displaying objects that undergo non-rigid deformations, e.g. a facial expression, is the following <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b16">17</ref>]:</p><p>1. The first step is to apply a statistical facial deformable model (generic or person-specific) which aligns the images and/or localizes a consistent set of facial landmarks. Some examples of such state-of-the-art models are <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b15">16]</ref>. Even though such deformable models demonstrate great capabilities, they require either thousands of manually annotated facial samples captured under various recording conditions (generic models) or the manual annotation of a set of frames in each and every video that is analysed (person-specific models). However, such extended manual annotation is a laborious and labour intensive procedure <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b1">2]</ref>.</p><p>2. The second step is to use the acquired densely aligned images or the localized landmarks to perform temporal alignment. However, one of the main challenges in aligning such visual data is their high dimensionality. This is the reason why various recently proposed methods perform temporal alignment by joint feature extraction and dimensionality reduction <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>Joint spatio-temporal alignment is more advantageous than spatial alignment, since the spatial ambiguities that may be present can be resolved. The alignment accuracy can also be improved, because all the available information is exploited. Despite those advantages, joint spatiotemporal alignment has received limited attention, mainly due to the difficulty in designing such frameworks <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12]</ref>. The methods that have been proposed typically assume rigid spatial and temporal motion models (i.e., affine-like) <ref type="bibr" target="#b7">[8]</ref>. Also, the video sequences display different views of the same dynamic scene <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12]</ref>. Hence, such methods are not suitable for the task of spatio-temporal alignment of sequences with deformable objects, such as faces.</p><p>To the best of our knowledge, no method has been proposed that is able to perform deformable joint spatiotemporal alignment of sequences that contain texture-varying deformable objects (e.g., faces). The existing methods for aligning such sequences usually require hours of manual annotation in order to first develop models that are able to extract deformations (commonly described by a set of sparse tracked landmarks), and then align the extracted deformations <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b16">17</ref>]. An additional advantage of methodologies that can jointly spatio-temporally align sequences of deformable objects is that the reliance on manual annotations can be minimized.</p><p>The major challenge of performing joint spatio-temporal alignment of sequences that display texture-varying deformable objects is the high dimensionality of the texture space. Hence, we need to device component analysis methodologies that can extract a small number of components suitable for both spatial and temporal alignment. Then, spatial non-rigid, as well as temporal, alignment can be conducted using the low-dimensional space. In this paper, motivated by the recent success on combining component analysis with (i) spatial non-rigid deformations by means of a statistical shape model for deformable alignment of image sets <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b32">33]</ref>, and (ii) temporal deformations by means of Dynamic Time Warping (DTW) <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b16">17]</ref>, we propose, the first, to the best of our knowledge, component analysis methodology which can perform joint spatio-temporal alignment of two sequences.</p><p>The proposed methodology is radically different compared to recent methods that perform joint component analysis and spatial alignment <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b32">33]</ref>. Specifically, our technique is totally different than <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b32">33]</ref>, which are based on pre-trained models of appearance and require annotations of hundreds of images in order to achieve good generalization properties. The most closely related methods are the unsupervised method of <ref type="bibr" target="#b28">[29]</ref> that performs component analysis for unsupervised non-rigid spatial alignment and the method of <ref type="bibr" target="#b33">[34]</ref> that performs temporal alignment. The component analysis methodology used in <ref type="bibr" target="#b33">[34]</ref> for joint dimensionality reduction and temporal alignment is based on Canonical Correlation Analysis (CCA). CCA does not use any temporal model or regularization, and most importantly, due to generalized orthogonality constraints, does not provide good reconstruction of the sequences. Hence, it is not ideal for spatial alignment (in Sec. 2.5.1 we thoroughly discuss the relationship of the proposed methodology with CCA). Similarly, the recently proposed temporally regularized Principal Component Analysis (PCA) (so called Autoregressive Component Analysis (ARCA)) <ref type="bibr" target="#b28">[29]</ref> is tailored only to preserve the reconstruction of the sequence's images, without discovering common low-dimensional features that can be used for temporal alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Method</head><p>In this section, we start by reviewing the spatial (Sec. 2.1) and temporal (Sec. 2.2) alignment methods of im-age sequences that are closely related to the proposed technique. Then, we present our method for describing a spatiotemporal phenomenon (Sec. 2.3). Finally, we discuss its convergence (Sec. 2.4), its relationship with existing CCA techniques and give a probabilistic interpretation (Sec. 2.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Unsupervised Deformable Spatial Alignment of Image Sequences</head><p>Recently, the line of research of joint component analysis and spatial alignment has received attention <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b32">33]</ref>. Some of the methods require a known set of bases that is build from a set of already aligned objects <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b32">33]</ref>. In this paper, we are interested in the unsupervised alignment of image sequences. The most recently proposed method for that task is <ref type="bibr" target="#b28">[29]</ref>. In that work, it is assumed that only a statistical model of the facial shape is given. Let us express a shape instance that comprises of a set of S landmarks as s = [x 1 , y 1 , . . . , x S , y S ] T , where (x i , y i ) are the coordinates that correspond to the i-th landmark. A statistical shape model can be easily learned by performing PCA on a set of training shapes in order to acquire a set of bases U S and the mean shapes. A new shape instance can be approximately parametrised using the learned model, as s t ≈s + U S p, where p is the set of parameters. Rigid transformations can be incorporated in the bases U S <ref type="bibr" target="#b15">[16]</ref>. Given an image and a vector of parameters p that describes a shape instance in the image, then the texture of the image can be warped into a predefined reference frame. In this paper, we denote the warped image as x(p). The warp can be formulated in two ways: (i) as a non-linear function, such as Piece-Wise Affine (PWA), in order to sample the whole image, and (ii) as a simple translational model <ref type="bibr" target="#b24">[25]</ref> that samples only the local texture around landmarks.</p><p>Given a set of N images stacked as the columns of a matrix X = [x 1 , . . . , x N ], the method proposed in <ref type="bibr" target="#b28">[29]</ref> (so called ARCA) learns a temporally regularized decomposition of X and, at the same time, estimates the shapes of the faces included in the images by extracting a set of parameters P = [p 1 , . . . , p N ]. The optimization problem is</p><formula xml:id="formula_0">P o , U o , V o = argmin P,U,V ||X(P) − UV|| 2 F + λtr[VLV T ] (1) where X(P) = [x 1 (p 1 ), . . . , x N (p N )]</formula><p>, and ||.|| 2 F and tr[.] denote the squared Frobenius norm of matrices and the trace matrix operator, respectively. Finally</p><formula xml:id="formula_1">L =        1 −φ −φ 1 + φ 2 −φ . . . . . . . . . −φ 1 + φ 2 −φ −φ 1       <label>(2)</label></formula><p>is an appropriate Laplacian matrix that incorporates first order Markov dependencies between data. The authors in <ref type="bibr" target="#b28">[29]</ref> follow an alternating minimization procedure and show that the above optimization problem, not only can provide a nonrigid alignment of the images, but the weights V contain smooth information that can be used to perform unsupervised analysis of facial behaviour (i.e., segment facial expressions with regards to several temporal segments). Furthermore, they explore the relationship between the above model and Slow Feature Analysis (SFA) <ref type="bibr" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Temporal Alignment of Image Sequences</head><p>DTW <ref type="bibr" target="#b14">[15]</ref> is a popular algorithm for the temporal alignment of two sequences that have different lengths. In particular, given two sequences stored as the columns of two matrices X 1 ∈ R F ×N1 and X 2 ∈ R F ×N2 , where N 1 and N 2 are the respective number of frames, DTW finds two binary warping matrices ∆ 1 and ∆ 2 so that the least squares error between the warped sequences is minimised. This is expressed as</p><formula xml:id="formula_2">∆ o 1,2 = argmin ∆ 1,2 X1∆1 − X2∆2 2 F s.t. ∆1 ∈ {0, 1} T 1 ×T , ∆2 ∈ {0, 1} T 2 ×T (3)</formula><p>where T is the length of the common aligned path. DTW is able to find the optimal alignment path by using dynamic programming <ref type="bibr" target="#b3">[4]</ref> despite the fact that the number of possible alignments is exponential with respect to T 1 and T 2 . However, DTW has some important limitations. Firstly, it is largely affected by the dimensionality of the data and, secondly, it is not able to align signals of different dimensions. In order to accommodate for the above, as well as for differences regarding the nature, style and subject variability of the signals, Canonical Time Warping (CTW) was proposed in <ref type="bibr" target="#b33">[34]</ref>. CTW combines DTW with CCA, in order to add a principled feature selection and dimensionality reduction mechanism within DTW. In particular, by taking advantage of the similarities between the least squares functional form of CCA <ref type="bibr" target="#b9">[10]</ref> and Eq. 3, CTW simultaneously discovers two linear operators (U 1 , U 2 ) and applies DTW on the low dimensional embedding of U T 1 X 1 and U T 2 X 2 by solving the following optimization problem</p><formula xml:id="formula_3">∆ o 1,2 ,U o 1,2 = argmin ∆1,2,U1,2 U T 1 X 1 ∆ 1 − U T 2 X 2 ∆ 2 2 F s.t. ∆ 1 ∈ {0, 1} T1×T , ∆ 2 ∈ {0, 1} T2×T U T 1 X 1 D 1 X 1 T U 1 = I, U T 2 X 2 D 2 X 2 T U 2 = I (4) where D 1 = ∆ 1 ∆ T 1 and D 2 = ∆ 2 ∆ T 2 .</formula><p>An alternating optimization approach was used in order to solve the above problem. One of the drawbacks of CTW is that it does not take into account the dynamic information of the signals. Furthermore, even though CTW can theoretically handle high dimensional spaces, in <ref type="bibr" target="#b33">[34]</ref> it has only been tested on alignment problems that deal with sparse sets of landmarks. According to our experiments, for the task of aligning facial behaviour using image pixel information, CTW can perform well only if a dimensionality reduction step has been applied on each video using PCA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">A Correlated Component Analysis for Describing a Spatio-Temporal Phenomenon</head><p>In this section, we build on the component analysis model of ARCA <ref type="bibr" target="#b28">[29]</ref> in order to describe a temporal phenomenon which is common in two sequences that are both spatially and temporally aligned (e.g. two video sequences depicting the same expression or Facial Action Unit (AU) <ref type="bibr" target="#b12">[13]</ref>). Then, we assume that the sequences' frames are neither spatially nor temporally aligned and we propose an optimization problem that jointly decomposes the image sequences into maximally correlated subspaces and performs spatial and temporal alignment.</p><p>Let us denote two image sequences as the stacked matrices</p><formula xml:id="formula_4">X 1 = [x 1 1 , . . . , x 1 N ] and X 2 = [x 2 1 , . . . , x 2 N ].</formula><p>We assume that both sequences are explained by a linear generative model. That is, we want to decompose the two sequences into two maximally correlated subspaces V 1 and V 2 using the orthonormal bases U 1 and U 2 , as</p><formula xml:id="formula_5">U o 1,2 , V o 1,2 = argmin U 1,2 ,V 1,2 ||X1 − U1V1|| 2 F + ||X2 − U2V2|| 2 F + λtr[V1LV T 1 ] + λtr[V2LV T 2 ] + ||V1 − V2|| 2 F s.t. U T 1 U1 = I, U T 2 U2 = I<label>(5)</label></formula><p>In Sec. 2.5.1 we show how the component analysis is linked to CCA and explore the main modelling differences. Assuming that the sequences X 1 ∈ R F ×N1 and X 2 ∈ R F ×N2 are neither temporally aligned, hence they do not have the same length, nor spatially aligned, we propose the following optimization problem</p><formula xml:id="formula_6">P o 1,2 , ∆ o 1,2 , U o 1,2 , V o 1,2 = = argmin P 1,2 ,∆ 1,2 ,U 1,2 ,V 1,2 ||(X1(P1) − U1V1)∆1|| 2 F + + ||(X2(P2) − U2V2)∆2|| 2 F + λtr[V1L1V T 1 ]+ + λtr[V2L2V T 2 ] + ||V1∆1 − V2∆2|| 2 F s.t. ∆1 ∈ {0, 1} N 1 ×N , ∆2 ∈ {0, 1} N 2 ×N U T 1 U1 = I, U T 2 U2 = I<label>(6)</label></formula><p>where L 1 ∈ R N1×N1 and L 2 ∈ R N2×N2 are Laplacian matrices and ∆ 1 and ∆ 2 are binary warping matrices. The above optimization problem forms the bases of our framework and enables us to perform joint spatio-temporal alignment of the sequences into a common frame defined as the mean shapes. In Section 2.5 we discuss the relationship between the above model and CCA/CTW. The advantages of the proposed model over CTW is (a) the proposed model <ref type="figure">Figure 1</ref>: Method overview. Given two video sequences, the proposed method performs joint deformable spatio-temporal alignment using an iterative procedure that gradually improves the result. The initialization is acquired by applying ARCA <ref type="bibr" target="#b28">[29]</ref> on both sequences.</p><p>incorporates temporal regularisation contraints, (b) we can perform jointly temporal and spatial alignment and (c) we can easily incorporate terms that account for gross corruptions/error <ref type="bibr" target="#b17">[18]</ref>.</p><p>The sequences that consist of the warped frames' vectors are given by</p><formula xml:id="formula_7">Xi(Pi) = x i 1 (p i 1 ), . . . , x i N i (p i N i ) , i = 1, 2<label>(7)</label></formula><p>where</p><formula xml:id="formula_8">P i = [p i 1 , . . . , p i Ni ]</formula><p>is the matrix of the shape parameters of each frame and i denotes the sequence index. As shown in overview of <ref type="figure">Fig. 1</ref>, the above optimization problem is iteratively solved in an alternating manner. The first step is to estimate matrices U 1,2 and V 1,2 based on the current estimate of the shape parameters P 1,2 and then apply DTW on V 1,2 in order to find ∆ 1,2 . The second step is to compute the parameters of the spatial alignment P 1,2 given the current estimation of U 1,2 , V 1,2 and ∆ 1,2 . The initial shapes are estimated by applying ARCA on both sequences. Therefore, the optimization of Eq. 6 is solved in the following two steps: 2.3.1 Fix P 1,2 and minimize with respect to U 1,2 , V 1,2 and ∆ 1,2</p><p>In this step of the proposed method, we aim to update U 1,2 and V 1,2 , assuming that we have a current estimate of the shape parameters' matrices P 1,2 , hence of the data matrices X 1,2 (P 1,2 ). Those updates are estimated by using an alternating optimization framework. Specifically, we first fix V 1,2 and compute U 1,2 and then we find V 1,2 by fixing U 1,2 . The warping matrices ∆ 1,2 are updated at the beginning of each such iteration.</p><p>Update ∆ 1,2 In the first iteration, we assume that we have the initial V 1,2 obtained by applying the ARCA algorithm on each sequence X 1,2 (P 1,2 ). Thus, the warping matrices ∆ 1,2 are estimated by applying DTW on these initial V 1,2 . In every subsequent iteration, ∆ 1,2 are estimated by applying DTW on the updated V 1,2 , thus (∆ 1 ,</p><formula xml:id="formula_9">∆ 2 ) = DTW(V 1 , V 2 ).</formula><p>Update U 1,2 Given the current estimate of V 1,2 , the optimization problem with regards to U 1,2 is given by</p><formula xml:id="formula_10">f (V1,2) = (X1(P1) − U1V1)∆1 2 F + (X2(P2) − U2V2)∆2 2 F s.t. ∆1 ∈ {0, 1} N 1 ×N , ∆2 ∈ {0, 1} N 2 ×N U T 1 U1 = I, U T 2 U2 = I<label>(8)</label></formula><p>The updates from the above optimization problem are derived by the Skinny Singular Value Decomposition (SSVD) <ref type="bibr" target="#b36">[37]</ref> of X i (P i )D i V T i . That is, given the SVD</p><formula xml:id="formula_11">X i (P i )D i V T i = R i S i M T i , then Ui = RiM T i , i = 1, 2<label>(9)</label></formula><p>where, for convenience, we set D i = ∆ i ∆ T i , i = 1, 2</p><p>Update V 1,2 Given U 1,2 , the optimization problem with regards to V 1,2 is formulated as</p><formula xml:id="formula_12">f (U1,2) = (X1(P1) − U1V1)∆1 2 F + λtr[V1L1V T 1 ] + (X2(P2) − U2V2)∆2 2 F + λtr[V2L2V T 2 ] + ||V1∆1 − V2∆2|| 2 F s.t. ∆1 ∈ {0, 1} N 1 ×N , ∆2 ∈ {0, 1} N 2 ×N U T 1 U1 = I, U T 2 U2 = I<label>(10)</label></formula><p>By evaluating the partial derivatives with respect to V i , ∀i = {1, 2} and equalize them with zero, we derive</p><formula xml:id="formula_13">Vi = (U T i XiDi + Ci)(2Di + λLi) −1 , i = 1, 2<label>(11)</label></formula><p>where</p><formula xml:id="formula_14">C 1 = V 2 ∆ 2 ∆ T 1 and C 2 = V 1 ∆ 1 ∆ T 2 .</formula><p>2.3.2 Fix U 1,2 , V 1,2 , ∆ 1,2 and minimize with respect to P 1,2</p><p>The aim of this step is to estimate the shape parameters' matrices P i , i = 1, 2 for each sequence, given the current estimate of the bases U 1,2 and the features V 1,2 . This is performed for each sequence independently and it can be expressed as the following optimization problem</p><formula xml:id="formula_15">P o i = argmin P i Xi(Pi) − UiVi 2 F = = argmin {p i j }, j=1,...,N i N i j=1 x i j (p i j ) − Uiv i j 2 2 , i = 1, 2<label>(12)</label></formula><p>where v i j , ∀j = 1, . . . , N i , ∀i = 1, 2 denotes the j-th column of the matrix V i that corresponds to each sequence. In other words, for each sequence (i = 1, 2), we aim to minimize the Frobenius norm between the warped frames X i (P i ) and the templates U i V i . The solution is obtained by employing the Inverse Compositional (IC) Image Alignment algorithm <ref type="bibr" target="#b2">[3]</ref>. Note that the IC alignment is performed separately for each frame of each sequence. In brief, the solution can be derived by introducing an incremental warp term (∆p i j ) on the part of the template of Eq. 12. Then, by linearizing (first order Taylor expansion) around zero (∆p i j = 0), the incremental warp is given by</p><formula xml:id="formula_16">∆p i j = H −1 J T |p=0 x i j (p i j ) − Uiv i j , j = 1, . . . , Ni, i = 1, 2</formula><p>where H = J T | p=0 J| p=0 is the Gauss-Newton approximation of the Hessian matrix and J T | p=0 is the Jacobian of each template U i v i j . The biggest advantage of the IC algorithm is that the Jacobian and the inverse of the Hessian matrix are constant and can be precomputed once, because the linearization of the solution is taken on the part of the template.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Empirical Convergence</head><p>Herein, we empirically investigate the convergence of the proposed optimization problem on MMI and UNS databases. <ref type="figure" target="#fig_0">Figure 2</ref> shows the values of the cost function of Eq. 6, averaged over all the videos. The results show that the proposed methodology converges monotonically and 4-5 iterations are adequate to achieve good performance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Theoretical Interpretation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Relationship to Canonical Component Analysis</head><p>In this section, we analyze the relationship between the proposed model of Sec. 2.3 and other methodologies that produce subspaces of correlated features. Naturally, this comparison is mostly targeted on the close related CCA. Let us formulate the optimization problem of Eq. 5 without the temporal regularization terms, as</p><formula xml:id="formula_17">U o 1,2 ,V o 1,2 = argmin U 1 ,U 2 ,V 1 ,V 2 ||X1 − U1V1|| 2 F + + ||X2 − U2V2|| 2 F + ||V1 − V2|| 2 F s.t. U T 1 U1 = I, U T 2 U2 = I<label>(13)</label></formula><p>By assuming that the weights matrices V 1 and V 2 are formed by projecting the sequences onto the respective orthonormal bases as V 1 = U T 1 X 1 and V 2 = U T 2 X 2 , and then substituting back to Eq. 13, we end up with</p><formula xml:id="formula_18">U o 1,2 = argmax U 1 ,U 2 tr U1 U2 T 0 X1X T 2 X2X T 1 0 U1 U2 s.t. U1 U2 T U1 U2 = I<label>(14)</label></formula><p>which is a special case of CCA with orthogonal instead of generalized orthogonal constraints 1 . The derivation of the above problem is shown in the supplementary material and its solution is given by performing eigen-analysis. Motivated by Eq. 14, it can be shown that the proposed component analysis formulation of Eq. 6 is a case of orthogonal CCA with temporal regularized terms. Specifically, by assuming that V 1 = U T 1 X 1 and V 2 = U T 2 X 2 , the optimization problem of Eq. 6 can be reformulated as</p><formula xml:id="formula_19">U o 1 , U o 2 = argmax U 1 ,U 2 tr U1 U2 T −X1LX T 1 X1X T 2 X2X T 1 −X2LX T 2 U1 U2 s.t. U1 U2 T U1 U2 = I<label>(15)</label></formula><p>which again can be solved by performing eigen-analysis. The above problem is a kind of temporally regularized orthogonal CCA.Temporal regularisation is probably the reason that the proposed approach outperforms CTW (which does not employ any temporal regularisation). Even though Laplacian regularization of component analysis techniques has recently been significantly studied <ref type="bibr" target="#b6">[7]</ref>, Laplacian regularization for CCA models has not received much attention <ref type="bibr" target="#b4">[5]</ref>. To the best of our knowledge, this is the first component analysis methodology which can 1 CCA has as constraints U T 1 X 1 X T 1 U 1 = I and U T 2 X 2 X T 2 U 2 = I.</p><p>lead to a CCA with temporal regularization terms 2 . We believe that the proposed component analysis method is superior to the CCA model for both spatial and temporal alignment, since (a) the bases are orthogonal and hence can be used to build better statistical models for spatial alignment <ref type="bibr" target="#b15">[16]</ref> and (b) we have applied temporal regularization terms which produce smoother latent spaces V 1 and V 2 which are better for temporal alignment. Finally, note that the reason why we solve the proposed decomposition using the least-squares approach and not eigen-analysis is numerical stability <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Probabilistic Interpretation</head><p>The proposed optimization problem also provides the maximum-likelihood solution of a shared space generative autoregressive model. That is, we assume we have two linear models that describe the generation of observations in the two sequences</p><formula xml:id="formula_20">x 1 i = U 1 v 1 i + e 1 i , e 1 i ∼ N (0, σ 1 I), i = 1, . . . , N 1 x 2 i = U 2 v 2 i + e 2 i , e 2 i ∼ N (0, σ 2 I), i = 1, . . . , N 2<label>(16)</label></formula><p>Let us also make the assumption that</p><formula xml:id="formula_21">V 1 = [v 1 1 , . . . , v 1 N1 ] forms an autoregressive sequence. That is, V 1 ∼ |L N | √ (2π) kN exp{− 1 2 tr[V 1 LV T 1 ]</formula><p>} with L being the Laplacian and V 2 is the same as V 1 up to a Gaussian noise, i.e. v 1 i = v 2 i + e i with e i ∼ N (0, σI). It is straightforward to show that maximizing the joint log likelihood of the above probabilistic model with regards to U 1 , U 2 , V 1 and V 2 is equivalent to optimizing the cost function in Eq. 13.</p><p>It is worthwhile to compare the proposed with the Dynamic Probabilistic CCA (DPCCA) method proposed in <ref type="bibr" target="#b16">[17]</ref>. The method in <ref type="bibr" target="#b16">[17]</ref> models shared and individual spaces in a probabilistic manner, i.e. by incorporating priors over these spaces and marginalising them out. Time series alignment is performed by applying DTW on the expectations of the shared space over the individual posteriors. Using the model in <ref type="bibr" target="#b16">[17]</ref> to perform joint spatial alignment is not trivial, that is why temporal alignment is performed on facial shape only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>In order to demonstrate the effectiveness of the proposed framework, we conduct experiments on two datasets: MMI <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26]</ref> which consists of videos with posed AUs and UvA-Nemo Smile (UNS) <ref type="bibr" target="#b10">[11]</ref> which contains videos with posed and spontaneous smiles. The MMI database contains more than 400 videos, in which a subject performs one or more AUs that are annotated with respect to the following temporal segments: (1) neutral when there is no facial motion, (2) onset when the facial motion starts, (3) apex, when the muscles reach the peak intensity, and (4) offset when the muscles begin to relax. The large-scale UNS database consists of more than 1240 videos (597 spontaneous and 643 posed) with 400 subjects. Since this database does not provide any annotations of temporal segments, we manually annotated 50 videos displaying spontaneous smiles and 50 videos displaying posed smiles using the same temporal segments as in the case of MMI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Temporal Alignment Results</head><p>In this section, we provide experimental results for the temporal alignment of pairs of videos from both the MMI and UNS databases. The pairs are selected so that the same AU is activated. The aim of those experiments is (a) to evaluate the performance of the proposed framework compared to various commonly used temporal alignment methods, and (b) to show that by treating the problems of spatial and temporal alignment jointly instead of independently we achieve better results. We compare the proposed unsupervised framework, labelled as joint ARCA+DTW, with (a) CTW, (b) SFA+DTW, and (c) ARCA+DTW in which the problems of temporal and spatial alignment are solved independently. For the joint ARCA+DTW, we set the parameter λ that regulates the contribution of the smoothness constraints equal to 150 for both sequences. Furthermore, the dimensionality of the latent space for all the examined methods is set to 25, which was the dimensionality that lead to the best performance in a validation set. The matrices were initialised by applying first ARCA on both sequences. The shape parameters were initialised with zeros and the mean shape was placed in the bounding box returned by Viola-Jones face detector <ref type="bibr" target="#b30">[31]</ref>. Finally, the proposed method is applied for 5 global iterations. We would like to note that we have run ARCA+DTW one and several iterations but because there is no joint subspace learned between two videos we have not observed any improvement.</p><p>The temporal alignment accuracy is evaluated by employing the metric used in recent works <ref type="bibr" target="#b16">[17]</ref>. Specifically, let us assume that we have 2 video sequences with the corresponding features (V i , i = 1, 2) and AU annotations (A i , i = 1, 2). Additionally, assume that we have recovered the alignment binary matrices ∆ i , i = 1, 2 for each video. By applying these matrices on the AU annotations (i.e., A 1 ∆ 1 and A 2 ∆ 2 ) we can find the temporal phase of the AU that each aligned frame of each video corresponds to. Therefore, for a given temporal phase (e.g., neutral), we have a set of frame indices which are assigned to the specific temporal phase in each video, i.e. N p 1 and N p 2 respectively.   The accuracy is then estimated as</p><formula xml:id="formula_22">|N p 1 ∩N p 2 | |N p 1 ∪N p 2 |</formula><p>, which essentially corresponds to the ratio of correctly aligned frames to the total duration of the temporal phase p across the aligned videos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">MMI database</head><p>In this section, we report the performance on MMI database. The experiments are conducted on 480 pairs of videos that depict the same AU. The results are split in three categories, based on the region of the face that is activated by the performed AU, i.e. mouth, eyes and brows. For each facial region, the results are further separated per temporal segment. The AUs that correspond to each facial region are:  <ref type="figure" target="#fig_3">Figure 3</ref> summarizes the temporal alignment of three experiments on the MMI database. Specifically, <ref type="figure" target="#fig_3">Figures 3i  and 3ii</ref> show the percentage of video pairs that achieved an accuracy less or equal than the corresponding value for mouth-related and eyes-related AUs, respectively. In other words, these Cumulative Accuracy Distributions (CAD) show the percentage of video pairs that achieved at most a specific accuracy percentage. The plots for each facial region are also separated with respect to the temporal segment in question. The results indicate that, for both mouth and eyes related AUs, our method outperforms the rest of techniques for the neutral and apex phases, and has a comparable performance for onset and offset. This is better illustrated in <ref type="figure" target="#fig_3">Fig. 3iii</ref> which reports the average accuracy over all the video pairs for each temporal phase separately. The results for the brows-related AUs are also included in this figure, which indicate that the proposed method significantly outperforms the other techniques for all the temporal phases. Due to limited space, the CAD curves for the brows-related AUs for each temporal phase is omitted and can be found in the supplementary material. Moreover, note that our methodology outperforms ARCA+DTW for all facial regions and temporal phases. This is an important result which indicates that treating the spatial and temporal alignment as a joint problem is more advantageous than solving them independently.</p><p>Regarding the alignment of mouth-related AUs, it is worth mentioning that a similar experiment with the one provided in this section ( <ref type="figure" target="#fig_3">Fig. 3iii (a)</ref>) was conducted in <ref type="bibr" target="#b16">[17]</ref> (section 7.3), which reports the average accuracy over 50 video pairs performing AU12 in MMI database. Specifically for this task, we obtained 71% accuracy over DPCTW which obtained 55% for the neutral phase in the features. Subsequently, we achieved 38% accuracy compared to 33% for the onset phase, 61% over 60% for the apex phase and 39% compared to 37% for the offset phase. We have to note that our algorithm is completely automatic in terms of both spatial and temporal alignment (requiring only a face detector) and uses raw pixel intensities. On the other hand the method in <ref type="bibr" target="#b16">[17]</ref> used, manually corrected, tracked landmarks. <ref type="figure" target="#fig_3">Figure 3iv</ref> reports the results of a second experiment that aims to assess the effect of spatial alignment in the temporal alignment procedure. Specifically, we apply the proposed technique with different spatial alignment approaches, that is (a) the proposed unsupervised spatial alignment, (b) using the manually annotated landmarks, (c) adding random noise to the manually annotated landmarks. The results indicate that in most cases, the proposed method with automatic spatial alignment greatly outperforms the case of random initialisation and has comparable performance with the case of perfectly aligned images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">UNS database</head><p>In this section, we provide temporal alignment results on the UNS database, which contains, not only posed, but also spontaneous smiles which are more complex due to their dynamics <ref type="bibr" target="#b31">[32]</ref>. We conduct the experiments on 188 pairs of videos with posed smiles and 122 pairs with spontaneous smiles. Specifically, <ref type="figure" target="#fig_4">Fig. 4</ref> reports the average accuracy over all video pairs with respect to the temporal segments. As can be seen, our technique outperforms all the other methods for all temporal phases with an average margin of 7 − 8%. Furthermore, the results illustrate once more that performing joint spatio-temporal alignemnt derives better results than applying the spatial and temporal alignment independently. Finally, we further evaluate the performance of the proposed method by applying different spatial alignment approaches (unsupervised, manual annotations, random initialisation), similar to MMI case. Due to limited space, this experiment is included in the supplementary material along with the CAD curves for each temporal phase separately as well as experiments in spatial alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>We proposed the first, to the best of our knowledge, spatio-temporal methodology for deformable face alignment. We proposed a novel component analysis for the task and we explored some of its theoretical properties, as well as its relationship with other component analysis (e.g., CCA). We showed that our methodology outperforms state-of-the-art temporal alignment methods that make use of manual image alignment. We also showed that it is advantageous to jointly solve the problems of spatial and temporal alignment than solving them independently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Acknowledgements</head><p>The work of E. Antonakos was supported by EPSRC project EP/J017787/1 (4DFAB). The work of S. Zafeiriou was funded by the FiDiPro program of Tekes (project number: 1849/31/2015). The work of M. Pantic and L. Zafeiriou was partially supported by EPSRC project EP/N007743/1 (FACER2VM).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Cost function error with respect to the iterations averaged over all (a) MMI and (b) UNS videos.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>of video pairs that achieve an accuracy less or equal than the respective value for mouth-related AUs. The subfigures correspond to the temporal phases as: (a) neutral, (b) onset, (c) apex, (d) offset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>) Percentage of video pairs that achieve an accuracy less or equal than the respective value for eyes-related AUs. The subfigures correspond to the temporal phases as: (a) neutral, (b) onset, (c) apex, (d) offset. ) Average accuracy over all the video pairs with respect to the temporal phase for (a) mouth-related AUs, (b) eyes-related AUs (c) brows-related AUs. ) Average accuracy of the proposed method for different spatial alignment scenarios for (a) mouth-related AUs, (b) eyes-related AUs, (c) brows-related AUs. Auto: Proposed joint unsupervised spatial alignment. Manual: Using the manually annotated landmarks. Initialisation: Random initialisation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Temporal alignment results on MMI database.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Average accuracy over all the video pairs with respect to the temporal phase for (a) spontaneous smiles, (b) posed smiles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>• Mouth: Upper Lip Raiser, Nasolabial Deepener, Lip Corner Puller, Cheek Puffer, Dimpler, Lip Corner Depressor, Lower Lip Depressor, Chin Raiser, Lip Puckerer, Lip Stretcher, Lip Funneler, Lip Tightener, Lip Pressor, Lips Part, Jaw Drop, Mouth Stretch, Lip Suck • Eyes: Upper Lid Raiser, Cheek Raiser, Lid Tightener, Nose Wrinkler, Eyes Closed, Blink, Wink, Eyes Turn Left and Eyes Turn Right • Brows: Inner Brow Raiser, Outer Brow Raiser and Brow Lowerer</figDesc><table></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Our component analysis is not to be confused with the so-called Dynamic CCA model proposed in<ref type="bibr" target="#b16">[17]</ref>, where special probabilistic Linear Dynamical Systems (LDS) are proposed with shared and common spaces. The proposed model is deterministic. It is also radically different to the so-called semi-supervised Laplacian CCA method of<ref type="bibr" target="#b4">[5]</ref>, where a semisupervised Linear Discriminant Analysis (LDA) is proposed.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Menpo: A comprehensive platform for parametric image alignment and visual deformable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alabort-I Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Booth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Snape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Multimedia</title>
		<meeting>the ACM International Conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="679" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automatic construction of deformable models in-the-wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1813" to="1820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Lucas-kanade 20 years on: A unifying framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dynamic programming and optimal control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Athena Scientific Belmont</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semisupervised laplacian regularization of kernel canonical correlation analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Correlation filters for object alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Boddeti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2291" to="2298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Graph regularized nonnegative matrix factorization for data representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1548" to="1560" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Spatio-temporal alignment of sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Caspi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1409" to="1424" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rank minimization across appearance and shape for aam ensemble fitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Saragih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="577" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A least-squares framework for component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Uva-nemo smile database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dibeklioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Salah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<ptr target="http://www.uva-nemo.org/.6" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Joint spatio-temporal alignment of sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Diego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Serrat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-MM</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1377" to="1387" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Facial action coding system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">V</forename><surname>Friesen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Style translation for human motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pulli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Popović</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOG</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1082" to="1089" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">View-independent action recognition from temporal selfsimilarities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">N</forename><surname>Junejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dexter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="172" to="185" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Active appearance models revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dynamic probabilistic cca for analysis of affective behavior and fusion of continuous annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nicolaou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pavlovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1299" to="1311" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Robust correlated and individual component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Panagakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nicolaou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis &amp; Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Robust canonical time warping for the alignment of grossly corrupted sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Panagakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Nicolaou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="540" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Webbased database for facial expression analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Valstar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rademaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Maat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICME</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-07" />
			<biblScope unit="page" from="317" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Raps: Robust and efficient automatic construction of personspecific deformable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Panagakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A semi-automatic methodology for facial landmark annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR&apos;W</title>
		<meeting><address><addrLine>Portland Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Automatic analysis of facial affect: A survey of registration, representation, and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sariyanidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gunes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>IEEE T-PAMI</publisher>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">1113</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deepface: Closing the gap to human-level performance in face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1701" to="1708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gauss-newton deformable part models for face alignment in-the-wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1851" to="1858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Mmi facial expression database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Valstar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
		<ptr target="http://www.mmifacedb.com/.6" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Slow feature analysis: Unsupervised learning of invariances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wiskott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="715" to="770" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Supervised descent method and its applications to face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="532" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Joint unsupervised face alignment and behaviour analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning slow features for behaviour analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Nicolaou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nikitidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A survey on face detection in the wild: past, present and future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A survey of affect recognition methods: Audio, visual, and spontaneous expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">I</forename><surname>Roisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="58" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Joint face alignment with a generic deformable face model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-K</forename><surname>Cham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="561" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Canonical time warping for alignment of human behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Generalized time warping for multi-modal alignment of human motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1282" to="1289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Hierarchical aligned cluster analysis for temporal clustering of human motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Hodgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="582" to="596" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sparse principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational and graphical statistics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="265" to="286" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
