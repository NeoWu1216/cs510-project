<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gaussian Conditional Random Field Network for Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raviteja</forename><surname>Vemulapalli</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Automation Research</orgName>
								<orgName type="institution" key="instit1">UMIACS</orgName>
								<orgName type="institution" key="instit2">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oncel</forename><surname>Tuzel</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Mitsubishi Electric Research Laboratories</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Mitsubishi Electric Research Laboratories</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Automation Research</orgName>
								<orgName type="institution" key="instit1">UMIACS</orgName>
								<orgName type="institution" key="instit2">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Gaussian Conditional Random Field Network for Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:40+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In contrast to the existing approaches that use discrete Conditional Random Field (CRF) models, we propose to use a Gaussian CRF model for the task of semantic segmentation. We propose a novel deep network, which we refer to as Gaussian Mean Field (GMF) network, whose layers perform mean field inference over a Gaussian CRF. The proposed GMF network has the desired property that each of its layers produces an output that is closer to the maximum a posteriori solution of the Gaussian CRF compared to its input. By combining the proposed GMF network with deep Convolutional Neural Networks (CNNs), we propose a new end-to-end trainable Gaussian conditional random field network. The proposed Gaussian CRF network is composed of three sub-networks: (i) a CNN-based unary network for generating unary potentials, (ii) a CNN-based pairwise network for generating pairwise potentials, and (iii) a GMF network for performing Gaussian CRF inference. When trained end-to-end in a discriminative fashion, and evaluated on the challenging PASCALVOC 2012 segmentation dataset, the proposed Gaussian CRF network outperforms various recent semantic segmentation approaches that combine CNNs with discrete CRF models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Semantic segmentation, which aims to predict a category label for every pixel in the image, is an important task for scene understanding. Though it has received significant attention from the vision community over the past few years, it still remains a challenging problem due to large variations in the visual appearance of the semantic classes and complex interactions between various classes in the visual world. Recently, convolutional neural networks have been shown to work very well for this challenging task <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b34">35]</ref>. Their success can be attributed to several factors such as their ability to represent complex input-output relationships, feed-forward nature of their inference, availability of large training datasets and fast computing hardware like GPUs, etc.</p><p>However, Convolutional Neural Networks (CNNs) may not be optimal for structured prediction tasks such as semantic segmentation as they do not model the interactions between output variables directly. Acknowledging this, various semantic segmentation approaches have been proposed in the recent past that use Conditional Random Field (CRF) models <ref type="bibr" target="#b25">[26]</ref> on top of CNNs <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b54">55]</ref>, and all these approaches have shown significant improvement in the segmentation results by using CRFs. By combining CNNs and CRFs, these approaches get the best of both worlds: the ability of CNNs to model complex input-output relationships and the ability of CRFs to directly model the interactions between output variables. While some of these approaches use CRF as a separate post-processing step <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b36">37]</ref>, some other approaches train the CNNs along with the CRFs in an end-to-end fashion <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b54">55]</ref>.</p><p>All of the above approaches use discrete graphical models, and hence end up using graph-cuts or mean field-based approximate inference procedures. Though these inference procedures do not have global optimum guarantees, they have been successfully used for the semantic segmentation task in conjunction with CNNs. In contrast to discrete graphical models, Gaussian graphical models <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b49">50]</ref> are simpler models, and have inference procedures that are guaranteed to converge to the global optimal solution. Gaussian graphical models have been used in the past for various applications such as image denoising <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b49">50]</ref>, depth estimation <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b41">42]</ref>, deblurring <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b55">56]</ref>, edge detection <ref type="bibr" target="#b53">[54]</ref>, texture classification <ref type="bibr" target="#b4">[5]</ref>, etc.</p><p>While a discrete CRF is a natural fit for labeling tasks such as semantic segmentation, one needs to use inference techniques that do not have optimality guarantees. While exact inference is tractable in the case of a Gaussian CRF, it is not clear if this model is a good fit for discrete labeling tasks. This leads us to the following question: Should we use a better model with approximate inference or an approximate model with better inference?</p><p>To answer this question, in this work, we use a Gaussian CRF (GCRF) model for the task of semantic segmentation.</p><p>To use a GCRF model for this discrete labeling task, we first replace each discrete variable with a vector of K mutually exclusive binary variables, where K is the number of possible values the discrete variable can take, and then model all the variables jointly as a multivariate Gaussian by relaxing the mutual exclusivity and binary constraints. After the GCRF inference, the discrete label assignment is done based on which of the K corresponding variables has the maximum value.</p><p>Though the Maximum a Posteriori (MAP) solution can be obtained in closed form in the case of GCRFs, it involves solving a linear system with number of variables equal to the number of nodes in the graph times the dimensionality of node variables (which is equal to the number of spatial locations times the number of classes in the case of semantic segmentation). Solving such a large linear system could be computationally prohibitive, especially for dense graphs where each node is connected to several other nodes. Hence, in this work, instead of exactly solving a large linear system, we unroll a fixed number of Gaussian Mean Field (GMF) inference steps as layers of a deep network, which we refer to as GMF network. Note that the GMF inference is different from the mean field inference used in <ref type="bibr" target="#b23">[24]</ref> for discrete CRFs with Gaussian edge potentials.</p><p>While GMF updates are guaranteed to give the MAP solution upon convergence, parallel updates are guaranteed to converge only under certain constraints such as diagonal dominance of the precision matrix of the joint Gaussian <ref type="bibr" target="#b52">[53]</ref>. If the nodes are updated serially, then the GMF inference is equivalent to an alternating minimization approach in which each subproblem is solved optimally, and hence it will converge (as finding the MAP solution for a GCRF is a convex problem with a smooth cost function). But, using serial updates would be very slow when the number of variables is large. To avoid both these issues, in this work, we use a bipartite graph structure that allows us to update half of the nodes in parallel in each step without loosing the convergence guarantee even when the diagonal dominance constraint is not satisfied. Using this bipartite structure, we ensure that each layer of our GMF network produces an output that is closer to the MAP solution compared to its input.</p><p>By combining the proposed GMF network with CNNs, we propose a new end-to-end trainable deep network, which we refer to as Gaussian CRF network, for the task of semantic segmentation. The proposed GCRF network consists of a CNN-based unary network for generating the unary potentials, a CNN-based pairwise network for generating the pairwise potentials and a GMF network for performing the GCRF inference. <ref type="figure" target="#fig_0">Figure 1</ref> gives an overview of the entire network. When trained discriminatively using the ImageNet and PASCALVOC data (ImageNet used for pretraining the CNNs), the proposed GCRF network gave a mean intersection-over-union (IOU) score of 73.2 on the challenging PASCALVOC 2012 test set <ref type="bibr" target="#b11">[12]</ref>, outperforming various recent approaches that combined CNNs with discrete CRFs. Also, when compared to just using the unary network, we improve the mean IOU by 6.2 points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions:</head><p>• Gaussian CRF for semantic segmentation: In contrast to the existing approaches that use discrete CRF models, we propose to use a GCRF model for the task of semantic segmentation. Compared to discrete CRFs, GCRFs are simpler models that can be solved optimally.</p><p>• GMF network: We propose a novel deep network by unfolding a fixed number of Gaussian mean field iterations. Using a bipartite graph structure, we ensure that each layer in our GMF network produces an output that is closer to the optimal solution compared to its input.</p><p>• Gaussian CRF network: We propose a new end-to-end trainable deep network that combines the GCRF model with CNNs for the task of semantic segmentation.</p><p>• Results: We show that the proposed GCRF network outperforms various existing discrete CRF-based approaches on the challenging PASCALVOC 2012 test set (when trained with ImageNet and PASCALVOC data).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Semantic segmentation using CNNs: In the recent past, numerous semantic segmentation approaches have been proposed based on CNNs. In <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17]</ref>, each region proposal was classified into one of the semantic classes by using CNN features. Instead of applying CNN to each region independently as in <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17]</ref>, <ref type="bibr" target="#b8">[9]</ref> applied the convolutional layers only once to the entire image, and generated region features by using pooling after the final convolutional layer. Different from the above approaches, <ref type="bibr" target="#b12">[13]</ref> trained a CNN to directly extract features at each pixel. To capture the information present at multiple scales, CNN was applied to the input image multiple times at different resolutions, and the features from all the resolutions were concatenated to get the final pixel features. This multiscale feature was then classified using a two-layer neural network. Finally, postprocessing steps like CRF and segmentation tree were used to further improve the results. Building on top of these CNN features, <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b46">47]</ref> introduced a recursive context propagation network that enriched the CNN features by adding image level contextual information. Instead of using a CNN multiple times, <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b30">31]</ref> proposed to use the features extracted by the intermediate layers of a deep CNN to capture the multi-scale information. Recently, <ref type="bibr" target="#b31">[32]</ref> trained a deconvolution network for the task of semantic segmentation. This network was applied separately to each region proposal, and all the results were aggregated to get the final predictions.</p><p>Most of the CNN-based methods mentioned above use superpixels or region proposals, and hence the errors in the initial proposals will remain no matter how good the CNN features are. Different from these methods, <ref type="bibr" target="#b29">[30]</ref> directly produced dense segmentation maps by upsampling the predictions produced by a CNN using a trainable deconvolution layer. To obtain finer details in the upsampled output, they combined the final layer predictions with predictions from lower layers.</p><p>Combining CNNs and CRFs for semantic segmentation: Though CNNs have been shown to work very well for the task of semantic segmentation, they may not be optimal as they do not model the interactions between the output variables directly, which is important for semantic segmentation. To overcome this issue, various recent approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b36">37]</ref> have used discrete CRF <ref type="bibr" target="#b25">[26]</ref> models on top of CNNs. While <ref type="bibr" target="#b12">[13]</ref> defined a CRF on superpixels and used graph-cuts based inference, <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b36">37]</ref> defined a CRF directly on image pixels and used the efficient mean field inference proposed in <ref type="bibr" target="#b23">[24]</ref>. Instead of using CRF as a post-processing step, <ref type="bibr" target="#b54">[55]</ref> trained a CNN along with a CRF in an end-to-end fashion by converting the mean field inference procedure of <ref type="bibr" target="#b23">[24]</ref> into a recurrent neural network. Similar joint training strategy was also used in <ref type="bibr" target="#b44">[45]</ref>.</p><p>In all these approaches, the CRF edge potentials were designed using hand-chosen features like image gradients, pixel color values, spatial locations, etc. and the potential function parameters were manually tuned. Contrary to this, recently, <ref type="bibr" target="#b27">[28]</ref> has learned both unary and pairwise potentials using CNNs. While all these approaches learn CNN-based potentials and use message passing algorithms to perform CRF inference, <ref type="bibr" target="#b26">[27]</ref> has recently proposed to use CNNs to directly learn the messages in message passing inference.</p><p>The idea of jointly training a CNN and graphical model has also been used for other applications such as sequence labeling <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b33">34]</ref>, text recognition <ref type="bibr" target="#b20">[21]</ref>, human pose estimation <ref type="bibr" target="#b51">[52]</ref>, predicting words from images <ref type="bibr" target="#b5">[6]</ref>, handwritten word recognition <ref type="bibr" target="#b3">[4]</ref>. Recently, various CNN-based semantic segmentation approaches have also been proposed for the semi and weakly supervised settings <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>Unrolling inference as a deep network: The proposed approach is also related to a class of algorithms that learn model parameters discriminatively by back-propagating the gradient through a fixed number of inference steps. In <ref type="bibr" target="#b1">[2]</ref>, the fields of experts <ref type="bibr" target="#b39">[40]</ref> model was discriminatively trained for image denoising by unrolling a fixed number of gradient descent inference steps. In <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b48">49]</ref> discrete graphical models were trained by back-propagating through either the mean field or the belief propagation inference iterations. In <ref type="bibr" target="#b38">[39]</ref>, message passing inference machines were trained by considering the belief propagation-based inference of a discrete graphical model as a sequence of predictors. In <ref type="bibr" target="#b14">[15]</ref>, a feed-forward sparse code predictor was trained by unrolling a coordinate descent-based sparse coding inference algorithm. In <ref type="bibr" target="#b18">[19]</ref>, a new kind of nonnegative deep network was introduced by deep unfolding of non-negative factorization model. Different from these approaches, in this work, we unroll the mean filed inference of a GCRF model as a deep network, and train our CNN-based potential functions along with the GCRF inference network in an end-to-end fashion.</p><p>Gaussian conditional random fields: GCRFs <ref type="bibr" target="#b49">[50]</ref> are popular models for structured inference tasks like denoising <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b55">56]</ref>, deblurring <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b55">56]</ref>, depth estimation <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b41">42]</ref>, etc., as they model continuous quantities and can be efficiently solved using linear algebra routines.</p><p>Gaussian CRF was also used for discrete labeling tasks earlier in <ref type="bibr" target="#b50">[51]</ref>, where a Logistic Random Field (LRF) was proposed by combining a quadratic model with logistic function. While the LRF used a logistic function on top of a GCRF to model the output, we directly model the output using a GCRF. Unlike <ref type="bibr" target="#b50">[51]</ref>, which used hand-chosen features like image gradients, color values, etc. to model the potentials, we use CNN-based potential functions.</p><p>Recently, <ref type="bibr" target="#b28">[29]</ref> trained a CNN along with a GCRF model for image-based depth prediction. The GCRF model of <ref type="bibr" target="#b28">[29]</ref> was defined on superpixels and had edges only between ad-jacent superpixels. As the resulting graph was sparse with few nodes, <ref type="bibr" target="#b28">[29]</ref> performed exact GCRF inference by solving a linear system. In contrast, we define our GCRF model directly on top of the dense CNN output and connect each node to several neighbors. Since the number of variables in our GCRF model is very large, exactly solving a linear system would be computationally expensive. Hence, we unfold a fixed number of GMF inference steps into a deep network. Also, while <ref type="bibr" target="#b28">[29]</ref> used hand-designed features like color histogram, local binary patterns, etc. for designing their pairwise potentials, we use CNN-based pairwise potentials.</p><p>The idea of combining the GCRF model with neural networks (one or two layers) has also been explored previously for applications such as document retrieval <ref type="bibr" target="#b37">[38]</ref> and facial landmark detection <ref type="bibr" target="#b0">[1]</ref>. However, the way we model our potential functions and perform inference is different from these works.</p><p>Notations: We use bold face small letters to denote vectors and bold face capital letters to denote matrices. We use A ⊤ and A −1 to denote the transpose and inverse of a matrix A. We use b 2 2 to denote the squared ℓ 2 norm of a vector b. A 0 means A is symmetric and positive semidefinite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Gaussian Conditional Random Field Model</head><p>In semantic segmentation, we are interested in assigning each pixel in an image X to one of the K possible classes. As mentioned earlier, we use K variables (one for each class) to model the output at each pixel, and the final label assignment is done based on which of these K variables has the maximum value. Let y i = [y i1 , . . . , y iK ] be the vector of K output variables associated with the i th pixel, and y be the vector of all output variables. In this work, we model the conditional probability density P (y|X) as a Gaussian distribution given by</p><formula xml:id="formula_0">P (y|X) ∝ exp − 1 2 E(y|X) , where E (y|X) = i y i − r i (X; θ u ) 2 2 + ij (y i − y j ) ⊤ W ij (X; θ p ) (y i − y j ) .<label>(1)</label></formula><p>The first term in the above energy function E is the unary term and the second term is the pairwise term 1 . Here, both r i and W ij 0 are functions of the input image X with θ u and θ p being the respective function parameters. Note that when W ij 0 for all pairs of pixels, the unary and pairwise terms can be combined together into a single positive semidefinite quadratic form.</p><p>The optimal y that minimizes the energy function E can be obtained in closed form since the minimization of E is an unconstrained quadratic program. However, this closed form solution involves solving a linear system with number of variables equal to the number of pixels times the number of classes. Since solving such a large linear system could be computationally prohibitive, in this work, we use the iterative mean field inference approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Gaussian mean field inference</head><p>The standard mean field approach approximates the joint distribution P (y|X) using a simpler distribution Q(y|X) which can be written as a product of independent marginals, i.e, Q(y|X) = i Q i (y i |X). 2 This approximate distribution is obtained by minimizing the KL-divergence between the distributions P and Q. In the case of Gaussian, the mean field approximation Q and the original distribution P have the same mean <ref type="bibr" target="#b52">[53]</ref>. Hence, finding the MAP solution y is equivalent to finding the mean µ of the distribution Q.</p><p>For the Gaussian distribution in <ref type="formula" target="#formula_0">(1)</ref>, the mean field updates for computing the mean µ are given by</p><formula xml:id="formula_1">µ i ← I + j W ij −1 r i + j W ij µ j .<label>(2)</label></formula><p>Here, µ i is the mean of marginal Q i . Please refer to the supplementary material for detailed derivations. It is easy to see that if we use the standard alternating minimization approach (in which we update one pixel at a time) to find the optimal y that minimizes the energy function in (1), we would end up with the same update equation. Since the energy function is a convex quadratic in the case of GCRF and update (2) solves each subproblem optimally, i.e., finds the optimal y i (or µ i ) when all the other y j (or µ j ) are fixed, performing serial updates is guaranteed to give us the MAP solution. However, it would be very slow since we are dealing with a large number of variables. While using parallel updates seems to be a reasonable alternative, convergence of parallel updates is guaranteed only under certain constraints like diagonal dominance of the precision matrix of the distribution P <ref type="bibr" target="#b52">[53]</ref>. Imposing such constraints could restrict the model capacity in practice. For example, in our GCRF model (1), we can satisfy the diagonal dominance constraint by making all W ij diagonal. However, this can be very restrictive, as making the non-diagonal entries of W ij zero will remove the direct inter-class interactions between pixels i and j, i.e., there will not be any interaction term in the energy function between the variables y ip and y jq for p = q. <ref type="figure">Figure 2</ref>: Each pixel in our CRF is connected to every other pixel along both rows and columns within a spatial neighborhood. Here, all the pixels that are connected to the center black pixel are shown in red. If the black pixel is on odd column, all the pixels connected to it will be on even columns and vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Bipartite graph structure for parallel updates</head><p>While we want to avoid the diagonal dominance constraint, we also want to update as many variables as possible in parallel. To address this problem, we use a bipartite graph structure, which allows us to update half of the variables in parallel in each step, and still guarantees convergence without the diagonal dominance constraint.</p><p>Note that our graphical model has a node for each pixel, and each node represents a vector of K variables. In order to update the i th node using (2), we need to keep all the other nodes connected to the i th node (i.e., all the nodes with non-zero W ij ) fixed. If we partition the image into odd and even columns (or odd and even rows) and avoid edges within the partitions, then we can optimally update all the odd columns (or rows) in parallel using (2) while keeping the even columns (or rows) fixed and vice versa. This is again nothing but an alternating minimization approach in which each subproblem (corresponding to half of the nodes in the graph) is optimally solved, and hence is guaranteed to converge to the global optimum (since we are dealing with a convex problem).</p><p>Generally when using graphical models, each pixel is connected to all the pixels within a spatial neighborhood. In this work, instead of using all the neighbors, we connect each pixel to every other neighbor along both rows and columns. <ref type="figure">Figure 2</ref> illustrates this for a 7 × 7 spatial neighborhood. It is easy to see that with this connectivity, we can partition the image into even and odd columns (or even and odd rows) without any edges within the partitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Gaussian CRF network</head><p>The proposed GCRF network consists of three components: Unary network, Pairwise network and GMF network. While the unary and pairwise networks generate the r i and W ij that are respectively used in the unary and pairwise terms of the energy function (1), the GMF network performs Gaussian mean field inference using the outputs of unary and pairwise networks. <ref type="figure" target="#fig_0">Figure 1</ref> gives an overview of the proposed GCRF network.</p><p>Unary network: To generate the r i used in the unary term of the energy function (1), we use the DeepLab-MSc-LargeFov network of <ref type="bibr" target="#b6">[7]</ref> (along with the softmax layer), which is a modified version of the popular VGG-16 network <ref type="bibr" target="#b47">[48]</ref>. Modifications compared to VGG-16 include converting the fully-connected layers into convolutional layers, skipping downsampling after the last two pooling layers, modifying the convolutional layers after the fourth pooling layer, and using multi-scale features similar to <ref type="bibr" target="#b17">[18]</ref>. Please refer to <ref type="bibr" target="#b6">[7]</ref> for further details. For brevity, we will refer to this DeepLab-MSc-LargeFov network as DeepLab CNN in the rest of the paper. We will denote the parameters of this unary DeepLab network using θ CN N u .</p><p>Pairwise network: Our pairwise network generates the matrices W ij that are used in the pairwise term of the energy function <ref type="bibr" target="#b0">(1)</ref>. In this work, we compute each W ij as</p><formula xml:id="formula_2">W ij = s ij C, C 0,<label>(3)</label></formula><p>where s ij ∈ [0, 1] is a measure of similarity between pixels i and j, and the learned matrix C encodes the class compatibility information. We compute the similarity measure s ij using</p><formula xml:id="formula_3">s ij = e −(zi−zj ) ⊤ F(zi−zj ) ,<label>(4)</label></formula><p>where z i is the feature vector extracted at i th pixel using a DeepLab CNN (with parameters θ CN N p ), and the learned matrix F 0 defines a Mahalanobis distance function. Note that the exponent of s ij can be written as</p><formula xml:id="formula_4">(z i − z j ) ⊤ F(z i − z j ) = M m=1 (f ⊤ m z i − f ⊤ m z j ) 2 , (5) where F = M m=1 f m f ⊤ m .</formula><p>Hence, we implement the Mahalanobis distance computation as convolutions (of z i with filters f m ) followed by an Euclidean distance computation.</p><p>The overall pairwise network consists of a DeepLab CNN that generates the pixel features z i , a similarity layer that computes s ij for every pair of connected pixels using (4) and <ref type="formula">(5)</ref>, and a matrix generation layer that computes the matrices W ij using (3). Note that here {f m } are the parameters of the similarity layer and C 0 are the parameters of the matrix generation layer.</p><p>GMF network: The proposed GMF network performs a fixed number of Gaussian mean field updates using the outputs of unary and pairwise networks. The input to the network is initialized using the unary output, µ 1 = r = {r i }. The network consists of several sequential GMF layers, where each GMF layer has two sub-layers (an even update layer followed by an odd update layer, See <ref type="figure" target="#fig_1">Figure 3</ref>): • Even update layer: This sublayer takes the output of previous layer as input, and updates the even column nodes using (2) while keeping odd column nodes fixed.</p><p>• Odd update layer: This sublayer takes the output of even update layer as input, and updates the odd column nodes using (2) while keeping even column nodes fixed. As explained in the previous section, because of the bipartite graph structure, the update performed by each of the above sublayers is an optimal update. Hence, each layer of our GMF network is guaranteed to generate an output that is closer to the MAP solution compared to its input (unless the input itself is the MAP solution, in which case the output will be equal to the input).</p><p>Combining the unary, pairwise and GMF networks, we get the proposed GCRF network, which can be trained in an end-to-end fashion. The parameters of the network are the unary network parameters θ u = θ CN N u , and the pairwise network parameters θ p = {θ CN N p , {f m }, C 0}. Note that since we use a fixed number of layers in our GMF network, the final output is not guaranteed to be the MAP solution of our GCRF model. However, since we train the entire network discriminatively in an end-to-end fashion, the unary and pairwise networks would learn to generate appropriate r i and W ij such that the output after a fixed number of mean field updates would be close to the desired output.</p><p>Note that the DeepLab network has three downsampling layers, and hence the size of its output is 1/8 times the input image size. We apply our GCRF model to this low resolution output and upsample the GMF network output to the input image resolution by using bilinear interpolation.</p><p>Discrete label assignment: Note that the final output at each pixel is a K-dimensional vector where K is the number of classes. Let y * i = [y * i1 , . . . , y * iK ] be the final output at i th pixel. Then the predicted class label of i th pixel is given by argmax k y * ik .</p><p>Training loss function: For training the network, we use the following loss function at each pixel</p><formula xml:id="formula_5">L (y * i , l i ) = −min 0, y * ili − max k =li y * ik − T ,<label>(6)</label></formula><p>where l i is the true class label. This loss function basically encourages the output associated with the true class to be greater than the output associated with all the other classes by a margin T .</p><p>Training: We train the proposed GCRF network discriminatively by minimizing the above loss function. We use standard backpropagation to compute the gradient of the network parameters. Due to space constraints, we present the derivative formulas in the supplementary material. Note that we have a constrained optimization problem here due to the symmetry and positive semidefiniteness constraints on the parameter C. We convert this constrained problem into an unconstrained one by parametrizing C as C = RR ⊤ , where R is a lower triangular matrix, and use stochastic gradient descent for optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments:</head><p>We evaluate the proposed GCRF network using the challenging PASCALVOC 2012 segmentation dataset <ref type="bibr" target="#b11">[12]</ref>, which consists of 20 object classes and one background class. The original dataset consists of 1464, 1449 and 1456 training, validation and test images, respectively. Similar to <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b54">55]</ref>, we augment the training set with the additional annotations provided by <ref type="bibr" target="#b15">[16]</ref>, resulting in a total of 10,582 training images. For quantitative evaluation, we use the standard mean intersection-over-union measure (averaged across the 21 classes).</p><p>Parameters: In our GCRF model, each node was connected to every other node along both rows and columns ( <ref type="figure">Figure 2</ref>) within a 23 × 23 spatial neighborhood. Note that since our GCRF model is applied to the CNN output whose resolution is 1/8 times the input resolution, the effective neighborhood size in the input image is 184 × 184. For our experiments, we used a five layer GMF network, which performs five full-image updates in the forward pass. During training, we used a value of 0.5 for the margin T used in our loss function. The number of filters M used in the similarity layer was set to be equal to the number of classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Training</head><p>We used the open source Caffe framework <ref type="bibr" target="#b22">[23]</ref> for training and testing our network. We initialized both of our DeepLab CNNs with the trained model provided by the authors of <ref type="bibr" target="#b6">[7]</ref>. Note that this model was finetuned using only the PASCALVOC segmentation data starting from ImageNet-trained VGG-16 model. For training, we used stochastic gradient descent with a weight decay of 5 × 10 −3 and momentum of 0.9.</p><p>Pretraining: Before training the full GCRF network, we pre-trained the similarity layer and CNN of the pairwise network such that the output s ij of the similarity layer is high for a pair of pixels that have same class label and low for a pair of pixels that have different class labels. For pretraining, we used the following loss function for each pair of connected pixels:</p><formula xml:id="formula_6">L ij = −✶[l i = l j ]s ij + ✶[l i = l j ] min(0, s ij − h),<label>(7)</label></formula><p>where l i and l j are respectively the class labels of pixel i and j, and h is a threshold parameter. This loss function encourages s ij to be high for similar pairs and below a threshold h for dissimilar pairs. The value of h was chosen as e −10 . For training, we used a mini-batch of 15 images and a starting learning rate of 10 −3 for the similarity layer parameters {f m } and 10 −4 for the CNN parameters θ CN N p . After training for 8000 iterations, we multiplied the learning rate of the similarity layer parameters by 0.1 and trained for additional 5000 iterations.</p><p>Finetuning: After the pre-training stage, we finetuned the entire GCRF network using a mini-batch of 5 images and a starting learning rate of 10 −2 for all parameters except θ CN N u , for which we used a small learning rate of 10 −6 . 3 After training for 6000 iterations, we multiplied the learning rate by 0.01 and trained for additional 25000 iterations. <ref type="table">Table 1</ref> compares the proposed GCRF network with state-of-the-art semantic segmentation approaches on the challenging PASCALVOC 2012 test set. We can infer the following from these results:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results</head><p>• The proposed GCRF network performs significantly (6.2 points) better than the DeepLab CNN, which was used for initializing our unary network. This shows that GCRFs can be successfully used to model output interactions in discrete labeling problems even though they are continuous models.</p><p>• The proposed approach outperforms several recent approaches that use discrete CRF models with CNNs. This shows that, despite being a continuous model, GCRF can be a strong competitor to discrete CRFs in discrete labeling tasks.</p><p>• Our result is on par with the state-of-the-art (lower by just 0.2 points) when trained using only ImageNet and PASCALVOC data. <ref type="figure">Figure 4</ref> provides a visual comparison of the proposed approach with DeepLab CNN (which is same as our unary network) and DeepLab CNN + discrete CRF. As we can see, the proposed GCRF model is able to correct the errors made by the unary network, and also produces more accurate segmentation maps compared to the discrete CRFbased DeepLab approach.</p><p>Computation time: The proposed GCRF network takes around 0.6 seconds to segment a 505 × 505 image on an NVIDIA TITAN GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this work, we proposed to use a GCRF model for the discrete labeling task of semantic segmentation. We proposed a novel deep network, which we refer to as GMF network, by unfolding a fixed number of Gaussian mean field inference steps. By combining this GMF network with CNNs, we proposed an end-to-end trainable GCRF network. When trained discriminatively, the proposed GCRF network outperformed various recent discrete CRF-based semantic segmentation approaches on the challenging PAS-CALVOC 2012 segmentation dataset. Our results suggest that, despite being a continuous model, GCRF can be successfully used for discrete labeling tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ground truth</head><p>DeepLab CNN DeepLab CNN-CRF Proposed <ref type="figure">Figure 4</ref>: Comparison of the proposed approach with DeepLab CNN <ref type="bibr" target="#b6">[7]</ref> and DeepLab CNN + discrete CRF <ref type="bibr" target="#b6">[7]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Proposed GCRF network: The GMF network performs GCRF inference using the outputs of unary and pairwise networks. The output of GMF network is upsampled to full image resolution using bilinear interpolation. Note that the parameters of this GCRF network are the unary network parameters θ CN N u and the pairwise network parameters {θ CN N p , {fm}, C 0}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>GMF Network. µ t e and µ t o are even and odd column nodes respectively where t indexes the layers, µ t = {µ t e , µ t o }. Network is initialized with unary network output µ 1 = r.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Method bkg areo bike bird boat bottle bus car cat chair cow table dog horse mbk person plant sheep sofa train tv mean Approaches that use CNNs and discrete CRFs Table 1: Comparison with state-of-the-art on PASCALVOC 2012 test set (when trained using ImageNet and PASCALVOC data).</figDesc><table>MSRA-CFM [9] 
87.7 75.7 26.7 69.5 48.8 65.6 81.0 69.2 73.3 30.0 68.7 51.5 69.1 68.1 71.7 67.5 50.4 66.5 44.4 58.9 53.5 61.8 

FCN-8s [30] 
91.2 76.8 34.2 68.9 49.4 60.3 75.3 74.7 77.6 21.4 62.5 46.8 71.8 63.9 76.5 73.9 45.2 72.4 37.4 70.9 55.1 62.2 

Hypercolumns [18] 
89.3 68.7 33.5 69.8 51.3 70.2 81.1 71.9 74.9 23.9 60.6 46.9 72.1 68.3 74.5 72.9 52.6 64.4 45.4 64.9 57.4 62.6 

DeepLab CNN [7] 
91.6 78.7 51.5 75.8 59.5 61.9 82.5 76.6 79.4 26.9 67.7 54.7 74.3 70.0 79.8 77.3 52.6 75.2 46.6 66.9 57.3 67.0 

ZoomOut [31] 
91.1 85.6 37.3 83.2 62.5 66.0 85.1 80.7 84.9 27.2 73.2 57.5 78.1 79.2 81.1 77.1 53.6 74.0 49.2 71.7 63.3 69.6 

Deep message passing [27] 93.9 90.1 38.6 77.8 61.3 74.3 89.0 83.4 83.3 36.2 80.2 56.4 81.2 81.4 83.1 82.9 59.2 83.4 54.3 80.6 70.8 73.4 

Deep structure models [28] 93.6 86.7 36.9 82.3 63.0 74.2 89.8 84.1 84.1 32.8 65.4 52.1 79.7 72.1 77.6 81.7 55.6 77.4 37.4 81.4 68.4 70.3 

DeconvNet + CRF [32] 
92.9 87.8 41.9 80.6 63.9 67.3 88.1 78.4 81.3 25.9 73.7 61.2 72.0 77.0 79.9 78.7 59.5 78.3 55.0 75.2 61.5 70.5 

object clique potentials [37] 92.8 80.0 53.8 80.8 62.5 64.7 87.0 78.5 83.0 29.0 82.0 60.3 76.3 78.4 83.0 79.8 57.0 80.0 53.1 70.1 63.1 71.2 

DeepLab CNN-CRF [7] 
93.3 84.4 54.5 81.5 63.6 65.9 85.1 79.1 83.4 30.7 74.1 59.8 79.0 76.1 83.2 80.8 59.7 82.2 50.4 73.1 63.7 71.6 

CRF-RNN [55] 
94.0 87.5 39.0 79.7 64.2 68.3 87.6 80.8 84.4 30.4 78.2 60.4 80.5 77.8 83.1 80.6 59.5 82.8 47.8 78.3 67.1 72.0 

DeconvNet + FCN + CRF [32] 93.1 89.9 39.3 79.7 63.9 68.2 87.4 81.2 86.1 28.5 77.0 62.0 79.0 80.3 83.6 80.2 58.8 83.4 54.3 80.7 65.0 72.5 

Proposed GCRF network 
93.4 85.2 43.9 83.3 65.2 68.3 89.0 82.7 85.3 31.1 79.5 63.3 80.5 79.3 85.5 81.0 60.5 85.5 52.0 77.3 65.1 73.2 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that we have only one term for each pair of pixels, i.e., we do not have separate W ij and W ji for the pair (i, j). We just have one W for (i, j) which can be interpreted as both W ij and W ji based on the context.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Note that instead of using marginals of scalar variables y ik , we are using marginals of vector variables y i .</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Since the Unary DeepLab CNN was trained by<ref type="bibr" target="#b6">[7]</ref> using PAS-CALVOC segmentation data, it was already close to a good local minima. Hence, we finetuned it with a small learning rate.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Continuous Conditional Neural Fields for Structured Regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Baltrusaitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Training an Active Random Field for Real-Time Image Denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2451" to="2462" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Material Recognition in the Wild with the Materials in Context Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Upchurch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Globally Trained Handwritten Word Recognizer Using Spatial Representation, Convolutional Neural Networks, and Hidden Markov Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Classification of Textures Using Gaussian Markov Random Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chatterjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="959" to="963" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning Deep Structured Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">BoxSup: Exploiting Bounding Boxes to Supervise Convolutional Networks for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Convolutional Feature Masking for Joint Object and Stuff Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural Conditional Random Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M T</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Artières</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning Graphical Model Parameters with Approximate Marginal Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Domke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2454" to="2467" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Pascal Visual Object Classes Challenge: A Retrospective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning Hierarchical Features for Scene Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Najman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning fast approximations of sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semantic Contours from Inverse Detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Simultaneous Detection and Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hypercolumns for Object Segmentation and Fine-grained Localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Deep unfolding: Model-based inspiration of novel deep architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Hershey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Weninger</surname></persName>
		</author>
		<idno>abs/1409.2574</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Decoupled Deep Neural Network for Semi-supervised Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Zisserman. Deep Structured Output Learning for Unconstrained Text Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Loss-specific Training of Non-parametric Image Restoration Models: A New State of the Art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jancsary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Caffe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5093</idno>
		<title level="m">Convolutional Architecture for Fast Feature Embedding</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Parameter Learning and Convergent Inference for Dense Random Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="513" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deeply Learning the Messages in Message Passing Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V D</forename><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">D</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V D</forename><surname>Hengel</surname></persName>
		</author>
		<idno>abs/1504.01013</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep Convolutional Neural Fields for Depth Estimation from a Single Image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fully Convolutional Networks for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Feedforward Semantic Segmentation with Zoom-out Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mostajabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yadollahpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shakhnarovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning Deconvolution Network for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Weakly and Semi-Supervised Learning of a DCNN for Semantic Image Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Conditional Neural Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Recurrent Convolutional Neural Networks for Scene Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H O</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">From image-level to pixel-level labeling with Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Semantic Segmentation with Object Clique Potentials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Neural Gaussian Conditional Random Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Radosavljevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vucetic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Obradovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Bagnell. Learning Message-passing Inference Machines for Structured Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Munoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fields of Experts. International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="205" to="229" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Gaussian Markov Random Fields: Theory and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Held</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">3-D Depth Reconstruction from a Single Still Image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Cascades of Regression Tree Fields for Image Restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jancsary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Shrinkage Fields for Effective Image Restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Fully Connected Deep Structured Networks. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<idno>abs/1503.02351</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep Hierarchical Parsing for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Recursive Context Propagation Network for Semantic Scene Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Empirical Risk Minimization of Graphical Model Parameters given Approximate Inference, Decoding, and Model Structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ropson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Freeman. Learning Gaussian Conditional Random Fields for Low-Level Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Tappen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The Logistic Random Field -A Convenient Graphical Model for Learning Parameters for MRFbased Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Tappen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G G</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Lyle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Graphical Models, Exponential Families, and Variational Inference. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Mean Field Annealing Using Compound Gauss-Markov Random Fields for Edge Detection and Image Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zerubia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="703" to="709" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Conditional Random Fields as Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">From Learning Models of Natural Image Patches to Whole Image Restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
