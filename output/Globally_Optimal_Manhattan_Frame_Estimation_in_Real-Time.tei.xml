<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Globally Optimal Manhattan Frame Estimation in Real-time</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyungdon</forename><surname>Joo</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">In So Kweon Robotics and Computer Vision Lab</orgName>
								<orgName type="institution">KAIST</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae-Hyun</forename><surname>Oh</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">In So Kweon Robotics and Computer Vision Lab</orgName>
								<orgName type="institution">KAIST</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsik</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">In So Kweon Robotics and Computer Vision Lab</orgName>
								<orgName type="institution">KAIST</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Globally Optimal Manhattan Frame Estimation in Real-time</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:40+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Given a set of surface normals, we pose a Manhattan Frame (MF) estimation problem as a consensus set maximization that maximizes the number of inliers over the rotation search space. We solve this problem through a branchand-bound framework, which mathematically guarantees a globally optimal solution. However, the computational time of conventional branch-and-bound algorithms are intractable for real-time performance. In this paper, we propose a novel bound computation method within an efficient measurement domain for MF estimation, i.e., the extended Gaussian image (EGI). By relaxing the original problem, we can compute the bounds in real-time, while preserving global optimality. Furthermore, we quantitatively and qualitatively demonstrate the performance of the proposed method for synthetic and real-world data. We also show the versatility of our approach through two applications: extension to multiple MF estimation and video stabilization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Most man-made structures, such as urban and indoor scenes, consist of a set of parallel and orthogonal planes. These structures are commonly approximated by the Manhattan World (MW) assumption <ref type="bibr" target="#b5">[5]</ref> in the fields of computer vision and robotics. Under the MW assumption, three orthogonal directions are used to represent a scene structure, which are referred to as the Manhattan Frame (MF) in previous studies <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b9">9]</ref>. Recent studies have proposed a variety of MF estimation methods for scene representation <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b21">21]</ref>. In addition to scene representation, an accurate estimation of MF is important as a key module for many computer vision applications, such as scene understanding <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b4">4,</ref><ref type="bibr" target="#b11">11]</ref>, SLAM <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b30">30]</ref>, focal length estimation <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b1">2]</ref>, and 3D reconstruction <ref type="bibr" target="#b8">[8]</ref>. Since MF estimation is typically used as an early phase module in such a wide range of applications, its overall performance is critical for the viability of the application as a whole. * The first and the second authors provided equal contributions.</p><p>In order to ensure the versatile applicability to a broad range of applications, a given MF estimation method requires two properties: stability and efficiency. For stability, the robustness against noise and outliers is essential, as well as the estimation method's insensitivity to its initialization. As for efficiency, the computational complexity of the MF estimation has to remain reasonable. Even when its stability is guaranteed, an MF estimation with a high order complexity is undesirable for time critical applications, e.g., SLAM.</p><p>In this research, we propose a robust and real-time Manhattan Frame (MF) estimation approach that guarantees a globally optimal solution with high stability and efficiency. We pose the MF estimation problem as that of a consensus set maximization, and solve it through a branch-andbound (BnB) framework <ref type="bibr" target="#b15">[15]</ref>. Typically, the bound computation is the most time-consuming part in a conventional BnB framework <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b12">12]</ref>. To combat this, we suggest a relaxation of the original problem and a new bound definition that can be efficiently computed on a 2D domain (i.e., EGI). This allows the bounds to be computed using a few simple arithmetic operations with linear complexity, while still preserving the global optimality and the convergence property of the BnB framework. The proposed framework is illustrated in <ref type="figure">Fig. 1</ref>. Our method is quantitatively and qualitatively validated with real and synthetic data. We also demonstrate the flexibility of our method by using it in two applications: multiple MF estimation (a mixture of Manhattan Frames) of a scene and video stabilization. In summary, the contributions of this work are as follows:</p><p>• We propose a branch-and-bound based, real-time MF estimation. Our approach can process around 300, 000 measurements in real-time. • We relax the problem and present a new and efficient bound computation with linear-time complexity, while guaranteeing a globally optimal solution. • Our method has been validated through systematic experiments and real world data. To show extensibility, we present multiple MF estimation and video stabilization as possible applications. • We make the source code of the proposed method available for future use.  <ref type="figure">Figure 1</ref>: Overview of the proposed MF estimation approach. First column: Input data and distribution of surface normals of a scene from NYUv2 dataset <ref type="bibr" target="#b24">[24]</ref>. Second column: Its surface normal histogram, i.e., EGI, the 2D-EGI and its integral image to efficiently calculate bounds. Third column: Illustration of the efficient bound based BnB framework using rotation search space. Last column: The estimated globally optimal MF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>MF estimation is commonly used as a key module for high-level vision tasks, such as scene understanding and 3D reconstruction. Understanding man-made scene structures can be boiled down to either estimating the orthogonal vanishing points (VP) in the image domain or estimating the three dominant orthogonal directions (or rotation matrix) with 3D information, such as the depth or surface normals. Image-based approaches fundamentally rely on the perspective cues of an image and lines, as in <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b4">4]</ref>. On the other hand, recent studies have focused on accurately estimating dominant orthogonal directions using 3D information <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b11">11]</ref>. As long as the related approaches are designed to reveal the Manhattan structure of a scene, we will refer to them as MF estimation approaches for the sake of clarity.</p><p>Silberman et al. <ref type="bibr" target="#b24">[24]</ref> generate all possible MF hypotheses of a scene with measured perspective cues and surface normals. Then, all the hypotheses are exhaustively scored by the number of measurements that support the MF, and then the best one is taken. Taylor et al. <ref type="bibr" target="#b28">[28]</ref> estimate a gravity vector, which corresponds to the floor normal, from RGB-D segmentation in order to sequentially estimate the other orthogonal normal vectors from wall plane segments. This approach is based on the assumptions that the vertical axis should be aligned with the gravity vector and that large planar regions should be placed near the bottom of the image. Similar to Taylor et al., <ref type="bibr">Gupta et al. [11]</ref> estimate and refine a single gravity vector from the y-axis of a RGB-D image as the initial gravity vector, without extending it to MF. Ghanem et al. <ref type="bibr" target="#b9">[9]</ref> has recently proposed a non-convex MF estimation that exploits the inherent sparsity of the membership of each measured normal vector. Unfortunately, all the algorithms mentioned above are all sub-optimal.</p><p>As the importance of MF has grown, high stability and efficiency of MF estimation are desirable for general pur-poses. To guarantee stability, Bazin et al. <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3]</ref> propose an orthogonal VP estimation based on the BnB framework, which guarantees a global optimal solution. In <ref type="bibr" target="#b0">[1]</ref>, they present an interval analysis-based BnB framework. This strategy is improved in <ref type="bibr" target="#b2">[3]</ref> by proposing an efficient bound computation on the rotation search space <ref type="bibr" target="#b12">[12]</ref>. However, BnB frameworks are usually too slow for real-time applications <ref type="bibr" target="#b19">[19]</ref>. For this purpose, Parra et al. <ref type="bibr" target="#b19">[19]</ref> propose a fast BnB rotation search method that uses an efficient bound function computation, which can register up to 1000 points in 2 seconds. However this method is still inadequate for real-time applications. Straub et al. <ref type="bibr" target="#b26">[26]</ref> propose a GPUsupported MF inference method that operates in real-time, but does not guarantee global optimality. In contrast to previous studies, the proposed MF estimation method with BnB framework guarantees a globally optimal solution, as well as real-time efficiency.</p><p>Straub et al. <ref type="bibr" target="#b27">[27]</ref> suggest a new perspective on MF, which they call a mixture of Manhattan Frames (MMF). The motivation behind the MMF is to represent general, real-world scenes that the conventional MW assumption fails to depict. Inspired by this work, we also extend our method to multiple MF estimation as an application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem Statement</head><p>The type of input for our problem can either be the 3D surface normals (from the depth map or 3D point cloud) or the VPs. For simplicity, we only consider the case in which the surface normals 1 are the input. Given a set of surface normals N = {n i } N i=1 , our goal is to estimate the MF of a scene, which consists of three orthogonal directions.</p><p>By virtue of the orthogonal property of an MF, the process of MF estimation becomes equivalent to that of estimating the proper rotation matrix R ∈ SO(3) that transforms the standard basis of a coordinate to a new three or-thogonal basis that are aligned to the dominant surface normals, up to a sign. Since the direction vector and its flipping vector indicate the same structural support, we incorporate both the basis vectors and their flipping vectors into a set E = {e j } 6 j=1 2 of six canonical vectors. To estimate the optimal rotation matrix R * , we formulate an optimization problem that maximizes the number of inliers as:</p><formula xml:id="formula_0">arg max R∈SO(3) N i=1 6 j=1 ∠(ni, Rej) ≤ τ ,<label>(1)</label></formula><p>where ∠(a, b) is the angle between the vectors a and b, τ is the inlier threshold, and · is the indicator function. Thus, the problem is to find the optimal rotation on the rotation manifold (i.e., solution search space) by counting the number of inlier normals in the input set (i.e., measurement space). However, Eq. (1) is not easy to handle in a numerical optimization. Similar to the approach of Li <ref type="bibr" target="#b17">[17]</ref>, we introduce an auxiliary variable y ij ∈ {0, 1} indicating whether the i-th surface normal is an inlier (y ij = 1) or an outlier (y ij = 0). Hence, we can reformulate Eq. (1) into an equivalent integer programming problem:</p><formula xml:id="formula_1">arg max {y ij },R∈SO(3) N i=1 6 j=1 yij s.t. yij∠(ni, Rej) ≤ yijτ, yij ∈ {0, 1}, ∀i = 1 · · · N, j = {1, · · · , 6}.<label>(2)</label></formula><p>Solving Eq. (2) is still challenging due to the non-linearities within the geodesic distance measure, the rotation manifold parameterization, and the engagement between the two aforementioned families of unknowns. Consequently, it constitutes a challenging type of non-convex problem. Fortunately, this can be dealt with the BnB framework described in later sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Branch-and-Bound with Rotation Search</head><p>Branch-and-bound (BnB) is a general framework for global optimization <ref type="bibr" target="#b15">[15]</ref>. The basic idea of BnB is to recursively divide a solution space into smaller sub-spaces and test each sub-space with a feasibility test to see whether it contains a globally optimal solution. The feasibility test is conducted by values called a bound of sub-space. The subspaces proven to be infeasible from the test are excluded from the search space and the remaining sub-spaces are subdivided for further searches until an optimal solution or a desired accuracy is reached. The key parts of the BnB framework are the determination of the appropriate search space and the bound function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Branching Part</head><p>The first key part of the BnB is to define the appropriate search space. The search space in our MF estimation problem is the rotation space. We employ an angle-axis parameterization to represent a rotation matrix R, which is formed by a three-dimensional vector β in a ball B π of radius π, whose direction and norm specify the axis β/ β and angle β <ref type="bibr" target="#b12">[12]</ref>. In the angle-axis parameterization, any rotation can be represented by a point in the ball B π , which is equivalent to the search space in this problem. Let D init be the initial cube that tightly encloses the ball B π . We divide the rotation search space into smaller sub-spaces via octal subdivision for branching in BnB, as illustrated in the top half of the third column in <ref type="figure">Fig. 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Bounding Part</head><p>For rotation search, a useful and efficient bound computation is suggested by Bazin et al. <ref type="bibr" target="#b2">[3]</ref>. We directly re-state the result of Bazin et al. to show its connection to our problem formulation in Eq. (2). Proposition 1 (Bazin et al. <ref type="bibr" target="#b2">[3]</ref>). Given a cube D with the half side length σ and the rotationR corresponding to the center of the cube D, the solutions of the following systems are the valid lower and upper bounds, L B and U B , of the inlier cardinality for any rotation in the cube D, respectively.</p><formula xml:id="formula_2">LB = max {y ij } N i=1 6 j=1 yij s.t. yij∠(ni,Rej) ≤ yijτ, yij ∈ {0, 1}, ∀i = 1 · · · N, j = {1 · · · 6}. (3) UB = max {y ij } N i=1 6 j=1 yij s.t. yij∠(ni,Rej) ≤ yij(τ + √ 3σ), yij ∈ {0, 1}, ∀i = 1 · · · N, j = {1 · · · 6}.<label>(4)</label></formula><p>Their proof can be directly followed in <ref type="bibr" target="#b2">[3]</ref>. In Proposition 1, the solutions of Eqs. <ref type="formula">(3)</ref> and <ref type="formula" target="#formula_2">(4)</ref>, L B and U B , are simply obtained by exhaustively checking the inlier constraint for each normal with respect to the rotation corresponding to the center of the given cube. We refer to this heuristic method as the exhaustive BnB, and will be compared with the proposed method.</p><p>According to Proposition 1, a single evaluation of either the lower or upper bound has O(N ) complexity, as each sample must go through a bound computation. The evaluation is linear to the number of input normals, but with an exponentially increasing number of cubes in the branching step, an efficient BnB is hard to realize. To overcome this inefficiency, we relax the problem defined in Eq. (2) and propose an efficient bound computation with O(1) complexity, which is effective for MF estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Efficient Bound Computation</head><p>To compute the bound values for a cube, we count the number of normal vectors that come within the given threshold. During the bound computation in Proposition 1, an inlier domain can be represented as a region on the measurement space. We call this region the inlier region (see  Traditionally, a bound computation is the main computational bottleneck in BnB frameworks. For an efficient bound computation, we represent a set of surface normals as a surface normal histogram, which is an approximation of the extended Gaussian image (EGI) representation <ref type="bibr" target="#b14">[14]</ref>. Based on the EGI representation, we relax the original problem in Eq. (2) and propose a new set of efficient bound functions. Throughout this paper, we will refer to the EGI representation and the surface normal histogram interchangeably.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Efficent Measurement Space on 2D-EGI</head><p>For the EGI representation, we discretize a unit sphere (i.e., measurement space) by simply tessellating by its azimuth and elevation, which have the ranges of 0∼360 • and 0∼180 • , respectively. A direction vector in the discretized domain is approximated and represented as its elevation and azimuth angles in discrete units. By accumulating the direction vectors (surface normals) as a histogram in each discrete unit, we can obtain the 2D-EGI (see second column of <ref type="figure">Fig. 1</ref>). We denote the 2D-EGI space as EGI ∈ R m×n + , where m and n are the height and width defined as 180 × s and 360 × s, respectively, and s denotes the EGI resolution parameter, meaning that the angle unit is 1/s • . There is a trade-off between accuracy and computation time by adjusting the EGI resolution (we empirically set s = 2 in our experiments). Although it may seem like a simple accumulation of surface normals, the EGI provides several powerful advantages, as it allows for a direct 2D representation <ref type="bibr" target="#b18">[18]</ref>.</p><p>Let X L and X U be the sets of densely sampled boundary points of the lower and upper inlier regions around the six direction vectors (blue and red points of <ref type="figure" target="#fig_0">Fig. 2a)</ref> on the spherical manifold of the measurement domain. Once X L and X U are mapped onto the 2D-EGI, the transferred boundariesX L andX U on the 2D-EGI domain appear as inlier regions with a curved boundary (light blue and red curves in <ref type="figure" target="#fig_0">Fig. 2b)</ref>. The lower and upper bounds, L B and U B , can be computed by summing the histogram values within the transferred boundaries on the 2D-EGI domain, but instead we further speed up the bound function evaluation by relaxing the original problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Rectangular Lower and Upper Bounds</head><p>Regardless of the tightness of the bounds, any valid bound guarantees a global optimum in the BnB framework with a breadth-first-search strategy <ref type="bibr" target="#b15">[15]</ref>. By slightly relaxing the inlier condition, we can improve the computational efficiency significantly while preserving the global optimality, if its new bounds are still valid.</p><p>Since the transferred boundariesX L andX U on the 2D-EGI have non-linear shapes, exhaustive traversal within the transferred boundaries is mandatory for computing the bounds. We instead relax the original problem defined in Eq. (2) by replacing the original constraint with a set of new axis-aligned inlier constraints as:</p><formula xml:id="formula_3">arg max {y ij },R∈SO(3) N i=1 6 j=1 yij s.t. yijφ(ni, Rej) ≤ yijτ el , yijθ(ni, Rej) ≤ yijτaz, yij ∈ {0, 1}, ∀i = 1 · · · N, j = {1 · · · 6},<label>(5)</label></formula><p>where φ(·, ·) and θ(·, ·) are the angle distances between two vectors along the elevation and the azimuth axes of EGI respectively, and τ el and τ az are the inlier thresholds for each axis. We will discuss how to choose these inlier thresholds later. These constraints form the box constraint.</p><p>We can formulate the relaxed problem in Eq. (5) into BnB by defining new valid lower and upper bound functions, similar to those in Proposition 1. For the new bound functions to be closer to those in the original problem in Eq. (2), we find the tightest circumscribed rectangles ofX L andX U . We call these inlier regions the rectangular inlier regions, as shown in <ref type="figure" target="#fig_0">Fig. 2</ref>. When we restrict the boundaries to be axis-aligned and rectangular, from the transferred point setsX L,U , the new boundaries are uniquely defined by finding a circumscribed rectangle with the left-most, rightmost, highest, and lowest points along the elevation and azimuth axes, as shown in <ref type="figure" target="#fig_0">Fig. 2c</ref>. We observe that the shape of the rectangular boundaries on the 2D-EGI varies depending on the location of r i . While the height of the rectangular boundary remains constant 3 , the width varies according to the elevation angle of r i on the 2D-EGI. Then, the bound functions of the relaxed problem in Eq. (5) can be defined as follows:</p><formula xml:id="formula_4">LR = max {y ij } N i=1 6 j=1 yij s.t. yijφ(ni,Rej) ≤ yijτ el , yijθ(ni,Rej) ≤ yijτ L az (φ(e2,Rej)), yij∈{0, 1}, ∀i={1 · · · N }, j={1 · · · 6},<label>(6)</label></formula><formula xml:id="formula_5">UR = max {y ij } N i=1 6 j=1 yij s.t. yijφ(ni,Rej) ≤ yij(τ el + √ 3σ), yijθ(ni,Rej) ≤ yijτ U az (φ(e2,Rej)), yij∈{0, 1}, ∀i={1 · · · N }, j={1 · · · 6},<label>(7)</label></formula><p>where e 2 is the basis of the y-axis of the 3D measurement space used to measure the elevation angle. τ L az (·) and τ U az (·) are the inlier threshold functions for the azimuth axis, which can be computed in advance by finding the circumscribed rectangles ofX L andX U and storing them into a look-up table, as will be explained in Sec. 5.5.</p><p>The feasibility constraints in the aforementioned rectangular inlier regions are interpreted as whether a pixel in the 2D-EGI map is inside the rectangular regions defined by the inlier thresholds. Thus, the bound computation can be done by summing up the values in the rectangular regions, which can be efficiently computed using the integral image <ref type="bibr" target="#b29">[29]</ref> (i.e., through simple add and subtract operations with the four corner values of the rectangular inlier region on the integral image). The proposed rectangular bound has the following property.</p><p>Lemma 1. For a cube D, let c * D be the optimal inlier cardinality of the relaxed problem (Eq. <ref type="formula" target="#formula_3">(5)</ref>). Then the bounds L R and U R obtained by the proposed method satisfy L R ≤ c * D ≤ U R . Also, when the maximum half side length of D, i.e., σ, goes to zero, then U R − L R ≤ ǫ.</p><p>Lemma 1 asserts that the proposed bound functions of Eqs. (6) and <ref type="formula" target="#formula_5">(7)</ref> are valid, and is useful for further theoretical analysis on the behavior of BnB using rectangular bounds, which will be discussed in a later section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Algorithm Procedure</head><p>The BnB procedure is formalized in Alg. 1. The algorithm reduces the search space iteratively by rejecting subspaces with the feasibility test until it converges to a globally optimal value or reaches a desired accuracy level. At first, the cube-list L is initialized with the cube D init that encloses the rotation ball B π . At every iteration, each cube in the cube-list is subdivided into octal sub-cubes with the half length size of its parent cube and stored in the cube-list while removing the parent cubes from the list. For each subcube, the rotation center and the lower and upper bounds are computed. Then, a feasibility test is conducted based on the rectangular bounds (c.f . Sec. 5.2). Cubes with an upper bound smaller than the maximum lower bound are excluded from the cube-list, as they are guaranteed to not contain the globally optimal solution. This procedure repeats iteratively</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 BnB on the Efficient Measurement Space</head><p>Initialize the cube list L with the rotation ball Bπ.</p><p>repeat</p><formula xml:id="formula_6">Subdivision(σ ← σ/2) of each cube D i of L.</formula><p>for each cube D i of L do Calculate the rotation R D i of the cube center. Compute the rectangular lower L R i and upper U R i bounds.</p><p>(c.f . Sec. 5.2). end for</p><formula xml:id="formula_7">L * = max i L R i , i * = arg max i U R i , U * = U R i * , R * = R D i * .</formula><p>Remove all the cubes from L such that U R i &lt; L * . until ∃i, such that L R i = U * (i.e., at least one cube whose lower bound is U * ) or it reaches the desired accuracy level. Output: R * (i.e., the rotation matrix maximizing the number of inliers). until a single cube, of which the lower bound and the upper bound are the same, remains or a desired accuracy is achieved. The solution is the rotation of the cube center that has the highest cardinality, i.e., the rotation guaranteed to be globally optimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Analysis</head><p>Computational Complexity Compared to the related studies <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b2">3]</ref>, Proposition 1 tells us that each bound computation has O(N ) complexity. For simplicity, let C be the number of cubes that should be evaluated in the BnB framework until convergence. Then, the computation complexity of the whole procedure is O <ref type="figure">(CN )</ref>.</p><p>In our framework, constructing the EGI by accumulating surface normals and the integral image take O(N ) and O(B), respectively, only at the initial stage, where B denotes the number of bins, i.e., mn of EGI. Each bound computation with the 2D-EGI representation takes O(1) on the integral image. Since the initial stage exhibits a linear complexity with respect to the resolution of EGI and the BnB procedure on the proposed problem shows a linear complexity with respect to the number of evaluated cubes C, the overall algorithm complexity is O(C + B) which is still linear.</p><p>We can see that the proposed method is much faster than the exhaustive BnB method <ref type="bibr" target="#b2">[3]</ref>, which has a quadratic complexity O(CN ). In practice, given a single depth image with a resolution of 640 × 480, N is around 300, 000 samples, and C is in the range of hundreds of thousands to millions. This gives a sense of what makes the proposed algorithm real-time. Convergence Since it is already shown that the rectangular bounds are valid bounds by Lemma 1, the proposed method with the rectangular bounds is guaranteed to compute the globally optimal solution <ref type="bibr" target="#b15">[15]</ref>. However, we utilize a discrete EGI representation, where a certain sub-division level exists such that subsequent upper bound values are quantized into the same value. Albeit with this discretization, our method still guarantees to converge to the bounded globally optimal solution. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Further Speed Up</head><p>Search Space Rejection As mentioned before, given a rotation matrix R = [r 1 r 2 r 3 ] of a cube, a direction r i and its flipping vector −r i (for i = {1, 2, 3}) indicate the same vector, i.e., the rotation matrices R and −R indicate the same solution. Hence, we do not need to search within the other half-sphere in the rotation solution space. <ref type="table">Table (</ref>LUT) We observed a few properties regarding the shape of the rectangular inlier region (c.f . Sec. 5.2). Firstly, the half height of the rectangular inlier region remains constant, i.e., τ and τ + √ 3σ for the lower and the upper rectangular inlier regions, respectively. That is, τ el in the 2D-EGI is equal to τ in the original domain. Secondly, the half width of the rectangular inlier region only depends on the elevation angle of the mapping point of r i (or −r i ) onto the 2D-EGI. Lastly, the shapes of the rectangular inlier regions on the same elevation angle are equal, regardless of azimuth angles, as illustrated in <ref type="figure" target="#fig_2">Fig. 3b</ref>. Therefore, we generate a look-up table (LUT), which describes τ L az (·) and τ U az (·), by precomputing the half widths of the rectangular inlier region along the elevation angles and along the level of subdivision (i.e., threshold τ + √ 3σ k ) in order to reduce redundant and repetitive computations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Look-Up</head><p>By virtue of the subdivision rule of the rotation search space <ref type="bibr" target="#b12">[12]</ref>, we can pre-compute a series of bound thresholds as τ + √ 3σ k , where σ k = σ 0 /2 k and σ 0 is the half side length of the initial cube. At the beginning of the algorithm, with the pre-computed bound thresholds, we construct an M -vector LUT for each level of subdivision, where M denotes the user specified deepest level. Entries of each vector store the calculated half width sizes of the rectangular inlier regions corresponding to the elevation angles 4 . By concatenating each vector-form LUT, we can generate a matrixform LUT (see <ref type="figure" target="#fig_2">Fig. 3c</ref>). By using the LUT matrix, we can obtain a rectangular inlier region without any computation while running the algorithm. <ref type="bibr" target="#b4">4</ref> The width calculation is done by finding the tightest rectangle enclosing the transferred boundariesX L orX U . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experimental Result</head><p>In this section, we present our experimental results to answer the following questions:</p><p>-Sensitivity: How sensitive is our method to the parameters (EGI resolution s and inlier threshold τ )? -Robustness: Is our method robust to noise and outliers? -Convergence: How many sub-divisions (iterations) are typically required until convergence? -Speed: How much faster is our method? -Practicality: Does our method robustly and efficiently work with real-world data?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Simulation</head><p>In synthetic simulations, we perform various experiments to demonstrate stability (accuracy and convergence) and efficiency (time profile) of the proposed BnB method. For synthetic data, we randomly selected three orthogonal direction vectors that correspond to the ground truth MF and two additional direction vectors to generate outlier directions. We then sampled 400, 000 surface normals on the von-Mises-Fisher (vMF) distribution <ref type="bibr" target="#b7">[7]</ref>  <ref type="bibr" target="#b5">5</ref> , which is an isotropic distribution over the unit sphere. We also sampled 10, 000 surface normals on a uniform distribution to generate sparse noise (see <ref type="figure" target="#fig_3">Fig. 4</ref>). Unless specifically mentioned otherwise, we fixed the inlier threshold τ as 5 • , the EGI resolution parameter s as 2, and the inverse kappa κ −1 as 0.01, for each experiment. We ran each experiment 100 times on MATLAB and measured the mean of the max angular error. Accuracy We tested the trade-off between the accuracy and runtime of the proposed method, with respect to the change in EGI resolution parameter s. As shown in <ref type="figure">Fig. 5a</ref>, the accuracy improves as the resolution parameter s increases, but the ratio of the increased runtime is critical. In all other experiments, we empirically chose the resolution parameter s = 2.</p><p>Our method shows stable accuracy regardless of the inlier threshold τ (see <ref type="figure">Fig. 5b</ref>). We also evaluated the change   in accuracy as the variation parameter of the vMF distribution changed, namely κ −1 , and compared it with the stateof-the-art robust MF estimation (RMFE) method <ref type="bibr" target="#b9">[9]</ref> 6 . For this experiment, we tested κ −1 within a range from 0.0012 to 0.08 on a log-scale. In <ref type="figure">Fig. 5c</ref>, the blue and red lines indicate the mean angular error, and the light blue and light red regions represent the standard deviation of angular error according to κ −1 . While RMFE is easily biased toward an outlier and shows an unstable error with a large standard deviation for small κ −1 values, the proposed method shows a stable and precise accuracy, as shown in <ref type="figure">Fig. 5c</ref>. Convergence The lower and upper bounds of the proposed BnB method converge to a specific value, demonstrating the convergence property of the proposed algorithm. It commonly converges within 7 iterations and shows that the efficient bounds are valid, as seen in <ref type="figure">Fig. 5d</ref>. Time Profiling To show improvements in the computational efficiency, we compared the time profiles of the exhaustive BnB <ref type="bibr" target="#b2">[3]</ref> and the proposed BnB (see <ref type="figure" target="#fig_5">Fig. 6</ref>). Both methods have three steps in common: branch (subdivision), rotation center estimation, and bound computation. In addition, the proposed BnB has an EGI generation step for efficient bound estimation. In the case of the exhaustive BnB, bound computation takes 108.178s, which is 99.98% of the entire computational time. On the other hand, the proposed BnB takes only 4.6ms to compute the bounds. This reduces the bound computation time by more than 20, 000 times, compared to that of the exhaustive BnB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Real-World Experiment</head><p>To evaluate the performance of our method on real-world data, we used the NYUv2 dataset <ref type="bibr" target="#b24">[24]</ref>, which contains 1449 RGB-D images of various indoor scenes. In particular, we (a) Exhaustive BnB <ref type="bibr" target="#b2">[3]</ref> (b) Proposed BnB used the recently introduced ground truth benchmark <ref type="bibr" target="#b9">[9]</ref> of the NYUv2 dataset for a quantitative evaluation. We compare the exhaustive BnB and the proposed BnB with MPE <ref type="bibr" target="#b28">[28]</ref>, MMF <ref type="bibr" target="#b27">[27]</ref>, ES <ref type="bibr" target="#b24">[24]</ref> and RMFE <ref type="bibr" target="#b9">[9]</ref>. Except for the exhaustive BnB and the proposed BnB, we directly quote the results from Ghanem et al. <ref type="bibr" target="#b9">[9]</ref>. We tested the average angular errors of the exhaustive BnB and the proposed BnB on similar hardware configurations (i.e., a 3GHz workstation on MATLAB), as done by Ghanem et al. Since MPE is based on the assumption that a large portion of the scene consists of the floor plane, it is sensitive to scene clutter and outliers. MMF also shows less accurate results than those of ES and RMFE. We deduce the reason for MMF's poor performance in angular errors as the absence of noise/outlier handling. ES and RMFE show comparable results, but their runtimes are inefficient for real-time applications. Exhaustive BnB shows the most accurate results, but its runtime is intractable in terms of efficiency. On the other hand, the proposed BnB performs stably while achieving real-time efficiency, as shown in <ref type="table" target="#tab_2">Table 1</ref>. Accuracy differences between the exhaustive BnB and the proposed one comes from the relaxation in Eq. (5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Applications</head><p>Extension to Multiple Manhattan Frames Since conventional MW assumptions cannot represent general realworld indoor and urban scenes, Straub et al. <ref type="bibr" target="#b27">[27]</ref> introduces a more flexible description of a scene, consisting of multiple MF, namely a mixture of Manhattan Frames (MMF). As an application, we extended the proposed method to MMF estimation by sequentially finding different MFs.  To estimate MMF, we applied a greedy-like algorithm. For a given input data, we estimated the optimal MF, and updated the normal data by excluding the set of normals that corresponds to the inliers of the optimal MF. We then sequentially estimated the next optimal MF for the updated normal data. As in <ref type="bibr" target="#b27">[27]</ref>, we only considered MFs with inlier normals that account for more than 15% of all valid normals, to deal with poor depth measurements. We qualitatively demonstrated our extension, i.e., MMF inference for the NYUv2 dataset <ref type="bibr" target="#b24">[24]</ref>, by comparing it with the original MMF approach <ref type="bibr" target="#b27">[27]</ref>. In <ref type="figure" target="#fig_7">Fig. 7</ref>, the proposed MMF inference shows comparable results with that of the original MMF, as well as the theoretical guarantees. Video Stabilization The goal of video stabilization is to generate a visually stable and pleasant video from a video with jitters due to camera shakes. Depending on the information used for stabilization, the approaches can be grouped into two categories: 2D and 3D motion-based stabilization. 3D-based stabilization reflects more realistic motion information than 2D-based stabilization. Recently, Jia et al. <ref type="bibr" target="#b16">[16]</ref> proposed a 3D video stabilization method that exploits the rotation of camera poses obtained from a built-in gyroscope in smartphones and tablet PCs. Instead of using the 3D rotations from the gyroscope, we apply the rotation matrices obtained by the proposed method and verify the applicability of the algorithm on video stabilization. For the experiment, we used the NYUv2 dataset <ref type="bibr" target="#b24">[24]</ref> with synthetic rotation noise that mimic egocentric head motions applied to the image and depth sequences.</p><p>We obtained the feature trajectories, shown in <ref type="figure" target="#fig_8">Fig. 8</ref>, only to visualize the stabilization performance. The initial features were detected by FAST <ref type="bibr" target="#b22">[22]</ref>, then tracked by KLT <ref type="bibr" target="#b23">[23]</ref> for consecutive frames. We compared the feature trajectories of the video processed in two different ways: using the YouTube video editor <ref type="bibr" target="#b10">[10]</ref> and the stabilization (a) Ground truth motion (b) Noise (c) YouTube video editor <ref type="bibr" target="#b10">[10]</ref> (d) proposed based on the proposed MF estimation. <ref type="figure" target="#fig_8">Fig. 8a</ref> shows the smooth feature trajectories of the original video that visualize the true camera motions. <ref type="figure" target="#fig_8">Fig. 8b</ref> shows the jittering feature trajectories of the synthetic rotation noise applied to the original video. Since the YouTube video editor uses 2D motion information, it generates a more smoothed trajectory, but it is far from the true camera motions, while the trajectory of our method shows similar tendencies to the original feature trajectory (see <ref type="figure" target="#fig_8">Fig. 8c</ref> and <ref type="figure" target="#fig_8">Fig. 8d</ref>). Note that the depth normals obtained from the NYUv2 dataset are very noisy and give inaccurate normal information. However, the stabilization using our method shows plausible results.</p><p>More qualitative experiments and analyses for the two applications are included in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>In this paper, we propose a robust and real-time MF estimation that guarantees a globally optimal solution. This can be achieved by relaxing the original cardinality problem, so that the computational complexity of BnB is dramatically reduced, to a linear complexity. We prove the efficiency and stability of the proposed method through various synthetic and real-world experiments. The proposed method outperforms previous methods' speed with precise accuracy. We also apply the method on two applications: multiple MF estimation and video stabilization, and confirm the applicability of our work on an application level.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of efficient inlier regions. We visualize only three direction vectors for illustration purposes. (a) Boundary point set of inlier region for lower and upper bounds on a spherical domain (XL and XU ). Blue and red indicate the boundaries of the lower and upper inlier regions, respectively. (b) An example of the transferred boundaries on the 2D-EGI (XL andXU ) and the rectangular inlier regions, which enclose the transferred one (this is nothing more than geometrical understanding). (c) Illustration of the rectangular inlier region on the 2D-EGI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2a )</head><label>2a</label><figDesc>. Thus, the bound computation counts the number of inliers within the inlier region.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Illustration of the properties of the rectangular inlier region in the 2D-EGI domain for LUT. (a) The four direction vectors and their inlier regions on the sphere domain. The same color direction vectors have the same azimuth value, but a different elevation value. (b) The rectangular inlier regions on the 2D-EGI. (c) The example of LUT, whose column axis indicates the elevation angle, row axis indicates the level of subdivision, and the values of entries encode the half width size of the corresponding rectangular inlier region.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Distributions of surface normals. (a) and (b) are synthetic data distribution according to κ −1 of vMF, 0.0012 and 0.08, respectively. (c) A sample distribution of real data from the NYUv2 dataset<ref type="bibr" target="#b24">[24]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Time profiles of the exhaustive BnB [3] and the proposed BnB approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Extension to Multiple Manhattan Frames. We show the RGB images, the original MMF [27] and the estimated MMF by our method on various indoor scenes in the first, second, and last row, respectively. (a) 1 MF. Each color indicates an MF axis. (b) 2 MFs. Each color (orange and blue) indicates different MFs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Video stabilization. We used the "NYUv2-living room part 1-living room 0009" dataset. Features are tracked between frames 265 and 285. The feature trajectories are overlaid as red polylines on frame 285.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Comparisons of average angular error and runtime for the 
ground truth of NYUv2 dataset [9]. 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Recently, Straub et al.<ref type="bibr" target="#b26">[26]</ref> show that estimating surface normals in realtime (about 15ms) on a single GPU is possible.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">i.e., e 1 = [1 0 0] ⊤ , e 2 = [0 1 0] ⊤ , e 3 = [0 0 1] ⊤ , e 4 = −e 1 , e 5 = −e 2 and e 6 = −e 3 .</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Actually, this does not hold in the polar regions of the 2D-EGI due to the range limit of the 2D-EGI map. However, by cropping the rectangular bound regions that exceed the map (or zero padding), we can equally measure the bound functions near the polar regions. This indeed provides the correct number by the structural property of the 2D-EGI.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">The von Mises-Fisher distribution for a p-dimensional unit vector x is defined by fp(x; µ, κ) = Zp(κ)exp(κµ T x), where µ is the mean direction, κ is the concentration and normalization constant Zp(κ) = κ p/2−1 (2π) −p/2 I p/2−1 (κ) −1 , where Iv denotes the modified Bessel function of the first kind at order v.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">For a fair comparison, we used the publicly available code and set the balancing parameter λ of the original paper<ref type="bibr" target="#b9">[9]</ref> to be equal to that in our implementation.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Globally optimal line clustering and vanishing point estimation in manhattan world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Bazin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Demonceaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vasseur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="638" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Globally optimal inlier set maximization with unknown rotation and focal length</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Bazin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="803" to="817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Globally optimal consensus set maximization through rotation search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Bazin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision (ACCV)</title>
		<imprint>
			<biblScope unit="page" from="539" to="551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Understanding indoor scenes using 3d geometric phrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pantofaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Manhattan world: Compass direction from a single image by bayesian inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Coughlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="941" to="947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An evaluation of the rgb-d slam system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Endres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Engelhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1691" to="1696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Statistical analysis of circular data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">I</forename><surname>Fisher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Manhattan-world stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1422" to="1429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Heilbron. Robust manhattan frame estimation from a single rgb-d image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Carlos</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Caba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Auto-directed video stabilization with robust l1 optimal camera paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grundmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kwatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Essa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="225" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Perceptual organization and recognition of indoor scenes from rgb-d images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="564" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Global optimization through rotation space search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">I</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="79" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Recovering the spatial layout of cluttered rooms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hedau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1849" to="1856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Extended gaussian images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K</forename><surname>Horn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1671" to="1686" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Global optimization: Deterministic approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Horst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tuy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Constrained 3d rotation smoothing via global manifold regression for video stabilization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">L</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="3293" to="3304" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Consensus set maximization with guaranteed global optimality for robust geometry estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1074" to="1080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fully automatic registration of 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Makadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1297" to="1304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fast rotation search with stereographic projections for 3d registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Parra Bustos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-J</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3930" to="3937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bayesian geometric modeling of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Pero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bowdish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kermgard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Barnard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2719" to="2726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Lifting 3d manhattan lines from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramalingam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="497" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fusing points and lines for high performance tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rosten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Drummond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1508" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Good features to track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="593" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Indoor segmentation and support inference from rgbd images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="746" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Piecewise planar stereo for image-based rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Steedly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1881" to="1888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Real-time manhattan world rotation estimation in 3d</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Straub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bhandari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1913" to="1920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A mixture of manhattan frames: Beyond the manhattan world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Straub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rosman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Freifeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3770" to="3777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Parsing indoor scenes using rgb-d imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Robotics: Science and Systems</title>
		<meeting>Robotics: Science and Systems</meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Rapid object detection using a boosted cascade of simple features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<idno>I-511-I-518</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Structslam: Visual slam with building structure lines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Vehicular Technology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1364" to="1375" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
