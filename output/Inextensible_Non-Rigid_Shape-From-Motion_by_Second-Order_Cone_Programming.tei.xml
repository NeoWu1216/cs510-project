<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Inextensible Non-Rigid Shape-from-Motion by Second-Order Cone Programming</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajad</forename><surname>Chhatkuli</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISIT -CNRS</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Auvergne</orgName>
								<address>
									<settlement>Clermont-Ferrand</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Pizarro</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISIT -CNRS</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Auvergne</orgName>
								<address>
									<settlement>Clermont-Ferrand</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">GEINTRA</orgName>
								<orgName type="institution">Universidad de Alcalá</orgName>
								<address>
									<settlement>Alcalá de Henares</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toby</forename><surname>Collins</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISIT -CNRS</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Auvergne</orgName>
								<address>
									<settlement>Clermont-Ferrand</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Bartoli</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISIT -CNRS</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Auvergne</orgName>
								<address>
									<settlement>Clermont-Ferrand</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Inextensible Non-Rigid Shape-from-Motion by Second-Order Cone Programming</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a global and convex formulation for template-less 3D reconstruction of a deforming object with the perspective camera. We show for the first time how to construct a Second-Order Cone Programming (SOCP) problem for Non-Rigid Shape-from-Motion (NRSfM) using the Maximum-Depth Heuristic (MDH). In this regard, we deviate strongly from the general trend of using affine cameras and factorization-based methods to solve NRSfM. In MDH, the points' depths are maximized so that the distance between neighbouring points in camera space are upper bounded by the geodesic distance. In NRSfM both geodesic and camera space distances are unknown. We show that, nonetheless, given point correspondences and the camera's intrinsics the whole problem is convex and solvable with SOCP. We show with extensive experiments that our method accurately reconstructs quasi-isometric surfaces from partial views under articulated and strong deformations. It naturally handles missing correspondences, non-smooth objects and is very simple to implement compared to previous methods, with only one free parameter (the neighbourhood size).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Non-Rigid Shape-from-Motion (NRSfM) is the problem of finding the 3D shape of a deforming object given a set of monocular images. This problem is naturally underconstrained because there can be many different deformations that produce the same images. By including deformation constraints one limits the set of solutions. Several methods have been proposed in the last decade to tackle NRSfM with a variety of deformation constraints. There are two main categories of methods based on the deformation constraints: statistics-based <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b11">12]</ref> and Corresponding author email: ajad.chhatkuli@gmail.com physics-based <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b1">2]</ref> methods. In the former group one assumes that the space of deformations is lowdimensional. These methods are accurate for deformations such as body gestures, facial expressions and simple smooth deformations. However they tend to perform poorly for objects with high-dimensional deformation spaces or atypical deformations. They can also be difficult to use when there is missing data due to e.g. occlusions. In the latter group one finds deformation models based on isometry <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b28">29]</ref>, elasticity <ref type="bibr" target="#b0">[1]</ref> or particle-interaction models <ref type="bibr" target="#b1">[2]</ref>. The isometric model is especially interesting and is an accurate model for a great variety of real objects. In the related problem of template-based reconstruction (also referred to as Shapefrom-Template <ref type="bibr" target="#b3">[4]</ref>) it has been proven to make the problem well-posed <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b7">8]</ref>. However in NRSfM, approaches based on isometry still lack in several aspects. For example solutions tend to be complex and often require very good initialization.</p><p>To address the shortcomings of state-of-the-art approaches we propose a method with the following properties: 1) a perspective camera model is used (unlike in low-rank models and few others), 2) the isometry constraint is used, 3) a global solution is guaranteed with a convex problem and no initialization (unlike in the recent methods which use gradient-based energy minimization) 4) we can handle non-smooth surfaces and do not require temporal continuity 5) we handle missing correspondences and 6) the complete set of constraints are tied together in a single problem.</p><p>We use the inextensibility constraint for approximating isometry. Inextensibility is a relaxation of isometry where one assumes that the Euclidean distances between points on the surface do not exceed their geodesic distances. Inextensibility alone is insufficient because the reconstruction can arbitrarily shrink to the camera's center. In template-based reconstruction inextensibility has been combined with the so-called Maximum-Depth Heuristic (MDH), where one maximizes the average depth of the surface subject to inextensibility constraints. This approach has been successfully applied in <ref type="bibr" target="#b22">[23]</ref>, providing very accurate results for isometrically deforming objects. The main feature of MDH in template-based scenarios is that it can be efficiently solved with convex optimization. However, in NRSfM, the template is unknown and thus MDH cannot be used out-of-thebox. Our main contribution is to show how to solve NRSfM using MDH for isometric deformations. The problem is solved globally with convex optimization, and handles perspective projection and difficult cases such as non-smooth objects and/or deformations, difficult surface topology and large amounts of missing data (e.g. 50% or more due to selfocclusions). Furthermore, our solution is far easier to implement than all state-of-the-art methods and has only one free parameter. It can be implemented in MATLAB using only 25 lines of code 1 . We provide extensive experiments where we show that we outperform existing work by a large margin in most cases.</p><p>We discuss the state-of-the-art in section 2, and present our problem modeling in section 3, our MDH-based inextensible NRSfM method in section 4, experimental results in section 5 and finally conclusions in section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Previous Work</head><p>Among the two broad classes of existing methods, factorization-based approaches using the low-rank deformation model have been the focus of research in NRSfM for a long time. Starting from the work of Bregler et al. <ref type="bibr" target="#b4">[5]</ref>, many works have been proposed to include priors in resolving the ambiguities of factorization-based NRSfM. Priors are important here even after applying the low-rank constraint because some shape ambiguities remain in affine projections <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b19">20]</ref>. These include the shape basis priors <ref type="bibr" target="#b10">[11]</ref>, spatial smoothness prior <ref type="bibr" target="#b26">[27]</ref> or spatio-temporal smoothness prior and non-linear modeling <ref type="bibr" target="#b13">[14]</ref> to name a few. <ref type="bibr" target="#b9">[10]</ref> proposed a method to complete NRSfM factorization with only the low-rank prior by improving on the way low rank is imposed in affine projections. Some works have also been done on shape recovery with factorization and perspective camera <ref type="bibr" target="#b14">[15]</ref>. Low-rank based factorization methods are global methods that use all available constraints, i.e. the image points are concatenated in a matrix which is decomposed to recover all shapes at once. These methods work well with small linear deformations but require learning <ref type="bibr" target="#b24">[25]</ref> or prior knowledge to set the number of shape basis, kernel and its parameters <ref type="bibr" target="#b13">[14]</ref>. Some improvements have been made for obtaining the basis size automatically but there is no guarantee that a given collection of shapes can be represented by a low number of shape basis accurately. Additionally, in many cases the affine camera has <ref type="bibr" target="#b0">1</ref> Optimized code is available at http://isit.u-clermont1.fr/ ∼ ab/Research/ the problem of local two-fold ambiguity <ref type="bibr" target="#b8">[9]</ref>.</p><p>Physical model-based approaches have been explored in the literature to avoid the difficulties and problems with statistical priors. Primarily, efforts have been made on using isometry or its relaxation to inextensibility to constrain the problem in NRSfM <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b6">7]</ref>, which should allow one to handle larger or more complex deformations. Unlike statistical priors, the isometric prior can be fairly accurate for a large variety of deformations. The isometric prior can be used in NRSfM problem locally (point-wise) or semilocally (patch-wise) or even globally by considering the whole set of surfaces and image points together. A semilocal method using a perspective camera and homographies is proposed in <ref type="bibr" target="#b28">[29]</ref>. It can reconstruct surfaces that are composed of large planar patches where it disambiguates surface normals obtained from homography decomposition using smoothness. <ref type="bibr" target="#b6">[7]</ref> is a local method that gives point-wise ambiguous solutions for normals which are disambiguated using other views rather than smoothness. However, it requires a smooth surface and very accurate registration represented by splines for computing second-order derivatives of the registration. <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b8">9]</ref> solved NRSfM locally using the orthographic camera. <ref type="bibr" target="#b25">[26]</ref> did this using sets of three points and four or more images with a convex relaxation. <ref type="bibr" target="#b8">[9]</ref> did this without a convex relaxation. It used automatically clustered point sets and solved the general case of three or more images. These methods assume a local rigidity prior, which is similar to an isometric prior. <ref type="bibr" target="#b29">[30]</ref> uses an orthographic camera and uses the isometric constraints. The method also provides a way to include the perspective camera. It uses discrete non-convex optimization, however, the solutions are not globally optimal and the optimization requires initialization. Furthermore, it is a complex method to implement and test.</p><p>Apart from the low rank statistical prior based methods and the isometric prior based methods, some other methods exist. For example, <ref type="bibr" target="#b1">[2]</ref> uses a shape basis as well as an isometry-like prior but the method requires an initialization, obtained from rigid factorization on the first set of frames. In that regard, it could be argued that the core of the method is rather like a template-based approach. <ref type="bibr" target="#b20">[21]</ref> proposes an interesting local solution based on local fundamental matrices computed from local point sets. However this is a local method that does not use all available constraints and is very complicated to implement. Compared to existing work, our method is the first to formulate a convex problem by relaxing isometry to inextensibility in NRSfM, from which we obtain a globally optimal solution using SOCP.</p><p>Notation. We use small-case Latin or Greek alphabets to denote scalars. Bold and small Latin letters denote 2-D vectors and bold and capital Latin letters denote 3-D vectors. Matrices are denoted by capital Latin letters. We use . 2 to denote the L2 norm of a vector and . fro to denote the Frobenius norm of a matrix. We index points with i ∈ {1 . . . n} where n is the number of scene points, and we index images with k ∈ {1 . . . m} where m is the number of images. We use a subscript to index the points and a superscript to index the images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Modeling</head><p>In <ref type="figure">figure 1</ref> we illustrate the problem and the associated geometric terms described in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image 1</head><p>Image 2 Image Intrinsic template <ref type="figure">Figure 1</ref>: The NRSfM problem and its associated geometric terms. We use O to represent the camera center from which we draw the sight lines. We show only three points for clarity. In practice there can be virtually any number of points and each point can have many neighbours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Point-based Reconstruction</head><p>We define image measurements as a set of n normalized point correspondences in m images denoted by</p><formula xml:id="formula_0">C {q k i }. The 2D vector q k i u k i v k i ⊤ denotes the ith point seen in the kth image. We define the unknown set of 3D points by R {Q k i }, where Q k i x k i y k i z k i ⊤ denotes the</formula><p>unknown 3D position of q k i in camera coordinates. Because we are using the perspective camera, Q k i and q k i are related by</p><formula xml:id="formula_1">Q k i = z k i q k ⊤ i 1 ⊤ + ǫ k i (1)</formula><p>where ǫ k i is measurement noise. The NRSfM problem is solved by determining the unknown set Z {z k i }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The Intrinsic Template</head><p>We solve Z using what we call an intrinsic template. We use the term intrinsic because it models properties of the surface that are invariant to isometric deformations. The intrinsic template is an undirected graph that links the n scene points through its edges. This is defined by a nearest-neighbourhood graph (NNG) whose edges store the geodesic distances between pairs of points. The NNG is denoted as N with n points (or nodes) and K edges per node. We denote N (i) as the set of K-neighbours of the ith point. Each edge e ij (i, [N (i)] j ) of the graph has an associated geodesic distance d ij . Because we assume the surface deforms isometrically, we can assume d ij is constant for any deformation. We denote the intrinsic template as the pair</p><formula xml:id="formula_2">T {N , D}, with D {d ij }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Template-Based Reconstruction</head><p>In template-based reconstruction (i.e. Shape-from-Template), T is known from the object's reference shape, which is usually built from a geometric mesh. We now describe the MDH for reconstructing an object from a single image. Without loss of generality we assume this is image 1, so the goal is to solve for {z 1 i }. A solution was first proposed in <ref type="bibr" target="#b18">[19]</ref>, then solved with convex optimization in <ref type="bibr" target="#b21">[22]</ref>. In MDH the deformation model is based on surface inextensibility, which says that the Euclidean distance between any two points Q k i and Q k j is upper bounded by the geodesic distance d ij . For simplicity we neglect the effect of the measurement noise ǫ k i as in <ref type="bibr" target="#b21">[22]</ref>. The problem formulation is as follows:</p><formula xml:id="formula_3">argmax {z 1 i } n i=1 z 1 i , s.t. ∀i ∈ {1 . . . n}, j ∈ N (i) z 1 i ≥ 0 z 1 i q 1 i 1 − z 1 j q 1 j 1 2 ≤ d ij .<label>(2)</label></formula><p>The main properties of problem (2) are the following. 1) It is a Second Order Cone Program (SOCP) that can be solved efficiently and globally with modern optimization tools such as MOSEK and SeDuMi.</p><p>2) The neighbour order K in the intrinsic template can be any. A larger K introduces more cone constraints, however it also significantly increases the computational time. Keeping a lower K is thus important for efficiency purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">MDH-based NRSfM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Initial Formulation</head><p>The MDH for NRSfM can be expressed as the maximization of the sum of all depths {z k i } under the inextensibility constraint and the condition that each depth and each distance are positive. Unlike in template-based reconstruction, we require multiple images and in general point correspondences will not be found in all images due to occlusions, missed tracks in optical flow, etc. We therefore introduce the visibility set V {v k i }, where v k i = 1 if the ith point is visible in the kth image and v k i = 0 otherwise. We formulate the problem as follows:</p><formula xml:id="formula_4">argmax {z k i },{dij } m k=1 n i=1 v k i z k i , s.t. ∀k ∈ {1 . . . m}, i ∈ {1 . . . n}, j ∈ N (i) z k i ≥ 0, d ij ≥ 0, v k i v k j z k i q k i 1 − z k j q k j 1 2 ≤ v k i v k j d ij .<label>(3)</label></formula><p>To handle missing correspondences, we fix z k i = 0 if v k i = 0 and therefore we do not reconstruct the points that are not visible. The visibility variables are used in problem <ref type="formula" target="#formula_3">(2)</ref> to disconnect the inextensibility conditions when any of the points involved is not visible. In contrast to the templatebased problem <ref type="formula" target="#formula_3">(2)</ref>, in the template-less problem (3) we do not know the intrinsic template T . It is clear that solving problem (3) directly is not possible for two reasons: 1) the optimization is not well posed because d ij is unbounded (one can keep increasing d ij and the constraints will still be satisfied), 2) the NNG is an unknown. We now give the solutions to both issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Bounding the Distances</head><p>In order to bound the problem, our idea is to fix the scale of the intrinsic template, by fixing the sum of the geodesic distances to a positive scalar (1 in our case). Formally we include in problem (3) the following linear constraint:</p><formula xml:id="formula_5">n i=1 j∈N (i) d ij = 1.<label>(4)</label></formula><p>By including equation <ref type="formula" target="#formula_5">(4)</ref>, {z k i } cannot increase indefinitely without violating equation <ref type="formula" target="#formula_5">(4)</ref>, yet the problem is still an SOCP. We illustrate this in figure 2. The effect of equation <ref type="formula" target="#formula_5">(4)</ref> is to fix the scale of the reconstruction. In NRSfM we are free to fix the scale of the reconstruction arbitrarily, because just like in rigid SfM, it is never recoverable. Having fixed the scale, the reconstructed depths cannot increase arbitrarily, because with a perspective camera as the depths increase so do Euclidean distances between pairs of points. At some point, the Euclidean distances will exceed the geodesic distances and the inextensibility constraints (last line of problem (3)) will be violated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">The Nearest-Neighbour Graph</head><p>The function of the NNG is to constrain the depths between pairs of points on the object's surface (problem (3), last line). These pairs can be any pairs of points, however they give the strongest constraints when the points are close together on the surface. This is because for closer points the inextensibility inequalities become tighter. Of course, we do not know exactly which points are close together a Image 1</p><p>Bounds on set by equation (4) on problem <ref type="formula" target="#formula_4">(3)</ref> Intrinsic template with three points <ref type="figure" target="#fig_0">Figure 2</ref>: Illustration of the bounds set by equation <ref type="formula" target="#formula_5">(4)</ref> for NRSfM using three points and one image. priori. A good estimate can be made from the distance of the correspondences in the images, because nearby points on the surface tend to be close in the images. We denote the Euclidean distance between two points q k i and q k j in image k by δ k ij , and we use these to build the NNG. The specific algorithm we propose is as follows:  The only parameter that needs to be selected here is the neighbourhood size K. Our method is not very sensitive to this parameter but a reasonable value (e.g., 20) should be chosen depending on the density of the correspondences and required speed of optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Implementation Details</head><p>We have implemented two versions of our method in MATLAB which uses the MOSEK [3] SOCP solver. MOSEK is faster than many other SOCP solvers, especially for large scale problems. The first version is only 25 lines and uses YALMIP to translate symbolic variables. The second version is longer and does not involve the translation, which can be expensive for large problems. In practice we use the second version because it is significantly faster. For example, we can solve with 50 images, 1000 points and K = 20 in about 1 minute in a standard desktop PC. This computation time is the fastest among the compared methods for the number of images and points considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Method Comparison and Error Metrics</head><p>We compare our results against five other methods whose source code is provided by the authors. We name our method as tlmdh. We name the non-convex soft inextensibility based method for orthographic camera <ref type="bibr" target="#b29">[30]</ref> as osinext and the local homography method for perspective camera <ref type="bibr" target="#b6">[7]</ref> as p-isolh. We name the prior free factorization method of <ref type="bibr" target="#b9">[10]</ref> as o-spfac and the kernel based factorization method <ref type="bibr" target="#b12">[13]</ref> as o-kfac. We name the locally rigid method based on 3-point SfM <ref type="bibr" target="#b25">[26]</ref> as o-lrigid. Each method requires one or more parameters to be tuned. We fix these parameters to optimal values for each dataset and keep them constant for all experiments.</p><p>We measure a method's accuracy with two metrics: 3D Root Mean Square Error (RMSE) and the normal error. The 3D RMSE is computed from the ground truth 3D point positions. Because NRSfM has a scale ambiguity no method can reconstruct the absolute scale of the object. For methods which use perspective camera (tlmdh and p-isolh) we scale their reconstructions to best align the with the ground truth. For the methods which use affine cameras (o-sinext, olrigid and o-spfac), we transform their reconstructions with a similarity transform to best align them with the ground truth. The normal error is computed by measuring the difference between the ground truth surface normal at each point and the reconstructed normals. We compute the normals by fitting a B-spline and measuring the normals from the B-spline coefficients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Developable Surfaces</head><p>Most non-rigid reconstruction methods focus on developable surfaces for experiments. A developable surface can be flattened into a planar surface without tearing or stretching, such as a piece of paper. Obtaining continuous tracks of correspondences without partial images is relatively easy for such surfaces. While the surfaces often appear simple, they sometimes have high frequency and non-linear deformations. We experiment with 4 different public datasets representing such surfaces.</p><p>The Flag dataset. We use the cloth capture data (mocap) <ref type="bibr" target="#b30">[31]</ref> to generate semi-synthetic data. Even though the object is real, the input data for all the methods are generated from a virtual camera with perspective projection. The data shows a flag waving with wind with some changes in the camera viewpoint, making it perhaps the simplest of all datasets. The images are generated with dimensions 640 px × 480 px using a camera focal length of 640 px. The data has altogether 450 frames. We use this data to test the performance of our method and the competitive methods in several practical scenarios: with changing number of images, changing number of corresponding points and missing correspondences. For changing the number of images, we randomly draw a subset of m images from the 450 images with m varying from 5 to 60. For varying the number of points, we randomly select a subset of n points varying  from 50 to 300. Finally, for varying the amount of missing correspondences for each image we randomly remove a percentage of correspondences ranging from 5 to 60. For the default conditions, we use 40 images, 300 points and no missing data. In order to fill the missing correspondences required by some methods we follow <ref type="bibr" target="#b15">[16]</ref> for matrix completion. Note that our method tlmdh works with incomplete data and therefore we do not complete missing correspondences for our method. p-isolh computes registration functions with B-splines and so we use them to fill in the missing correspondences for that method. <ref type="figure" target="#fig_2">Figure 3</ref> shows the plots for the dataset. The results show that our method tlmdh performs very well with just 5 images and considerably better than all other methods. The factorization-based method o-spfac and the local homography based method p-isolh also does better compared to other methods. We obtain an RMSE 3D error of 6.3 mm using 40 images. Similarly, it can be seen that our method is able to reconstruct the surface with as many as 60% random missing data.</p><p>The KINECT Paper dataset. We use the KINECT Paper dataset <ref type="bibr" target="#b27">[28]</ref> as one of our real datasets for evaluation, originally used for template-based reconstruction <ref type="bibr" target="#b17">[18]</ref>. The dataset shows a VGA resolution sequence of a large piece of textured paper undergoing smooth deformations.We generate correspondences by tracking points in the sequence using an optical flow-based method <ref type="bibr" target="#b11">[12]</ref> designed for nonrigid surfaces. The tracks are outlier free and semi-dense. Due to the large number of frames we again subsample them for all methods except o-kfac, which requires temporal continuity. <ref type="figure" target="#fig_4">Figure 4</ref> shows the plots against the number of images for the rest of the methods. We obtain very accurate reconstructions that in fact compares with template-based reconstructions <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b7">8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kinect Paper</head><p>Hulk T-Shirt  The Hulk and the T-Shirt dataset. The Hulk dataset <ref type="bibr" target="#b6">[7]</ref> consists of a comic cover printed on a piece of paper in 21 different deformations. Similarly, the T-Shirt dataset <ref type="bibr" target="#b6">[7]</ref> consists of a textured T-Shirt with 10 different deformations. These datasets provide images with wide-baseline matches. We do not test the factorization-based methods on these datasets as they have very few images and also do not form a temporal sequence. Large number of images (m &gt; 3/2L), where L is the number of shape basis here, are required by o-spfac and a continuous video sequence is required by o-kfac. We show the results of different methods in the bar plot of <ref type="figure" target="#fig_4">figure 4</ref>. We obtain a mean depth error of 3.5 mm in the Hulk dataset and 4.9 mm in the Tshirt dataset. The next best performing method is p-isolh that gives a mean depth error of 14.53 mm and 8.94 mm for the Hulk and T-shirt datasets respectively. Similarly we obtain a mean depth error of 22.98 mm for o-spfac in the Hulk dataset. We do not obtain good results with o-lrigid and o-sinext in these datasets.</p><p>Failure cases. Failure cases occur in NRSfM due to the problem being ill-posed due to lack of motion and deformation. Naturally any method would fail when the problem is ill-posed. However, a method can also fail to give good results with a well-posed problem. We found one such example for our method from <ref type="bibr" target="#b23">[24]</ref>. The dataset is a bending piece of paper imaged from a fixed camera viewpoint with a relatively longer focal length, and it contains no ground truth. We use optical flow <ref type="bibr" target="#b5">[6]</ref> to obtain correspondences. The qualitative reconstructions for three frames are shown in <ref type="figure" target="#fig_5">figure 5</ref>. The general shape of the paper looks reasonable but in the first image it is bent when it should be flat and the degree of bending is not properly captured in the second image. We know that better reconstructions are possible on this dataset <ref type="bibr" target="#b29">[30]</ref>, so the problem is not itself ill-posed. The imperfect reconstruction from our method is probably caused by the lack of change in camera viewpoint. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Non-Developable Objects</head><p>We use two different datasets to perform NRSfM on non-developable surfaces. They are complex objects where some of the compared methods are not even applicable, for example, p-isolh requires registration warps, which is nontrivial to implement in volumetric objects. We perform experiments here to show what we can obtain in highly difficult non-rigid reconstruction applications. Below we describe the datasets and the experiments performed.</p><p>The Stepping Trousers dataset. The dataset <ref type="bibr" target="#b30">[31]</ref> is constructed from motion capture ground truth data with perspective projection. The data shows a pair of trousers stepping around with considerable rapid deformations of the cloth. The images are obtained at a resolution of 640 px × 480 px with a perspective camera of focal length 320 px. The dataset is semi-synthetic but due to articulations, volume/partial views and rapid nonlinear deformations, it is arguably the most complex data used for NRSfM to date. Unlike the flag dataset, missing correspondences are significant due to self-occlusions. The missing correspondences are handled by filling in the correspondences using <ref type="bibr" target="#b15">[16]</ref> for all methods except ours. <ref type="figure" target="#fig_6">Figure 6</ref> shows three reconstructed frames. From top to bottom, it shows our best reconstruc-tion, a reconstruction with medium accuracy and our worst reconstruction. Alongside we show the reconstructions for the compared method o-spfac. Note that it is non-trivial to implement the compared methods in the missing data scenario without using a low-rank prior. Thus we only test the best performing low-rank method o-spfac. The plots of 3D error for each image for these two methods are shown in <ref type="figure" target="#fig_7">figure 7</ref>. Because this is a large object, the 3D RMSE error can be large, yet the reconstructions can appear reasonable. We therefore also measure accuracy with a relative 3D reconstruction error, which is defined as follows:</p><formula xml:id="formula_6">% 3D error = P GT − P REC fro P GT fro<label>(5)</label></formula><p>where P GT represents the ground truth 3D shape (3 × n matrix) and P REC represents the reconstructed 3D shape. We obtain a mean 3D error of 22.54 mm and % 3D error of 2.37% for our method while for o-spfac those are 51.5 mm and 11.56% respectively. Our results indeed show that large objects with complex deformations in small scale can be reconstructed with our method, although some difficulties can be seen primarily due to high surface curvature. The reconstructions and the plot show that our method can capture a large portion of the deformations correctly even though the parts of the object undergoing deformation are very small in the image, making the projections almost affine. In certain cases, however, it estimates the shapes incorrectly on those parts as shown in the third reconstruction of the sequence in <ref type="figure" target="#fig_6">figure 6</ref>.</p><p>The hand dataset. In tasks such as gesture recognition, several applications require reconstructing a moving hand. When such a task is done, usually a specialized modeling of hand motion and its articulations is used. We show that an accurate reconstruction of a deforming hand can be done solely with the inextensibility prior using our method. We test with two sequences of a deforming hand recorded by an endoscopic camera. The camera images are of dimensions 960 × 540 px, taken with a focal length of 462 px and capture detailed texture. We obtain ground truth reconstructions of the first and last frame using stereo and post processing. We compute correspondences by densely tracking the hand's texture using <ref type="bibr" target="#b5">[6]</ref>. Note that the correspondences are not perfect due to image noise and weak texture. Because most methods cannot handle a huge number of points, we uniformly subsample to 1000 points. <ref type="figure" target="#fig_9">Figure 8</ref> shows reconstructions of the hand compared to ground truth for our method, o-spfac and p-isolh (which were the best performing state-of-the-art methods). The results show that our method can handle complex deformations of a hand. Both the compared methods were unable to capture the second deformation where they gave rather planar or smooth surfaces with 3D error of over 60 mm. On the other hand we  obtain a slightly higher 3D error of 7.38 mm in the third column.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">NRSfM with Rigid Objects</head><p>All rigid objects are isometric, therefore our NRSfM method can be used to reconstruct rigid scenes. However isometry is weaker than rigidity, so it can be expected to perform slightly worse. Nonetheless it is interesting to study such cases for two reasons. First our method gives a convex  solution to the problem with a general number of images, which has not been seen before in rigid SfM with perspective cameras. It may therefore find uses for initialising rigid bundle adjustment. The second reason is for a theoretical understanding of our method using rigid scenes, which may be simpler to analyse than for deformable scenes. For example, it may be interesting to study the critical motions associated with the inextensibility relaxation. We show some results from the public dataset <ref type="bibr" target="#b16">[17]</ref> on the house sequence using SIFT correspondences. We plot the average % 3D error for each of the 49 images for our method and compare this to a state-of-the-art rigid SfM method (VisualSfM <ref type="bibr" target="#b31">[32]</ref>). We see that a reasonable error is obtained for the majority of the images.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>We have brought forward the MDH-based formulation, which has enjoyed great success in inextensible templatebased reconstruction, to the more general problem of templateless non-rigid reconstruction known as NRSfM. We have shown that this leads to a convex formulation, which can be solved globally and optimally as an SOCP problem. This forms the first convex, global and optimal NRSfM formulation based on physical constraints. Results on synthetic and real images have shown a great promise and our method outperforms existing ones by a large margin in many cases. In future work, we plan to study the inclusion of outliers in our formulation using slack variables and a theoretical study of the problem's conditioning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2 .</head><label>2</label><figDesc>If the ith or jth point is not visible in image k, set: δ k ij = −∞. 3. Take the maximum distance over the images. δ ij = max k {δ k ij } ∀i ∈ {1 . . . n}, j ∈ {1 . . . n}. 4. For each point i put into N (i) the points j with the K smallest values ofδ ij (j = i).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Plots for synthetic Flag dataset. The 3D errors shown in the left column and the normal errors in the right column. Legends are shown on the top.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Legend tlmdh o-sinext o-lrigid p-isolh o-spfac o-kfac tlmdh o-sinext o-lrigid p-isolh o-spfac o-kfac3D RMSE in mmNormal error in degrees</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Mean 3D errors for the real developable surfaces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Failure cases: Images (top row) and their respective reconstructions (bottom row). The first two shapes appear largely incorrect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Reconstructions of the stepping trousers dataset for our method and o-spfac. Top row shows the reconstructed meshes overlaid on top of the ground truth. Bottom row shows the reconstructed mesh texture mapped with 3D error for each face in the color code shown. Note that we show our best result in the first column and the worst in the last column with a medium accuracy result in the middle.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Plot of the depth error in trousers for each sampled image (legend infigure 3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Results on the hand dataset. We use the best performing methods in other datasets for comparison: o-spfac and p-isolh. Ground truth is shown for three images, overlaid on top of the reconstructions. We texture map the meshes and show qualitative results for the two other images where ground truth 3D is not available.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 :</head><label>9</label><figDesc>Results on rigid scenes. VisualSfM results are shown in cyan dots.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>1 .</head><label>1</label><figDesc>Compute distances {δ k ij } ∀i ∈ {1 . . . n}, j ∈ {1 . . . n}, k ∈ {1 . . . m}, and i = j.</figDesc><table></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. This research has received funding from the EUs FP7 through the ERC research grant 307483 FLEXABLE. The work has also been supported by the Spanish Ministry of Economy and Competitiveness under project SPACES-UAH (TIN2013-47630-C2-1-R), and by the University of Alcalá under project ARMIS (CCG2015/EXP-054). The work is also supported by Almerys Corporation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Good vibrations: A modal analysis approach for sequential nonrigid structure from motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Agapito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Calvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M M</forename><surname>Montiel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Simultaneous pose and non-rigid shape with particle dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Moreno-Noguer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The MOSEK optimization toolbox for MATLAB manual. Version 7.1 (Revision 28)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aps</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Shape-from-template</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bartoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gérard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chadebecq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pizarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2099" to="2118" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Recovering non-rigid 3D shape from image streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Biermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">High accuracy optical flow estimation based on a theory for warping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bruhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Non-rigid shapefrom-motion for isometric surfaces using infinitesimal planarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chhatkuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pizarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bartoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Stable templatebased isometric 3D reconstruction in all imaging conditions by linear least-squares</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chhatkuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pizarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bartoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Locally affine and planar deformable surface reconstruction from video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bartoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Vision, Modeling and Visualization</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A simple prior-free method for non-rigid structure-from-motion factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A factorization approach to structure from motion with shape priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Del</forename><surname>Bue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dense variational reconstruction of non-rigid surfaces from monocular video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roussos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Agapito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Computing smooth time trajectories for camera and deformable shape in structure from motion with occlusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Gotardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2051" to="2065" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Kernel non-rigid structure from motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F U</forename><surname>Gotardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Martínez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Perspective nonrigid shape and motion recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fast and accurate matrix completion via truncated nuclear norm regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2117" to="2130" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Large scale multi-view stereopsis evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Vogiatzis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Aanaes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Laplacian Meshes for Monocular 3D Shape Recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">O M</forename><surname>Östlund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Monocular template-based reconstruction of inextensible surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perriollat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bartoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Isowarp and conwarp: Warps that exactly comply with weak-perspective projection of deforming objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pizarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bartoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Video pop-up: Monocular 3d reconstruction of dynamic scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Agapito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Reconstructing sharply folding surfaces: A convex formulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Linear local models for monocular reconstruction of deformable surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="931" to="944" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Convex optimization for deformable surface 3-D tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Non-rigid structure from motion with diffusion maps prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Matuszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Non-rigid structure from locally-rigid motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Jepson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Kutulakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Nonrigid structure-from-motion: Estimating shape and motion with hierarchical priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="878" to="892" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A constrained latent variable model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Template-free monocular reconstruction of deformable surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Soft inextensibility constraints for template-free non-rigid reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Agapito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Capturing and animating occluded cloth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Towards linear-time incremental structure from motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3DV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
