<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PatchBatch: a Batch Augmented Loss for Optical Flow</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">(</forename><surname>Dedi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Blavatnik School of Computer Science</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">)</forename><surname>Gadot</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Blavatnik School of Computer Science</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Blavatnik School of Computer Science</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PatchBatch: a Batch Augmented Loss for Optical Flow</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a new pipeline for optical flow computation, based on Deep Learning techniques. We suggest using a Siamese CNN to independently, and in parallel, compute the descriptors of both images. The learned descriptors are then compared efficiently using the L2 norm and do not require network processing of patch pairs. The success of the method is based on an innovative loss function that computes higher moments of the loss distributions for each training batch. Combined with an Approximate Nearest Neighbor patch matching method and a flow interpolation technique, state of the art performance is obtained on the most challenging and competitive optical flow benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Optical flow estimation is a classical problem in computer vision. In recent works, there has been a shift from using engineered descriptors to using Convolution Neural Networks (CNNs) <ref type="bibr" target="#b24">[24]</ref> that are trained on pairs of patches that either match or do not match. Yet, the newly proposed architectures usually suffer from significant computation requirements following the tendency of using Neural Network layers as a matching function instead of traditional distance functions such as the Euclidean (L2) distance.</p><p>To support rapid computation when comparing pairs of patches, it is extremely beneficial to work in a feed-forward pipeline that encodes each patch separately and then uses conventional vector norms for comparing patches. This poses a design restriction on our method that is not shared with recent CNN approaches, which are optimized for accuracy at the cost of significant computation time.</p><p>In order to achieve state of the art results despite this restriction, half a dozen novelties are brought to the field of deep patch representation. Some of the novelties arise from borrowing design choices from CNNs used for object recognition and stereo matching.</p><p>A second group of novelties are general and introduced here for the first time. We have designed new metric learn-ing losses by augmenting the DrLIM <ref type="bibr" target="#b18">[18]</ref> method. Two orthogonal augmentations are studied: the first replaces the loss of DrLIM, which is based on the potential of a spring, with a loss that is based on the potential of a centrifuge. This leads to a marked improvement on the very competitive KITTI benchmarks and in some of our synthetic experiments. The other type of augmentation is obtained by adding, to both spring and centrifuge variants of the DrLIM loss, a term that minimizes the Standard Deviation (SD) of the two distributions: L2 distances between matching patches, and L2 distances between non-matching patches.</p><p>The two SDs are computed on the samples from each training batch and a new type of loss for training CNNs emerges. While in conventional loss functions per-sample losses are aggregated per batch, in the new type of losses the samples of the entire batch contribute jointly to the loss.</p><p>In another contribution, centered around per-batch computations, we propose a new variant of batch normalization <ref type="bibr" target="#b21">[21]</ref> which is more fine-grained than previously proposed. The new method improves performance but comes at a cost: the addition of these layers is not compatible with a fully convolutional deployment of the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Method overview</head><p>The optical flow solution described below is comprised of a series of well established building blocks, where at the heart of the pipeline lies a novel way to compute descriptors and compare patches.</p><p>First, a pair of gray-level input images is normalized by subtracting from each image its mean and dividing by its SD. We then compute, independently and in parallel, descriptors per each pixel of each image. These descriptors are learned from examples using a Siamese Deep Neural Network architecture.</p><p>The PatchMatch <ref type="bibr" target="#b1">[2]</ref> (PM) method is then used as an Approximate Nearest Neighbor (ANN) algorithm on top of the learned descriptors. The conventional L2 metric is used, thus simplifying the ANN computation, as opposed to previous works which use Neural Network layers to compute the matching score.</p><p>We then employ a bidirectional consistency check and eliminate all non-consistent matches. In addition, we remove small independent clusters of flow predictions using a connected component analysis. The surviving matches provide sparse optical flow. The flow maps are downsampled, for computational reasons, by a factor of 2 and 4 for the KITTI datasets and the MPI-Sintel dataset respectively. The decimated maps are then given as input to the EpicFlow <ref type="bibr" target="#b32">[32]</ref> algorithm, which interpolates the correspondence fields and creates a dense optical flow map.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Previous work</head><p>Dense optical flow methods have been the subject of research for the past 35 years, starting with the work of Horn and Schunk <ref type="bibr" target="#b20">[20]</ref>. At the beginning, optical flow research was limited to small displacements only. A significant advancement occurred with the work of Brox and Malik <ref type="bibr" target="#b6">[7]</ref> who were the first to provide reasonable performance for large displacements.</p><p>The three major modern datasets in the field are KITTI2012 <ref type="bibr" target="#b17">[17]</ref>, which is a real world database consisting of images taken from a moving vehicle; MPI-Sintel <ref type="bibr" target="#b7">[8]</ref>, which is a synthetic database consisting of computercreated movies; and the latest KITTI2015 <ref type="bibr" target="#b27">[27]</ref>, which is a new real world database in which both the camera and the scene are non-stationary.</p><p>It is common to distinguish between 2-frame (pure) optical flow methods and methods that require more complex inputs. While the former relies solely on an input of two sequential images, the latter may employ stereo images, more than two input images, etc. Out of the 2-frame optical flow algorithms the FlowFields method <ref type="bibr" target="#b0">[1]</ref> provides an elaborate pipeline, somewhat similar to ours, and presents near stateof-the-art performance on the KITTI2012 database. There are several significant differences between our work and <ref type="bibr" target="#b0">[1]</ref>. The most important is that the latter uses engineered features while we use CNNs in order to compute initial correspondences. Another prominent algorithm is PH-Flow <ref type="bibr" target="#b39">[39]</ref>, which brings state-of-the-art performance to the KITTI2012 database, at the cost of extensive computation time.</p><p>An additional reference work is EpicFlow <ref type="bibr" target="#b32">[32]</ref>. In the original paper the authors used a matching technique called DeepMatching <ref type="bibr" target="#b31">[31]</ref> in order to compute a sparse correspondence field that is then being interpolated in order to create a dense flow field. The interpolation is based on edge-aware averaging of the sparse correspondence field. In our work we employ EpicFlow's interpolation technique on a sparse correspondence field which is calculated using our descriptors and PatchMatch <ref type="bibr" target="#b1">[2]</ref>. An alternative method for interpolating a dense optical flow, which has also been applied to DeepMatching-based inputs is DeepFlow <ref type="bibr" target="#b38">[38]</ref>.</p><p>As previously mentioned, our pipeline employs the PM algorithm <ref type="bibr" target="#b1">[2]</ref> in order to compute the initial correspondence field. PM uses the inherent smoothness and coherency of natural images in order to propagate accurate "guesses" between neighboring pixels, in addition to a random-search stage which helps to avoid local minima. Image-based ANN alternatives include variants such as TreeCANN <ref type="bibr" target="#b29">[29]</ref> and CSH <ref type="bibr" target="#b23">[23]</ref>. However, we chose PM as our ANN algorithm due to its simplicity, efficiency and modularity. These properties allow us to modify PM for our pipeline. When using PM, instead of utilizing image-based patches as inputs, we use our own features, which were computed using a CNN architecture as mentioned before.</p><p>Recent advancements in Deep Learning did not skip the fields of Optical Flow and Stereo Matching. In the FlowNet pipeline <ref type="bibr" target="#b15">[15]</ref>, a CNN was presented that conducts almost the entire optical-flow computation inside the neural network. Though not achieving state-of-the-art results on any of the major datasets, their network runs in real-time and opens a gate to other (almost) complete end-to-end solutions being computed with a single neural network.</p><p>In a recent work on stereo matching <ref type="bibr" target="#b42">[42]</ref>, a CNN architecture compares two candidate stereo patches, followed by extensive post-processing. Each of the patch pairs goes through several identical computations. The resulting activations are then combined and processed through similarity computing layers. However, computational efficiency would be much higher, if an L2 distance of the separate activations would be used instead <ref type="bibr" target="#b43">[43]</ref>. This makes our architecture fully-convolutional, allowing an improved run time. An additional difference is that while <ref type="bibr" target="#b42">[42]</ref> uses small 9 × 9 patches, we found that larger patches are beneficial, and our main architecture uses 51 × 51 patches.</p><p>Computing patch similarity using deep networks is a thoroughly investigated subject. In <ref type="bibr" target="#b41">[41]</ref> the authors inspected several CNN architectures which are able to produce a patch-similarity score. Their conclusion was that there is a sizable advantage for computing the final similarity score using a complex function that involves several dense layers (see also <ref type="bibr" target="#b42">[42]</ref>). Yet, having to pass every two patches through a comparison network leads to a sharp increase in run time. Thus we chose a different path and insist on using per-patch representations that support L2 distance comparisons. This is done in order to reduce the method's computational complexity in the ANN computation stage.</p><p>In order to learn patch representations that can be effectively compared using the L2 norm, we employ several variants of the DrLIM method <ref type="bibr" target="#b18">[18]</ref>, which is widely used to learn similar from non-similar. However, there are only a few variants of it in the literature.</p><p>A major contribution of our work is the incorporation of per-batch statistics, collected during training. Somewhat related is the Batch Normalization method <ref type="bibr" target="#b21">[21]</ref>, which takes advantage of batch-based statistics in order to normalize the activations and accelerate the network's training, and avoid some of the local minima. This is different from our usage of batch statistics for augmenting the loss itself.</p><p>In addition to using batch statistics in order to incorporate distribution information to the loss, we also expand the idea of batch normalization to allow fine-grained control of the network's convergence. This is done by performing the normalization at each activation and not at the level of the entire layer as is done in <ref type="bibr" target="#b21">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Network architecture</head><p>We study patches of typical sizes of 51 × 51 or 71 × 71. This is similar to the 64 × 64 patches used in <ref type="bibr" target="#b41">[41]</ref>. In addition, unlike previous work <ref type="bibr" target="#b41">[41]</ref>, we do not employ patches at multiple scales in our network. While color information might be be useful, e.g., on MPI-Sintel, we discard color since the KITTI2012 benchmark is grayscale.</p><p>We train a fully-convolutional neural network, which creates descriptors we later use in the matching process. Inspired by modern object recognition networks <ref type="bibr" target="#b34">[34]</ref>, we use small 3 × 3 filters in each convolution layer other than the last. The network is built out of a repeating pattern of three layers such that each layer triplet is a combination of a convolutional layer, a batch-normalization layer, and a max-pooling layer. In the last layer triplet we omit the max-pooling layer and use 2 × 2 filters. Leaky ReLU <ref type="bibr" target="#b26">[26]</ref>, with a parameter of 0.1 is used as the non-linearity following each convolutional layer, including the last one. Overall we use 5 such structures, see Tab. 1 within a Siamese architecture <ref type="bibr" target="#b9">[10]</ref>. While some may claim that max-pooling layers hinder matching accuracy by causing the network to become translation-invariant, when using our architecture one can observe no such phenomena.</p><p>We employ a variant of the batch normalization layer, which differs from the conventional batch normalization method <ref type="bibr" target="#b21">[21]</ref>. While the latter employs a single value of mean, SD, γ, and β parameters for each feature map, our variant computes these parameters for each single pixel. For example, for the output of the first convolutional layer, there are 32 × 49 × 49 × 2 learned parameters (γ and β) and the same number of computed batch statistics (mean and SD, for each activation in the volume). Once computed, each activation is normalized by subtracting the mean, dividing by the SD and it then undergoes a scale and shift transformation: y i = γx i +β, wherex i is the normalized activation and y i is the post-transformation value.</p><p>As shown by our experiments, this modification creates a significant gap in performance, see Sec. 5. However, it comes at a cost: the need to normalize each pixel separately does not allow for an efficient fully convolutional computation of the descriptors. Instead, it requires a much slower sliding window approach. We therefore also study an alternative architecture called FAST in which the batch normalization process is done in a conventional way.</p><p>The network is strictly-Siamese, which allows us to later compute the descriptors of each image independently. The matching cost is computed using a simple L2 metric. The patch representation (descriptor) size is typically of length 512. Experiments reveal that using a larger descriptor leads to a small increase in accuracy, and using a descriptor size as small as 32 leads to only a moderate loss of accuracy.</p><formula xml:id="formula_0">Layer Filter/Stride Output size Input - 1 × 51 × 51 Conv1 3 × 3 / 1 32 × 49 × 49 Batch Normalization - 32 × 49 × 49 Max Pool 2 × 2 / 2 32 × 25 × 25 Conv2 3 × 3 / 1 64 × 23 × 23 Batch Normalization - 64 × 23 × 23 Max Pool 2 × 2 / 2 64 × 12 × 12 Conv3 3 × 3 / 1 128 × 10 × 10 Batch Normalization - 128 × 10 × 10 Max Pool 2 × 2 / 2 128 × 5 × 5 Conv4 3 × 3 / 1 256 × 3 × 3 Batch Normalization - 256 × 3 × 3 Max Pool 2 × 2 / 2 256 × 2 × 2 Conv5 2 × 2 / 1 512 × 1 × 1 Batch Normalization - 512 × 1 × 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Loss</head><p>Architectures similar to the one described above were explored by previous work <ref type="bibr" target="#b41">[41,</ref><ref type="bibr" target="#b43">43]</ref>. In each previous work, such per-patch architectures were found to be significantly inferior to the architectures that use two patches as inputs. Much of the improved performance we present in this work can be attributed to the novel variants of the DrLIM's loss employed, which are explored next.</p><p>The conventional DrLIM loss, which is motivated by the spring model is given by</p><formula xml:id="formula_1">(1 − Y ) 1 2 D 2 w + (Y ) 1 2 {max(0, m − D w )} 2 ,<label>(1)</label></formula><p>where, Y = 0 for matching pairs, Y = 1 otherwise, m is the margin parameter, and D w is the L2 distance between the pair of samples. We suggest two orthogonal modifications. The first modification is to insert the square into the hinge and obtain the following formula:</p><formula xml:id="formula_2">(1 − Y ) 1 2 D 2 w + (Y ) 1 2 {max(0, m 2 − D 2 w )} .<label>(2)</label></formula><p>Whereas the original DrLIM was motivated by the spring model analogy <ref type="bibr" target="#b18">[18]</ref>, the new loss can be said to model a sticky centrifuge. Let M be a mass of a particle located at rest at a distance r in a frame rotating at an angular velocity ω around the origin. The particle feels the centrifugal force F = mω 2 rr in directionr. This force is derived from the potential V (r) = −M ω 2 r 2 as F = −∇V . Assuming that the centrifuge has a sticky boundary at a radius m, particles at a radius larger than m would just rotate with the centrifuge. The potential then becomes</p><formula xml:id="formula_3">V cen (r) = M ω 2 max 0, m 2 − r 2 .</formula><p>Based on the underlying physical models, the terms SPRING and CENTRIFUGE will be used below to refer to the conventional DrLIM of Eq. 1 and the variant of Eq. 2. <ref type="figure" target="#fig_0">Fig. 1</ref>(a) depicts the shape of the loss functions on the negative (Y=1) pairs.</p><p>The second modification we add to the DrLIM loss is based on per-batch statistics. The augmented loss then incorporates these statistics, unlike any loss in the literature we are aware of. The effect of this modification can be dramatic, as can be observed in <ref type="figure" target="#fig_0">Fig. 1</ref></p><formula xml:id="formula_4">(b),(c).</formula><p>The batch statistics we consider are the SD of the distances of the two classes -matching and non-matching. The basic motivation for this strategy is the need to increase the separation between the two distributions. While the DrLIM loss pulls the samples to be close to either 0 or m, we found the two distributions to overlap considerably. Adding the requirement of a small SD directly pulls the two distributions closer to their respective means and improves separability.</p><p>Let σ Y , Y = 0, 1 be the SD value, in a training batch, of the pairwise distance D w for samples that match or do not match, respectively. The SPRING+SD variant is defined as:</p><formula xml:id="formula_5">(1−Y )λD 2 w +(Y )λ{max(0, m−D w )} 2 +(1−λ)(σ 0 +σ 1 )<label>(3)</label></formula><p>The CENTRIFUGE+SD variant is given by:</p><formula xml:id="formula_6">(1−Y )λD 2 w +(Y )λ{max(0, m 2 −D 2 w )}+(1−λ)(σ 0 +σ 1 )<label>(4)</label></formula><p>In both variants, a parameter λ is added which controls the tradeoff between the core DrLIM variants and the augmentation by the standard deviation. In all the experiments in this paper λ was set to a value of 0.8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Training</head><p>Each image of a chosen dataset is normalized by subtracting its own mean and dividing by its own SD. The same normalization is later used during test time. We sample two populations, matching and non-matching, by collecting 51 × 51 patches and using the given ground-truth flow computation. For the non-matching population we employ a random shift from the ground truth in both the X and Y axes of 1-8 pixels. Requiring even small translations to become non-matching is in contrast, for example, with <ref type="bibr" target="#b42">[42]</ref>, which used 4-8 pixels for the non-matching class.</p><p>In order to augment the data, flips and 90 degree rotations are applied on-the-fly during train time. We use AdaDelta <ref type="bibr" target="#b44">[44]</ref> as an efficient, adaptive, learning rule and Lasagne <ref type="bibr" target="#b10">[11]</ref>, which is a Theano <ref type="bibr" target="#b3">[4]</ref> based Deep Neural Network framework. We trained the final network for 4000 epochs, in each epoch we used 50,000 random samples from our created database with a batch-size of 256.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Matching and Interpolation</head><p>Since our architecture is strictly Siamese, we can compute the features of each image independently and in parallel. Calculating descriptors using the FAST architecture takes approximately 2 seconds per image. Using the AC-CURATE architecture is more time consuming, due to the fact that the image is being split to patches and each patch descriptor is then computed independently in a sliding window manner. This takes approximately 27 seconds per image using an NVIDIA Titan X GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Matching</head><p>When using PM as an ANN algorithm, we use as input our created descriptors and not the gray-scale image patches, similar to the Generalized PM <ref type="bibr" target="#b2">[3]</ref> approach. The squared L2 distance is used as the matching metric.</p><p>We only run PM for two iterations in order to reduce the computation time and also, more importantly, since it was found that adding iterations causes additional matching outliers to appear. The same phenomenon was described in <ref type="bibr" target="#b0">[1]</ref>: the additional iterations of the ANN used there were said to create "resistant outliers", whose matching distances are below those of the true matches.</p><p>PM is used twice, in parallel, from the first image to the second and vice-versa, in order to check for the consistency of the two flow fields. All matches which do not exactly point to one another in this bidirectional consistency check are being eliminated (PM's output is an integer assignment).</p><p>It was found empirically that allowing a large randomsearch radius during the PM process helped to improve performance on the KITTI datasets while we saw no such effect on the MPI-Sintel dataset. This observation is consistent with the average highest disparity for each image-pair in the different datasets. Following these observations the random search parameter of PM was set to 500 on the KITTI datasets, and to only 10 on the MPI-Sintel dataset.</p><p>Following the bidirectional consistency check, a binary mask indicating reliable flows is considered, and its connected components are identified. Small connected components are then considered unreliable. Specifically, we use a threshold area of 10,000 for the KITTI datasets and 400 for MPI-Sintel. For the MPI-Sintel dataset we also eliminate all the matches around the borders of the image (30 pixels) since we have found that there are more outliers there than in the rest of the image, probably due to the relatively large patch size we are using.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Interpolation</head><p>Given a sparse correspondence field, describing the matches which met the bidirectional consistency criterion and the connected component filtering, we employ EpicFlow <ref type="bibr" target="#b32">[32]</ref> to obtain a dense correspondence field. The EpicFlow algorithm interpolates each missing prediction using its neighboring predictions from the sparse correspondence field, i.e. its support. From this support, a number of affine transformations are calculated using multiple subsets of correspondences. An edge map is computed using the SED method <ref type="bibr" target="#b11">[12]</ref>, and the affine transformations are then averaged based on the geodesic distance computed from the image's edge map.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In order to demonstrate the effectiveness of the new Dr-LIM variants beyond the scope of optical flow computations, we have conducted a series of synthetic experiments in addition to testing the impact of the new variants on real datasets.</p><p>In the first experiment, n c multivariate Gaussian centers are uniformly sampled from a 256D hypercube of edge length 1. Pairs of samples are then drawn from Gaussians i and j with a fixed diagonal covariance matrix τ I. When sampling matching pairs i = j; for non-matching pairs i = j. 10, 000 training samples and 10, 000 test samples are used, half of which are matching and half non-matching.</p><p>The representation networks had three hidden layers of size 256 and ReLU activations. Four Siamese networks were trained, based on the four DrLIM variants: SPRING, CENTRIFUGE, SPRING+SD, and CENTRIFUGE+SD.</p><p>Two sets of experiments are conducted. In the first set, τ = 3 and n c varies between 4 and 20. In the second set n c = 10 and τ varies between 2 and 5. Each setting is repeated 10 times, and the plots in <ref type="figure" target="#fig_1">Fig. 2(a)</ref>,(b) depict the mean Area Under Curve (AUC) obtained when training the network on the training data and evaluating on the test data for the first and the second set respectively. As can be seen, in almost all experiments, SPRING outperforms CENTRIFUGE and SPRING+SD outperforms CEN-TRIFUGE+SD. It is also clear that the SD versions of each physical model greatly outperform the vanilla versions.</p><p>The entire experiment was then repeated, with a slight variant. In the second variant, the sampling process is identical except that the two samples in each pair are both normalized to have a norm of one. The exact same experiments were repeated. In <ref type="figure" target="#fig_1">Fig. 2(c)</ref>, n c varies while τ = 3 is fixed. In <ref type="figure" target="#fig_1">Fig. 2(d)</ref>, τ varies while n c = 10. In these experiments, the SD version also outperforms the plain SPRING and CENTRIFUGRE versions by a large margin. However, among the physical models the leading performance for the normalized inputs is obtained using the CENTRIFUGE method. This is true for both the SD and the vanilla variants.</p><p>In all experiments performed we have added a baseline method, which is the norm of the difference between the pairs of points. This method does moderately better than chance (AUC of about 0.6) and is, in general, much inferior to the network representations. However, when the number of classes dramatically increases, or when the variance is very high, this simple method has an advantage over the learned models.</p><p>One additional experiment we conducted is to evaluate our method using the "accuracy@10" measure proposed in <ref type="bibr" target="#b31">[31]</ref>. "Accuracy@10" is defined as the proportion of correct assignments from the first image to the second with respect to the total number of pixels. A pixel assignment is consid-ered correct if its Euclidean error is smaller than 10 pixels. The "accuracy@10" score achieved by DeepMatching <ref type="bibr" target="#b31">[31]</ref> on the KITTI2012 dataset is 0.856. We computed the same score using our descriptors on our own validation set (last 20% of images by file order) and achieved a score of 0.960.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Comparison of loss variants on optical flow datasets</head><p>In our optical flow experiment, we make use of the three largest and most competitive datasets: KITTI2012 &amp; KITTI2015, both of which contain real image datasets taken from a moving vehicle in a city environment and MPI-Sintel, which is an extensive computer graphics dataset.</p><p>We ran the four variants up to 1500 epochs while conducting the comparison. The margin parameter m was determined, for each variant, using initial runs of 500 epochs. The performance was evaluated on a set of images set aside for this purpose: 20% of the images of the KITTI2012 and KITTI2015 training sets, which come last in the file order, and a random sample of 50 images of the FINAL training subset of MPI-Sintel.</p><p>The results are reported in Tab. 2 and 3 for KITTI2012, KITTI2015, and MPI-Sintel respectively. Each table compares the four variants: SPRING, CENTRIFUGE, SPRING+SD, and CENTRIFUGE+SD. The nature of the error rate used depends on the dataset conventions: in KITTI2012 and KITTI2015, the percent of pixels that displaced more than 3 pixels (Euclidean error) from the ground truth is used; in MPI-Sintel, the mean end point error is reported for all and matching-only pixels. In the KITTI2012 and KITTI2015 lines two error rates are reported in each cell: one obtained after the PM matching process only, and the second error after applying the interpolation process.</p><p>One can observe a consistent drop in the error rate when shifting from the SPRING model to the CENTRIFUGE model, especially prior to the interpolation. There is an additional consistent drop in error when adding an SD term to either losses. Based on these partial experiments, we decided to focus on the CENTRIFUGE+SD method and train using this variant for 4,000 epochs on each of the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Benchmark results</head><p>We trained our main architecture (51 × 51 patch-size, CENTRIFUGE+SD loss) on all three datasets. The network architecture is identical in all three cases. As a training set for KITTI2012 and KITTI2015, we took the first 80% of the image pairs and as a validation set, the remaining 20%. For MPI-Sintel we chose 80% of the image pairs for training and the rest for validation. We chose 2M random samples out of those 20% images to act as the validation samples during training. Training was performed for 4000 epochs, and the configuration with the best validation loss was recorded and deployed. As can be seen in Tab. 4, 5, 6, we were able to achieve state-of-the-art results on the official KITTI2012 and KITTI2015 benchmarks, and rank in the 6th place on the MPI-Sintel benchmark. The gap in ranking between the KITTI datasets and MPI-Sintel might arise from the fact that we are the only top reported system that does not use color on MPI-Sintel.</p><p>Since CENTRIFUGE+SD was not clearly preferable on MPI-Sintel to other methods by epoch 1500 (Tab. 3), we submitted results for all 4 DrLIM variants on this benchmark. The obtained order of results (Tab. 6) is CENTRIFUGE+SD, SPRING, SPRING+SD, and CEN-TRIFUGE. A significant gap of 0.4 EPE exists between CENTRIFUGE+SD and SPRING.</p><p>On KITTI2012, we have also submitted the predictions of the FAST network, in which our fine-grained batch normalization (Sec. 3) is replaced with the conventional batch normalization. There are only four methods that are ranked between the ACCURATE and the FAST methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Network variants</head><p>We explored several network variants on the KITTI2012 validation benchmark. These variants explore different descriptor sizes and different patch sizes, in addition to our </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Out-Noc Running time PatchBatch-ACCRTE-PS71 5.29% 60.5s PatchBatch-ACCURATE 5.44% 50.5s PH-Flow <ref type="bibr" target="#b39">[39]</ref> 5.76% 800s FlowFields <ref type="bibr" target="#b0">[1]</ref> 5.77% 23s CPM-Flow (anon.) 5.80% 2s NLTGV-SC <ref type="bibr" target="#b30">[30]</ref> 5.93% 16s PatchBatch-FAST 5.94% 25.5s DDS-DF <ref type="bibr" target="#b37">[37]</ref> 6.03% 1m TGV2ADCSIFT <ref type="bibr" target="#b4">[5]</ref> 6.20% 12s DiscreteFlow <ref type="bibr" target="#b28">[28]</ref> 6.23% 3m <ref type="table">Table 4</ref>. Top 10 KITTI2012 2-frame (Pure) Optic Flow Algorithms as published on the submission date. Out-Noc is the percentage of pixels with euclidean error &gt; 3 pixels out of the non-occluded pixels variant of batch normalization. The results of these experiments are displayed in Tab. 7. The table shows the percentage of pixels with displacement error larger than 3 pixels after the ANN matching process and after the interpolation process. The full ("AC-CURATE") method is compared with the FAST network. We also compared to an ACCURATE network in which the input patch size is 71 × 71 pixels. Two other variants in which the final descriptor size varies are shown. The descriptor size was altered by replacing Conv5's filter-size to 1 × 1 to obtain a 1024D descriptor, or by adding an additional convolutional (and batch-normalization) layer with 32 feature maps to obtain a 32D descriptor. The 1024D descriptor makes PM run much slower. The converse is true</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Fl-all Running time PatchBatch-ACCURATE 21.69% 50.5s DiscreteFlow <ref type="bibr" target="#b28">[28]</ref> 22.38% 3min CPM-Flow (anon.) <ref type="bibr" target="#b24">24</ref>.24% 2s EpicFlow <ref type="bibr" target="#b32">[32]</ref> 27.10% 15s FilteringFlow (anon.)</p><p>28.50% 116s DeepFlow <ref type="bibr" target="#b38">[38]</ref> 29.18% 17s HS <ref type="bibr" target="#b35">[35]</ref> 42.18% 2.6m DB-TV-L1 <ref type="bibr" target="#b40">[40]</ref> 47.97% 16s HAOF <ref type="bibr" target="#b5">[6]</ref> 50.29% 16.2s PolyExpand <ref type="bibr" target="#b13">[14]</ref> 53.32% 1s for 32D. Based on these results, further improvements of our method's accuracy are expected with larger patch and representation sizes.</p><p>In another experiment we tested the ACCURATE network trained on KITTI2015 on the KITTI2012 validation images. The performance seems comparable to that of the KITTI2012 ACCURATE network, attesting to the generality of the learned patch matching function.</p><p>Our method was designed with the requirement of obtaining a generic pipeline that employs L2 distances of patches. In this way, the ANN and interpolation methods can be replaced with other, perhaps more efficient methods, and the gain in performance can be preserved. The running time of each step of the computation for the baseline and the Method EPE all, 'final' pass FlowFields <ref type="bibr" target="#b0">[1]</ref> 5.810 CPM-Flow (anon.) 5.960 DiscreteFlow <ref type="bibr" target="#b28">[28]</ref> 6.077 EpicFlow <ref type="bibr" target="#b32">[32]</ref> 6.285 Deep+R <ref type="bibr" target="#b12">[13]</ref> 6.769 PatchBatch-CENT+SD 6.783 DeepFlow2 (anon.) <ref type="bibr" target="#b5">6</ref>.928 PatchBatch-SPRG 7.188 SparseFlowFused <ref type="bibr" target="#b36">[36]</ref> 7.189 DeepFlow <ref type="bibr" target="#b38">[38]</ref> 7.212 FlowNetS+ft+v <ref type="bibr" target="#b15">[15]</ref> 7.218 NNF-Local <ref type="bibr" target="#b8">[9]</ref> 7.249 PatchBatch-SPRG+SD 7.281 PatchBatch-CENT 7.323 SPM-BP <ref type="bibr" target="#b25">[25]</ref> 7.325 AggregFlow <ref type="bibr" target="#b16">[16]</ref> 7.329  <ref type="table">Table 7</ref>. Additional variants comparison on KITTI2012. All results are reported using the CENTRIFUGE+SD loss, while taking the model with the lowest loss on validation data out of 4000 epochs. The error is computed on the local validation set. Each row presents the % of pixels with euclidean error &gt; 3 pixels after the ANN process (left) and after the interpolation and bidirectional consistency check (right). In addition, the time it takes to compute the patch descriptors in seconds is shown. As can be seen, additional improvement for our method is expected when using larger patches and a longer representation vector.</p><p>FAST methods are detailed in Tab. 8. The patch encoding process is the only process currently done on the GPU. Its running time dominates the ACCURATE network's execution time, but is less than 10% of that of the FAST network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion and future work</head><p>Using CNNs for encoding each patch separately leads to a solution that is entirely flexible. On one hand the CNN can be modified, pruned, or compressed <ref type="bibr" target="#b33">[33]</ref> in order to control</p><p>Step ACCURATE FAST Descriptor computation 27s 2.5s ANN (PatchMatch) 6.5s 6.5s Connected component analysis 0.5s 0.5s Interpolation (EpicFlow) 16s 16s Total 50s 25.5s <ref type="table">Table 8</ref>. The runtime of our ACCURATE network (using finegrained batch normalizatoin) and the FAST method. The descriptor computation is done in parallel for the two images and so are the PatchMatch computations per direction.</p><p>the accuracy to run time trade-off. On the other hand, the other steps can be replaced, implemented on the GPU, or bypassed as needed. A fast alternative, for example, for the ANN solution employed is the kd-tree solution of <ref type="bibr" target="#b19">[19]</ref>. Our reliance on simple vector representations means that this integration does not require any modification. The problem of metric learning is a central Machine Learning task that is used in computer vision domains ranging from low-level vision to almost all high level vision tasks. Mahalanobis distances, and other distances that translate to L2 matching of learned representations dominate the relevant literature.</p><p>The DrLIM loss is a prominent solution for learning L2 distances using deep networks. We believe that the two orthogonal types of improvements that we presented here can lead not only to state of the art optical flow, but also to improved results in many other domains. The success on what might be the simplest imaginable (and therefore the most general) synthetic data is highly suggestive of that.</p><p>In addition to this very general contribution, the very idea of using batch losses is novel, as far as we know. Losses are always constructed per sample and then aggregated. This locality is compatible with the stochastic gradient descent. However, when using mini batches, per batch losses are also compatible.</p><p>Batch losses can tie together the samples in a batch and support the design of networks that take into account interrelations between the samples in the batch. We have demonstrated the effectiveness of this approach in the domain of metric learning. Future work might take advantage of this in order to whiten the representation layer, whiten the error of regressors along the output dimensions, or balance the error between the classes in a multiclass scenario.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Demonstrating the effect of DrLIM variants. (a) A comparison of the loss (y-axis) on negative pairs as a function of the distance Dw (x-axis) for m = 100 for the original DrLIM (SPRING) and the CENTRIFUGE variant. The CENTRIFUGE is more sensitive to value shifts near the margin and then loses its sensitivity. (b) The distribution of distances for matching (left side, blue) and non-matching (right side, red) pairs, for KITTI2012 validation data, when using the CENTRIFUGRE variant. The plot shows distance vs. frequency. (c) The same two distributions for the CENTRIFUGE+SD loss. Adding the batch SD to the loss causes the means to be somewhat closer. However, the SD of both distributions is much reduced.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Results of the synthetic experiment. The first row shows the results of the baseline experiment. The second row shows the results where each datapoint was normalized to have a fixed norm. All plots show mean and SD of AUC (y-axis) obtained for five types of features. In all plots, the faint (red) dotted line presents the original random features sampled, as describe in Sec.<ref type="bibr" target="#b4">5</ref>. The thin solid line presents the results obtained for the original DrLIM method (SPRING). The thin dashed line shows the results for the CENTRIFUGE variant. The thick solid and dashed lines show the respective counterparts where SD was added to the loss. (a) and (c) present results when varying (x-axis) the number of Gaussians nc from which points where sampled. (b)and (d) explore the effect of changing the variance parameter τ . As can be seen, SD improves performance in almost all experiments. For the baseline data SPRING outperforms CENTRIFUGE. The situation is reversed when the norm of the sampled datapoints is fixed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 .</head><label>1</label><figDesc>The network model for representing a grayscale 51 × 51 input patch as a 512D vector. The Batch Normalization used is our fine-grained variant. Leaky ReLU units<ref type="bibr" target="#b26">[26]</ref> (with α = 0.1) are used as activation functions following the five batch normalization layers.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 5 .</head><label>5</label><figDesc>Top 10 KITTI2015 2-frame Optic Flow Algorithms as of the submission date. Fl-all is the percentage of pixels with euclidean error &gt; 3 pixels. The FAST network was not trained on this benchmark by the submission time.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 6 .</head><label>6</label><figDesc>Top MPI-Sintel results as of the submission date. Each number represents the EPE (end-point-error), averaged over all the pixels in the comparison images, using the 'final' rendering pass of MPI-Sintel. Four ACCURATE variants are shown. The CENT-FIGURE+SD network is ranked 6th as of the paper's submission date. The TF+OFM method<ref type="bibr" target="#b22">[22]</ref> (EPE 6.727) is removed from this table since it is not a pure 2-frame optical flow method.</figDesc><table>Method 
KITTI2012 err Encode time 
ACCURATE 
8.08 / 4.80 
27s 
FAST 
9.45 / 5.3 
2.5s 
ACCURATE 71 × 71 
7.85 / 4.79 
37s 
ACCURATE 32D 
9.34 / 5.23 
27s 
ACCUARTE 1024D 
8.10 / 4.81 
37s 
Train on KITTI2015 
8.99 / 4.97 
27s 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research is supported by the Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI). The authors would like to thank Michael Rotman for valuable insights.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Flow fields: Dense correspondence fields for highly accurate large displacement optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bailer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Taetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stricker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.05151</idno>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The generalized patchmatch correspondence algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="29" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The generalized PatchMatch correspondence algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Theano: a CPU and GPU math expression compiler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Breuleux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Python for Scientific Computing Conference (SciPy)</title>
		<meeting>the Python for Scientific Computing Conference (SciPy)</meeting>
		<imprint>
			<date type="published" when="2010-06" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A general dense image matching framework combining direct and feature-based costs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Braux-Zin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bartoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="185" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">High accuracy optical flow estimation based on a theory for warping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bruhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Large displacement optical flow: descriptor matching in variational motion estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="500" to="513" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A naturalistic open source movie for optical flow evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="611" to="625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Large displacement optical flow from nearest neighbor fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2443" to="2450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schlter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Snderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thoma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Battenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lasagne: First release</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Structured forests for fast edge detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1841" to="1848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Combinatorial regularization of descriptor matching for optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Drayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Two-frame motion estimation based on polynomial expansion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Farnebäck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Analysis</title>
		<imprint>
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ilg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Häusser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hazirbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Van Der Smagt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.06852</idno>
		<title level="m">Flownet: Learning optical flow with convolutional networks</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Aggregation of local parametric candidates with exemplar-based occlusion handling for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fortun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bouthemy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kervrann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1407.5759</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Are we ready for autonomous driving? the kitti vision benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Computing nearest-neighbor fields via propagation-assisted kd-trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="111" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Determining optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">G</forename><surname>Schunck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Society for Optics and Photonics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="319" to="331" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
	<note>Technical symposium east</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Optical flow with geometric occlusion estimation and fusion of multiple frames</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Energy Minimization Methods in Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="364" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Coherency sensitive hashing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Korman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1607" to="1614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Convolutional networks for images, speech, and time series. The handbook of brain theory and neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>1995. 1</idno>
		<imprint>
			<biblScope unit="volume">3361</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SPM-BP: Sped-up PatchMatch belief propagation for continuous MRFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Object scene flow for autonomous vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Discrete optimization for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Heipke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="16" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Treecann-kd tree coherence approximate nearest neighbor algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Olonetsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="602" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Non-local total generalized variation for optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranftl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bredies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="439" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Deepmatching: Hierarchical deformable dense matching. CoRR, abs/1506.07656</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Epicflow: Edge-preserving interpolation of correspondences for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1501.02565</idno>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6550</idno>
		<title level="m">Fitnets: Hints for thin deep nets</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A quantitative analysis of current practices in optical flow estimation and the principles behind them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="137" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sparse flow: Sparse matching for small to large displacement optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1100" to="1106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A data-driven regularization model for stereo and flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on 3D Vision (3DV)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="277" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deepflow: Large displacement optical flow with deep matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1385" to="1392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Dense, accurate optical flow estimation with piecewise parametric model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A duality based approach for realtime tv-l 1 optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.03641</idno>
		<title level="m">Learning to compare image patches via convolutional neural networks</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Computing the stereo matching cost with a convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zbontar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Stereo matching by training a convolutional neural network to compare image patches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zbontar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.05970</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">ADADELTA: an adaptive learning rate method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.5701</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
