<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Synthesized Classifiers for Zero-Shot Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soravit</forename><surname>Changpinyo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">U. of Southern California</orgName>
								<orgName type="department" key="dep2">U. of California</orgName>
								<orgName type="institution">U. of Central Florida Orlando</orgName>
								<address>
									<settlement>Los Angeles, Los Angeles</settlement>
									<region>CA, FL, CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lun</forename><surname>Chao</surname></persName>
							<email>weilunc@usc.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">U. of Southern California</orgName>
								<orgName type="department" key="dep2">U. of California</orgName>
								<orgName type="institution">U. of Central Florida Orlando</orgName>
								<address>
									<settlement>Los Angeles, Los Angeles</settlement>
									<region>CA, FL, CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
							<email>bgong@crcv.ucf.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">U. of Southern California</orgName>
								<orgName type="department" key="dep2">U. of California</orgName>
								<orgName type="institution">U. of Central Florida Orlando</orgName>
								<address>
									<settlement>Los Angeles, Los Angeles</settlement>
									<region>CA, FL, CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sha</forename><surname>Fei</surname></persName>
							<email>feisha@cs.ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">U. of Southern California</orgName>
								<orgName type="department" key="dep2">U. of California</orgName>
								<orgName type="institution">U. of Central Florida Orlando</orgName>
								<address>
									<settlement>Los Angeles, Los Angeles</settlement>
									<region>CA, FL, CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Synthesized Classifiers for Zero-Shot Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Given semantic descriptions of object classes, zeroshot learning aims to accurately recognize objects of the unseen classes, from which no examples are available at the training stage, by associating them to the seen classes, from which labeled examples are provided. We propose to tackle this problem from the perspective of manifold learning. Our main idea is to align the semantic space that is derived from external information to the model space that concerns itself with recognizing visual features. To this end, we introduce a set of "phantom" object classes whose coordinates live in both the semantic space and the model space. Serving as bases in a dictionary, they can be optimized from labeled data such that the synthesized real object classifiers achieve optimal discriminative performance. We demonstrate superior accuracy of our approach over the state of the art on four benchmark datasets for zero-shot learning, including the full ImageNet Fall 2011 dataset with more than 20,000 unseen classes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Visual recognition has made significant progress due to the widespread use of deep learning architectures <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b41">41]</ref> that are optimized on large-scale datasets of humanlabeled images <ref type="bibr" target="#b36">[37]</ref>. Despite the exciting advances, to recognize objects "in the wild" remains a daunting challenge. Many objects follow a long-tailed distribution: in contrast to common objects such as household items, they do not occur frequently enough for us to collect and label a large set of representative exemplar images.</p><p>For example, this challenge is especially crippling for fine-grained object recognition (classifying species of birds, designer products, etc.). Suppose we want to carry a visual search of "Chanel Tweed Fantasy Flap * Equal contributions Handbag". While handbag, flap, tweed, and Chanel are popular accessory, style, fabric, and brand, respectively, the combination of them is rare -the query generates about 55,000 results on Google search with a small number of images. The amount of labeled images is thus far from enough for directly building a high-quality classifier, unless we treat this category as a composition of attributes, for each of which more training data can be easily acquired <ref type="bibr" target="#b21">[22]</ref>.</p><p>It is thus imperative to develop methods for zero-shot learning, namely, to expand classifiers and the space of possible labels beyond seen objects, of which we have access to the labeled images for training, to unseen ones, of which no labeled images are available <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b30">31]</ref>. To this end, we need to address two key interwoven challenges <ref type="bibr" target="#b30">[31]</ref>: <ref type="bibr" target="#b0">(1)</ref> how to relate unseen classes to seen ones and (2) how to attain optimal discriminative performance on the unseen classes even though we do not have their labeled data.</p><p>To address the first challenge, researchers have been using visual attributes <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b31">32]</ref> and word vectors <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b40">40]</ref> to associate seen and unseen classes. We call them the semantic embeddings of objects. Much work takes advantage of such embeddings directly as middle layers between input images and output class labels <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b40">40]</ref>, whereas others derive new representations from the embeddings using, for example, Canonical Correlation Analysis (CCA) <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b25">26]</ref> or sparse coding <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b47">46,</ref><ref type="bibr" target="#b48">47]</ref>. For the second challenge, the hand-designed probabilistic models in <ref type="bibr" target="#b21">[22]</ref> have been competitive baselines. More recent studies show that nearest neighbor classifiers in the semantic space are very effective <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b29">30]</ref>. Finally, classifiers for the unseen classes can directly be constructed in the input feature space <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b48">47]</ref>.</p><p>In this paper, we tackle these two challenges with ideas from manifold learning <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15]</ref>, converging to a two-pronged approach. We view object classes in a se-  <ref type="figure">Figure 1</ref>: Illustration of our method for zero-shot learning. Object classes live in two spaces. They are characterized in the semantic space with semantic embeddings (as) such as attributes and word vectors of their names. They are also represented as models for visual recognition (ws) in the model space. In both spaces, those classes form weighted graphs. The main idea behind our approach is that these two spaces should be aligned. In particular, the coordinates in the model space should be the projection of the graph vertices from the semantic space to the model space -preserving class relatedness encoded in the graph. We introduce adaptable phantom classes (b and v) to connect seen and unseen classes -classifiers for the phantom classes are bases for synthesizing classifiers for real classes. In particular, the synthesis takes the form of convex combination. mantic space as a weighted graph where the nodes correspond to object class names and the weights of the edges represent how they are related. Various information sources can be used to infer the weights -humandefined attributes or word vectors learnt from language corpora. On the other end, we view models for recognizing visual images of those classes as if they live in a space of models. In particular, the parameters for each object model are nothing but coordinates in this model space whose geometric configuration also reflects the relatedness among objects. <ref type="figure">Fig. 1</ref> illustrates this idea conceptually.</p><p>But how do we align the semantic space and the model space? The semantic space coordinates of objects are designated or derived based on external information (such as textual data) that do not directly examine visual appearances at the lowest level, while the model space concerns itself largely for recognizing lowlevel visual features. To align them, we view the coordinates in the model space as the projection of the vertices on the graph from the semantic space -there is a wealth of literature on manifold learning for computing (low-dimensional) Euclidean space embeddings from the weighted graph, for example, the well-known algorithm of Laplacian eigenmaps <ref type="bibr" target="#b4">[5]</ref>.</p><p>To adapt the embeddings (or the coordinates in the model space) to data, we introduce a set of phantom object classes -the coordinates of these classes in both the semantic space and the model space are adjustable and optimized such that the resulting model for the real object classes achieve the best performance in discriminative tasks. However, as their names imply, those phantom classes do not correspond to and are not optimized to recognize any real classes directly. For mathematical convenience, we parameterize the weighted graph in the semantic space with the phantom classes in such a way that the model for any real class is a convex combinations of the coordinates of those phantom classes. In other words, the "models" for the phantom classes can also be interpreted as bases (classifiers) in a dictionary from which a large number of classifiers for real classes can be synthesized via convex combinations. In particular, when we need to construct a classifier for an unseen class, we will compute the convex combination coefficients from this class's semantic space coordinates and use them to form the corresponding classifier.</p><p>To summarize, our main contribution is a novel idea to cast the challenging problem of recognizing unseen classes as learning manifold embeddings from graphs composed of object classes. As a concrete realization of this idea, we show how to parameterize the graph with the locations of the phantom classes, and how to derive embeddings (i.e., recognition models) as convex combinations of base classifiers. Our empirical studies extensively test our synthesized classifiers on four benchmark datasets for zero-shot learning, including the full ImageNet Fall 2011 release <ref type="bibr" target="#b6">[7]</ref> with 20,345 unseen classes. The experimental results are very encouraging; the synthesized classifiers outperform several state-ofthe-art methods, including attaining better or matching performance of Google's ConSE algorithm <ref type="bibr" target="#b29">[30]</ref> in the large-scale setting.</p><p>The rest of the paper is organized as follows. We give an overview of relevant literature in Section 2, describe our approach in detail in Section 3, demonstrate its effectiveness in Section 4, and conclude in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In order to transfer knowledge between classes, zeroshot learning relies on semantic embeddings of class labels, including attributes (both manually defined <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b43">43]</ref> and discriminatively learned <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b45">45]</ref>), word vectors <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b40">40]</ref>, knowledge mined from the Web <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref>, or a combination of several embeddings <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>Given semantic embeddings, existing approaches to zero-shot learning mostly fall into embedding-based and similarity-based methods. In the embedding-based approaches, one first maps the input image representations to the semantic space, and then determines the class labels in this space by various relatedness measures implied by the class embeddings <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b43">43]</ref>. Our work as well as some recent work combine these two stages <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b43">43,</ref><ref type="bibr" target="#b47">46,</ref><ref type="bibr" target="#b48">47]</ref>, leading to a unified framework empirically shown to have, in general, more accurate predictions. In addition to directly using fixed semantic embeddings, some work maps them into a different space through CCA <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b25">26]</ref> and sparse coding <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b47">46,</ref><ref type="bibr" target="#b48">47]</ref>.</p><p>In the similarity-based approaches, in contrast, one builds the classifiers for unseen classes by relating them to seen ones via class-wise similarities <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref>. Our approach shares a similar spirit to these models but offers richer modeling flexibilities thanks to the introduction of phantom classes.</p><p>Finally, our convex combination of base classifiers for synthesizing real classifiers can also be motivated from multi-task learning with shared representations <ref type="bibr" target="#b3">[4]</ref>.</p><p>While labeled examples of each task are required in <ref type="bibr" target="#b3">[4]</ref>, our method has no access to data of the unseen classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>We describe our methods for addressing zero-shot learning where the task is to classify images from unseen classes into the label space of unseen classes.</p><formula xml:id="formula_0">Notations Suppose we have training data D = {(x n ∈ R D , y n )} N n=1</formula><p>with the labels coming from the label space of seen classes S = {1, 2, · · · , S}. Denote by U = {S + 1, · · · , S + U} the label space of unseen classes.</p><p>We focus on linear classifiers in the visual feature space R D that assign a labelŷ to a data point x bŷ</p><formula xml:id="formula_1">y = arg max c w T c x,<label>(1)</label></formula><p>where w c ∈ R D , although our approach can be readily extended to nonlinear settings by the kernel trick <ref type="bibr" target="#b38">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Main idea</head><p>Manifold learning The main idea behind our approach is shown by the conceptual diagram in <ref type="figure">Fig. 1</ref>.</p><p>Each class c has a coordinate a c and they live on a manifold in the semantic embedding space. In this paper, we explore two types of such spaces: attributes <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b42">42]</ref> and class name embeddings via word vectors <ref type="bibr" target="#b28">[29]</ref>. We use attributes in this text to illustrate the idea and in the experiments we test our approach on both types. Additionally, we introduce a set of phantom classes associated with semantic embeddings b r , r = 1, 2, . . . , R. We stress that they are phantom as they themselves do not correspond to any real objects -they are introduced to increase the modeling flexibility, as shown below.</p><p>The real and phantom classes form a weighted bipartite graph, with the weights defined as</p><formula xml:id="formula_2">s cr = exp{−d(a c , b r )} R r=1 exp{−d(a c , b r )} (2)</formula><p>to correlate a real class c and a phantom class r, where</p><formula xml:id="formula_3">d(a c , b r ) = (a c − b r ) T Σ −1 (a c − b r ),<label>(3)</label></formula><p>and Σ −1 is a parameter that can be learned from data, modeling the correlation among attributes. For simplicity, we set Σ = σ 2 I and tune the scalar free hyperparameter σ by cross-validation. The more general Mahalanobis metric can be used and we propose one way of learning such metric as well as demonstrate its effectiveness in the Suppl. The specific form of defining the weights is motivated by several manifold learning methods such as SNE <ref type="bibr" target="#b14">[15]</ref>. In particular, s cr can be interpreted as the conditional probability of observing class r in the neighborhood of class c. However, other forms can be explored and are left for future work.</p><p>In the model space, each real class is associated with a classifier w c and the phantom class r is associated with a virtual classifier v r . We align the semantic and the model spaces by viewing w c (or v r ) as the embedding of the weighted graph. In particular, we appeal to the idea behind Laplacian eigenmaps <ref type="bibr" target="#b4">[5]</ref>, which seeks the embedding that maintains the graph structure as much as possible; equally, the distortion error</p><formula xml:id="formula_4">min wc,vr w c − R r=1 s cr v r 2 2</formula><p>is minimized. This objective has an analytical solution</p><formula xml:id="formula_5">w c = R r=1 s cr v r , ∀ c ∈ T = {1, 2, · · · , S + U} (4)</formula><p>In other words, the solution gives rise to the idea of synthesizing classifiers from those virtual classifiers v r . For conceptual clarity, from now on we refer to v r as base classifiers in a dictionary from which new classifiers can be synthesized. We identify several advantages. First, we could construct an infinite number of classifiers as long as we know how to compute s cr . Second, by making R ≪ S, the formulation can significantly reduce the learning cost as we only need to learn R base classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Learning phantom classes</head><p>Learning base classifiers We learn the base classifiers {v r } R r=1 from the training data (of the seen classes only). We experiment with two settings. To learn oneversus-other classifiers, we optimize,</p><formula xml:id="formula_6">min v1,··· ,v R S c=1 N n=1 ℓ(x n , I yn,c ; w c ) + λ 2 S c=1 w c 2 2 , (5) s.t. w c = R r=1 s cr v r , ∀ c ∈ T = {1, · · · , S} where ℓ(x, y; w) = max(0, 1 − yw T x) 2 is the squared hinge loss. The indicator I yn,c ∈ {−1,</formula><p>1} denotes whether or not y n = c. Alternatively, we apply the Crammer-Singer multi-class SVM loss <ref type="bibr" target="#b5">[6]</ref>, given by</p><formula xml:id="formula_7">ℓ cs (x n , y n ; {w c } S c=1 ) = max(0, max c∈S−{yn} ∆(c, y n ) + w c T x n − w yn T x n ),</formula><p>We have the standard Crammer-Singer loss when the structured loss ∆(c, y n ) = 1 if c = y n , which, however, ignores the semantic relatedness between classes. We additionally use the ℓ 2 distance for the structured loss ∆(c, y n ) = a c − a yn 2 2 to exploit the class relatedness in our experiments. These two learning settings have separate strengths and weaknesses in empirical studies.</p><p>Learning semantic embeddings The weighted graph eq. (2) is also parameterized by adaptable embeddings of the phantom classes b r . For this work, however, for simplicity, we assume that each of them is a sparse linear combination of the seen classes' attribute vectors:</p><formula xml:id="formula_8">b r = S c=1</formula><p>β rc a c , ∀r ∈ {1, · · · , R}, Thus, to optimize those embeddings, we solve the following optimization problem</p><formula xml:id="formula_9">min {vr} R r=1 ,{βrc} R,S r,c=1 S c=1 N n=1 ℓ(x n , I yn,c ; w c ) + λ 2 S c=1 w c 2 2 + η R,S r,c=1 |β rc | + γ 2 R r=1 ( b r 2 2 − h 2 ) 2 , s.t. w c = R r=1 s cr v r , ∀ c ∈ T = {1, · · · , S},</formula><p>where h is a predefined scalar equal to the norm of real attribute vectors (i.e., 1 in our experiments since we perform ℓ 2 normalization). Note that in addition to learning {v r } R r=1 , we learn combination weights {β rc } R,S r,c=1 . Clearly, the constraint together with the third term in the objective encourages the sparse linear combination of the seen classes' attribute vectors. The last term in the objective demands that the norm of b r is not too far from the norm of a c .</p><p>We perform alternating optimization for minimizing the objective function with respect to {v r } R r=1 and {β rc } R,S r,c=1 . While this process is nonconvex, there are useful heuristics to initialize the optimization routine. For example, if R = S, then the simplest setting is to let b r = a r for r = 1, . . . , R. If R ≤ S, we can let them be (randomly) selected from the seen classes' attribute vectors {b 1 , b 2 , · · · , b R } ⊆ {a 1 , a 2 , · · · , a S }, or first perform clustering on {a 1 , a 2 , · · · , a S } and then let each b r be a combination of the seen classes' attribute vectors in cluster r. If R &gt; S, we could use a combination of the above two strategies. We describe in more detail how to optimize and cross-validate hyperparameters in the Suppl.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Comparison to several existing methods</head><p>We contrast our approach to some existing methods. <ref type="bibr" target="#b26">[27]</ref> combines pre-trained classifiers of seen classes to construct new classifiers. To estimate the semantic embedding (e.g., word vector) of a test image, <ref type="bibr" target="#b29">[30]</ref> uses the decision values of pre-trained classifiers of seen objects to weighted average the corresponding semantic embeddings. Neither of them has the notion of base classifiers, which we introduce for constructing the classifiers and nothing else. We thus expect them to be more effective in transferring knowledge between seen and unseen classes than overloading the pretrained and fixed classifiers of the seen classes for dual duties. We note that <ref type="bibr" target="#b0">[1]</ref> can be considered as a special case of our method. In <ref type="bibr" target="#b0">[1]</ref>, each attribute corresponds to a base and each "real" classifier corresponding to an actual object is represented as a linear combination of those bases, where the weights are the real objects' "descriptions" in the form of attributes. This modeling is limiting as the number of bases is fundamentally limited by the number of attributes. Moreover, the model is strictly a subset of our model. <ref type="bibr" target="#b0">1</ref> Recently, <ref type="bibr" target="#b47">[46,</ref><ref type="bibr" target="#b48">47]</ref> propose similar ideas of aligning the visual and semantic spaces but take different approaches from ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We evaluate our methods and compare to existing state-of-the-art models on several benchmark datasets. While there is a large degree of variations in the current empirical studies in terms of datasets, evaluation protocols, experimental settings, and implementation details, we strive to provide a comprehensive comparison to as many methods as possible, not only citing the published results but also reimplementing some of those methods to exploit several crucial insights we have discovered in studying our methods.</p><p>We summarize our main results in this section. More extensive details are reported in the Suppl. We provide not only comparison in recognition accuracy but also analysis in an effort to understand the sources of better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Setup</head><p>Datasets We use four benchmark datasets in our experiments: the Animals with Attributes (AwA) <ref type="bibr" target="#b21">[22]</ref>, CUB-200-2011 Birds (CUB) <ref type="bibr" target="#b42">[42]</ref>, SUN Attribute (SUN) <ref type="bibr" target="#b32">[33]</ref>, and the ImageNet (with full 21,841 classes) <ref type="bibr" target="#b36">[37]</ref>. <ref type="table" target="#tab_0">Table 1</ref> summarizes their key characteristics. The Suppl. provides more details.</p><p>Semantic spaces For the classes in AwA, we use 85dimensional binary or continuous attributes <ref type="bibr" target="#b21">[22]</ref>, as well as the 100 and 1,000 dimensional word vectors <ref type="bibr" target="#b27">[28]</ref>, derived from their class names and extracted by Fu et al. <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. For CUB and SUN, we use 312 and 102 dimensional continuous-valued attributes, respectively. We also thresh them at the global means to obtain binary-valued attributes, as suggested in <ref type="bibr" target="#b21">[22]</ref>. Neither datasets have word vectors for their class names. For ImageNet, we train a skip-gram language model <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b0">1</ref> For interested readers, if we set the number of attributes as the number of phantom classes (each br is the one-hot representation of an attribute), and use Gaussian kernel with anisotropically diagonal covariance matrix in eq. (3) with properly set bandwidths (either very small or very large) for each attribute, we will recover the formulation in <ref type="bibr" target="#b0">[1]</ref> when the bandwidths tend to zero or infinity.  <ref type="bibr" target="#b21">[22]</ref>. ‡ : 4 (or 10, respectively) random splits, reporting average. § : Seen and unseen classes from ImageNet ILSVRC 2012 1K <ref type="bibr" target="#b36">[37]</ref> and Fall 2011 release <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b29">30]</ref>. <ref type="bibr" target="#b28">29</ref>] on the latest Wikipedia dump corpus 2 (with more than 3 billion words) to extract a 500-dimensional word vector for each class. Details of this training are in the Suppl. We ignore classes without word vectors in the experiments, resulting in 20,345 (out of 20,842) unseen classes. For both the continuous attribute vectors and the word vector embeddings of the class names, we normalize them to have unit ℓ 2 norms unless stated otherwise.</p><p>Visual features Due to variations in features being used in literature, it is impractical to try all possible combinations of features and methods. Thus, we make a major distinction in using shallow features (such as color histograms, SIFT, PHOG, Fisher vectors) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b43">43]</ref> and deep learning features in several recent studies of zero-shot learning. Whenever possible, we use (shallow) features provided by those datasets or prior studies. For comparative studies, we also extract the following deep features: AlexNet <ref type="bibr" target="#b19">[20]</ref> for AwA and CUB and GoogLeNet <ref type="bibr" target="#b41">[41]</ref> for all datasets (all extracted with the Caffe package <ref type="bibr" target="#b17">[18]</ref>). For AlexNet, we use the 4,096-dimensional activations of the penultimate layer (fc7) as features. For GoogLeNet, we take the 1,024dimensional activations of the pooling units, as in <ref type="bibr" target="#b1">[2]</ref>. Details on how to extract those features are in the Suppl.</p><p>Evaluation protocols For AwA, CUB, and SUN, we use the (normalized, by class-size) multi-way classification accuracy, as in previous work. Note that the accuracy is always computed on images from unseen classes.</p><p>Evaluating zero-shot learning on the large-scale Ima-geNet requires substantially different components from evaluating on the other three datasets. First, two evaluation metrics are used, as in <ref type="bibr" target="#b9">[10]</ref>: Flat hit@K (F@K) and Hierarchical precision@K (HP@K).</p><p>F@K is defined as the percentage of test images for which the model returns the true label in its top K predictions. Note that, F@1 is the multi-way classification accuracy. HP@K takes into account the hierarchical organization of object categories. For each true label, we generate a ground-truth list of K closest categories in the hierarchy and compute the degree of overlapping (i.e., precision) between the ground-truth and the model's top K predictions. For the detailed description of this metric, please see the Appendix of <ref type="bibr" target="#b9">[10]</ref> and the Suppl.</p><p>Secondly, following the procedure in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b29">30]</ref>, we evaluate on three scenarios of increasing difficulty:</p><p>• 2-hop contains 1,509 unseen classes that are within two tree hops of the seen 1K classes according to the ImageNet label hierarchy 3 .</p><p>• 3-hop contains 7,678 unseen classes that are within three tree hops of seen classes.</p><p>• All contains all 20,345 unseen classes in the Ima-geNet 2011 21K dataset that are not in the ILSVRC 2012 1K dataset.</p><p>The numbers of unseen classes are slightly different from what are used in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b29">30]</ref> due to the missing semantic embeddings (i.e., word vectors) for certain class names.</p><p>In addition to reporting published results, we have also reimplemented the state-of-the-art method ConSE <ref type="bibr" target="#b29">[30]</ref> on this dataset, introducing a few improvements. Details are in the Suppl.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation details</head><p>We cross-validate all hyperparameters -details are in the Suppl. For convenience, we set the number of phantom classes R to be the same as the number of seen classes S, and set b r = a c for r = c. We also experiment setting different R and learning b r . Our study (cf. <ref type="figure" target="#fig_1">Fig. 2)</ref> shows that when R is about 60% of S, the performance saturates. We denote the three variants of our methods in constructing classifiers (Section 3.2) by Ours o-vs-o (one-versus-other), Ours cs (Crammer-Singer) and Ours struct (Crammer-Singer with structured loss). <ref type="table">Table 2</ref> compares the proposed methods to the state-ofthe-art from the previously published results on benchmark datasets. While there is a large degree of variations <ref type="table">Table 2</ref>: Comparison between our results and the previously published results in multi-way classification accuracies (in %) on the task of zero-shot learning. For each dataset, the best is in red and the 2nd best is in blue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Main results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>AwA CUB SUN ImageNet DAP <ref type="bibr" target="#b21">[22]</ref> 41. Results reported on a particular seen-unseen split. ⋆ : Results were just brought to our attention. Note that VGG <ref type="bibr" target="#b39">[39]</ref> instead of GoogLeNet features were used, improving on AwA but worsening on CUB. Our results using VGG will appear in a longer version of this paper.</p><p>in implementation details, the main observation is that our methods attain the best performance in most scenarios. In what follows, we analyze those results in detail.</p><p>We also point out that the settings in some existing work are highly different from ours; we do not include their results in the main text for fair comparison <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b45">45</ref>] -but we include them in the Suppl. In some cases, even with additional data and attributes, those methods underperform ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Large-scale zero-shot learning</head><p>One major limitation of most existing work on zero-shot learning is that the number of unseen classes is often small, dwarfed by the number of seen classes. However, real-world computer vision systems need to face a very large number of unseen objects. To this end, we evaluate our methods on the large-scale ImageNet dataset. <ref type="table" target="#tab_2">Table 3</ref> summarizes our results and compares to the ConSE method <ref type="bibr" target="#b29">[30]</ref>, which is, to the best of our knowledge, the state-of-the-art method on this dataset. <ref type="bibr" target="#b3">4</ref> Note that in some cases, our own implementation ("ConSE by us" in the table) performs slightly worse than the reported results, possibly attributed to differences in visual features, word vector embeddings, and other implementation details. Nonetheless, the proposed methods (using the same setting as "ConSE by us") always outperform both, especially in the very challenging scenario of All where the number of unseen classes is 20,345, significantly larger than the number of seen classes. Note also that, for both types of metrics, when K is larger, the improvement over the existing approaches is more pronounced. It is also not surprising to notice that as the number of unseen classes increases from the setting 2hop to All, the performance of both our methods and ConSE degrade.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Detailed analysis</head><p>We experiment extensively to understand the benefits of many factors in our and other algorithms. While trying all possible combinations is prohibitively expensive, we have provided a comprehensive set of results for comparison and drawing conclusions.</p><p>Advantage of continuous attributes It is clear from <ref type="table">Table 4</ref> that, in general, continuous attributes as semantic embeddings for classes attain better performance than binary attributes. This is especially true when deep learning features are used to construct classifiers. It is somewhat expected that continuous attributes provide a more accurate real-valued similarity measure among classes. This presumably is exploited further by more powerful classifiers.</p><p>Advantage of deep features It is also clear from <ref type="table">Table 4</ref> that, across all methods, deep features significantly boost the performance based on shallow features. We use GoogLeNet and AlexNet (numbers in parentheses) and GoogLeNet generally outperforms AlexNet. It is worthwhile to point out that the reported results under deep features columns are obtained using linear classifiers, which outperform several nonlinear classifiers that use shallow features. This seems to suggest that deep features, often thought to be specifically adapted to seen training images, still work well when transferred to unseen images <ref type="bibr" target="#b9">[10]</ref>.</p><p>Which types of semantic space? In <ref type="table" target="#tab_3">Table 5</ref>, we show how effective our proposed method (Ours o-vs-o ) exploits the two types of semantic spaces: (continuous) attributes and word-vector embeddings on AwA (the only dataset with both embedding types). We find that attributes yield better performance than word-vector embeddings. However, combining the two gives the best result, suggesting that these two semantic spaces could be complementary and further investigation is ensured. <ref type="table" target="#tab_5">Table 6</ref> takes a different view on identifying the best semantic space. We study whether we can learn optimally the semantic embeddings for the phantom classes that correspond to base classifiers. These preliminary studies seem to suggest that learning attributes could have a positive effect, though it is difficult to improve over word-vector embeddings. We plan to study this issue more thoroughly in the future.</p><p>How many base classifiers are necessary? In <ref type="figure" target="#fig_1">Fig. 2</ref>, we investigate how many base classifiers are needed - <ref type="table">Table 4</ref>: Detailed analysis of various methods: the effect of feature and attribute types on multi-way classification accuracies (in %). Within each column, the best is in red and the 2nd best is in blue. We cite both previously published results (numbers in bold italics) and results from our implementations of those competing methods (numbers in normal font) to enhance comparability and to ease analysis (see texts for details). We use the shallow features provided by <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b32">[33]</ref> for AwA, CUB, SUN, respectively.  <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b32">33]</ref>. § : On the attribute vectors without ℓ2 normalization, while our own implementation shows that normalization helps in some cases. ♯ : As co-occurrence statistics are not available, we combine pre-trained classifiers with the weights defined in eq. (2). so far, we have set that number to be the number of seen classes out of convenience. The plot shows that in fact, a smaller number (about 60% -70%) is enough for our algorithm to reach the plateau of the performance curve. Moreover, increasing the number of base classifiers does not seem to have an overwhelming effect. Further details and analysis are in the Suppl.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have developed a novel classifier synthesis mechanism for zero-shot learning by introducing the notion of "phantom" classes. The phantom classes connect the dots between the seen and unseen classes -the classifiers of the seen and unseen classes are constructed from the same base classifiers for the phantom classes and with the same coefficient functions. As a result, we can conveniently learn the classifier synthesis mechanism leveraging labeled data of the seen classes and then readily apply it to the unseen classes. Our approach outperforms the state-of-the-art methods on four benchmark datasets in most scenarios.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>We vary the number of phantom classes R as a percentage of the number of seen classes S and investigate how much that will affect classification accuracy (the vertical axis corresponds to the ratio with respect to the accuracy when R = S). The base classifiers are learned with Ours o-vs-o .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Key characteristics of studied datasets</figDesc><table>Dataset 
# of seen # of unseen 
Total # 
name 
classes 
classes 
of images 
AwA  † 
40 
10 
30,475 
CUB  ‡ 
150 
50 
11,788 
SUN  ‡ 
645/646 
72/71 
14,340 
ImageNet  § 
1,000 
20,842 
14,197,122 

 † : Following the prescribed split in </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 :</head><label>3</label><figDesc>Comparison between results by ConSE and our method on ImageNet. For both types of metrics, the higher the better.</figDesc><table>Scenarios 
Methods 
Flat Hit@K 
Hierarchical precision@K 
K= 
1 
2 
5 
10 
20 
2 
5 
10 
20 
2-hop 
ConSE [30] 
9.4 
15.1 24.7 32.7 41.8 21.4 24.7 26.9 28.4 
ConSE by us 
8.3 
12.9 21.8 30.9 41.7 21.5 23.8 27.5 31.3 
Ours o-vs-o 
10.5 16.7 28.6 40.1 52.0 25.1 27.7 30.3 32.1 
Ours struct 
9.8 
15.3 25.8 35.8 46.5 23.8 25.8 28.2 29.6 
3-hop 
ConSE [30] 
2.7 
4.4 
7.8 
11.5 16.1 
5.3 
20.2 22.4 24.7 
ConSE by us 
2.6 
4.1 
7.3 
11.1 16.4 
6.7 
21.4 23.8 26.3 
Ours o-vs-o 
2.9 
4.9 
9.2 
14.2 20.9 
7.4 
23.7 26.4 28.6 
Ours struct 
2.9 
4.7 
8.7 
13.0 18.6 
8.0 
22.8 25.0 26.7 
All 
ConSE [30] 
1.4 
2.2 
3.9 
5.8 
8.3 
2.5 
7.8 
9.2 
10.4 
ConSE by us 
1.3 
2.1 
3.8 
5.8 
8.7 
3.2 
9.2 
10.7 12.0 
Ours o-vs-o 
1.4 
2.4 
4.5 
7.1 
10.9 
3.1 
9.0 
10.9 12.5 
Ours struct 
1.5 
2.4 
4.4 
6.7 
10.0 
3.6 
9.6 
11.0 12.2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 5 :</head><label>5</label><figDesc>Effect of types of semantic embeddings on AwA.</figDesc><table>Semantic embeddings 
Dimensions Accuracy (%) 
word vectors 
100 
42.2 
word vectors 
1000 
57.5 
attributes 
85 
69.7 
attributes + word vectors 
185 
73.2 
attributes + word vectors 
1085 
76.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>† : Results reported by the authors on a particular seen-unseen split. ‡ : Based on Fisher vectors as shallow features, different from those provided in</figDesc><table>Methods 
Attribute 
Shallow features 
Deep features 
type 
AwA 
CUB 
SUN 
AwA 
CUB 
SUN 
DAP [22] 
binary 
41.4 
28.3 
22.2 
60.5 (50.0) 
39.1 (34.8) 
44.5 
IAP [22] 
binary 
42.2 
24.4 
18.0 
57.2 (53.2) 
36.7 (32.7) 
40.8 
BN [43] 
binary 
43.4 
-
-
-
-
-
ALE [1]  ‡ 
binary 
37.4 
18.0  † 
-
-
-
-
ALE 
binary 
34.8 
27.8 
-
53.8 (48.8) 
40.8 (35.3) 
53.8 
SJE [2] 
continuous 42.3  ‡ 19.0  † ‡ 
-
66.7 (61.9) 50.1 (40.3)  † 
-
SJE 
continuous 
36.2 
34.6 
-
66.3 (63.3) 
46.5 (42.8) 
56.1 
ESZSL [36]  § continuous 
49.3 
37.0 
-
59.6 (53.2) 
44.0 (37.2) 
8.7 
ESZSL 
continuous 
44.1 
38.3 
-
64.5 (59.4) 
34.5 (28.0) 
18.7 
ConSE [30] 
continuous 
36.5 
23.7 
-
63.3 (56.5) 
36.2 (32.6) 
51.9 
COSTA [27] ♯ continuous 
38.9 
28.3 
-
61.8 (55.2) 
40.8 (36.9) 
47.9 
Ours o-vs-o 
continuous 
42.6 
35.0 
-
69.7 (64.0) 
53.4 (46.6) 
62.8 
Ours cs 
continuous 
42.1 
34.7 
-
68.4 (64.8) 
51.6 (45.7) 
52.9 
Ours struct 
continuous 
41.5 
36.4 
-
72.9 (62.8) 
54.5 (47.1) 
62.7 

 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 6 :</head><label>6</label><figDesc>Effect of learning semantic embeddings</figDesc><table>Datasets Types of embeddings 
w/o learning 
w/ learning 
AwA 
attributes 
69.7% 
71.1% 
100-d word vectors 
42.2% 
42.5% 
1000-d word vectors 
57.6% 
56.6% 
CUB 
attributes 
53.4% 
54.2% 
SUN 
attributes 
62.8% 
63.3% 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://dumps.wikimedia.org/enwiki/latest/ enwiki-latest-pages-articles.xml.bz2 on September 1, 2015</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://www.image-net.org/api/xml/structure_ released.xml</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We are aware of recent work by Lu<ref type="bibr" target="#b25">[26]</ref> that introduces a novel form of semantic embeddings.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Label-embedding for attribute-based classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Evaluation of output embeddings for fine-grained image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">How to transfer? zeroshot object recognition via hierarchical transfer of semantic attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Al-Halah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Convex multitask feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Argyriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="243" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps for dimensionality reduction and data representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the algorithmic implementation of multiclass kernel-based vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="265" to="292" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Write a classifier: Zero-shot learning using purely textual descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elgammal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Describing objects by their attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Endres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Devise: A deep visualsemantic embedding model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Transductive multi-view embedding for zero-shot recognition and annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Transductive multi-view zero-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Zero-shot object recognition by semantic manifold distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Active transfer learning with zero-shot priors: Reusing past datasets for future tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gavves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G M</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Stochastic neighbor embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Zero-shot recognition with unreliable attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Decorrelating semantic visual attributes by resisting the urge to share</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for zero-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to detect unseen object classes by between-class attribute transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Attributebased classification for zero-shot visual object categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>TPAMI</publisher>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="453" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Predicting deep zero-shot convolutional neural networks using textual descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semi-supervised zero-shot classification with label representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Attributes make sense on segmented objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gavves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Unsupervised learning of neural network outputs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.00990</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Costa: Co-occurrence statistics for zero-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gavves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshops</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Zero-shot learning by convex combination of semantic embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Zero-shot learning with semantic output codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palatucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Relative attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The sun attribute database: Beyond categories for deeper scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="59" to="81" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Evaluating knowledge transfer and zero-shot learning in a largescale setting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">What helps where-and why? semantic relatedness for knowledge transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Szarvas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An embarrassingly simple approach to zero-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note>Imagenet large scale visual recognition challenge. IJCV</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Learning with kernels: support vector machines, regularization, optimization, and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Zeroshot learning through cross-modal transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ganjoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
		<title level="m">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A unified probabilistic approach modeling relationships between attributes and objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A unified perspective on multi-domain and multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Designing category-level attributes for discriminative visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Classifying unseen instances by learning class-independent similarity functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.04512</idno>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Zero-shot learning via semantic similarity embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
