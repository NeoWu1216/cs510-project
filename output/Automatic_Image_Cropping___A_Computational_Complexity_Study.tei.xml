<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automatic Image Cropping : A Computational Complexity Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiansheng</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaocheng</forename><surname>Bai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoheng</forename><surname>Liang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengqin</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automatic Image Cropping : A Computational Complexity Study</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Attention based automatic image cropping aims at preserving the most visually important region in an image. A common task in this kind of method is to search for the smallest rectangle inside which the summed attention is maximized. We demonstrate that under appropriate formulations, this task can be achieved using efficient algorithms with low computational complexity. In a practically useful scenario where the aspect ratio of the cropping rectangle is given, the problem can be solved with a computational complexity linear to the number of image pixels. We also study the possibility of multiple rectangle cropping and a new model facilitating fully automated image cropping.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the rapid development of imaging and storage technologies, pixel resolution of digital images captured by modern imaging devices such as the digital camera, webcam or mobile phone has increased dramatically. Images containing over millions of pixels has become more and more common even in mobile devices. This has brought difficulties to the transmission and sharing of the images especially through the mobile Internet. Considering both the time and the cost, images are usually excessively down sampled or compressed before transmission, leading to serious degradation of image quality on the receiver's side.</p><p>Visual importances vary a log across different regions in real life images. Examples are shown in <ref type="figure">Figure 1</ref>. Actually, with the continuous increasing of pixel resolution of capturing devices, people tends to include a unnecessary amount of less important background or unrelated scenery in the image when taking pictures. In addition to causing difficulties to image transmission, these relatively less important image pixels may also harm the visual effectiveness of important image parts, especially after image retargeting for mobile devices equipped with small sized displays. To solve this problem, previous researchers have proposed a number of context aware image cropping/resizing methods which can be generally divided into two categories, atten-tion based methods and aesthetics oriented methods <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Previous works</head><p>The fundamental idea of attention based methods is trying to preserve visually important area of an image after cropping or resizing. Pixel importances for visual attention are usually estimated using their saliency scores <ref type="bibr" target="#b4">[5]</ref> [20] <ref type="bibr" target="#b17">[18]</ref>  <ref type="bibr" target="#b15">[16]</ref>, objectness <ref type="bibr" target="#b26">[27]</ref>  <ref type="bibr" target="#b6">[7]</ref>, or empirically defined energy functions <ref type="bibr" target="#b14">[15]</ref>  <ref type="bibr" target="#b0">[1]</ref>. Chen et al. were among the first to study the image cropping problem in order to facilitate viewing large images on small sized displays <ref type="bibr" target="#b4">[5]</ref>. Pixel saliency values calculated using Itti's model <ref type="bibr" target="#b8">[9]</ref> was combined with face and text detection results for generating the attention map. Suh et al. extended this work by using summed saliency values within cropping rectangles for determining the best cropping position <ref type="bibr" target="#b19">[20]</ref>. Santella et al. acquired image saliency values by means of human-computer interaction <ref type="bibr" target="#b17">[18]</ref>. User fixation data were captured and utilized together with image segmentation results to identify important image contents and compute the best crop. By assuming that images sharing similar global visual appearances are likely to share similar salience, Marchesotti et al. <ref type="figure">Figure 1</ref>. Examples of automatic image cropping. Images are selected from the MSRA Salient Object Database <ref type="bibr" target="#b12">[13]</ref>. 1 st column: cropping results using the graph cut based method <ref type="bibr" target="#b15">[16]</ref>. 2 nd column: cropping resultsR(τ * ) using the proposed method. 3 rd column: cropped images using the proposed method. 4 th column: retargeted images using the shortest path base method <ref type="bibr" target="#b0">[1]</ref>. trained a simple classifier on an annotated image database for generating attention maps based on which image thumbnailing were achieved <ref type="bibr" target="#b15">[16]</ref>. Zhang et al. focused on faces in the image by selecting regions of interest according to face detection results. Images were then cropped by aligning faces according to predefined image composition templates <ref type="bibr" target="#b26">[27]</ref>. Ciocca et al. combined visual saliency information with face and skin color detection results for placing bounding box in image cropping <ref type="bibr" target="#b6">[7]</ref>. Ma et al. proposed an comprehensive energy function based on image entropy, area size and position for measuring the visual importance before cropping <ref type="bibr" target="#b14">[15]</ref>. Avidan et al. simply used the amplitude of image gradient as the energy function for describing pixel importance <ref type="bibr" target="#b0">[1]</ref>. Instead of preserving pixels with high importances, Avidan et al. removed 8-connected paths of minimum summed energy values consecutively.</p><p>The aesthetics oriented method aims at maximizing the visual attractiveness of the cropped images. Although the visual aesthetics obeys certain general principles, it is also known to be influenced by subjective factors such as the culture, personal experiences, education level, or even the psychological state <ref type="bibr" target="#b3">[4]</ref>. Therefore, most existing aesthetics oriented image cropping approaches are based on photo quality assessment studies <ref type="bibr" target="#b10">[11]</ref> [3] <ref type="bibr" target="#b21">[22]</ref> using certain objective aspects of images, such as low level image features and empirical photographic composition rules. Nishiyama et al. statistically built a image quality classifier using low level image features such as color histogram and Fourier coefficients. The image cropping candidate with the highest quality score was then selected <ref type="bibr" target="#b16">[17]</ref>. Cheng et al. studied the spatial correlation distributions of two arbitrary patches in an image for generating an omni-context prior which was combined with visual words to form a posterior probability model for measuring image quality <ref type="bibr" target="#b5">[6]</ref>. Zhang et al. introduced small connected subgrpahs, or graphlets, extracted from the region adjacency graph, for representing image aesthetic features. A probabilistic model based on the graphlet was then used for transfer aesthetic features from the training images onto the cropped images <ref type="bibr" target="#b25">[26]</ref>. In a more recent work, Yan et al. proposed features for modeling what is changed after image cropping. The influence of these features on cropping learned from manually marked image pairs was then used for generating effective crops <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Motivation</head><p>In this work, we focus on a specific aspect which has to some extend been overlooked in previous studies. In most existing attention based image cropping approaches <ref type="bibr" target="#b19">[20]</ref>   <ref type="bibr" target="#b14">[15]</ref>. These methods are either heuristic or of nearly the same complexity as the brute force search. In this work, we propose several practical formulations of the optimum rectangle search problem and design algorithms with essentially low computational complexity to solve them.</p><p>The rest of this paper is organized as follows. Section 2 presents our problem formulations. Section 3 elaborates the proposed algorithms and corresponding complexity analysis. Experimental results are demonstrated in Section 4. The last section concludes our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Problem formulations</head><p>As we have stated above, the target of optimum cropping rectangle search on a given attention map is twofold. Firstly, the area of the rectangle should be minimized so as to crop out as much visually unimportant image regions as possible. Secondly, the sum of attention value inside the rectangle should be maximized so as to preserve as much visually important image regions as possible. These two objectives are dual and the problem can be defined either way.</p><p>Suppose G is a non-negative valued attention map extracted from an image I. Larger attention values in G indicate higher visual importance of corresponding pixels in I. Without loosing generality, we formulate the optimum cropping rectangle search problem as Problem 1, in which τ is the minimum percentage of total attention to be preserved andR is the smallest rectangle satisfying this requirement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem 1 [Minimum Rectangle Search]</head><p>: Given a percentile ratio τ , find a rectangleR(τ ) of the minimum possible area size, inside G, to satisfy <ref type="bibr" target="#b0">(1)</ref>.</p><formula xml:id="formula_0">∑ p∈R (τ ) G(p) ≥ τ ∑ p G(p), τ ∈ [0, 1]<label>(1)</label></formula><p>The attention value of an image pixel can be considered as the measurement of its visual importance. It is reasonable to think that every pixel may contain certain amount of visual information. Therefore in this work we simply assume that attention values are non-negative. This is also consistent with most existing works for calculating the attention map <ref type="bibr" target="#b8">[9]</ref> [10] <ref type="bibr" target="#b24">[25]</ref>  <ref type="bibr" target="#b7">[8]</ref>. In case of no ambiguity, we denote ∑ p∈R G(p) as ∑R G, and ∑ p G(p) as ∑ G. Also, a rectangle is called valid if it satisfies (1).</p><p>Let ∥R(τ )∥ be the rectangular area ofR(τ ). For any given G, ∥R(τ )∥ is an increasing function of τ as is expressed in <ref type="bibr" target="#b1">(2)</ref>. This can be deduced using abductive reasoning. Suppose that ∥R(τ 1 )∥ &lt; ∥R(τ 2 )∥, combining <ref type="formula" target="#formula_0">(1)</ref> and</p><formula xml:id="formula_1">(2), we have ∑R (τ1) G ≥ τ 1 ∑ G ≥ τ 2 ∑ G. This indi- cates thatR(τ 1 )</formula><p>is also a rectangle with summed attention value greater than or equal to τ 2 ∑ G. However, according</p><p>to Problem 1 definition, among all such rectangles,R(τ 2 ) should be the smallest, leading to obvious contradiction. In case of no ambiguity, we set the rectangular area of the attention map to be 1, so that the value of ∥R∥ stands for the percentage of area occupied byR in G.</p><formula xml:id="formula_2">∀τ 1 ≥ τ 2 , ∥R(τ 1 )∥ ≥ ∥R(τ 2 )∥<label>(2)</label></formula><p>It should be emphasized that for a given τ ,R(τ ) may not be unique. In our algorithms, we always chooseR(τ ) with the largest summed attention value. Even so, the uniqueness ofR(τ ) still cannot be ensured. This is acceptable in practice considering that it only lead to different cropping results but with equal area sizes as well as equal visual importance. It should also be noted that ∥R(τ )∥ is not a monotonic increasing function of τ . It is possible that ∥R(τ 1 )∥ = ∥R(τ 2 )∥ when τ 1 ̸ = τ 2 . This usually happens when the difference between τ 1 and τ 2 is very small.</p><p>At the first glance, Problem 1 is similar to the famous Maximum Submatrix problem which is to find for a matrix its submatrixS of which the sum of elements is maximized [2] <ref type="bibr" target="#b20">[21]</ref>. Despite of their seeming resemblance, these two problems are intrinsically different. First of all, finding the maximum submatrix of a non-negative valued matrix, such as G, is trivial since the solution is usually the matrix itself. Also, converting these two problems to each other leads to meaningless results. A easy to come up with, yet incorrect solution to Problem 1 is to subtract average attention G from G and then get the maximum submatrix of G −Ḡ. A slight more reasonable solution is to take τ into account and get the maximum submatrix for G − τḠ. However, <ref type="figure">Figure 2</ref> demonstrates that the three problems may lead to absolutely different answers shown by shaded rectangles.</p><p>Another practical consideration for image cropping is related to the application of image retargeting. Nowadays, aspect ratio various a lot across different display devices such as the desktop PC, mobile phone, or wearable device. To achieve the optimum display efficiency, a promising choice is to let the cropped image to have the same aspect ratio as the target display, leading to the definition of Problem 2.</p><formula xml:id="formula_3">(a)R(0.6) of G (b)S of G −Ḡ (c)S of G − 0.6Ḡ</formula><p>For a rectangle, we define the aspect ratio to be its width divided by its height. Later we will see that by constraining the aspect ratio of the cropping rectangle, Problem 2 is intrinsically simpler than Problem 1. Hence, its low computational complexity as well as its appropriateness for image retargeting make it practically useful. Nevertheless, it should be noticed that unlikeR(τ ),R(τ, r) may not exist for certain τ and r values in a given attention map due to the hard constraint of the aspect ratio. What is more, because of the spatial discretization of pixels, sometimes the aspect ratio constraint can only be approximately satisfied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem 2 [Fixed Aspect Ratio Rectangle Search] :</head><p>Given a percentile ratio τ , find a rectangleR(τ, r) of the minimum possible area size, with a fixed aspect ratio r &gt; 0, inside G, to satisfy <ref type="bibr" target="#b0">(1)</ref>.</p><p>An issue that has seldom been addressed in previous studies is that sometimes it may not be appropriate to select only one cropping rectangle from an image containing multiple visually important regions that are spatially scattered. A typical example is shown in <ref type="figure">Figure 3</ref>, in which τ is set to 0.75. By selecting two instead of only one cropping rectangle, the total cropping area size is halved and the cropping result is visually much more reasonable. Based on this understanding, we define Problem 3 which can be regarded as a generalization of Problem 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem 3 [Multiple Rectangle Search]</head><p>: Given a percentile ratio τ , find no more than N non-intersected rect-anglesR 1 ,R 2 , ...,R N inside G, all with fixed aspect ratio r &gt; 0. Denote the union of these rectangles to bë R(τ, r, N ) =R 1 ∪R 2 ∪ ... ∪R N . Minimizing the total area size ∥R∥ while satisfying <ref type="bibr" target="#b0">(1)</ref>.</p><p>By allowing more cropping rectangles, Problem 2 increases the degree of freedom of the search process, leading to higher effectiveness of image cropping by decreasing the total area size to be preserved. Nevertheless, it is obvious that such a generalization will increase the problem complexity combinatorially. Therefore, in this paper we will only discuss the case of N = 2. It should be noted that for certain images, using more than one cropping rectangles may not be advantageous. In other words, some of the rectangles may be found empty while solving Problem 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Algorithms and analysis</head><p>In this section, we will present algorithms for solving the three problems defined above. We will focus on elucidating their correctness and analyzing their computational complexity. We assume that the attention map G is of m rows and n columns, and m ≤ n. To solve the spatial discretization problem mentioned above, we use the following approximation for aspect ratio calculation. Given a aspect ratio r, suppose the height of a candidate rectangle is h, then its width is decided by <ref type="formula">(3)</ref>.</p><formula xml:id="formula_4">w = ⌈h × r⌉</formula><p>(3) For a given attention map G, we adopt matrix like notations : G(i, j) stands for the attention value at the i th (i ∈ [1, m]) row and j th (j ∈ [1, n]) column; G(i, :) (or G(:, j)) stands for the one dimensional array of the i th row (or j th column) of G. In case of no ambiguity, we let G(i, j) = 0 whenever i ≤ 0 or j ≤ 0. We define the integral map G + of G, so that G + (i, j) = ∑ i k=1 ∑ j l=1 G(k, l). To facilitate descriptive conciseness, we also define a column based integral map G + c which stores the column-wise accumulative sum of G, so that G + c (i, j) = ∑ i k=1 G(k, j). <ref type="figure">Figure 4</ref> shows samples of the two integral maps. G + c and G + can be calculated simutaneously using accumulative summation with an overall computational complexity of O(mn) <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem 1</head><p>A brute force algorithm for solving Problem 1 is to exhaustively examine every possible rectangle inside G so as to find the smallest rectangle satifying (1). More specifically, as is shown in <ref type="figure">Figure 5</ref> </p><formula xml:id="formula_5">R G = G + (i 2 , j 2 ) − G + (i 2 , j 1 − 1) −G + (i 1 − 1, j 2 ) + G + (i 1 − 1, j 1 − 1)<label>(4)</label></formula><p>Careful observation of <ref type="figure">Figure 5</ref>(a) reveals that many unnecessary calculations have been performed in the brute force algorithm. For example, if we have already found that R is valid, or in other words, it satisfies (1). Then any rectangle with area size larger than R should not be considered any more. A typical example is the larger dash lined rectangle containing R shown in <ref type="figure">Figure 5</ref>(a). Even more aggressively, all the rectangles with upper left corner (i 1 , j 1 ) and lower right corner (i 2 , j &gt; j 2 ) can be safely ignored.</p><formula xml:id="formula_6">∑ i2 i=i1 G(i, :) = G + c (i 2 , :) − G + c (i 1 − 1, :)<label>(5)</label></formula><p>Suppose we are examining all the candidate rectangles with their upper border at row i 1 and lower border at row i 2 , as is shown in <ref type="figure">Figure 6</ref>(a). We are actually looking for two column index j 1 and j 2 as close to each other as possible, while the shaded rectangle is valid. By accumulating row i 1 to row i 2 column-wisely, this two dimensional problem can be converted to a one dimension problem illustrated at the bottom of <ref type="figure">Figure 6(a)</ref>. Given a non-negative input array, we are to find the shortest subarray of which the sum of elements is larger than or equal to a given threshold. Specifically in our case, the threshold is τ ∑ G, and the input array is ∑ i2 i=i1 G(i, :) which can be calculated using the column-wise integral map with O(n) complexity using <ref type="bibr" target="#b4">(5)</ref>.</p><p>This Shortest Subarray problem can be efficiently solved using Algorithm 1, in which st and ed are two moving pointers pointing to the starting and ending positions of the current subarray. Whenever the sum of the current subarray is smaller than the threshold T , it is prolonged by moving ed one step forward (line 7). Otherwise, the current subarray is valid and will be used to update the shortest subarray when necessary (line 16), after which it will be shortened by moving st one step forward (line 18). The above two steps are repeated until the pointers reach the end of the input array.</p><p>The key idea of the algorithm is that whenever a valid subarray candidate is found, it will be shortened in the next step so that any longer subarray starting from st are automatically ignored to avoid redundant calculation. Specifically, j 1 = j 2 = 0 if the subarray is not found or T ≤ 0. Inside each loop, either st or ed will be increased by 1. Noticing that both st and ed will not exceed n on exit, the loop body will be executed for at most 2n times. Therefore, the overall computation complexity is O(n).</p><p>Combining Algorithm 1 and the idea illustrated </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Problem 2</head><p>Due to the restriction of the aspect ratio of the cropping rectangle, Problem 2 is intrinsically simpler than Problem 1. This can be observed from the illustration of the brute force algorithm shown in <ref type="figure">Figure 5</ref>(b). As stated before, given the Algorithm 1 shortestSubarray(â, T ) Input:â is a non-negative valued array with length n; T is threshold of the subarray sum. Output: Starting and ending index, j 1 and j 2 , of the shortest contiguous subarray ofâ which has a sum larger than T . τ is the percentage of total attention to be preserved; suppose integral maps G + and G + c are calculated. Output: The smallest valid cropping rectangleR; four values to defineR : i and j are the upper left corner coordinates, w and h are the width and height. end for 15: end for 16: return i, j, w, h height h of a rectangle with fixed aspect ratio r, its width will be uniquely decided by <ref type="bibr" target="#b2">(3)</ref>. Therefore in <ref type="figure">Figure 5</ref> The idea for improving the algorithm is illustrated in <ref type="figure">Figure 6(b)</ref>. With a fixed aspect ratio, all the candidate rectangles bounded by i 1 and i 2 are of the same size w 0 × h 0 , in Algorithm 3 maxSubarrayF L(â, w, T ) Input:â is a non-negative valued array with length n; w is length of the subarray; T is the threshold of the subarray sum. Output: Starting index j 1 of the contiguous subarray of fixed length w having the maximum sum ≥ T ; suppose the accumulative sum arrayâ + is calculated. end for 9: end if 10: return j 1 , S max which w 0 = i 2 −i 1 +1. Obviously, there are O(n) different such rectangles. We only need to find among these rectangles the one with the maximum summed attention value. Similar to the idea used in the last section, this problem can be converted to a one dimensional search problem which is to find a fixed length subarray with maximum sum. Specifically in our case, this maximum sum should be greater than or equal to the given threshold τ ∑ G. This is a naive problem which can be easily solved with O(n) complexity as is shown in Algorithm 3.</p><formula xml:id="formula_7">1: i ← 0, j ← 0, w ← ∞, h ← ∞ 2: S min ← −1, T ← τ G + (m, n) 3: for i 1 = 1 to m do 4: for i 2 = i 1 to m do 5:â ← G + c (i 2 , :) − G + c (i 1 − 1, :) 6: j 1 , j 2 , S 0 ← shortestSubarray(â, T ) 7: if j 1 &gt; 0 ∧ j 2 &gt; 0 then 8: w 0 ← j 2 − j 1 + 1, h 0 ← i 2 − i 1 + 1 9: if w 0 h 0 &lt; wh ∨ (w 0 h 0 = wh ∧ S 0 &gt; S min ) then 10: i ← i 1 , j ← j 1 , w ← w 0 , h ← h</formula><formula xml:id="formula_8">1: j 1 ← 0, S max ← −1 2: if T &gt; 0 ∧ w &gt; 0 then 3: for st = 1 to n − w + 1 do 4: S 0 ←â + (st + w − 1) −â + (st − 1) 5: if S 0 ≥ T ∧ S 0 &gt; S max</formula><p>Problem 2 can be solved by simply looping for all possible (i 1 , i 2 ) while invoking Algorithm 3. Unfortunately, such an approach is meaningless since it will lead to a computational complexity of O(m 2 n), which is identical to the brute force search. However, as stated above, in <ref type="figure">Figure 6</ref>(b), area size of the candidate rectangle is fully decided by the distance between i 1 and i 2 . As such, for a given i 1 value, if a valid rectangle has been found for a certain i 2 , then any position below i 2 , for example i ′ 2 in <ref type="figure">Figure 6</ref>(b), will no longer need to be considered because of the definitely increased rectangular area size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 4 F ixed AspRatio Rectangle(G, τ, r)</head><p>Input: G is a non-negative attention map with size m×n; τ is the percentage of total attention to be preserved; r is the aspect ratio of cropping rectangle; suppose integral maps G + and G + c are calculated. Output: The smallest rectangleR with aspect ratio r that satisfies <ref type="bibr" target="#b0">(1)</ref>; four values to defineR : i and j are the upper left corner coordinates, w and h are the width and height.</p><formula xml:id="formula_9">1: i ← 0, j ← 0, w ← ∞, h ← ∞ 2: i 1 ← 1, i 2 ← 1, T ← τ G + (m, n), S min ← −1 3: repeat 4: h 0 ← i 2 − i 1 + 1, w 0 ← ⌈h 0 × r⌉ 5:</formula><p>if w 0 &gt; n then <ref type="bibr">6:</ref> i 1 ← i 1 + 1 7:  Algorithm 4 is proposed based on this understanding. Two pointers i 1 and i 2 are pointing to the upper and lower boundaries of the candidate rectangle. Pointer i 2 is moved forward to enlarge the search area until the first valid rectangle is found (line 17). Then pointer i 1 is moved forward to reduce the search area until no valid rectangle can be found (line 15). The above two steps are performed alternatively until the two pointers reach the bottom of G. During the process,R keeps being updated accordingly .</p><formula xml:id="formula_10">else 8:â = G + c (i 2 , :) − G + c (i 1 − 1, :) 9: j 1 , S 0 ← maxSubarrayF L(â, w 0 , T ) 10: if j 1 &gt; 0 then 11: if w 0 h 0 &lt; wh ∨ (w 0 h 0 = wh ∧ S 0 &gt; S min ) then 12: i ← i 1 , j ← j 1 , w ← w 0 , h ← h</formula><formula xml:id="formula_11">end if 20: until i 2 &gt; m ∧ i 1 ≥ m 21: return i, j, w, h (a) v(i 1 , i 2 ) = 1 (b) v(i ′ 1 , i 2 ) = 0 (c) v(i ′ 1 , i ′ 2 ) = 1</formula><p>We use <ref type="figure" target="#fig_8">Figure 7</ref> to help proving the correctness of Algorithm 4. Let's define a bool function v(i 1 , i 2 ) to denote whether a valid rectangle bounded by row i 1 and row i 2 exists. Obviously, this function fulfills (6) due to the nonnegativity of G. Supposed at a certain stage of execution, we have v(i 1 , i 2 ) = 1 as is shown in <ref type="figure" target="#fig_8">Figure 7</ref>(a). According to the algorithm, i 1 is then moved to the very first position to let v(i ′ 1 , i 2 ) = 0 as is shown in <ref type="figure" target="#fig_8">Figure 7</ref></p><formula xml:id="formula_12">(b). No- tice that this also implies v(i ′ 1 − 1, i 2 ) = 1. Finally, i 2 is moved to the very first position to let v(i ′ 1 , i ′ 2 ) = 1, imply- ing v(i ′ 1 , i ′ 2 − 1) = 0. v(i, j) = 0 ⇒ ∀i * , j * ∈ [i, j], v(i * , j * ) = 0<label>(6)</label></formula><p>To ensure completeness, we ought to inspect all the cases</p><formula xml:id="formula_13">when i * 2 ∈ [i 2 , i ′ 2 ) and i * 1 ∈ [1, i * 2 ]. If i * 1 ∈ [1, i ′ 1 − 2]</formula><p>, any rectangle bounded by row i * 1 and row i * 2 can be safely ignored since it is definitely larger than the already considered valid rectangle bound by row i</p><formula xml:id="formula_14">′ 1 − 1 and row i 2 considering i * 2 −i * 1 ≥ i 2 −(i ′ 1 −2) &gt; i 2 −(i ′ 1 −1)</formula><p>. When i * 1 = i ′ 1 −1, the case of i * 2 = i 2 has already been considered and all the other cases where i * 2 &gt; i 2 can be similarly ignored due to the definitely increased rectangular area size. <ref type="bibr" target="#b5">(6)</ref>. The above reasoning is valid through out the execution of the whole algorithm.</p><formula xml:id="formula_15">If i * 1 ∈ [i ′ 1 , i * 2 ], since i * 1 , i * 2 ∈ [i ′ 1 , i ′ 2 − 1] and v(i ′ 1 , i ′ 2 − 1) = 0, we have v(i * 1 , i * 2 ) = 0 according to</formula><p>Algorithm 4 is of very low computation complexity. Inside each loop, either i 1 or i 2 will be increased by 1. Since both i 1 and i 2 will not exceed m on exit, the loop body will be executed for at most 2m times. Therefore the overall computational complexity is O(mn), which is actually the naive lower bound of the problem considering that there are altogether m × n elements in G and each element has to be considered for at least once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Problem 3</head><p>For Problem 3, we only consider the case when N = 2. Namely, to find at most two disjoint rectangles. Even though, the complexity is substantially increased considering the explosion of the solution space due to the combination of the positions and relative sizes of two rectangles. An even tougher problem is the distribution of total attention values among the two rectangles. In this work, we merely explore the feasibility of this problem by proposing a preliminary solution which is illustrated in <ref type="figure" target="#fig_9">Figure 8</ref>.</p><p>Two non-intersected rectangles can be spatially separated either vertical or horizontal. Without losing generality, suppose the two rectangles are vertically separable. Divided the attention map vertically to get G 1 and G 2 with n 1 columns and n 2 columns respectively, and n 1 + n 2 = n. Suppose h 1 is the height of the left sided rectangleR 1 inside G 1 . Then the width ofR 1 equals ⌈h 1 × r⌉. Let T 1 be the sum of attention values insideR 1 , maximize the value of T 1 by exhaustive search in G 1 . This is straightforward since the shape ofR 1 is fixed, and the complexity is obviously O(mn 1 ). Find in G 2 the smallest rectangleR 2 with summed attention value no less than τ ∑ G − T 1 using Algorithm 4 with computational complexity O(mn 2 ). Loop for all possible values of h 1 and n 1 to minimize ∥R 1 ∥ + ∥R 2 ∥. It is not difficult to see that the overall computational complexity is O(m 2 n 2 ). Similar method can be used for N &gt; 2 with even higher complexity. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Automatic selection of τ</head><p>According to our definition, τ is the percentage of attention to be preserved. Generally speaking, the value of τ can be selected empirically or according to user requirements. Due to the low complexity of the proposed algorithms, we may even allow users to change τ in real time. Nevertheless, it may still be interesting to investigate the possibility of selecting τ automatically. We only study this issue for Problem 1 considering thatR(τ ) always exist for ∀τ ∈ [0, 1] in Problem 1, leading to conciseness in analysis.</p><p>Considering the nature of image cropping, selection of τ relies heavily on the mathematical property of function ∥R(τ )∥. Obviously, ∥R(τ )∥ is a complicate function which varies a lot for different attention maps. Ideally, for a uniform attention map in which all pixels are equally important, we have ∥R(τ )∥ = τ . Also for a positive valued attention map, ∥R(0)∥ = 0 and ∥R(1)∥ = 1. In real life images, pixels with high attention values are often spatially concentrated, leading to the phenomenon that ∥R(τ )∥ usu- ally increases slowly for small τ and fast for large τ values as is shown in the third row of <ref type="figure" target="#fig_10">Figure 9</ref>. The function curve may vary significantly for different images. However, by plotting them in a logarithmic coordinate shown in the fourth row of <ref type="figure" target="#fig_10">Figure 9</ref>, strong linear correlation between log(∥R(τ )∥) and log(τ ) can be observed. To further validate this observation, we calculate the Pearson's correlation coefficients between log(∥R(τ )∥) and log(τ ) for 1000 randomly selected Microsoft COCO images <ref type="bibr" target="#b11">[12]</ref>. The mean and standard deviation of the correlation coefficients are 0.995 and 0.004 respectively, indicating a strong statistical validity of this assumption of logarithmic linearity.</p><formula xml:id="formula_16">τ * = argmax τ τ (1 − ∥R(τ )∥) = argmax τ (τ − τ 1+γ ) (7)</formula><p>We thus propose a simple power function model as ∥R(τ )∥ = τ γ , (γ ≥ 1), in which γ can actually be used to measure the degree of concentration of the intention map. Larger value of γ usually indicates higher degree of visual attention concentration as is shown in <ref type="figure" target="#fig_10">Figure 9</ref>(b). For a given image, γ can be estimated by linearly fitting log(∥R(τ )∥) to log(τ ). In practice, we choose 10 sampling points of τ for fitting. Based on this model, different objectives can be easily defined for selecting the optimum τ . As an example, we propose a simple objective function in <ref type="formula">(7)</ref> of which the rationale is to achieve a equilibrium between attention preserving and region cropping. Analytically solving (7) leads to τ * = (1 + γ) −1/γ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Although we focus on improving the computational efficiency of cropping rectangle search, it is of no doubt that the key to cropping effectiveness is still the reliability of the attention map. In all the visual results shown below, we use attention maps generated using two different methods. The yellow and red rectangles are calculated based on attention maps generated using <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b9">[10]</ref> respectively. All the images used in our experiments are selected from the Microsoft COCO database <ref type="bibr" target="#b11">[12]</ref>. <ref type="figure" target="#fig_11">Figure 10</ref> and <ref type="figure" target="#fig_12">Figure 11</ref> show results of minimum area cropping defined in Problem 1. <ref type="figure" target="#fig_11">Figure 10</ref> illustrates the influence of τ value. It can be observed that both the size and position of the cropping rectangle change with τ . <ref type="figure" target="#fig_12">Figure 11</ref> demonstrates the effectiveness of automatic τ selection. <ref type="figure" target="#fig_13">Figure 12</ref> presents the visual results of Problem 2 when the aspect ratio changes. Quite surprisingly, cropping rectangles with different aspect ratio all seem to be visually reasonable. <ref type="figure" target="#fig_14">Figure 13</ref> are the multiple rectangle cropping results. The attention model proposed in <ref type="bibr" target="#b9">[10]</ref> intentionally emphasizes the visual importance near the image center, leading unsatisfactory results shown by red rectangles in <ref type="figure" target="#fig_14">Figure 13</ref>.  We also compare the average running time of Algorithm 2 and Algorithm 4 to the corresponding brute force algorithms on 1000 randomly selected images. The experiment is performed on a desktop PC equipped with a 3.6GHz CPU and 16GB memory using Matlab implementations. The acceleration ratios are plot against τ in <ref type="figure" target="#fig_15">Figure 14</ref>. All the attention maps are generated using <ref type="bibr" target="#b7">[8]</ref> and m = 188, n = 250. The average running time for all τ values is 137.8ms for Algorithm 2 and 4.2ms for Algorithm 4.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We study the computational complexity of the optimum rectangle search in the attention based automatic image cropping. According to different application requirements as well as image properties, we propose three problem formulations, for which algorithms with low computational complexity are designed. We also propose a fully automated image cropping approach based on a new model describing the relationship between attention preserving and region cropping. Experimental results have demonstrated the effectiveness and efficiency of our proposals. There are still problems left to be studied in the future. For example, the relationship between visual satisfactory and the selection of τ value; and the possibility of fusing different attention maps. It is also interesting to extend this research to aesthetics oriented image cropping methods. This work was supported by the Tsinghua University Initiative Scientific Research Program (20131089382), the Beijing Higher Education Young Elite Teacher Project (YETP0104), and the National Natural Science Foundation of China (61101152).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Problem 1 v.s. Maximum Submatrix problem. Multiple rectangle cropping.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a), for each point (i, j) in G, the algorithm examines all the rectangles R with (i, j) as their upper left corner. The summed attention value inside R can be efficiently calculated using the integral map as is expressed by (4). For each upper left corner point, there are O(mn) rectangles to be examined. Looping through all possible upper left conner points leads to an overall all computational complexity of O(m 2 n 2 ).∑</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .(a) Problem 1 (b) Problem 2 Figure 5 .</head><label>4125</label><figDesc>(a) G (b) G + (c) G +c Integral map and column-wise integral map. Illustration of brute force algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>(a) Problem 1 (b) Problem 2 Figure 6 .</head><label>126</label><figDesc>Illustration of proposed algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Algorithm 2 is proposed for solving Problem 1. The basic idea it to loop for all possible (i 1 , i 2 ) while finding the corresponding shortest subarray. The most time consuming operations in this algorithm are at lines 5 and line 6. As we have already explained, both of these two operations are of O(n) complexity. They will be executed m 2 /2 times by looping for all possible (i 1 , i 2 ), leading to an overall computation complexity of O(m 2 n). Or more accurately, O(m 2 n + mn) considering the extra calculation of the two integral maps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>1: j 1 ← 0, j 2 ← 0 2: L min ← ∞, S min ← −1 3: st ← 1, ed ← 1, S 0 ←â(L &lt; L min ∨ (L = L min ∧ S 0 &gt; S min ) then 16: j 1 ← st, j 2 ← ed, L min ← L, S min ← S until st &gt; n 21: end if 22: return j 1 , j 2 , S min Algorithm 2 M ininum Rectangle(G, τ ) Input: G is a non-negative attention map with size m × n;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>(b), the number of possible rectangles with upper left corner (i 1 , j 1 ) becomes much smaller. It is actually decided by the number of different height values, which is basically O(m). By looping for all possible (i 1 , i 2 ), the overal computational complexity of the brute force algorithm is O(m 2 n).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>Illustration of Algorithm 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 .</head><label>8</label><figDesc>A solution to Problem 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 .</head><label>9</label><figDesc>Relationship between ∥R(τ )∥ and τ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 .</head><label>10</label><figDesc>Problem 1 : cropping results for different τ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 11 .</head><label>11</label><figDesc>Problem 1 : automatic τ selectionR(τ * )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 12 .</head><label>12</label><figDesc>Problem 2 : cropping results for different aspect ratio.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 13 .</head><label>13</label><figDesc>Problem 3 : multiple rectangle croppingR(0.5, 3/4, 2).The high acceleration ratio for large τ values are caused by the extremely low practical complexity of the proposed algorithms for large τ values. For example, when τ = 0.9, the average running time is 5.7ms for Algorithm 2 and 0.9ms for Algorithm 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 14 .</head><label>14</label><figDesc>Acceleration ratio of proposed algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc><ref type="bibr" target="#b6">[7]</ref> <ref type="bibr" target="#b13">[14]</ref> [19]<ref type="bibr" target="#b14">[15]</ref>, a common task after generating the attention map is to search for an optimum cropping rectangle. Usually, this optimum rectangle search process aims at achieving a tradeoff between minimizing the cropping area and maximizing the total pixel attention val-ues inside it. Considering the huge number of possible candidate rectangles, brute force search could be prohibitively slow. To solve this problem, Luo et al. adopted the integral image<ref type="bibr" target="#b22">[23]</ref> to speed up the global search [14]; Suh et al. used a greedy algorithm to incrementally including salient peak points outside the current rectangle [20]; Stentiford et al. reduced the search space by setting a series of fixed sizes for the rectangles [19]; Ciocca et al. binarized the attention map and considered only the connectivity of pixels [7]; Ma et al. introduced human interaction to facilitate the searching process</figDesc><table></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Seam carving for content-aware image resizing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="10" to="11" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Programming Pearls</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bentley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Addison Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A framework for photo-quality assessment and enhancement based on visual aesthetics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="271" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Distinction, A Social Critique of the Judgement of Taste</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bourdieu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>Harvard University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A visual attention model for adapting images on small displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="353" to="346" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to photograph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="291" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Self adaptive image cropping for small displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ciocca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cusano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gasparini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schettini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Consumer Electronics</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1622" to="1627" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Context-aware saliency detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goferman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelinik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1915" to="1926" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A model of saliency based visual attension of rapid scene analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1254" to="1259" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning to predict where humans look</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Judd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ehinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The design of high-level features for photo quality assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="419" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2106" to="2113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to detect a salient object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Subject content-based intelligent cropping of digital photos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICME</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="2218" to="2221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic image cropping for mobile devices with built-in camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Consumer Communication and Networking</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="710" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A framework for visual salicency detection with applications to image thumbnailing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marchesotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cifarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2232" to="2239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sensation based photo cropping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mishiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Okabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="669" to="672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gaze-based interaction for semi-automatic photo cropping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Decarlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Salesin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCHI</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="771" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Attention based auto image cropping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Stentiford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICVS</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic thumbnail cropping and its effectiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Symp. UIST</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="95" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficient algorithms for the maximum subarray problem by distance matrix multiplication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Takaoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronic Notes in Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="191" to="200" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Content-based photo quality assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Multimedia</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1930" to="1943" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Robust real-time face detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning the change for automatic image cropping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Top-down visual saliency via joint crf and dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Probabilistic graphlet transfer for photo cropping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="802" to="815" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Auto cropping for digital photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICME</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
