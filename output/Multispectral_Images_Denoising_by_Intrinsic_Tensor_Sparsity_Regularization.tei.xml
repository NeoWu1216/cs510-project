<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multispectral Images Denoising by Intrinsic Tensor Sparsity Regularization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Xie</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
							<email>shuhanggu@gmail.comwmzuo@hit.edu.cncslzhang@comp.polyu.edu.hk</email>
							<affiliation key="aff1">
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Multispectral Images Denoising by Intrinsic Tensor Sparsity Regularization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multispectral images (MSI) can help deliver more faithful representation for real scenes than the traditional image system, and enhance the performance of many computer vision tasks. In real cases, however, an MSI is always corrupted by various noises. In this paper, we propose a new tensor-based denoising approach by fully considering two intrinsic characteristics underlying an MSI, i.e., the global correlation along spectrum (GCS) and nonlocal self-similarity across space (NSS). In specific, we construct a new tensor sparsity measure, called intrinsic tensor sparsity (ITS) measure, which encodes both sparsity insights delivered by the most typical Tucker and CANDE-COMP/PARAFAC (CP) low-rank decomposition for a general tensor. Then we build a new MSI denoising model by applying the proposed ITS measure on tensors formed by non-local similar patches within the MSI. The intrinsic GC-S and NSS knowledge can then be efficiently explored under the regularization of this tensor sparsity measure to finely rectify the recovery of a MSI from its corruption. A series of experiments on simulated and real MSI denoising problems show that our method outperforms all state-of-the-arts under comprehensive quantitative performance measures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>A multispectral image (MSI) consists of multiple images of a real scene captured by sensors over various discrete bands. As compared with traditional image collecting systems which integrate the product of the intensity at only a few typical band intervals, MSI facilitates a fine delivery of more faithful knowledge under real scenes. Such full knowledge representation capability of MSI has been substantiated to greatly enhance the performance of various computer vision tasks, such as superresolution <ref type="bibr" target="#b12">[13]</ref>, inpainting <ref type="bibr" target="#b6">[7]</ref>, and tracking <ref type="bibr" target="#b21">[22]</ref>.</p><p>In real cases, however, due to the acquisition errors conducted by sensor, an MSI generally contains certain extent of noises, which inclines to negatively influence the subse- quent MSI processing tasks. Therefore, MSI denoising has become a critical and inevitable issue for MSI analysis.</p><p>The most significant issue of recovering a clean MSI from its corruption is to rationally extract prior structure knowledge under a to-be-reconstructed MSI, and fully utilize such prior information to rectify the configuration of the recovered MSI in a sound manner. The most commonly utilized prior structures for MSI recovery include its global correlation along spectrum (GCS) and nonlocal selfsimilarity across space (NSS). Specifically, the GCS prior indicates that an MSI contains a large amount of spectral redundancy and the images obtained across the spectrum of an MSI are generally highly correlated. And the NSS prior refers to the fact that for a given local fullband patch (FBP) of an MSI (which is stacked by patches at the same location of MSI over all bands), there are many FBPs similar to it. It has been extensively shown that such two kinds of prior knowledge are very helpful for various MSI recovery problems <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>Albeit demonstrated to be effective to certain MSI denoising cases, most of the current methods to this task only consider one such prior knowledge in their model, like BM3D <ref type="bibr" target="#b7">[8]</ref> only considering the NSS and PARAFAC <ref type="bibr" target="#b15">[16]</ref>) only considering the GCS. Their potential capacity thus still has room to be further enhanced. The TDL <ref type="bibr" target="#b22">[23]</ref> method was recently proposed by taking both priors into account and achieved the state-of-the-art MSI denoising performance. The method, however, coarsely encodes the NSS prior under relatively small amount of FBP clusters while does not fully consider the entire NSS knowledge across all FBPs. Besides, its realization is relatively heuristic and short of a concise formulation to abstract such latent priors underlying an MSI, which makes the methodology hard to be extended to other MSI recovery problems.</p><p>To alleviate this problem, this paper proposes a new MSI denoising technique which not only fully takes both GCS and NSS knowledge into account, but also is with a concise formulation to regularize such priors which can be easily transferred to general MSI restoration problems. Specifically, we regard each FBP as a matrix with a spatial mode and a spectral mode, and build a 3-order tensor by stacking all its non-local similar FBPs (see the upper part of <ref type="figure" target="#fig_0">Fig. 1</ref>). Such a tensor naturally forms a faithful representation to deliver both the latent GCS and NSS knowledge underlying the MSI. Since GCS and NSS imply the correlation along the spectral and FBP-number modes of this tensor, respectively, the key problem is then transferred to how to construct a rational sparsity measure to reflect such correlation and use it to regularize the MSI recovery from corrupted one.</p><p>To handle the aforementioned issues, this paper makes the following three-fold contributions. Firstly, a new measure for tensor sparsity is proposed. Beyond traditional tensor sparsity measures without an evident physical meaning, this new measure can be easily interpreted as a regularization for the number of rank-1 Kronecker bases for representing this tensor. Such measure not only unifies the traditional understanding of sparsity from vector (1-order tensor) to matrix (2-order tensor), but also encodes both sparsity insights delivered by the most typical Tucker and CP low-rank decomposition for a general tensor. We thus call it intrinsic tensor sparsity (ITS) for convenience.</p><p>Secondly, we propose a new tensor-based denoising model by performing tensor recovery with the proposed ITS measure to encode the inherent spatial and spectral correlation of the nonlocal similar FBP groups. The model is with a concise formulation and can be easily extended to solving other MSI recovery problems.</p><p>Thirdly, we design an effective alternating direction method of multipliers (ADMM) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15]</ref> based algorithm for solving the model, and deduce the closed-form equations for updating each involved parameter, which makes it able to be efficiently implemented. Experiments on benchmark and real MSI data show that the proposed method achieves the state-of-the-art performance on MSI denoising among various quality assessments.</p><p>Throughout the paper, we denote scalar, vector, matrix and tensor as non-bold lower case, bold lower case, upper case and calligraphic upper case letters, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Notions and preliminaries</head><p>A tensor, shown as a multi-dimensional data array, is a multilineal mapping over a set of vector spaces. A ten-sor of order N is denoted as A ∈ R I1×I2×···I N . Elements of A are denoted as a i1···in···i N where 1 ≤ i n ≤ I n . The mode-n vectors of an N -order tensor A are the I n dimensional vectors obtained from A by varying index i n while keeping the others fixed. The unfolding matrix A (n) = unfold n (A) ∈ R In×(I1···In−1,In+1···I N ) is composed by taking the mode-n vectors of A as its columns. This matrix can also be naturally seen as the mode-n flattening of the tensor A. Conversely, the unfolding matrices along the n th mode can be transformed back to the tensor by A = fold n A (n) , 1 ≤ n ≤ N . The n-rank A, denoted as r n , is the dimension of the vector space spanned by the mode-n vectors of A.</p><p>The product between matrices can be generalized to the product of a tensor and a matrix. The mode-n product of a tensor A ∈ R I1×I2×···In by a matrix B ∈ R Jn×In , denoted by A × n B, is an N -order tensor C ∈ R I1×···×Jn×···I N , whose entries are computed by</p><formula xml:id="formula_0">c i1×···in−1×jn×in+1...i N = in a i1···in···i N b jnin .</formula><p>The mode-n product C = A × n B can also be calculated by the matrix multiplication C (n) = BA (n) , followed by the re-tensorization of undoing the mode-n flattening. The Frobenius norm of an tensor A is</p><formula xml:id="formula_1">A F = i1,···in |a i1,···i N | 2 1/2 .</formula><p>We call a tensor A ∈ R I1×I2×...I N is rank-1 if it can be written as the outer product of N vectors, i.e.,</p><formula xml:id="formula_2">A = a (1) • a (2) • · · · • a (N ) ,</formula><p>where • represents the vector outer product. This means that each element of the tensor is the product of the corresponding vector elements:</p><formula xml:id="formula_3">a i1,i2,··· ,i N = a (1) i1 a (2) i2 ...a (N ) i N ∀ 1 ≤ i n ≤ I n . (1)</formula><p>such a simple rank-1 tensor is also called a Kronecker basis in the tensor space. For example, in a 2D case, a Kronecker basis is a rank-1 matrix expressed as the outer product uv T of two vectors u and v.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related work</head><p>Approaches for MSI denoising can be generally grouped into two categories: the 2D extended approach and the tensor-based approach.</p><p>2D extended approach. As a classical problem in computer vision, 2D image denoising has been studied for more than 50 years and a large amount of methods have been proposed on this problem, such as NLM <ref type="bibr" target="#b2">[3]</ref>, K-SVD <ref type="bibr" target="#b9">[10]</ref> and BM3D <ref type="bibr" target="#b7">[8]</ref>. These methods can be directly applied to MSI denoising by treating the images located at different bands separately. This extension, however, neglects the intrinsic properties of MSIs and generally cannot attain good perfor-mance in real applications. Another more reasonable extension is specifically designed for the patch-based image denoising methods, which takes the small local patches of the image into consideration. By building small 3D cubes of an MSI instead of 2D patches of a traditional image, the corresponding 3D-cube-based MSI denoising algorithm can then be constructed <ref type="bibr" target="#b23">[24]</ref>. The state-of-the-art of 3Dcube-based approach is represented by the BM4D method <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>, which exploits the 3D NSS of MSI to remove noise in similar MSI 3D cubes collaboratively. The deficiency of these methods is that they neglect the useful GCS knowledge underlying an MSI, and still have not essentially reached the full potential for handling this task.</p><p>Tensor-based approach. An MSI is composed by a stack of 2D images, which can be naturally regarded as a 3-order tensor. The tensor-based approach implements the MSI denoising by applying the tensor factorization techniques to the MSI tensor. Along this research line, Renard et al. <ref type="bibr" target="#b20">[21]</ref> presented a low-rank tensor approximation (LR-TA) method by employing the Tucker decomposition <ref type="bibr" target="#b26">[27]</ref> to obtain the low-rank approximation of the input MSI. Liu et al. <ref type="bibr" target="#b15">[16]</ref> designed the PARAFAC method by utilizing the parallel factor analysis <ref type="bibr" target="#b5">[6]</ref>. The advantage of both methods is that they take the correlation between MSI images over different bands into consideration, and try to eliminate the spectral redundancy of MSIs. However, they have not utilized the NSS prior of MSI. The state-of-the-art method of this category is represented by tensor dictionary learning (TDL) <ref type="bibr" target="#b22">[23]</ref> which takes both GCS and NSS under MSI into account. This method, however, only consider NSS among several FBP clusters while not fully utilize the fine-grained NSS structures across all FBPs over the tensor space. There is thus still much room for further improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">MSI denoising by intrinsic tensor sparsity regularization 4.1. GCS and NSS modeling for MSI denoising</head><p>We first briefly introduce a general NSS-based framework for image denoising, which has been adopted by multiple literatures in image cases <ref type="bibr" target="#b11">[12]</ref>, aiming to reconstruct the original image Z from its noisy observation</p><formula xml:id="formula_4">Y . Separat- ing Y into a set of image patches Ω = {y i ∈ R d } N i=1</formula><p>(where d is the pixel number of each patch) with overlap, and by performing block matching <ref type="bibr" target="#b7">[8]</ref>, a set of patches which is most similar to each patch y i can be extracted. By stacking all these patches to form a matrix Y i ∈ R d×n , where n is the number of these nonlocal similar patches, we can then recover the corresponding original nonlocal-similar-patchmatrix X i through</p><formula xml:id="formula_5">X i = arg min X S(X) + γ 2 Y i − X 2 F ,<label>(2)</label></formula><p>where S(X) denotes the 2-order sparsity measure on the true matrix X and γ is the compromise parameter. The matrix rank is generally recognized as a rational sparsity measure for matrix <ref type="bibr" target="#b30">[31]</ref>, and it as well as its relaxations can thus be readily adopted into the model for implementation. When all X i s are obtained, the recovered image Z can then be estimated by aggregating X i at each pixels.</p><p>The similar denoising model can be easily extended to MSI cases. Denote d H , d W and d S as the spatial height, spatial width and spectral band number of an MSI, and we can express it as a 3-order tensor Y ∈ R d H ×d W ×d S with two spatial modes and one spectral mode. By sweeping all across the MSI with overlaps, we can build a group of 2D FBPs</p><formula xml:id="formula_6">{P ij } 1≤i≤d H −d h ,1≤j≤d W −dw ⊂ R d h dw×d S (d h &lt; d H , d w &lt; d W )</formula><p>to represent the MSI, where each band of a FBP is ordered lexicographically as a column vector. We can now reformulate all FBPs as a group of 2D patches</p><formula xml:id="formula_7">Ω Y = {Y i ∈ R d h dw×d S } N i=1 , where N = (d H − d h + 1) × (d W − d w + 1)</formula><p>is the number of patches over the whole MSI. According to the NSS of MSI, for a given local FBP Y i , we can find a collection of FBPs similar to it from Ω Y in a non-local neighboring area of it. Denote Y i ∈ R d h dw×d S ×dn (where d n is the number of nonlocal similar FBPs of Y i ) as the 3-order tensor stacked by Y i and its non-local similar FBPs in Ω Y , and then both GC-S and NSS knowledge are well preserved and reflected by such representation, along its spectral and nonlocal-similarpatch-number modes, respectively.</p><p>Then, similar to the image cases, we can estimate the corresponding true nonlocal similarity FBPs X i from its corruption Y i by solving the following optimization problem:</p><formula xml:id="formula_8">X i = arg min X S(X ) + γ 2 Y i − X 2 F ,<label>(3)</label></formula><p>where S(X ) is the sparsity measure imposed on X . By aggregating all reconstructed X i s we can reconstruct the estimated MSI. The whole denoising progress can be easily understood by seeing <ref type="figure" target="#fig_0">Fig. 1</ref>. Obviously, the key issue now is to design an appropriate tensor sparsity measure on X .</p><p>Different from the vector/matrix cases, where the sparsity measure can be easily constructed as nonzero-elementnumber/matrix-rank based on very direct intuitions, constructing a rational tensor sparsity is a relatively more difficult task. Most of the current work directly extended the 2order sparsity measure to higher-order cases by easily ameliorating it as the weighted sum of ranks (or its relaxations) along all tensor modes <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b4">5]</ref>, i.e.,</p><formula xml:id="formula_9">S(X ) = d i=1 w i rank(X (i) ).<label>(4)</label></formula><p>Such formulation, however, on one hand is short of a clear physical meaning for general tensors, and on the other hand lacks a consistent relationship with previous defined sparsity measures for vector/matrix. To ameliorate this issue,  we attempt to propose a new measure for more rationally assessing tensor sparsity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Intrinsic tensor sparsity measure</head><p>We first briefly review two particular forms of tensor decomposition, both containing insightful understanding of tensor sparsity: Tucker decomposition <ref type="bibr" target="#b26">[27]</ref> and CP decomposition <ref type="bibr" target="#b13">[14]</ref>.</p><p>In Tucker decomposition, an N -order tensor X ∈ R I1×I2×...×I N is written as the following form:</p><formula xml:id="formula_10">X = S × 1 U 1 × 2 U 2 × 3 ... × N U N ,<label>(5)</label></formula><p>where S ∈ R r1×r2×3...× N r N is called the core tensor, and</p><formula xml:id="formula_11">U i ∈ R Ii×ri (1 ≤ i ≤ N )</formula><p>is composed by the r i orthogonal bases along the i th mode of X . Tucker decomposition considers the low-rank property of the vector subspace unfolded along each of its modes. Such a sparsity understanding naturally conducts a block shape for the coefficients affiliated from all combinations of tensor subspace bases, represented by the core tensor term. It, however, has not considered the fine-grained sparsity configurations inside this coefficient tensor. Specifically, if we assume that the subspace bases along each mode have been sorted based on their importance for tensor representation, then the value of elements of the core tensor will show an approximate descending order along each of tensor modes. Along some modes, the corresponding tensor factor might have strong correlations across data, and then the coefficients in the core tensor along this mode tends to be decreasing very fast to zeroes. While for those modes with comparatively weaker correlation, albeit still approximately decreasing along the mode, the core tensor elements might be all non-zeroes. <ref type="figure" target="#fig_2">Fig. 2</ref> depicts a visualization for facilitating the understanding of the above analysis. Tucker decomposition cannot well describe such an elaborate information, and thus is still hard to conduct a rational measure for comprehensively delivering the sparsity knowledge underlying a tensor.</p><p>CP decomposition attempts to decompose an N -order tensor X ∈ R I1×I2×...×I N into the linear combination of a series of Kroneker bases, written as:</p><formula xml:id="formula_12">X = r i=1 c i V i = r i=1 c i v i1 • v i2 • ... • v i N ,<label>(6)</label></formula><p>where c i denotes the coefficient imposed on the Kroneker basis V i . By arranging each Kroneker coefficients c i into its corresponding i 1 , i 2 , · · · , i N position of a core tensor, CP decomposition can be equivalently formulated as a Tucker decomposition form. Yet the core tensor will always be highly sparse since generally only a small amount of affiliated combinations of tensor bases are involved. Opposite to Tucker cases, such a tensor reformulation, however, ignores the low-rank property of the tensor subspaces along its modes. An extreme example is that when the core tensor obtained from a CP transformation on a tensor is approximately diagonal, the subspace along each tensor mode induced from this decomposition will not be low-rank, although the core tensor is very sparse. This deviates most real scenarios that the data representation along a meaningful factor should always has an evident correlation and thus a low-rank structure. Such a useful knowledge, however, cannot be well expressed by CP decomposition. By integrating rational sparsity understanding elements from both decomposition forms, we attempt to construct the following quantity, which we call intrinsic tensor sparsity (ITS) for convenience, for measuring the sparsity of a tensor X :</p><formula xml:id="formula_13">S(X ) = t S 0 + (1 − t) N i=1 rank X (i) ,<label>(7)</label></formula><p>where S is the core tensor of X obtained from the Tucker decomposition, 0 &lt; t &lt; 1 is a tradeoff parameter to compromising the role of two terms.</p><p>Note that the new ITS measure takes both sparsity insights of Tucker and CP decompositions into consideration. Its first term constrains the number of Kronecker bases for representing the objective tensor, complying with intrinsic mechanism of the CP decomposition. The second term is physically interpreted as the size of the core tensor in Tucker decomposition. It inclines to regularize the low-rank property of the subspace spanned upon each tensor mode. Such integrative consideration in the new measure facilitates a tensor with both inner sparsity configurations in the core tensor and low-rank property of the tensor subspace along each tensor mode, and thus is hopeful to alleviate the limitations in both Tucker and CP decompositions as aforementioned.</p><p>It should be noted that very recently, Zhao et al. <ref type="bibr" target="#b33">[34]</ref> also proposed a tensor sparsity measure by only considering the second (rank-product) term of (7). Such a measure can only provide a coarse regularization for rectifying the tensor sparsity (i.e., the block size of the core tensor) while cannot finely rectify the fine-grained tensor sparsity inside the coefficient tensor. The neglection of the important CP sparsity element tends to evidently degenerate its MSI denoising performance, as verified by our experiments.</p><p>Apart from the above insight of the proposed ITS measure, its superiority also lies on the following two aspects as compared with the conventional tensor sparsity measures.</p><p>On one hand, it has a natural physical interpretation. As shown in <ref type="figure" target="#fig_2">Fig. 2</ref>, when the rank of a d-order tensor along its i th mode is r i , the second term of the proposed tensor sparsity (7) not only corresponds to the low-rank sparsity of the subspace spanned upon each tensor mode, but also corresponds to a upper bound of the number of Kronecker bases for representing this tensor, and the first term further more accurately describes the intrinsic Kronecker basis number utilized for this tensor representation. This means that the new tensor sparsity quantity represents a reasonable proxy for measuring the capacity of tensor space, in which the entire tensor located, by taking Kronecker basis as the fundamental representation component.</p><p>On the other hand, it unifies the sparsity measures throughout vector to matrix. The sparsity of a vector is conventionally measured by the number of the bases (from a predefined codebook/dictionary) that can represent the vector as the linear combination of them. Since in vector case, a Kronecker basis is just a common vector, this measurement is just the number of Kronecker bases required to represent the vector, which fully complies with our proposed sparsity measure and its physical meaning. The sparsity of a matrix is conventionally assessed by its rank. Actually there are the following results: (1) if the ranks of a matrix along its two dimensions are r 1 and r 2 , respectively, then r 1 = r 2 = r, implying the second term in <ref type="formula" target="#formula_13">(7)</ref> is r 2 ; (2) if the matrix is with rank r, then it can be represented as r Kronecker bases (each with form uv T ), implying the first term in <ref type="formula" target="#formula_13">(7)</ref> is r. This means that the ITS measure is also proportional to the conventional one in matrix cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Relaxation</head><p>Note that the l 0 and rank terms in <ref type="formula" target="#formula_13">(7)</ref> can only take discrete values, and lead to combinatorial optimization problem in applications which is hard to solve. We thus relax the ITS as a log-sum form to ease computation. Such relaxation has been substantiated as an effective strategy to solve l 0 <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b25">26]</ref> or rank minimization <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b11">12]</ref> problems.</p><p>Instead of solving (3), our aim is then changed to solving the following optimization problem:</p><formula xml:id="formula_14">min X P ls (S) + λ 3 j=1 P * ls X (j) + β 2 Y i − X F ,<label>(8)</label></formula><p>where λ = 1−t t ,β = γ t , and</p><formula xml:id="formula_15">P ls (A) = i 1 ,i 2 ,i 3 log(|ai 1 ,i 2 ,i 3 | + ε), P * ls (A) = j log (σj(A) + ε),</formula><p>which are the log-sum forms of the vector and matrix sparsities, respectively. ε is a small positive number, and σ j (A) defines the j th singular of A ∈ R m×n . An efficient algorithm is then proposed in the following section to solve the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">ADMM algorithm</head><p>We apply the alternating direction method of multipliers (ADMM) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15]</ref>, an effective strategy for solving large scale optimization problems, to solving <ref type="bibr" target="#b7">(8)</ref>. Firstly, we need to introduce 3 auxiliary tensors M j (j = 1, 2, 3) and equivalently reformulate (8) as follows:</p><formula xml:id="formula_16">min S,M j ,U j P ls (S)+λ 3 j=1 P * ls M j(j) + β 2 Yi−S ×1 U1 ×2 U2 ×3 U3 2 F s.t. S ×1 U1 ×2 U2 ×3 U3 −Mj = 0, U T j Uj = I, j = 1, 2, 3,</formula><p>where M j(j) = unfold j (M j ). Then its augmented Lagrangian function is with the form:</p><formula xml:id="formula_17">Lµ(S, M 1 ,M 2 , M 3 , U 1 , U 2 , U 3 ) = P ls (S) + λ 3 j=1 P * ls M j(j) + β 2 Y i − S × 1 U 1 × 2 U 2 × 3 U 3 2 F + 3 j=1 S × 1 U 1 × 2 U 2 × 3 U 3 − M j , P j + 3 j=1 µ 2 S × 1 U 1 × 2 U 2 × 3 U 3 − M j 2 F ,</formula><p>where P j s are the Lagrange multipliers, µ is a positive scalar and U j must satisfy U T j U j = I, ∀j = 1, 2, 3. Now we can solve the problem within the ADMM framework.</p><p>With other parameters fixed, S can be updated by solving min S L µ (S, M 1 , M 2 , M 3 , U 1 , U 2 , U 3 ), which is equivalent to the following sub-problem:</p><formula xml:id="formula_18">min S bP ls (S) + 1 2 S × 1 U 1 × 2 U 2 × 3 U 3 − O 2 F , (9) where b = 1 β+3µ and O = βYi+ j (µMj −Pj ) β+3µ . Since D × V 2 F = D 2 F , ∀ V T V = I,<label>(10)</label></formula><p>by mode-j producting U T j on each mode, Eq. (9) turns to the following problem:</p><formula xml:id="formula_19">min S bP ls (S) + 1 2 S − Q 2 F ,<label>(11)</label></formula><formula xml:id="formula_20">where Q = O × 1 U T 1 × 2 U T 2 × 3 U T 3</formula><p>, which has been proved to have a closed-form solution <ref type="bibr" target="#b10">[11]</ref>:</p><formula xml:id="formula_21">S + = D b,ε (Q).<label>(12)</label></formula><p>Here, D b,ε (·) is the thresholding operator defined as:</p><formula xml:id="formula_22">D b,ε (x) = 0 if c 2 ≤ 0 sign(x) c1+ √ c2 2 if c 2 &gt; 0<label>(13)</label></formula><p>with that c 1 = |x| − ε, c 2 = (c 1 ) 2 − 4(b − ε|x|).</p><p>When updating U j (1 ≤ j ≤ 3) with other parameters fixed, we can also deduce its closed-form solution. Let's take U 1 as an example. With U 2 , U 3 and other parameters fixed, we update U 1 by solving min U1 L µ (S, M 1 , M 2 , M 3 , U 1 , U 2 , U 3 ), which is equivalent to the following problem:</p><formula xml:id="formula_23">min U1 S × 1 U 1 × 2 U 2 × 3 U 3 − O 2 F .<label>(14)</label></formula><p>By employing (10) and the following equation</p><formula xml:id="formula_24">B = D × n V ⇐⇒ B (n) = V D (n) ,<label>(15)</label></formula><p>we can obtain that <ref type="formula" target="#formula_9">(14)</ref> is equivalent to</p><formula xml:id="formula_25">max U T 1 U1=I A 1 , U 1 ,<label>(16)</label></formula><p>where</p><formula xml:id="formula_26">A 1 = O (1) unfold 1 (S × 2 U 2 × 3 U 3 )</formula><p>. It can be easily seen that U 2 and U 3 can be updated by solving</p><formula xml:id="formula_27">max U T k U k =I A k , U k .<label>(17)</label></formula><p>We can use the following theorem to obtain the closed-from solution of (17). Theorem 1. ∀ A ∈ R m×n , the following problem:</p><formula xml:id="formula_28">max U T U =I A, U ,<label>(18)</label></formula><formula xml:id="formula_29">has the closed-form solutionÛ = BC T , where A = BDC T is the SVD decomposition of A.</formula><p>The proof of Theorem 1 can be found in supplementary material. We can now update U k by the following formula:</p><formula xml:id="formula_30">U + k = B k C k T .<label>(19)</label></formula><p>where A k = B k DC T k is the SVD decomposition of A k . With M j (j = k) and other parameters fixed, M k can be updated by solving the following problem:</p><formula xml:id="formula_31">min M k a k P * ls M k(k) + 1 2 L + 1 µ P k − M k 2 F ,<label>(20)</label></formula><p>where a k = λ µ j =k P * ls M j(j) and L = S × 1 U 1 × 2 U 2 × 3 U 3 . This sub-problem can be easily solved by virtue of the following theorem:</p><formula xml:id="formula_32">Theorem 2. Given Y ∈ R m×n , m ≥ n, let Y = U diag(σ 1 , σ 2 , ..., σ n )V T be the SVD of Y . Let 0 &lt; λ, 0 &lt; ε &lt; min √ λ, λ σ1</formula><p>, and define d i as the i-th singular value of X, the solution to the following problem:</p><formula xml:id="formula_33">min X∈R m×n λ n i=1 log(d i + ε) + 1 2 X − Y 2 F<label>(21)</label></formula><p>can be expressed asX = U diag(d 1 ,d 2 , ...,d n )V T , wherê d i = D λ,ε (σ i ), i = 1, 2, ..., n.</p><p>The proof of Theorem 2 can be found in the supplementary material. We can now update M k by following equation:</p><formula xml:id="formula_34">M + k = fold k V 1 Σ a k V T 2 ,<label>(22)</label></formula><p>where Σ a k = diag (D a k ,ε (σ 1 ), D a k ,ε (σ 2 ), · · ·, D a k ,ε (σ n )) and V 1 diag(σ 1 , σ 2 , ..., σ n )V T 2 is the SVD of unfold k L+ 1 µ P k . The proposed algorithm for MSI denoising can be summarized in Algorithm 1, and we denote the proposed method as ITSReg (Intrinsic Tensor Sparsity Regularization) for convenience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Algorithm for MSI Denoising</head><formula xml:id="formula_35">Input: Noisy MSI Y 1: Initialize X (0) = Y 2: for l = 1 : L do 3: Calculate Y (l) = X (l−1) + δ Y − X (l−1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Construct the entire FBP set Ω Y (l)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Construct the set of similar FBP group set {Yi} K i=1 6:</p><p>for each FBP groups Yi do 7:</p><p>//Solve the problem (8) by ADMM <ref type="bibr">8:</ref> while not convergence do Update S by <ref type="formula" target="#formula_5">(12)</ref> 10:</p><p>Update U k by <ref type="bibr" target="#b18">(19)</ref>, ∀k = 1, 2, 3 <ref type="bibr">11:</ref> Update M k by <ref type="formula" target="#formula_5">(22)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental results</head><p>To validate the effectiveness of the proposed method for MSI denoising, we perform both simulated and real data experiments and compare the experimental results both quantitatively and visually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Simulated MSI denoising</head><p>Columbia Datasets. The Columbia MSI Database <ref type="bibr" target="#b31">[32]</ref> 1 is utilized in our simulated experiment. This MSI data set contains 32 real-world scenes of a wide variety of realworld materials and objects, each with spatial resolution 512 × 512 and spectral resolution 31, which includes full spectral resolution reflectance data collected from 400nm to 700nm in 10nm steps. In our experiments, each of these MSIs is scaled into the interval [0, 1].</p><p>Implementation details. Additive Gaussian noises with variance v are added to these testing MSIs to generate the noisy observations with v ranging from 0.1 to 0.3. There are two parameters λ and β in our model. The former λ is used to balance two parts in the same order of magnitude, and we just simply set λ = 10 in all our experiments, β is dependent on v, and we let β = cv, where c is set as the constant 10 −3 . More clarifications on such parameter settings are provided in the supplementary material.   Comparison methods. The comparison methods include: band-wise K-SVD [1] 2 and band-wise BM3D <ref type="bibr" target="#b7">[8]</ref>  <ref type="bibr" target="#b2">3</ref> , representing state-of-the-arts for the 2D extended bandwise approach; 3D-cube K-SVD [10] 4 , ANLM3D <ref type="bibr" target="#b19">[20]</ref>  <ref type="bibr" target="#b4">5</ref> and BM4D <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>  <ref type="bibr" target="#b5">6</ref> , representing state-of-the-arts for the 2D extended 3D-cube-based approach; LRTA <ref type="bibr" target="#b20">[21]</ref>, PARAFAC <ref type="bibr" target="#b15">[16]</ref>  <ref type="bibr" target="#b6">7</ref> and TDL <ref type="bibr" target="#b22">[23]</ref> 8 representing state-of-thearts for the tensor-based approach. All parameters involved in the competing algorithms were optimally assigned or automatically chosen as described in the reference papers.</p><p>Evaluation measures. Four quantitative picture quality indices (PQI) are employed for performance evaluation, including peak signal-to-noise ratio (PSNR), structure similarity (SSIM <ref type="bibr" target="#b29">[30]</ref>), feature similarity (FSIM <ref type="bibr" target="#b32">[33]</ref>), erreur relative globale adimensionnelle de synthèse (ERGAS <ref type="bibr" target="#b27">[28]</ref>). PSNR and SSIM are two conventional PQIs in image processing and computer vision. They evaluate the similarity between the target image and the reference image based on MSE and structural consistency, respectively. FSIM emphasizes the perceptual consistency with the reference image. The larger these three measures are, the closer the target MSI is to the reference one. ERGAS measures fidelity of the restored image based on the weighted sum of MSE in each band. Different from the former three measures, the smaller ERGAS is, the better does the target MSI estimate the reference one.</p><p>Performance evaluation. For each noise setting, all of the four PQI values for each competing MSI denoising methods on all 32 scenes have been calculated and recorded. <ref type="table" target="#tab_1">Table 1</ref> lists the average performance (over different scenes and noise settings) of all methods. From these quantitative comparison, the advantage of the proposed method can be evidently observed. Specifically, our method can significantly outperform other competing methods with respective to all evaluation measures, e.g., the PSNR obtained by our  method are more than 1.5 larger and ERGAS is around 10 smaller than the second best methods. More details are listed in our supplementary material.</p><p>To further depict the denoising performance of our method, we show in <ref type="figure" target="#fig_5">Fig. 3</ref> two bands in chart and stuffed toy that centered at 400nm (the darker one) and 700nm (the brighter one), respectively. From the figure, it is easy to observe that the proposed method evidently performs better than other competing ones, both in the recovery of finergrained textures and coarser-grained structures. Especially, when the band energy is low, most competing methods begin to fail, while our method still performs consistently well in such harder cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Real MSI denoising</head><p>In this section, urban area HYDICE MSI of natural scenes 9 is used in our experiments. The original MSI is of the size 304 × 304 × 210. As the bands 76, 100-115, 130-155 and 201-210 are seriously polluted by the atmosphere and water absorption and can provide little useful information, we remove them and leave the remaining test data with a size of 304 × 304 × 157.</p><p>We scale the MSI into the interval [0, 1], and employed the similar implementation strategies and parameter settings for all competing methods as previous simulated experiments. Since the noise level is unknown for real noisy images, we use an off-the-shelf noise estimation method <ref type="bibr" target="#b8">[9]</ref> to estimate it.</p><p>We illustrate the experimental results at the first band of the test MSI in <ref type="figure" target="#fig_7">Fig. 4</ref>. It can be easily observed that the image restored by our method is capable of properly removing the stripes and Gaussian noise while finely preserving the structure underlying the MSI. BM3D and BM4D can perform comparatively better in stripes noise removing, but their results contain evident blurry area , where our method finely recovers the details hiding under the corrupted MSI. <ref type="bibr" target="#b8">9</ref> http://www.tec.army.mil/Hypercube </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Analysis of the new tensor sparsity measure</head><p>Since our the proposed ITS measure is composed of two terms, we give some experimental analysis to verify if both terms could contribute to the denoising performance. To this aim, we perform MSI denoising within the proposed framework, while using sparsity measure S(X ) containing only its first term, second term (the work of Zhao et al. <ref type="bibr" target="#b33">[34]</ref> corresponds to only considering the second term) and both terms. <ref type="figure" target="#fig_8">Fig. 5</ref> shows the denoising results on face MSI from Columbia Dataset, in terms of PSNR and SSIM, with different noise levels (similar tendency can also be observed on other MSIs and with other evaluation measures). It is easy to see that the proposed ITS benefits from both of its terms. Only considering either one tends to degenerate the performance of MSI denoising.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we have provided a new MSI denoising model under a newly designed sparsity measure which finely encodes the correlation insights under the known Tucker and CP decomponstion for tensors. We have also designed an efficient ADMM algorithm to solve the model. The experiments on simulated and real MSI denoising have substantiated the superiority of the proposed method beyond state-of-the-arts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Flowchart of the proposed MSI denoising algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>(a) An MSI X0 ∈ R 80×80×26 (upper) and a nearly perfect reconstruction X0 (PSNR=61.25). (b) Core tensor S ∈ R 69×71×17 of X . Note that 78.4% of its elements are zeroes and more than half of them are very small. (c) Typical Slices of S, where deeper color of the element represents a larger value of it.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 .</head><label>3</label><figDesc>(a) The image at two bands (400nm and 700nm) of chart and staffed toy; (b) The corresponding images corrupted by Gaussian noise with variance v = 0.2, (c)-(k) The restored image obtained by the 9 utilized MSI denoising methods. Two demarcated areas in each image are amplified at a 4 times larger scale and the same degree of contrast for easy observation of details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 .</head><label>4</label><figDesc>(a) The Original image located at the 1 st band in HYDICE urban data set; (b)-(j) The restored image obtained by the 9 utilized MSI denoising methods. The demarcated areas in each image are amplified at a 2.5 times larger scale and the same degree of contrast.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 .</head><label>5</label><figDesc>PSNR (a) and SSIM (b) of resorted MSI obtained by the 3 sparsity measures over different noise levels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Calculate Xi = S ×1 U1 ×2 U2 ×3 U3</figDesc><table>, ∀k = 1, 2, 3 

12: 

Update the multipliers and let µ := ρµ 

13: 

end while 

14: 

15: 

end for 

16: 

Aggregate {Xi} K 
i=1 to form the clean image X (l) 
17: end for 
Output: Denoised MSI X (L) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table>Average performance of 9 competing methods with re-
spect to 4 PQIs. For both settings, the results are obtained by av-
eraging through the 32 scenes and the varied parameters. 

PSNR 
SSIM 
FSIM 
ERGAS 
v = 0.1, 0.15, 0.2, 0.25, 0.3 
Nosiy image 14.59±3.38 0.06±0.05 0.47±0.15 1151.54±534.17 
BwK-SVD 
27.77±2.01 0.47±0.10 0.81±0.06 
234.58±66.73 
BwBM3D 
34.00±3.39 0.86±0.06 0.92±0.03 
116.91±42.76 
3DK-SVD 
30.31±2.23 0.69±0.06 0.89±0.03 
176.58±43.78 
LRTA 
33.78±3.37 0.82±0.09 0.92±0.03 
120.79±46.06 
PARAFAC 
31.35±3.42 0.72±0.12 0.89±0.04 
160.66±66.95 
ANLM3D 
34.12±3.19 0.86±0.07 0.93±0.03 
117.01±35.79 
TDL 
35.71±3.09 0.87±0.07 0.93±0.04 
96.21±34.36 
BM4D 
36.18±3.03 0.86±0.07 0.94±0.03 
91.20±29.70 
ITSReg 
37.78±3.32 0.90±0.07 0.96±0.02 
77.35±30.16 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www1.cs.columbia.edu/CAVE/databases/ multispectral</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://www.cs.technion.ac.il/˜elad/software 3 http://www.cs.tut.fi/˜foi/GCF-BM3D/ 4 http://www.cs.technion.ac.il/˜elad/software 5 http://personales.upv.es/jmanjon/denoising/ arnlm.html 6 http://www.cs.tut.fi/˜foi/GCF-BM3D/ 7 http://www.sandia.gov/tgkolda/TensorToolbox/ index-2.5.html 8 http://gr.xjtu.edu.cn/web/dymeng/2</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An algorithm for designing overcomplete dictionaries for sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Aharon</forename><surname>K-Svd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4311" to="4322" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations &amp; Trends?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peleato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enhancing sparsity by reweighted l1 minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Wakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Fourier analysis and applications</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="877" to="905" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Folded-concave penalization approaches to tensor completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="page" from="261" to="273" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Analysis of individual differences in multidimensional scaling via an n-way generalization of eckart-young decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-J</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="283" to="319" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The inpainting of hyperspectral images: A survey and adaptation to hyperspectral data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-d transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">De-noising by soft-thresholding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Information Theory</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="613" to="627" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3781" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A general iterative shrinkage and thresholding algorithm for nonconvex regularized optimization problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Weighted nuclear norm minimization with application to image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">High-resolution hyperspectral imaging via matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ben-Ezra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tensor decompositions and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="500" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Linearized alternating direction method with adaptive penalty for low-rank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="612" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Denoising of hyperspectral images using the parafac model and statistical performance analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bourennane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fossati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3717" to="3724" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generalized singular value thresholding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Nonlocal transform-domain denoising of volumetric data with groupwise adaptive variance estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maggioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A nonlocal transform-domain filter for volumetric data denoising and reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maggioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="133" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adaptive non-local means denoising of mr images with spatially varying noise levels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Manjón</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Coupé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martí-Bonmatí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Robles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Magnetic Resonance Imaging</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="192" to="203" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Denoising and dimensionality reduction using multilinear tools for hyperspectral images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B N</forename><surname>Renard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blanc-Talon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="138" to="142" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Tracking via object reflectance using a hyperspectral video camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshop</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decomposable nonlocal tensor dictionary learning for multispectral image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">3-D nonlocal means filter with noise estimation for hyperspectral imagery denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IGARSS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A new convex relaxation for tensor completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sparse channel estimation with l p-norm and reweighted l 1-norm penalized least mean squares</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Taheri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Some mathematical notes on three-mode factor analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="279" to="311" />
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wald</surname></persName>
		</author>
		<title level="m">Data Fusion: Definitions and Architectures: Fusion of Images of Different Spatial Resolutions. Presses des lEcole MINES</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Low-rank tensor completion with spatio-temporal consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Robust principal component analysis: Exact recovery of corrupted low-rank matrices via convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generalized assorted pixel camera: postcapture control of resolution, dynamic range, and spectrum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yasuma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitsunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Iso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2241" to="2253" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fsim: a feature similarity index for image quality assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2378" to="2386" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A novel sparsity measure for tensor recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deblurring and sparse unmixing for hyperspectral images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Plemmons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="4045" to="4058" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
