<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">6D Dynamic Camera Relocalization from Single Reference Image</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Feng</surname></persName>
							<email>wfeng@tju.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Peng</forename><surname>Tian</surname></persName>
							<email>tianfeipeng@tju.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
							<email>qianz@tju.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jizhou</forename><surname>Sun</surname></persName>
							<email>jzsun@tju.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Technology</orgName>
								<orgName type="department" key="dep2">Tianjin Key Laboratory of Cognitive Computing and Application</orgName>
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">6D Dynamic Camera Relocalization from Single Reference Image</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Dynamic relocalization of 6D camera pose from single reference image is a costly and challenging task that requires delicate hand-eye calibration and precision positioning platform to do 3D mechanical rotation and translation. In this paper, we show that high-quality camera relocalization can be achieved in a much less expensive way. Based on inexpensive platform with unreliable absolute repositioning accuracy (ARA), we propose a hand-eye calibration free strategy to actively relocate camera into the same 6D pose that produces the input reference image, by sequentially correcting 3D relative rotation and translation. We theoretically prove that, by this strategy, both rotational and translational relative pose can be effectively reduced to zero, with bounded unknown hand-eye pose displacement. To conquer 3D rotation and translation ambiguity, this theoretical strategy is further revised to a practical relocalization algorithm with faster convergence rate and more reliability by jointly adjusting 3D relative rotation and translation. Extensive experiments validate the effectiveness and superior accuracy of the proposed approach on laboratory tests and challenging real-world applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Camera pose registration and relocalization is an essential problem in computer vision and robotics, fundamentally supporting a number of important real-world applications, such as structure-from-motion (SfM) <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b15">16]</ref>, 3D tracking and mapping <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b16">17]</ref>, monocular SLAM <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b33">34]</ref>, and scene change detection <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b4">5]</ref>.</p><p>Despite the diversity of previous successful methods, in computer vision, most recent efforts on this topic have been focused on static camera registration and relocalization (SCR) <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b9">10]</ref>. That is, for one or a group of input images, SCR studies how to align their camera poses into a unified world coordinate system that may come from a known 3D scene <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b14">15]</ref> or from 3D reconstruction us- * is the corresponding author. Tel: (+86)-22-27406538. ing the input images <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b15">16]</ref>. In SCR, the camera poses of input images are fixed and cannot be actively readjusted. In this paper, we treat camera pose relocalization as a dynamic process and study dynamic (or active) camera relocalization (DCR) from single reference image. Our work was originally motivated by a real-world problem, minute change monitoring and measurement of ancient murals for preventive conservation. This is indeed a very challenging problem due to three major reasons.  <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b25">26]</ref>. However, high precision robotics are not applicable to wild environment and cannot be frequently disassembled and reassembled, and its accuracy highly relies on hand-eye calibration <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b27">28]</ref>. Rephotography <ref type="bibr" target="#b0">[1]</ref> cannot do this either, due to its much lower relocalization accuracy and the limited ability to physically handle only 3D relative translation. In contrast, as shown in <ref type="figure" target="#fig_0">Fig. 1</ref> (c)-(e), the proposed approach guarantees to produce high-quality 6D DCR for both near-planar and nonplanar scenes. <ref type="figure" target="#fig_0">Fig. 1</ref> also shows that our DCR has successfully discovered 0.1mm real mural changes occurred in Dunhuang Mogao Grottoes, which truly provides ice-breaking results for this important real-world problem and has great potentials in other areas, such as online status monitoring of high speed train. Our major contribution is three-fold: 1) hand-eye calibration free, which enables frequent equipments disassembling/reassembling without losing precision; 2) applicable to common platforms and wild environments; 3) theoretically guaranteed convergence and feasible boundary condi-tion. To our best knowledge, it is the first solid hand-eye calibration free 6D DCR method in CV and robotics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Static camera relocalization (SCR). Many fundamental computer vision applications relate to camera pose registration and relocalization, such as sparse or dense 3D reconstruction <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b26">27]</ref>, monocular SLAM and camera tracking from RGB <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b33">34]</ref> or RGBD images <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b9">10]</ref>. Basically, they share a common SCR problem. That is, they all want to align camera poses of input one or multiple images within a unified world coordinate system, which can be defined by a (partially) known 3D scene (e.g., monocular SLAM <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b33">34]</ref> and active scene scanning <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b34">35]</ref>) or reconstructed via SfM pipeline <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>.</p><p>Fast and reliable camera pose estimation is critical to SCR. State-of-the-art method is 5-point algorithm <ref type="bibr" target="#b24">[25]</ref>, due to its generality and superior accuracy <ref type="bibr" target="#b30">[31]</ref>. Given the matched feature points set <ref type="bibr" target="#b19">[20]</ref> extracted from input images, 5-point algorithm can faithfully generate their relative rotation R and relative translation directiont. <ref type="bibr" target="#b0">1</ref> Besides, ESM is also used in camera pose estimation <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>Visual servoing. Robotic visual servoing (VS), aiming to control the pose of robot end-effector (hand) via visual feedback (eye) <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b20">21]</ref>, is closely related to our work. In restricted environment, e.g., objects with markers or planar moving assumption <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b38">39]</ref>, well-calibrated VS could be used to dynamically relocalize camera pose. However, as aforementioned, VS is not a cheap and reliable DCR worker, whose accuracy highly relies on hand-eye calibration or other restricted conditions.</p><p>Rephotography. Computational rephotography aims to recapture a photograph from the same viewpoint of a historical photograph. Previous work mainly focuses on the study of history <ref type="bibr" target="#b31">[32]</ref>, monitoring of natural environment, such as glacier melting <ref type="bibr" target="#b8">[9]</ref> and geological erosion <ref type="bibr" target="#b10">[11]</ref>, ecological research <ref type="bibr" target="#b32">[33]</ref>. These work highly relies on manual judgment, that makes it quite hard for operation and its accuracy is not high. Recently, several computational rephotogra-phy (CRP) methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b32">33]</ref> have been proposed and improved the efficiency and accuracy. West et al. <ref type="bibr" target="#b32">[33]</ref> present a linear blending based rephotography method for the purpose of monitoring urban tree canopy. Bae et al. <ref type="bibr" target="#b0">[1]</ref> propose an interactive and computational tool to guide users to reach the desired viewpoint, which can achieve about 0.5m physical relocalization accuracy. However, these existing methods rely on many user interactions and lack the accuracy to support minute change detection of high-value scenes.</p><p>Hand-eye calibration. Hand-eye calibration estimates relative pose between robot hand and eye coordinate systems, by solving AX = XB, where X is the homogeneous representation of the relative pose R X , t X between the eye coordinate system R A , t A and the hand system R B , t B <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b27">28]</ref>. Generally, accurate hand-eye calibration involves nonlinear optimization in SO(3) and R 3 <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. State-of-the-art methods apply branch-andbound strategy to search global optimum using labeled images with object markers in restricted environment <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b13">14]</ref>. In contrast, this paper gives a hand-eye calibration free approach to DCR and provides theoretical upper bound of hand-eye pose displacement, under which relative rotational and translational pose can be certainly decreased to zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">6D Dynamic Camera Relocalization</head><p>Notation. A 3D rotation matrix R ∈ SO(3) can also be expressed by axis-angle representation θ,ē and quaternion (cos θ 2 ,ē sin θ 2 ), where unit vectorē is the invariant Euler axis of R and θ is the rotation magnitude aboutē. In this paper, we use R ≃ θ,ē ≃ (cos θ 2 ,ē sin θ 2 ) to indicate the equivalence of three kinds of representations for a 3D rotation. Let R X , t X be the constant relative pose between eye coordinate system R A , t A and hand system R B , t B , where R denotes the orientation and t is the position of a coordinate system w.r.t. a fixed world coordinate system. As shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, the input reference image defines the target camera pose R ref</p><formula xml:id="formula_0">A , t ref A . Our problem is to dynamically relocalize current eye system R A , t A to the target pose R ref A , t ref A by properly moving hand, with unknown R X , t X . We use i to indicate iteration number, thus R i A , t i A and R i B , t i B</formula><p>represent the current camera and hand poses after i-iterations movement, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem formulation</head><p>We want to realize hand-eye calibration free DCR on common low-cost positioning platform. Compared to expensive high-precision platforms whose absolute repositioning accuracy (ARA) and repetitive repositioning accuracy (RRA) are both reliable, for proper low-cost platforms, their ARA is unreliable but RRA can be trusted. <ref type="bibr" target="#b1">2</ref> Hence, we should make best use of repetitive moving strategy. Besides, our DCR model needs to overcome two realistic difficulties:</p><p>1. Difficulty 1: Unknown hand-eye calibration, 2. Difficulty 2: We can only obtain the direction of relative camera translationt from images <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b30">31]</ref>.</p><p>We start from the ideal relations between the hand and eye coordinate systems during the DCR process. Let p ∈ R 3 be an arbitrary 3D point in world coordinate system, c and h denote its new coordinate in the reference camera system and corresponding target hand system, respectively. Similarly, c i and h i denote the coordinate of point p in current camera and hand system after i-iterations adjustment. Since hand-eye relation is fixed and 5-point algorithm can produce reliable camera pose, ideally, we have</p><formula xml:id="formula_1">c = R i A c i + t i A , h = R i B h i + t i B , c = R X h + t X , c i = R X h i + t X .</formula><p>(1)</p><p>Since we want hand-eye calibration free DCR (difficulty 1), we need to "guess" hand-eye relative pose, denoted by R X ,t X . Considering camera pose adjustment is achieved by moving hand, in practice, we have</p><formula xml:id="formula_2">c i+1 =R i A c i +t i A , h i+1 =R i B h i +t i B ,<label>(2)</label></formula><p>where R i A ,t i A and R i B ,t i B are deviated pose adjustment, caused by inaccurate guess of R X ,t X .</p><p>Considering difficulty 2, we cannot obtain real t i A but its orientationt i A from two consecutively captured images. Its length should also be "guessed" by s i , thus yielding another approximationt</p><formula xml:id="formula_3">i A = s it i A .<label>(3)</label></formula><p>Combining Eqs. (1)-(3) leads to</p><formula xml:id="formula_4">c = R i+1 A c i+1 + t i+1 A , R i+1 A = R i A R * X R i A −1 R * X −1 , t i+1 A = t i A + △t i A , △t i A = R i A t X − R i A R * Xt X − R i A R * X R i A −1 q, q =t i A −t X + R * X −1 t X ,<label>(4)</label></formula><formula xml:id="formula_5">where R * X = R XR −1 X . Eq. (4)</formula><p>is a general hand-eye calibration free DCR model that shows the recurrence relation of camera pose between two adjacent adjustments. A feasible DCR process should guarantee to reduce the relative 3D rotational and translation pose displacement to zero rapidly. The major obstacle comes from the inaccurate guesses R X ,t X andt i A , due to Difficulty 1 and 2. It is clear to see that, if the two guesses are correct, Eq. (4) trivially collapses to a one-step relocalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">An easy-to-understand strategy</head><p>Here we give an easy-to-understand strategy by first relocalizing 3D relative rotational pose to convergence via iteratively adjustments using Eq. (5), then reducing 3D relative translation to zero using the bisection-try method described in Theorem 2. The following two theorems theoretically guarantee that the influence of bounded hand-eye relative pose displacement R X , t X can be simply ignored in DCR. Specifically, we can just guessR X = I andt X = 0. Accordingly, Eq. (4) can be simplified to</p><formula xml:id="formula_6">R i+1 A = R i A R X R i A −1 R X −1 ,<label>(5)</label></formula><formula xml:id="formula_7">t i+1 A = t i A − R i A R X R i A −1 (t i A + R X −1 t X ) + R i A t X . (6) Theorem 1 (R A convergence)</formula><p>. By the rotation adjustment strategy defined by Eq. <ref type="formula" target="#formula_6">(5)</ref>, if θ X ≤ π 3 , then θ i+1 ≤ θ i and lim i→∞ θ i = 0. θ i andē i are the angle and axis of R i A . θ X andē X are the angle and axis of R X .</p><p>Proof. Using quaternion representation, we have</p><formula xml:id="formula_8">R i+1 A ≃ (cos θ i+1 2 ,ē i+1 sin θ i+1 2 ), R i A ≃ (cos θ i 2 ,ē i sin θ i 2 ), R X ≃ (cos θX 2 ,ē X sin θX 2 ), R i A −1 ≃ (cos θ i 2 , −ē i sin θ i 2 ), R X −1 ≃ (cos θX 2 , −ē X sin θX 2 ).<label>(7)</label></formula><p>From Eqs. <ref type="formula" target="#formula_6">(5)</ref> and <ref type="formula" target="#formula_8">(7)</ref>, we have</p><formula xml:id="formula_9">R i A R X ≃ (cos θ i 2 cos θX 2 − sin θ i 2 sin θX 2 ē i ,ē X , cos θ i 2 sin θX 2ē X + sin θ i 2 cos θX 2ē i + sin θ i 2 sin θX 2ē i ×ē X ),<label>(8)</label></formula><formula xml:id="formula_10">R i A −1 R X −1 ≃ (cos θ i 2 cos θX 2 −sin θ i 2 sin θX 2 ē i ,ē X , − cos θ i 2 sin θX 2ē X −sin θ i 2 cos θX 2ē i + sin θ i 2 sin θX 2ē i ×ē X ),<label>(9)</label></formula><p>where ē i ,ē X andē i ×ē X denote the inner and cross product ofē i andē X , respectively. Combing Eqs. <ref type="formula" target="#formula_6">(5)</ref>, <ref type="formula" target="#formula_9">(8)</ref> and <ref type="formula" target="#formula_10">(9)</ref> yields</p><formula xml:id="formula_11">cos θ i+1 2 = cos 2 θ i 2 + (1 − 2 sin 2 θX 2 ) sin 2 θ i 2 + sin 2 θ i 2 sin 2 θX 2 ē i ,ē X 2 ≥ cos 2 θ i 2 + cosθ X sin 2 θ i 2 .<label>(10)</label></formula><p>Note, by the right-hand rule, θ i ∈ [0, π] and θ X ∈ [0, π].</p><p>Define f (θ i ) = cos 2 θ i 2 + cosθ X sin 2 θ i 2 − cos θ i 2 that is an even function. We need to prove f (θ</p><formula xml:id="formula_12">i ) ≥ 0 for θ i ∈ [0, π]. Since f ′ (θ i ) = sin θ i 2 [cos θ i 2 (cosθ X − 1) + 1 2 ]. Clearly, when θ X ≤ π 3 , f ′ (θ i ) ≥ 0. Hence, f (θ i ) is non-decreasing in [0, π].</formula><p>Meanwhile, due to f (0) = 0 and the fact that f (θ i ) is an even function, we have f (θ i ) ≥ 0 in [−π, π], thus cos θ i+1 2 ≥ cos θ i 2 and θ i+1 ≤ θ i .</p><p>Moreover, note that f ′ (θ i ) ≥ 0 with the equality only occurs at θ i = 0. Therefore, θ i will consistently be reduced to zero, i.e., lim</p><formula xml:id="formula_13">i→∞ R i A = I or lim i→∞ θ i = 0 equivalently.</formula><p>Theorem 2 (t A bisection-try convergence). When eye relative rotation R i A converges to I, with current step size</p><formula xml:id="formula_14">s i , we measure t i+1 A ,t i A . If t i+1 A ,t i A ≥ 0, we guess the length of t i+1 A by s i+1 = s i , otherwise we do bisec- tion s i+1 := si 2 and guesst i+1 A = s i+1t i+1</formula><p>A . Using this bisection-try method, just before the bisection, we strictly have t i+1 A ≤ s i+1 . As s i is monotonically reduced to zero, so is t i+1</p><formula xml:id="formula_15">A .</formula><p>Proof. If the relative rotation has converged to I, Eq. <ref type="formula">(6)</ref> can be reduced to</p><formula xml:id="formula_16">t i+1 A = t i A − △ i = t i A − R Xt i A = t i A − R X s it i A ,<label>(11)</label></formula><p>where s i is the bisection step size before i-th adjustment. By Rodrigues' rotation formula, we have</p><formula xml:id="formula_17">R X t i A = cosθ X t i A + sinθ X (ē X × t i A ) +(1 − cosθ X ) ē X , t i A ē X .<label>(12)</label></formula><p>Hence,</p><formula xml:id="formula_18">R X t i A , t i A ≥ 0, because R X t i A , t i A = cosθ X t i A 2 + 0 +(1 − cosθ X ) ē X , t i A 2 ≥ 0.<label>(13)</label></formula><p>That is,</p><formula xml:id="formula_19">∠(t i A , R X t i A ) ≤ π 2 ,</formula><p>where ∠(a, b) denotes the angle between vectors a and b. Since</p><formula xml:id="formula_20">∠(△ i , R X t i A ) = 0, ∠(t i A , △ i ) ≤ π 2 and 0 ≤ cos∠(t i A , △ i ) ≤ 1. Now, let us check the i-th iteration i when s bisection happens. We have ∠(t i+1 A , t i A ) ≥ π 2 . This means t i A − △ i , t i A = t i A 2 − △ i , t i A = t i A 2 − t i A s i cos∠(t i A , △ i ) ≤ 0.<label>(14)</label></formula><p>Hence, we have t i</p><formula xml:id="formula_21">A 2 ≤ t i A s i cos∠(t i A , △ i ) ≤ t i A s i , which leads to t i</formula><p>A ≤ s i . Theorem 2 shows that using the bisection-try method, t i A = s it i A can gradually approach to t i A . In this case, Eq. <ref type="formula">(6)</ref> and <ref type="formula" target="#formula_16">(11)</ref> can be further simplified to</p><formula xml:id="formula_22">t i+1 A = t i A − R X t i A = (I − R X )t i A .<label>(15)</label></formula><p>Therefore, we have t i+1</p><formula xml:id="formula_23">A ≤ t i A ,</formula><p>if and only if (iff) the magnitudes of eigenvalues of I − R X are not greater than 1. Clearly, since the eigenvalues of R X are 1 and e ±jθX , the eigenvalues of I−R X are 0 and 1−cosθ X ±j sinθ X , whose magnitudes are not greater than 1 iff cosθ X ≥ 1 2 . That is, we need θ X ≤ π 3 to guarantee t i+1 A ≤ t i A in Eq. (15). Theorem 1 and 2 theoretically prove that this easy-tounderstand strategy can lead to convergent DCR. Moreover, the bisection strategy to approach relative camera translation takes advantage of the RRA of inexpensive positioning platforms, thus its real repetitive accuracy is reliable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">The algorithm and implementation details</head><p>As shown in <ref type="figure" target="#fig_0">Fig. 1(a)</ref>, there exist pair ambiguities between particular axes rotation and translation, e.g., pitch and height movement. That is, with the existence of translational displacement, during the first rotational relocalization stage, the theoretical DCR strategy may be not able to converge well, because in this case the 5-point algorithm is quite possible to generate unreliable large rotation estimation that is actually caused by translation. To overcome this problem, based on Theorem 1 and 2, we propose a practical DCR algorithm that jointly adjusts both 3D rotation and translation in the process. Detailed working flow of the proposed DCR algorithm is shown in <ref type="figure" target="#fig_1">Fig. 2</ref> and Algorithm 1. Besides, separately relocalizing rotational and translational relative pose highly relies on the mechanical independence of rotation and translation platforms. In practice, some translation axes movement may cause extra rotational displacement, even the first stage of relative rotational pose relocalization does very well, subsequent translation axes movement may certainly jeopardize the final DCR accuracy. As verified by our extensive experiments, the rotation-translation joint relocalization algorithm constantly outperforms sequential adjustment strategy in both convergence rate and accuracy. Rotate platform byR i Specifically, since precision positioning platforms usually cannot have large moving range, we first use the homography-based CR <ref type="bibr" target="#b6">[7]</ref> to roughly relocate camera to make its relative pose within the range of mechanical platforms. We then repeatedly capturing current image and calculate its 6D pose displacement R i A ,t i A . We directly rotate R i A and check the direction consistency oft i A and t i−1 A . If they are not in the same direction and s is not small enough, this means last time move has passed the objec- tively position, i.e., s is too large and need to be bisected s ← s 2 first and then to move st i A ; otherwise, we directly move st i A . In practice, we initialize s 0 as 1 5 full translation range of the platform. Larger or smaller s 0 , if feasible, will only impact the convergence rate. Besides, to counteract inevitable mechanical gaps, for a single axis movement along a particular direction with length L, we first go 1.1L along that direction and then return 0.1L inversely.</p><formula xml:id="formula_24">B =R −1 X R i AR X = R i A ; 6: ift i A ·t i−1 A &lt; 0</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head><p>Baselines. We compare our DCR with manual relocalization, homography-based relocalization <ref type="bibr" target="#b6">[7]</ref> and computational rephotography <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b32">33]</ref>. Note, manual relocalization just uses human visual judgment to manually steer camera pose. For better performance, we do manual relocalization very carefully in our experiments. The homography-based relocalization uses reference image and current image to generate a homography matrix that produces two navigation rectangles, guiding users to correct relative camera pose <ref type="bibr" target="#b6">[7]</ref>.</p><p>Criterion. To evaluate the performance of camera relocalization, we present feature-point displacement flow (FDF), a sparse field of feature-point displacement vectors, and average feature-point displacement (AFD) to quantitatively measure the relocalization accuracy:</p><formula xml:id="formula_25">AFD(P ref , P cur ) = 1 n n i=1 P i ref − P i cur 2<label>(16)</label></formula><p>where P ref and P cur are the matched feature-point coordinates in reference image and current relocalized image, respectively, n is the number of matches. In our experiments, we use SIFT feature detector, descriptor and robust matching with RANSAC correction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Convergence and accuracy</head><p>Laboratory tests. Given the initialization of R A , t A and fixed known R X , t X , we can simulate the proposed camera relocalization process in computer. <ref type="figure" target="#fig_3">Fig. 3</ref> demonstrates the rotation and translation convergence process of our DCR. The initial setup is as follows: initial angle of R A , t A , angle of R X and t X are ( π 4 , π 5 ,-π 4 ), <ref type="bibr">(20,-15,15)</ref>, ( π 8 , π 8 , π 8 ) and (15,10,10), respectively. <ref type="figure" target="#fig_3">Fig. 3</ref> is a typical DCR convergence process, which clearly shows that t A is bounded by the step size s during the whole DCR procedure. With the decrease of step size s, t A is accordingly descending. In contrast, the angle θ of R A is monotonically decreasing to zero. <ref type="figure" target="#fig_3">Fig. 3</ref> indeed validates the theoretical convergence of our DCR. Convergence rate comparison of two strategies. Here, we provide detailed comparison of the convergence rate and accuracy of the proposed two DCR strategies. <ref type="table" target="#tab_0">Table 1</ref> compares the AFD and iteration number in 10 independent DCR tests using the two strategies. In <ref type="figure" target="#fig_5">Fig. 4</ref>, we visually compare the DCR accuracy of the two strategies. Note, the selected scene in <ref type="figure" target="#fig_5">Fig. 4</ref> has minimum AFD value in 10-times tests using the theoretical strategy.  From <ref type="table" target="#tab_0">Table 1</ref> and <ref type="figure" target="#fig_5">Fig. 4</ref>, we can clearly see that the proposed algorithm consistently converges faster than the theoretically strategy, and produces much better accuracy. This is because separately relocalizing 3D rotational and translational relative pose highly relies on the mechanical independence of rotation and translation platforms. In practice, some translation axes movement may cause extra rotational displacement, even after the first stage of relative rotational pose relocalization, which may inevitably jeopardize the final DCR accuracy.</p><p>DCR accuracy comparison. Physically measuring the relocalization error is an important and direct criterion to evaluate relocalization accuracy. However, ground truth is hard to obtain in practice. To this end, we establish scenerelated FDF/AFD rulers by densely sampling the platform positions and orientations in 6 DoFs, with two adjacent samplings having only 0.1mm positional displacement or 0.01 degree rotation shift. Via such rulers, for a particular scene, we can quantitatively evaluate physically meaningful 6D DCR accuracy with radar chart. <ref type="figure" target="#fig_6">Fig. 5</ref> shows the physical DCR accuracy measurement on two different scenes, including one near-planar scene and one nonplanar scene. <ref type="table" target="#tab_3">Table 2</ref> gives the detailed statistics. From <ref type="figure" target="#fig_6">Fig. 5</ref> and <ref type="table" target="#tab_3">Table 2</ref>, we can clearly see that our DCR algorithm has reached subpixel accuracy and always  outperforms the baseline manual and homography-based relocalization methods significantly. We also observe that, in all tested scenes, the physical deviations in Z axis for both rotation and translation are constantly larger than other axes. This mainly attributes to the particular focal length and FoV of the camera. That is, in our camera configuration, it requires relatively larger movement and rotation in Z axis to cause comparable pixel displacement in image plane than the translation and rotation in other axes. We also compare the proposed DCR with a state-of-theart computational rephotography (CRP) tool, rephoto <ref type="bibr" target="#b32">[33]</ref>. <ref type="figure">Fig. 6</ref> shows the comparative results in two outdoor scenes. <ref type="table" target="#tab_4">Table 3</ref> gives a comparison of physical camera relocalization error of our DCR and another CRP method <ref type="bibr" target="#b0">[1]</ref>. It is clear that, compared to CRP, the proposed DCR have much higher physical relocalization accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Active panorama acquisition</head><p>With the proposed DCR, we can realize active acquisition of high-quality panorama. <ref type="figure" target="#fig_8">Fig. 7</ref> illustrates the detailed working flow of active HD panorama acquisition by the proposed DCR. Intuitively, we repeatedly relocalize the "left" part of current camera FoV to the same 6D pose of the reference image, which is the "right" part of the lasttime captured image. With high-quality camera calibration and relocalization, this process guarantees to produce AFD 0 7131 = .</p><p>AFD 9.9712 = <ref type="figure">Figure 6</ref>. Accuracy of our DCR with 2 state-of-the-art competitors: Rephoto <ref type="bibr" target="#b32">[33]</ref> and homography-based coarse camera relocalization <ref type="bibr" target="#b6">[7]</ref>. seamless panoramic images, by direct image stitching, with theoretically "unlimited" resolution, as such panorama can be actively captured as long and big as possible. Note, to guarantee the stitching quality, we suggest the ratio of common part of two successive images is not less than 30%. As shown in <ref type="figure">Fig. 8</ref>, compared to state-of-the-art image stitching method, like APAP <ref type="bibr" target="#b35">[36]</ref>, the proposed DCR-based active panorama acquisition is able to generate warping and artifact free panoramic image, even for highly-structured scenes taken at very close distance. <ref type="figure" target="#fig_0">Fig. 1</ref> (f) shows a HD panorama of ancient mural acquired by our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Minute change monitoring of ancient murals</head><p>Another promising application of the proposed DCR is long-time-interval minute change monitoring of ancient Mogao murals, which, as discussed in Sec. <ref type="bibr" target="#b0">1</ref>, is an open real-world problem. Although ancient Mogao murals have been seriously protected, they still suffer from many types of deteriorations caused by various environmental and human influences. As a result, their status is constantly changing in a very low speed. It is critically important to provide feasible imaging method, through which fine-grained changes become visually apparent thus timely detection and accurate measurement of such minute changes can trigger and support multi-disciplinary protective preservation.</p><p>However, current fact is no suitable method and equipment can be used for accurate minute change imaging within the unrestricted environment in Dunhuang Mogao Grottoes.</p><p>Using our inexpensive DCR platform shown in <ref type="figure" target="#fig_0">Fig. 1(g)</ref>, we selected 46 monitoring spots (very small regions) from 11 real Dunhuang caves and have conducted twice DCRbased image capturing in June 2014 and July 2015, respectively. The proposed approach and platform have successfully discovered 0.1mm-level minute changes (measured by close-range photogrammetry) in 31 monitoring spots (67%). This is truly a breakthrough, considering practical state-of-the-art way is simply naked-eye observation by experts that can only support object-level change detection during 100-year period. Some realistic yearly DCR results and corresponding changes derived by image-differenceaided human labeling are shown in <ref type="figure" target="#fig_9">Fig. 9</ref>. Our yearly monitoring data also find that caves open for tourists have 14 times faster deterioration speed than closed caves. This, for the first time, provides real data evidence about the influence of tourism to cultural heritages during 1 year period.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we have proposed an inexpensive 6D dynamic camera relocalization approach. We theoretically APAP Ours <ref type="figure">Figure 8</ref>. Comparison of panorama acquisition using state-of-the-art image stitching method APAP <ref type="bibr" target="#b35">[36]</ref> and the proposed approach. prove that both 3D rotational and translational pose displacement can be effectively reduced to zero based on lowcost RRA-reliable platform, without hand-eye calibration. We also find that, to make the proposed strategy work, the feasible upper bound of hand-eye 3D orientation displacement angle should be less than π 3 . Extensive tests validate the effectiveness and accuracy of our approach. More importantly, we demonstrate the promising applications of our approach in solving two challenging real-world problems: 1) active acquisition of seamless high-definition panorama image; and 2) 0.1mm-level minute deterioration monitoring of very-slowly-changed ancient murals in Dunhuang Mogao Grottoes. Our work indeed shows the great potentials of combining algorithms with common hardware in active vision. In near future, we plan to further accelerate our DCR approach based on reliable superpixel segmentation and matching <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b37">38]</ref> and apply it to solve more realworld change monitoring problems. Besides, we want to extend the proposed DCR model to faithfully relocalize hand coordinate system from multiple images. We are also interested in dynamic lighting recurrence from single image.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Inexpensive single image DCR. (a) Coordinate systems of eye RA, tA , hand RB, tB , target camera pose R ref A , t ref A , and the unknown hand-eye relative pose RX, tX . (b) DCR dynamic convergence process. (c)-(d) Our DCR results for nearplanar and nonplanar scenes. (e) Real minute changes (0.1mm level), occurred during June 2014 and July 2015, discovered by our DCR in Cave-465 of Dunhuang Mogao Grottoes. (f) HD panoramic image directly captured by a moving camera whose trajectory is controlled by our DCR. (g) Our inexpensive DCR platform. See text for more details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Working flow of the proposed 6D dynamic camera relocalization. See text for details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1</head><label>1</label><figDesc>Practical 6D dynamic camera relocalization Input: I ref , initial and stopping moving step s 0 and s min . 1: Initialization: initialize platform to zero position, s = s 0 , R X = I,t X = 0 , i = 1,t 0 A = 0; 2: Homography-based coarse camera relocalization to reduce error in the range of platform [7]; 3: while s &gt; s min do 4:Capture current image I i and compute R i A ,t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Convergence of RA and tA. (a) and (b) represent the 3D rotation and translation convergence, respectively. Red, green and blue lines represent X, Y and Z axis respectively, and black lines indicate the angle θ and step size s in (a) and (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>A visual comparison of DCR using theoretical strategy and the proposed algorithm on a near-planar scene.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>DCR accuracy measurement for two scenes, (a) nearplanar scene, (b) nonplanar scene.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>Working flow of DCR-based active panorama acquisition. Detailed DCR process in red block is shown inFig. 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 .</head><label>9</label><figDesc>Real minute deteriorations of Dunhuang Mogao murals discovered by the proposed DCR from June 2014 and July 2015.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>1 .</head><label>1</label><figDesc>High accuracy requirement. We want to find and measure very fine changes occurred on murals with complex image content and deterioration patterns. 2. Wild environment applicability. Both the equipment and algorithm should work well in unrestricted environments, where both the unpleasant weather and the need of frequent disassembling/reassembling equipments to realize portability for different caves/spots can jeopardize hardware accuracy. 3. Long time interval. Relics usually change very slowly, thus we must precisely relocalize 6D camera pose to capture the possible minute changes. Note, there is NO mature solution satisfying all the above three requirements. For instance, single image DCR could be directly solved as a robotic visual servoing problem</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>DCR result I i−1 .</figDesc><table>then 

7: 

Bisection s = s 
2 ; 

8: 

end if 

9:t i 

A = st i 
A ; 

10: 

Translate platform byt i 
B =t i 
A ; 

11: 

i++; 
12: end while 
Output: </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 .</head><label>1</label><figDesc>Average number of iterations and AFD of 10-times DCR tests of theoretical strategy and the proposed algorithm.</figDesc><table>Theoretical strategy 
The algorithm 
#iterations 
AFD 
#iterations AFD 
14.4 
13.37 
10.4 
0.85 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 2 .</head><label>2</label><figDesc>DCR accuracy statistics for two scenes. Unit of measurement is 1 degree for rotation and 1mm for translation.</figDesc><table>Near-planar R Ax 
R Ay 
R Az 
t Ax 
t Ay 
t Az 
AFD 
manual 
0.58 
0.56 
1.48 
7.8 
8.2 
27.2 
20.18 
homogrphy 
0.22 
0.24 
0.6 
2.8 
3 
12 
8.82 
ours 
0.01 
0.02 
0.01 
0.1 
0.1 
0.2 
0.26 
Nonplanar 
R Ax 
R Ay 
R Az 
t Ax 
t Ay 
t Az 
AFD 
manual 
0.24 
0.22 
0.56 
3.5 
3.6 
13.5 
6.98 
homogrphy 
0.13 
0.13 
0.34 
2 
2 
8 
6.01 
ours 
0.03 
0.02 
0.03 
0.3 
0.3 
1.3 
0.81 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 .</head><label>3</label><figDesc>Comparison of physical camera relocalization error.</figDesc><table>CRP [1] Ours Ratio 
Translation error (m) 1.135 0.00038 2987 
Rotation error (•) 
NA 
0.02 
NA 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Unlike relative rotation R, only the directiont = t t of relative translation t can be determined purely from images.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">An industrial-grade 6D miniature hexapod could worth more than 50,000 USD and requires clean working environment. The repositioning system in our DCR platform worths less than 30,000 RMB.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements We thank Xudong Wang, Bomin Su, Mingming Wang, Gangquan Chen, Qinglin Guo, Xiaowei Wang, Bolong Chai, Shujun Ding, Shengli Sun of Dunhuang Academy China for valuable discussions on slow-and-minute change monitoring of ancient murals. We thank Jiliang Sun, Jiawan Zhang, Qifeng Yue, Nan Zhang, Rui Huang, Yifeng Zhang, Dongrui Xiao for their contributions to our platform development and onsite data collection. This work is supported by the National Science and Technology Support Project (2013BAK01B01, 2013BAK01B05) and NSFC (61572354, 61272266).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Computational rephotography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOG</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Real-time simultaneous localization and mapping with a single camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Homography-based visual servo regulation of mobile robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Dawson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chawda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1041" to="1050" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Part B: Cybernetics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Self-validated labeling of Markov random fields for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1871" to="1887" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Region-level image authentication using Bayesian structural content abstraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2413" to="2424" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A spectral-multiplicity-tolerant approach to robust graph matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-M</forename><surname>Pun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2819" to="2829" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fine-grained change detection of misaligned scenes with varied illuminations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-P</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Real-time RGB-D camera relocalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISMAR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">An inconvenient truth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Guggenheim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Documentary</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<pubPlace>Paramount Classics Hollywood, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-output learning for camera relocalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guzman-Rivera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Photo point monitoring handbook: Part A-field procedures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Hall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>USDA Forest Service</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Global optimization through rotation space search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="79" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Trumpf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<title level="m">Rotation averaging. IJCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="267" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A branch-and-bound algorithm for globally optimal hand-eye calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Havlena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">From structure-from-motion point clouds to fast location recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Irschara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A global linear method for camera pose registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Parallel tracking and mapping for small ar workspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISMAR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Rephotography using image collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-Y.</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Maximum cohesive grid of superpixels for fast object localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image-based visual servoing for nonholonomic mobile robots using epipolar geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Mariottini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Oriolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Prattichizzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="87" to="100" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Live dense reconstruction with a single moving camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">KinectFusion: Real-time dense surface mapping and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Molyneaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISMAR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">DTAM: Dense tracking and mapping in real-time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Lovegrove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An efficient solution to the five-point relative pose problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nistér</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="756" to="770" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Novel position-based visual servoing approach to robust global stability under field-of-view constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I.-J</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4735" to="4752" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">MonoFusion: Real-time 3D reconstruction of small scenes with a single web camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bleyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bathiche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISMAR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Globally optimal handeye calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ruland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kruger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A branch-and-bound algorithm for globally optimal calibration of a camera-androtation-sensor system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Scene coordinate regression forests for camera relocalization in RGB-D images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Recent developments on direct relative orientation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stewenius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Engels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nistér</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Journal of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="284" to="294" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Western landscapes, western images: a rephotography of US Highway 89</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">I</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
		<respStmt>
			<orgName>Kansas State University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Collaborative rephotography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Halley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>O&amp;apos;neil-Dunne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pless</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH Studio Talks</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatic relocalization and loop closing for real-time monocular SLAM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1699" to="1712" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Autoscanning for coupled scene reconstruction and proactive object analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caichen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH Asia</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">As-projective-as-possible image stitching with moving dlt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-J</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-H</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1285" to="1298" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Consistent depth maps recovery from a video sequence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-T</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="974" to="988" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Bag of squares: A reliable model of measuring superpixel similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-M</forename><surname>Pun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICME</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Motion-estimation-based visual servoing of nonholonomic mobile robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1167" to="1175" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
