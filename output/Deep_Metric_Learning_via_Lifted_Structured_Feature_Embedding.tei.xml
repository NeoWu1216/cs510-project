<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Metric Learning via Lifted Structured Feature Embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun</forename><forename type="middle">Oh</forename><surname>Song</surname></persName>
							<email>hsong@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<orgName type="institution" key="instit3">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
							<email>yuxiang@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<orgName type="institution" key="instit3">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><forename type="middle">Jegelka</forename><surname>Mit</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<orgName type="institution" key="instit3">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<orgName type="institution" key="instit3">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Metric Learning via Lifted Structured Feature Embedding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning the distance metric between pairs of examples is of great importance for learning and visual recognition. With the remarkable success from the state of the art convolutional neural networks, recent works [1, 31] have shown promising results on discriminatively training the networks to learn semantic feature embeddings where similar examples are mapped close to each other and dissimilar examples are mapped farther apart. In this paper, we describe an algorithm for taking full advantage of the training batches in the neural network training by lifting the vector of pairwise distances within the batch to the matrix of pairwise distances. This step enables the algorithm to learn the state of the art feature embedding by optimizing a novel structured prediction objective on the lifted problem. Additionally, we collected Stanford Online Products dataset: 120k images of 23k classes of online products for metric learning. Our experiments on the CUB-200-2011 [37], CARS196 [19], and Stanford Online Products datasets demonstrate significant improvement over existing deep feature embedding methods on all experimented embedding sizes with the GoogLeNet [33] network. The source code and the dataset are available at: https://github.com/rksltnl/ Deep-Metric-Learning-CVPR16.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Comparing and measuring similarities between pairs of examples is a core requirement for learning and visual competence. Being able to first measure how similar a given pair of examples are makes the following learning problems a lot simpler. Given such a similarity function, classification tasks could be simply reduced to the nearest neighbor problem with the given similarity measure, and clustering tasks would be made easier given the similarity matrix. In this regard, metric learning <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b33">34]</ref> and dimensionality reduction <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b1">2]</ref> techniques aim at learning semantic distance measures and embeddings such that similar input objects are mapped to nearby points on a manifold and dissimilar objects are mapped apart from each other. Furthermore, the problem of extreme classification <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26]</ref> with enormous number of categories has recently attracted a lot of attention in the learning community. In this setting, two major problems arise which renders conventional classification approaches practically obsolete. First, algorithms with the learning and inference complexity linear in the number of classes become impractical. Second, the availability of training data per class becomes very scarce. In contrast to conventional classification approaches, metric learning becomes a very appealing technique in this regime because of its ability to learn the general concept of distance metrics (as opposed to category specific concepts) and its compatibility with efficient nearest neighbor inference on the learned metric space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Retrieval</head><p>With the remarkable success from the state of the art convolutional neural networks <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b32">33]</ref>, recent works <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b30">31]</ref> discriminatively train neural network to directly learn the the non-linear mapping function from the input image to a lower dimensional embedding given the input label annotations. In high level, these embeddings are optimized to pull examples with different class labels apart from each other and push examples from the same classes closer to each other. One of the main advantages of these discriminatively trained network models is that the network jointly learns the feature representation and semantically meaningful embeddings which are robust against intra-class variations.</p><p>However, the existing approaches <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b30">31]</ref> cannot take full advantage of the training batches used during the mini batch stochastic gradient descent training of the networks <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b32">33]</ref>. The existing approaches first take randomly sampled pairs or triplets to construct the training batches and compute the loss on the individual pairs or triplets within the batch. Our proposed method lifts the vector of pairwise distances (O(m)) within the batch to the matrix of pairwise distances (O(m 2 )). Then we design a novel structured loss objective on the lifted problem. Our experiments show that the proposed method of learning the embedding with the structured loss objective on the lifted problem significantly outperforms existing methods on all the experimented embedding dimensions with the GoogLeNet <ref type="bibr" target="#b32">[33]</ref> network.</p><p>We evaluate our methods on the CUB200-2011 <ref type="bibr" target="#b36">[37]</ref>, CARS196 <ref type="bibr" target="#b18">[19]</ref>, and Stanford Online Products dataset we collected. The Stanford Online Products has approximately 120k images and 23k classes of product photos from online e-commerce websites. To the best of our knowledge, the dataset is one of the largest publicly available dataset in terms of the number and the variety of classes. We plan to maintain and grow the dataset for the research community.</p><p>In similar spirit of general metric learning where the task is to learn a generic concept of similarity/distance, we construct our train and test split such that there is no intersection between the set of classes used for training versus testing. We show that the clustering quality (in terms of standard F 1 and NMI metrics <ref type="bibr" target="#b22">[23]</ref>) and retrieval quality (in terms of standard Recall@K score) on images from previously unseen classes are significantly better when using the proposed embedding. <ref type="figure" target="#fig_0">Figure 1</ref> shows some example retrieval results with the Stanford Online Products dataset using the proposed embedding. Although we experiment on clustering and retrieval tasks, the conceptual contribution of this paper -lifting a batch of examples into a dense pairwise matrix and defining a structured learning problem -is generally applicable to a variety of learning and recognition tasks where feature embedding is employed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related works</head><p>Our work is related to three lines of active research: (1) Deep metric learning for recognition, (2) Deep feature embedding with convolutional neural networks, and (3) Zero shot learning and ranking.</p><p>Deep metric learning: Bromley et al. <ref type="bibr" target="#b2">[3]</ref> paved the way on deep metric learning and trained Siamese networks for signature verification. Chopra et al. <ref type="bibr" target="#b4">[5]</ref> trained the network discriminatively for face verification. Chechik et al. <ref type="bibr" target="#b3">[4]</ref> learn ranking function using triplet <ref type="bibr" target="#b38">[39]</ref> loss. Qian et al. <ref type="bibr" target="#b26">[27]</ref> uses precomputed <ref type="bibr" target="#b19">[20]</ref> activation features and learns a feature embedding via distance metric for classification.</p><p>Deep feature embedding with state of the art convolutional neural networks: Bell et al. <ref type="bibr" target="#b0">[1]</ref> learn embedding for visual search in interior design using contrastive <ref type="bibr" target="#b13">[14]</ref> embedding, FaceNet <ref type="bibr" target="#b30">[31]</ref> uses triplet <ref type="bibr" target="#b38">[39]</ref> embedding to learn embedding on faces for face verification and recognition. Li et al. <ref type="bibr" target="#b21">[22]</ref> learn a joint embedding shared by both 3D shapes and 2D images of objects. In contrast to the existing approaches above, our method computes a novel structured loss and the gradient on the lifted dense pairwise distance matrix to take full advantage of batches in SGD. Zero shot learning and ranking: Frome et al., <ref type="bibr">Socher et al.,</ref><ref type="bibr">and Weston et al. [12,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b39">40]</ref> leverage text data to train visual ranking models and to constrain the visual predictions for zero shot learning. Wang et al. <ref type="bibr" target="#b37">[38]</ref> learns to rank input triplet of data given human rater's rank ratings on each triplets and also released a triplet ranking dataset with 5,033 triplet examples <ref type="bibr" target="#b7">[8]</ref>. However, the approach is not scalable with the size of the training data because it's very costly to obtain ranking annotations in contrast to multiclass labels (i.e., product name) and because the approach is limited to ranking the data in triplet form. Lampert et al. <ref type="bibr" target="#b20">[21]</ref> does zero shot learning but with attributes (such as objects's color or shape) provided for both the train and the test data. On a related note, <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28]</ref> do zero-shot learning for visual recognition but rely on the WordNet hierarchy for semantic information of the labels. The paper is organized as follows. In section 3, we start with a brief review of recent state of the art deep learning based embedding methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b30">31]</ref>. In section 4, we describe how we lift the problem and define a novel structured loss. In section 5 and 6, we describe the implementation details and the evaluation metrics. We present the experimental results and visualizations in section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Review</head><p>In this section, we briefly review recent works on discriminatively training networks to learn semantic embeddings.</p><p>Contrastive embedding <ref type="bibr" target="#b13">[14]</ref> is trained on the paired data {(x i , x j , y ij )}. The contrastive training minimizes the distance between a pair of examples with the same class label and penalizes the negative pair distances for being smaller than the margin α. The cost function is defined as,</p><formula xml:id="formula_0">J = 1 m m/2 (i,j) y i,j D 2 i,j + (1 − y i,j ) [α − D i,j ] 2 + ,<label>(1)</label></formula><p>where m stands for the number of images in the batch, f (·) is the feature embedding output from the network,</p><formula xml:id="formula_1">x 1 x 2 x 3 x 4 x 5 x 6 x x x x x x (a) Contrastive embedding x 1 x 2 x 3 x 4 x 5 x 6 (b) Triplet embedding x 1 x 2 x 3 x 4 x 5 x 6</formula><p>(c) Lifted structured embedding </p><formula xml:id="formula_2">D i,j = ||f (x i ) − f (x j )|| 2 , and the label y i,j ∈ {0, 1}</formula><p>indicates whether a pair (x i , x j ) is from the same class or not. The [·] + operation indicates the hinge function max(0, ·). Please refer to <ref type="bibr" target="#b13">[14]</ref> for more details.</p><p>Triplet embedding <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b30">31]</ref> is trained on the triplet data </p><formula xml:id="formula_3">x (i) a , x (i) p , x (i) n where x (i) a , x</formula><formula xml:id="formula_4">J = 3 2m m/3 i D 2 ia,ip − D 2 ia,in + α + ,<label>(2)</label></formula><p>where</p><formula xml:id="formula_5">D ia,ip = ||f (x a i ) − f (x p i )|| and D ia,in = ||f (x a i ) − f (x n i )||.</formula><p>Please refer to <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b38">39]</ref> for the complete details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Deep metric learning via lifted structured feature embedding</head><p>We define a structured loss function based on all positive and negative pairs of samples in the training set:</p><formula xml:id="formula_6">J = 1 2| P| (i,j)∈ P max (0, Ji,j) 2 ,<label>(3)</label></formula><p>Ji,j = max max</p><formula xml:id="formula_7">(i,k)∈ N α − D i,k , max (j,l)∈ N α − D j,l + Di,j</formula><p>where P is the set of positive pairs and N is the set of negative pairs in the training set. This function poses two computational challenges: (1) it is non-smooth, and <ref type="formula" target="#formula_4">(2)</ref> both evaluating it and computing the subgradient requires mining all pairs of examples several times.</p><p>We address these challenges in two ways: First, we optimize a smooth upper bound on the function instead. Second, as is common for large data sets, we use a stochastic approach. However, while previous work implements a stochastic gradient descent by drawing pairs or triplets of points uniformly at random <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b21">22]</ref>, our approach deviates from those methods in two ways: (1) it biases the sample towards including "difficult" pairs, just like a subgradient of J i,j would use the close negative pairs 1 ; (2) it makes use of the full information of the mini-batch that is sampled at a time, and not only the individual pairs. ⊺ , the dense pairwise squared distance matrix can be efficiently constructed by computing,</p><formula xml:id="formula_8">D 2 =x1 ⊺ + 1x ⊺ − 2XX ⊺ , where D 2 ij = ||f (x i ) − f (x j )|| 2 2 .</formula><p>However, it is important to note that the negative edges induced between randomly sampled pairs carry limited information. Most likely, they are different from the much sharper, close ("difficult") neighbors that a full subgradient method would focus on.</p><p>Hence, we change our batch to be not completely random, but integrate elements of importance sampling. We sample a few positive pairs at random, and then actively add their difficult neighbors to the training mini-batch. This augmentation adds relevant information that a subgradient would use. <ref type="figure" target="#fig_4">Figure 3</ref> illustrates the mining process for one positive pair in the batch, where for each image in a posi-tive pair we find its close (hard) negative images. Note that our method allows mining the hard negatives from both the left and right image of a pair in contrast to the rigid triplet structure <ref type="bibr" target="#b30">[31]</ref> where the negative is defined only with respect to the predefined anchor point. Indeed, the procedure of mining hard negative edges is equivalent to computing the loss augmented inference in structured prediction setting <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b16">17]</ref>. Our loss augmented inference can be efficiently processed by first precomputing the pairwise batch squared distance matrix D 2 . Furthermore, mining the single hardest negative with nested max functions (eqn. 4) in practice causes the network to converge to a bad local optimum. Hence we optimize the following smooth upper boundJ(D(f (x))). Concretely, our loss function per each batch is defined as,</p><formula xml:id="formula_9">x 1 x 2 x 3 x 4 x 5 x 6 x 1 x 2 x 3 x 4 x 5 x 6</formula><formula xml:id="formula_10">Ji,j = log   (i,k)∈N exp{α − D i,k } + (j,l)∈N exp{α − D j,l }   + Di,j J = 1 2|P| (i,j)∈P max 0,Ji,j 2 ,<label>(4)</label></formula><p>where P denotes the set of positive pairs in the batch and N denotes the set of negative pairs in the batch. The back propagation gradients for the input feature embeddings can be derived as shown in algorithm 1, where the gradients with respect to the distances are,</p><formula xml:id="formula_11">∂J ∂Di,j = 1 |P|J i,j ✶[Ji,j &gt; 0]<label>(5)</label></formula><formula xml:id="formula_12">∂J ∂D i,k = 1 |P|J i,j ✶[Ji,j &gt; 0] − exp{α − D i,k } exp{Ji,j − Di,j}<label>(6)</label></formula><formula xml:id="formula_13">∂J ∂D j,l = 1 |P|J i,j ✶[Ji,j &gt; 0] − exp{α − D j,l } exp{Ji,j − Di,j} ,<label>(7)</label></formula><p>where ✶[·] is the indicator function which outputs 1 if the expression evaluates to true and outputs 0 otherwise. As shown in algorithm 1 and equations 5, 6, and 7, our method provides informative gradient signals for all negative pairs as long as they are within the margin of any positive pairs (in contrast to only updating the hardest negative) which makes the optimization much more stable. </p><formula xml:id="formula_14">(i, k) ∈ N do ∂J /∂f(xi) ← ∂J /∂f(xi)+ ∂J /∂D i,k ∂D i,k/∂f (xi) ∂J /∂f(x k ) ← ∂J /∂f(x k )+ ∂J /∂D i,k ∂D i,k/∂f (x k ) end for l = 1, . . . , m, s.t. (j, l) ∈ N do ∂J /∂f(xj) ← ∂J /∂f(xj)+ ∂J /∂D j,l ∂D j,l/∂f (xj )</formula><p>∂J /∂f(x l ) ← ∂J /∂f(x l )+ ∂J /∂D j,l ∂D j,l/∂f (x l ) end end end Algorithm 1: Backpropagation gradient</p><p>Having stated the formal objective, we now illustrate and discuss some of the failure modes of the contrastive <ref type="bibr" target="#b13">[14]</ref> and triplet <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b38">39]</ref> embedding in which the proposed embedding learns successfully. <ref type="figure" target="#fig_6">Figure 4</ref> illustrates the failure cases in 2D with examples from three different classes. Contrastive embedding <ref type="figure" target="#fig_6">(Fig. 4a)</ref> can fail if the randomly sampled negative (x j ) is collinear with the examples from another class (purple examples in the figure). Triplet embedding <ref type="figure" target="#fig_6">(Fig. 4b)</ref> can also fail if such sampled negative (x n ) is within the margin bound with respect to the sampled the positive example (x p ) and the anchor (x a ). In this case, both contrastive and triplet embedding incorrectly pushes the positive (x i /x a ) towards the cluster of examples from the third class. However, in the proposed embedding <ref type="figure" target="#fig_6">(Fig. 4c)</ref>, given sufficiently large random samples m, the hard negative examples (x k 's in <ref type="figure" target="#fig_6">Fig. 4c</ref>) within the margin bound pushes the positive x i towards the correct direction. </p><formula xml:id="formula_15">x i x j (a) Contrastive embedding x a x p x n (b) Triplet embedding x j x i x k 1 x k 2 x k 3 (c) Lifted structured similarity</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implementation details</head><p>We used the Caffe <ref type="bibr" target="#b15">[16]</ref> package for training and testing the embedding with contrastive <ref type="bibr" target="#b13">[14]</ref>, triplet <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b38">39]</ref>, and ours. Maximum training iteration was set to 20, 000 for all the experiments. The margin parameter α was set to 1.0. The batch size was set to 128 for contrastive and our method and to 120 for triplet. For training, all the convolutional layers were initialized from the network pretrained on ImageNet ILSVRC <ref type="bibr" target="#b29">[30]</ref> dataset and the fully connected layer (the last layer) was initialized with random weights. We also multiplied the learning rate for the randomly ini- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Evaluation</head><p>In this section, we briefly introduce the evaluation metrics used in the experiments. For the clustering task, we use the F 1 and NMI metrics. F 1 metric computes the harmonic mean of precision and recall. F 1 = 2P R P +R . The normalized mutual information (NMI) metric take as input a set of clusters Ω = {ω 1 , . . . , ω K } and a set of ground truth classes C = {c 1 , . . . , c K }. 2(H(Ω)+H(C)) . We direct interested readers to refer <ref type="bibr" target="#b22">[23]</ref> for complete details. For the retrieval task, we use the Recall@K <ref type="bibr" target="#b14">[15]</ref> metric. Each test image (query) first retrieves K nearest neighbors from the test set and receives score 1 if an image of the same class is retrieved among the K nearest neighbors and 0 otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Experiments</head><p>We show experiments on CUB200-2011 <ref type="bibr" target="#b36">[37]</ref>, CARS196 <ref type="bibr" target="#b18">[19]</ref>, and our Stanford Online Products datasets where we use the first half of classes for training and the rest half classes for testing. For testing, we first compute the embedding on all the test images at varying embedding sizes {64, 128, 256, 512} following the practice in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b30">31]</ref>. For clustering evaluation, we run affinity propagation clustering <ref type="bibr" target="#b10">[11]</ref> with bisection method <ref type="bibr" target="#b9">[10]</ref> for the desired number of clusters set equal to the number of classes in the test set. The clustering quality is measured in the standard F 1 and NMI metrics. For the retrieval evaluation, we report the result on the standard Recall@K metric <ref type="bibr" target="#b14">[15]</ref>    <ref type="figure">Figure 6</ref>: F 1 , NMI, and Recall@K score metrics on the test split of CARS196 with GoogLeNet <ref type="bibr" target="#b32">[33]</ref>.</p><p>the batch size as shown in tables 1 and 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">CUB-200-2011</head><p>The CUB-200-2011 dataset <ref type="bibr" target="#b36">[37]</ref> has 200 classes of birds with 11,788 images. We split the first 100 classes for training (5,864 images) and the rest of the classes for testing <ref type="bibr" target="#b4">(5,</ref><ref type="bibr">924</ref> images). <ref type="figure">Figure 5</ref> shows the quantitative clustering quality for the contrastive <ref type="bibr" target="#b13">[14]</ref>, triplet <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b30">31]</ref>, and using pool5 activation from the pretrained GoogLeNet <ref type="bibr" target="#b32">[33]</ref> network on ImageNet <ref type="bibr" target="#b29">[30]</ref>, and our method on both F 1 , NMI, and Recall@K metrics. Our embedding shows significant performance margin both on the standard F 1 , NMI, and Re-call@K metrics on all the embedding sizes. Please refer to the supplementary material for qualitative retrieval results on the test split of CUB200-2011 <ref type="bibr" target="#b36">[37]</ref> dataset. <ref type="figure" target="#fig_9">Figure 7</ref> shows the Barnes-Hut t-SNE visualization <ref type="bibr" target="#b35">[36]</ref> on our 64 dimensional embedding. Although t-SNE embedding does not directly translate to the high dimensional embedding, it is clear that similar types of birds are quite clustered together and are apart from other species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">CARS196</head><p>The CARS196 data set <ref type="bibr" target="#b18">[19]</ref> has 198 classes of cars with 16,185 images. We split the first 98 classes for training <ref type="bibr" target="#b7">(8,</ref><ref type="bibr">054</ref> images) and the other 98 classes for testing <ref type="bibr" target="#b7">(8,</ref><ref type="bibr">131</ref> images). <ref type="figure">Figure 6</ref> shows the quantitative clustering quality for the contrastive <ref type="bibr" target="#b13">[14]</ref>, triplet <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b30">31]</ref>, and using pool5 activation from pretrained GoogLeNet <ref type="bibr" target="#b32">[33]</ref> network on Im-ageNet <ref type="bibr" target="#b29">[30]</ref>. Our embedding shows significant margin in terms of the standard F 1 , NMI, and Recall@K metrics on all the embedding sizes. Please refer to the supplementary material for qualitative retrieval results on the test split of Cars196 <ref type="bibr" target="#b18">[19]</ref> dataset. <ref type="figure" target="#fig_10">Figure 8</ref> shows the Barnes-Hut t-SNE visualization <ref type="bibr" target="#b35">[36]</ref> on our 64 dimensional embedding. We can observe that the embedding clusters the images from the same brand of cars despite the significant pose variations and the changes in the body paint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.">Stanford Online Products dataset</head><p>We used the web crawling API from eBay.com <ref type="bibr" target="#b8">[9]</ref> to download images and filtered duplicate and irrelevant images (i.e. photos of contact phone numbers, logos, etc). The preprocessed dataset has 120,053 images of 22,634 online products (classes) from eBay.com. Each product has approximately 5.3 images. For the experiments, we split 59,551 images of 11,318 classes for training and 60,502 images of 11,316 classes for testing. <ref type="figure" target="#fig_11">Figure 9</ref> shows the quantitative clustering and retrieval results on F 1 , NMI, and Recall@K metric with GoogLeNet. Figures 10 and 11    ization of the learned embedding on our Stanford Online Products dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>We described a deep feature embedding and metric learning algorithm which defines a novel structured prediction objective on the lifted pairwise distance matrix within the batch during the neural network training. The experimental results on CUB-200-2011 <ref type="bibr" target="#b36">[37]</ref>, CARS196 <ref type="bibr" target="#b18">[19]</ref>, and Stanford Online Products datasets show state of the art performance on all the experimented embedding dimensions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Example retrieval results on our Stanford Online Products dataset using the proposed embedding. The images in the first column are the query images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Illustration for a training batch with six examples. Red edges and blue edges represent similar and dissimilar examples respectively. In contrast, our method explicitly takes into account all pair wise edges within the batch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>referred to as an anchor of a triplet. Intuitively, the training process encourages the network to find an embedding where the distance between x some margin α. The cost function is defined as,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figures</head><label></label><figDesc>2a and 2b illustrate a sample batch of size m = 6 for the contrastive and triplet embedding. Red edges in the illustration represent positive pairs (same class) and the blue edges represent negative pairs (different class) in the batch. In this illustration, it is important to note that adding extra vertices to the graph is a lot more costly than adding extra edges because adding vertices to the graph incurs extra I/O time and/or storage overhead. To make full use of the batch, one key idea is to enhance the mini-batch optimization to use all O(m 2 ) pairs in the batch, instead of O(m) separate pairs. Figure 2c illustrates the concept of of transforming a training batch of examples to a fully connected dense matrix of pairwise distances. Given a batch of c-dimensional embedded features X ∈ R m×c and the column vector of squared norm of individual batch elements x = ||f (x 1 )|| 2 2 , . . . , ||f (x m )|| 2 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Hard negative edge is mined with respect to each left and right example per each positive pairs. In this illustration with 6 examples in the batch, both x 3 and x 4 independently compares against all other negative edges and mines the hardest negative edge.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>input : D, α output:∂J /∂f(xi), ∀i ∈ [1, m] Initialize: ∂J /∂f(xi) = 0, ∀i ∈ [1, m] for i = 1, . . . , m do for j = i + 1, . . . , m, s.t. (i, j) ∈ P do ∂J /∂f(xi) ← ∂J /∂f(xi) + ∂J /∂Di,j ∂Di,j /∂f(xi) ∂J /∂f(xj) ← ∂J /∂f(xj) + ∂J /∂Di,j ∂Di,j /∂f(xj)for k = 1, . . . , m, s.t.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Illustration of failure modes of contrastive and triplet loss with randomly sampled training batch. Brown circles, green squares, and purple diamonds represent three different classes. Dotted gray arcs indicate the margin bound (where the loss becomes zero out of the bound) in the hinge loss. Magenta arrows denote the negative gradient direction for the positives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>tialized fully connected layers by 10.0 for faster convergence. All the train and test images are normalized to 256 by 256. For training data augmentation, all images are randomly cropped at 227 by 227 and randomly mirrored horizontally. For training, we exhaustively use all the positive pairs of examples and randomly subsample approximately equal number of negative pairs of examples as positives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>ω i indicates the set of examples with cluster assignment i. c j indicates the set of examples with the ground truth class label j. NMI is defined by the ratio of mutual information and the average entropy of clusters and the entropy of labels. NMI (Ω, C) = I(Ω;C)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 :</head><label>7</label><figDesc>Barnes-Hut t-SNE visualization [36] of our embedding on the test split (class 101 to 200; 5,924 images) of CUB-200-2011. Best viewed on a monitor when zoomed in.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Barnes-Hut t-SNE visualization<ref type="bibr" target="#b35">[36]</ref> of our embedding on the test split (class 99 to 196; 8,131 images) of CARS196. Best viewed on a monitor when zoomed in.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 :</head><label>9</label><figDesc>F 1 , NMI, and Recall@K score metrics on the test split of Stanford Online Products with GoogLeNet<ref type="bibr" target="#b32">[33]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 :Figure 11 :</head><label>1011</label><figDesc>Examples of successful queries on our Stanford Online Products dataset using our embedding (size 512). Images in the first column are query images and the rest are five nearest neighbors.show some example queries and nearest neighbors on the dataset for both successful and failure cases. Despite the huge changes in the viewpoint, configuration, and illumination, our method can successfully retrieve examples from the same class and most retrieval failures come from fine grained subtle differences among similar products. Please refer to the supplementary material for the t-SNE visual-Examples of failure queries on Stanford Online Products dataset. Most failures are fine grained subtle differences among similar products. Images in the first column are query images and the rest are five nearest neighbors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>in log space of K. The experiments are performed with GoogLeNet [33]. 7.1. Ablation study: effect of the batch size m</figDesc><table>F 1 NMI R@1 

m = 32 18.4 53.2 42.4 
m = 48 19.1 53.8 42.1 
m = 64 19.9 53.8 42.4 
m = 128 19.7 54.1 42.8 

Table 1: CUB200 

F 1 NMI R@1 

m = 32 20.5 55.6 46.9 
m = 48 21.2 55.9 49.4 
m = 64 22.7 56.6 50.3 
m = 128 22.8 56.7 49.5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Cars196 Tables 1 and 2show the effect of batch size (m) for CUB-200-211 and CARS196 datasets in terms of F1, NMI, and R@1. On GoogLeNet, the maximum batch size is limited to 128 due to GPU (NVIDIA K80) memory constraint. The minimum batch size where the training doesn't diverge due to unstable gradient is around 32. Computing the proposed smooth structured estimation provides stability in terms of</figDesc><table>12 

14 

16 

18 

20 

22 

Embedding size 

F 

1 

score (%) 

64 128 
256 
512 1024 

GoogLeNet pool5 
Contrastive 
Triplet 
LiftedStruct 

46 

48 

50 

52 

54 

56 

Embedding size 

NMI score (%) 

64 128 
256 
512 1024 

GoogLeNet pool5 
Contrastive 
Triplet 
LiftedStruct 

1 
2 
4 
8 
16 
32 

30 

40 

50 

60 

70 

80 

90 

K 

Recall@K score (%) 

GoogLeNet pool5 
Contrastive 
Triplet 
LiftedStruct 

Figure 5: F 1 , NMI, and Recall@K score metrics on the test split of CUB200-2011 with GoogLeNet [33]. 

10 

15 

20 

25 

Embedding size 

F 
1 score (%) 

64 128 
256 
512 1024 

GoogLeNet pool5 
Contrastive 
Triplet 
LiftedStruct 

35 

40 

45 

50 

55 

Embedding size 

NMI score (%) 

64 128 
256 
512 1024 

GoogLeNet pool5 
Contrastive 
Triplet 
LiftedStruct 

1 
2 
4 
8 
16 
32 

30 

40 

50 

60 

70 

80 

90 

K 

Recall@K score (%) 

GoogLeNet pool5 
Contrastive 
Triplet 
LiftedStruct 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Strictly speaking, this would be a subgradient replacing the nested max by a plus.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We acknowledge the support of ONR grant #N00014-13-1-0761 and grant #122282 from the Stanford AI Lab-Toyota Center for Artificial Intelligence Research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning visual similarity for product design with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Out-of-sample extensions for lle, isomap, mds, eigenmaps, and spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Paiement</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Signature verification using a &quot;siamese&quot; time delay neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Słckinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Large scale online learning of image similarity through ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chechik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Extreme multi class classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Choromanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Multidimensional scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Chapman and Hill</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Data</surname></persName>
		</author>
		<ptr target="https://sites.google.com/site/imagesimilaritydata/" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ebay Developers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Program</surname></persName>
		</author>
		<ptr target="http://go.developer.ebay.com/what-ebay-api" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dueck</surname></persName>
		</author>
		<ptr target="http://www.psi.toronto.edu/affinitypropagation/apclusterK.m" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Clustering by passing messages between data points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dueck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Devise: A deep visual-semantic embedding model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neighbourhood component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Product quantization for nearest neighbor search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jegou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PAMI</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5093</idno>
		<title level="m">Caffe: Convolutional architecture for fast feature embedding</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cutting-plane training of structural svms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-N</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">I</forename><surname>Jolliffe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-F</forename><surname>Li</surname></persName>
		</author>
		<idno>3dRR-13</idno>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Attributebased classification for zero-shot visual object categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TPAMI</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Joint embeddings of shapes and images via cnn image purification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH Asia</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Introduction to Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schtze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge university press</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Metric learning for large scale image classification: Generalizaing to new classes at near-zero cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Zero-shot learning with semantic output codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palatucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fastxml: A fast, accurate and stable tree-classifier for extreme multi-label learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fine-grained visual categorization via multi-stage metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evaluating knowledge transfer and zero-shot learn-ing in a large-scale setting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Nonlinear dimensionality reduction by locally linear embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
		<respStmt>
			<orgName>ImageNet Large Scale Visual Recognition Challenge. IJCV</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Zero-shot learning through cross-modal transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D M M</forename><surname>Ganjoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bastani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Pose-sensitive embedding by nonlinear nca regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Spiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Support vector machine learning for interdependent and structured output spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Altun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Accelerating t-sne using tree-based algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JMLR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
		<title level="m">The caltech-ucsd birds-200-2011 dataset</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning fine-grained image similarity with deep ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Wsabi: Scaling up to large vocabulary image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usurer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
