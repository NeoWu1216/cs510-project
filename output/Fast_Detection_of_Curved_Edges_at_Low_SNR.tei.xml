<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast Detection of Curved Edges at Low SNR</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nati</forename><surname>Ofir</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Weizmann Institute of Science Rehovot</orgName>
								<address>
									<postCode>76100</postCode>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meirav</forename><surname>Galun</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Weizmann Institute of Science Rehovot</orgName>
								<address>
									<postCode>76100</postCode>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boaz</forename><surname>Nadler</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Weizmann Institute of Science Rehovot</orgName>
								<address>
									<postCode>76100</postCode>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronen</forename><surname>Basri</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Weizmann Institute of Science Rehovot</orgName>
								<address>
									<postCode>76100</postCode>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fast Detection of Curved Edges at Low SNR</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:40+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Detecting edges is a fundamental problem in computer vision with many applications, some involving very noisy images. While most edge detection methods are fast, they perform well only on relatively clean images. Unfortunately, sophisticated methods that are robust to high levels of noise are quite slow. In this paper we develop a novel multiscale method to detect curved edges in noisy images. Even though our algorithm searches for edges over an exponentially large set of candidate curves, its runtime is nearly linear in the total number of image pixels. As we demonstrate experimentally, our algorithm is orders of magnitude faster than previous methods designed to deal with high noise levels. At the same time it obtains comparable and often superior results to existing methods on a variety of challenging noisy images.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This paper considers the problem of detecting faint edges in noisy images. Our key contribution is the introduction of a new, computationally efficient algorithm to detect faint curved edges of arbitrary shapes and lengths, under low signal-to-noise ratios (SNRs). A key feature of our algorithm is that the longer an edge is, the fainter it can be and still be detected. This is consistent with the performance of the human visual system, as illustrated in <ref type="figure">Fig. 1</ref>.</p><p>Edges with low signal-to-noise-ratio are common in a variety of imaging domains, specifically when images are captured under poor visibility conditions. Examples include biomedical, satellite and high shutter speed imaging. As an illustrative example, <ref type="figure">Fig. 2</ref> shows an image of Plankton acquired with an underwater imaging system <ref type="bibr" target="#b4">[5]</ref>. Automated algorithms that detect the boundaries of different Plankton species, segment and classify them are fundamental in the study of ocean ecosystems. However, segmenting Plankton in such images is challenging due to their low contrast and background noise.</p><p>Noise poses an obstacle to edge detection since it can reduce the contrast of actual edges, and introduce spurious <ref type="bibr">Figure 1</ref>. A noisy binary pattern with three curved fibers at high noise level (left, SNR=1) or low noise level (middle, SNR=2). The clean pattern is shown on the right. While the long fiber is noticeable already at the low SNR. the two shorter fibers can be spotted only at the higher SNR. <ref type="figure">Figure 2</ref>. From left to right: Noisy image of a Plankton acquired by an underwater imaging system <ref type="bibr" target="#b4">[5]</ref> containing several faint edges; our result; Canny result, and Canny after BM3D denoising. high contrasts at background pixels. Thus, detecting edges using only local image gradients is highly sensitive to noise. To be more robust to noise, Canny <ref type="bibr" target="#b6">[7]</ref>, for example, first denoises the image with a Gaussian filter, before computing its gradients. While this smoothing operation indeed attenuates the noise, it also blurs existing edges, thus decreasing their contrast. Applying more sophisticated image denoising algorithms before edge detection does not, in general, solve the problem. We illustrate this point in <ref type="figure">Fig. 2</ref>. The edges found by Canny <ref type="bibr" target="#b6">[7]</ref> on either the noisy image or the image denoised by the state-of-the art BM3D algorithm <ref type="bibr" target="#b8">[9]</ref> are shown in the two rightmost panels. Both methods fail to accurately detect the Plankton boundaries. In contrast, as shown in the middle-left panel, our proposed method is far more robust to noise and yields a significantly more accurate result. We further illustrate this point in Sec. 6, using additional images from different application domains.</p><p>Our approach to detect faint curved edges is based on applying a large collection of matched filters to the image, and retaining only those which are statistically significant. By definition, each of these matched filters computes the average contrast of the image pixel intensities along its corresponding curve. When this curve traces an actual edge, the filter smoothes the noise on either side of the edge while maintaining its contrast. Hence, this operation does not suffer from the degradation of the general purpose denoising approaches described above. The longer the edge and its corresponding matched filter, the more aggressively the noise is attenuated, allowing detection of fainter edges.</p><p>The computational challenge in applying this approach is that the locations and shapes of the edges, and hence the corresponding matched filters, are a-priori unknown. Moveover, there are in general an exponential number of candidate curves and corresponding matched filters. Hence, a naive direct approach to compute all of them would be prohibitively slow. The main contribution of this paper is the development of a highly efficient algorithm to detect curved edges. Our detection scheme is multiscale and utilizes a hierarchical binary partition of the image, constructing matched filters for the detected edges in a bottom-up strategy. With this construction, even though our method searches for edges over a huge set of candidate curves, its runtime is nearly linear in the total number of image pixels. As we analyze in Sec. 4, our algorithm is orders of magnitude faster than other edge detection methods that can deal with high noise levels (e.g., <ref type="bibr" target="#b0">[1]</ref>). Yet, as we demonstrate in Sec. 6, it obtains comparable, if not better, edge detection quality on challenging noisy images from a variety of applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Previous and Related Work</head><p>Edge detection is a well studied problem with a rich history. Traditional methods considered step edges and relied on local gradients to detect them <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b6">7]</ref>. In contrast, recent methods addressed the problem of boundary detection in natural images <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15]</ref>. These methods rely on supervised learning of complex boundary features that account for intensity, color and texture. Despite the high accuracy achieved by these methods on natural images, as shown experimentally in Sec. 6, they exhibit poor performance on images with faint edges.</p><p>In this paper we focus on the problem of detecting step edges at high levels of noise. As mentioned in the introduction, this is an important task in a variety of imaging domains. One of the first proposed methods for step edge detection was the Sobel operator <ref type="bibr" target="#b18">[19]</ref>, which does so by thresholding the gradient magnitude at each pixel sepa-rately. Marr &amp; Hildreth <ref type="bibr" target="#b15">[16]</ref> proposed to detect edges by identifying the zero crossings of a 2D Laplacian of a Gaussian filter applied to the image. These local approaches for edge detection are very efficient, essentially with lineartime complexity in the total number of pixels. However, due to their local nature, they are sensitive to noise and exhibit poor performance at low SNR. One exception is the algorithm suggested by Canny <ref type="bibr" target="#b6">[7]</ref>, which extends Sobel by hysteresis thresholding of the local gradient magnitudes. This post-processing operation significantly improves its robustness to noise. We thus choose the Canny algorithm as one of the baselines for comparison to our work.</p><p>A potentially promising approach to detect edges in noisy images is to first denoise the image and then apply some edge detection algorithm. The problem of image denoising received considerable attention in recent years, and various methods were proposed, including bilateral filtering <ref type="bibr" target="#b19">[20]</ref>, anisotropic diffusion <ref type="bibr" target="#b17">[18]</ref>, non-local means <ref type="bibr" target="#b5">[6]</ref>, BM3D <ref type="bibr" target="#b8">[9]</ref> and more. These methods, however, are not optimized for edge detection and typically denoise the image based on small local patches. Hence, they may blur faint edges, making their detection even more difficult.</p><p>Another set of edge detection algorithms utilize a wavelet-based bank of filters that vary in length and width, see a review in <ref type="bibr" target="#b20">[21]</ref>. Given the availability of fast wavelet transforms, these methods are also quite fast. However, a key difference from our approach is that these wavelet methods do not adapt to the shape of actual curved edges. Hence, their performance at low SNRs is sub-optimal.</p><p>Several recent studies proposed to use matched filters to improve the detection of faint edges. The method of Galun et al. <ref type="bibr" target="#b11">[12]</ref> detects straight edges using O(N log N ) operations for an input image with N pixels. A significantly faster method to detect long straight edges, with sub-linear run-time in the image size, was proposed in <ref type="bibr" target="#b13">[14]</ref>. An algorithm for detecting faint curved edges, based on the Beamlet data structure <ref type="bibr" target="#b10">[11]</ref> and its corresponding quad-tree partition of the input image. was proposed by Alpert et al. <ref type="bibr" target="#b0">[1]</ref>. While their method is also multiscale, it suffers from a high complexity of O(N 2.5 ) operations, which translates into a non-practical runtime of several minutes on typical images.</p><p>In our work, we detect curved edges with a significantly reduced complexity. The two key ideas are to instead construct a binary tree partition, and perform a sophisticated processing on it. We present two variants of our algorithm, which both require a memory of O(N log N ). The first, more stringent variant has time complexity O(N 1.5 ), whereas the second faster one incurs a slight loss of detection accuracy, but has even faster runtime at O(N log N ) operations. For illustrative purposes, the run time of our latter algorithm, implemented in C++, is roughly 1 second on a small 129 × 129 image and 5 seconds on a 257 × 257 image. In contrast, the runtime of <ref type="bibr" target="#b0">[1]</ref>, as reported in their paper, is several minutes per image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Beam-Curve Binary Tree</head><p>In this paper we develop edge detection algorithms that efficiently examine a huge set of possible candidate curves. This section describes in detail how we achieve this goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Setup and Notations</head><p>The input to our method is a noisy gray-level image I with N = m × n pixels containing an a-priori unknown number of curved edges at unknown locations and shapes. In developing the algorithm and its theoretical analysis, we assume for simplicity square images with m = n where n is a power of 2, and an additive Gaussian noise model. Namely, the input image can be decomposed as I = I clean + I noise where I clean is a noise free image, with step edges of constant contrast, and I noise (x, y)</p><formula xml:id="formula_0">i.i.d. ∼ N (0, σ 2 )</formula><p>. An edge is a non self-intersecting curve γ, with step discontinuity in the pixel intensities of the unobserved I clean . Its SNR is defined as the absolute difference in image intensities across the step edge, divided by the noise level. To each candidate curve γ of total length L, passing through a set of pixels P , we associate the following response vector</p><formula xml:id="formula_1">φ(γ) = [R, L, C, P ].<label>(1)</label></formula><p>The response value R, determined by the matched filter corresponding to the curve γ, is the difference between the sums of intensities on the two sides of the curve. The variable C = R/m(L) is the average contrast along the curve, where m(L) is the total number of pixels of the matched filter of length L. Let γ 1 and γ 2 be two curves with a common endpoint, and with corresponding vectors</p><formula xml:id="formula_2">φ(γ i ) = [R i , L i , C i , P i ], i = 1, 2. The response vector of their concatenation is φ(γ 1 +γ 2 ) = [R 1 +R 2 , L 1 +L 2 , R 1 + R 2 m(L 1 ) + m(L 2 ) , P 1 ∪P 2 ].</formula><p>(2) To detect statistically significant curved edges in the image I, we first construct its beam-curve binary tree and its corresponding data structure, denoted BC. Geometrically, each node of the tree corresponds to a tile in the image (a region of a prescribed shape). A tile V of area A, is split into two sub-tiles V 1 , V 2 of roughly equal area by an interface (a straight line in our implementation) whose length is proportional to √ A. The root node, at level j = 0 represents the full image, whereas at each finer level j there are 2 j tiles. The tree is constructed bottom-up, starting from a fine level j b , whose tiles all have area approximately n min × n min , where n min (typically a few pixels) is a user chosen parameter.</p><p>Within each tile V , for every pair of pixels p 1 and p 2 on its boundary ∂V , the beam curve data structure BC stores a response vector φ(γ). Postponing exact definitions to Sec. 5, this response vector corresponds to a single curve γ between p 1 and p 2 , which is most likely to be an edge. See Alg. 1 for a pseudo-code of the tree construction, and <ref type="figure" target="#fig_0">Fig. 3</ref> for its implementation based on a rectangular tile partition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The Edge Detection Algorithm</head><p>As described in Alg. 1, the matched filter responses of the various curves are calculated in a bottom-up fashion, from the leaves of the tree to its root. For each leaf tile V at the bottom level j b , we set the response of each pair of boundary pixels p 1 , p 2 ∈ ∂V to be the matched filter response of the straight line segment that connects them. See Alg. 2 for a pseudo-code of the bottom level processing.</p><p>Next, given the response vectors at level j + 1 we compute responses at the next coarser level j. We do this by concatenating curves from sibling tiles as follows. Let V 1 , V 2 be sibling tiles at level j + 1, with a parent tile V at level j. We consider all pairs of pixels such that p 1 ∈ ∂V 1 ∩ ∂V and p 2 ∈ ∂V 2 ∩ ∂V . Now, for each such pair of pixels (p 1 , p 2 ), in the stringent variant of our algorithm, we consider all pixels in the joint interface V 12 = ∂V 1 ∩ ∂V 2 . For each pixel p 3 ∈ V 12 we compute the response of the curve obtained by concatenating the two curves from p 1 to p 3 and p 3 to p 2 . Among all of these concatenated curves, we store the one with highest response score (defined explicitly in Eq. (12) below). See Alg. 3 for pseudo-code of the coarser level construction.</p><p>The final output of our algorithm is a soft edge map image E. A value E ij = 0 means that there is no detected edge passing through pixel (i, j), whereas the higher the value of E ij , the stronger is the statistical evidence that an edge passes there. This edge map E is constructed as follows: We initially set all pixels of E to zero. For every response vector φ(γ), as detailed in Sec. 5, we assign a significance score that depends on its mean contrast C and its length L. A positive score indicates that the curve marks a statistically significant edge. Then, we sort all the curves in the tree whose score is positive from highest score to lowest. For each curve γ in this sorted list, for each pixel p ∈ P we set E(p) to hold the score of γ. To deal with overlapping curves with positive scores, we apply the following simple non-maximal suppression procedure: First, if at some pixel p, the current value E(p) is already positive, we do not decrease it; and, secondly, if most of the pixels in P were already marked by previous curves (of higher scores), we discard the current curve γ and do not add its pixels to E.</p><p>In principle, the generic algorithm above can be implemented with any binary partition of the image. In Sec. 4 we make a detailed complexity analysis, under the assumption that the children tiles are roughly half the area of their parent tile and the length of their interface is roughly the square root of their area. We prove that under these conditions, the algorithm complexity is O(N 1.5 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 BeamCurveT ree(V )</head><p>Require: Tile V whose maximal side length is n.</p><p>if n ≤ n min then</p><formula xml:id="formula_3">BC ← BottomLevel(V ) else V 1 , V 2 ← SubT iles(V ) { The tile is split into two sub-tiles of equal area} BC 1 ← BeamCurveT ree(V 1 ) BC 2 ← BeamCurveT ree(V 2 ) BC ← CoarserLevel(V, V 1 , V 2 , BC 1 , BC 2 ) end if return BC Algorithm 2 BottomLevel(V ) Require: Small tile V . BC ← EmptySet for ∀p 1 , p 2 ∈ ∂V do γ ← straight line from p 1 to p 2 BC.add(φ(γ)) end for return BC Algorithm 3 CoarserLevel(V, V 1 , V 2 , BC 1 , BC 2 )</formula><p>Require: V is an image tile, V 1 and V 2 are its sub-tiles. Require: BC 1 is a set of the responses of sub-tile V 1 . Require: BC 2 is a set of the responses of sub-tile V 2 .</p><p>BC</p><formula xml:id="formula_4">← BC 1 ∪ BC 2 if BasicMode then Interf aceSet ← ∂V 1 ∩ ∂V 2 else if OptimizedMode then Interf aceSet ← BestP ixels(∂V 1 ∩ ∂V 2 ) end if for ∀p 1 , p 2 : p 1 ∈ ∂V ∩ ∂V 1 , p 2 ∈ ∂V ∩ ∂V 2 do AllResponses ← EmptySet for ∀p 3 ∈ Interf aceSet do γ 1 ← curve from p 1 to p 3 in set BC 1 γ 2 ← curve from p 3 to p 2 in set BC 2 φ(γ) ← concatenate(φ(γ 1 ), φ(γ 2 ))</formula><p>AllResponses.add(φ(γ)) end for BC.add(AllResponses.bestResponse()) end for return BC Rectangular partition. In this partition, we split the square image into two rectangles of equal size. We next split each rectangle into two squares and continue recursively until squares of size n min × n min are obtained. Specifically in our implementation, we used n min = 5. We call the ob-  tained data structure Rectangle-Partition-Tree (RPT). See <ref type="figure" target="#fig_0">Fig. 3</ref> for an illustration of the RPT levels. Triangular Partition. A second possible beam curve binary tree, which we denote as the Triangle-Partition-Tree (TPT), is based on triangular tiles, see <ref type="figure" target="#fig_1">Fig. 4</ref>. Here, at the topmost level we split the image along its diagonal into two triangles. Then, at any subsequent level we split each triangle into two sub-triangles recursively. For a square image, the triangles obtained are all right angled isosceles. It can be shown that the TPT-based edge detection algorithm is slightly faster than the RPT-based one. Specifically, for a square image of N pixels, the TPT algorithm requires ≈ 14N 1.5 operations (derivation omitted due page limit restrictions). In contrast, as we analyze in detail in Sec. 4 below, the RPT construction requires ≈ 18N 1.5 operations. In addition, the set of potential curves scanned by both partitions is of comparable size. Hence, both partitions yield a similar edge detection performance. Let V be a tile at level j with children tiles V 1 , V 2 and let p 1 , p 2 ∈ ∂V . In this variant, the algorithm still seeks to compute the curve with best response between p 1 , p 2 . However, instead of scanning all pixels in the joint interface V 12 = ∂V 1 ∩ ∂V 2 , it only considers a subset of k pixels for some fixed constant k. To select this subset, for each pixel p 3 ∈ V 12 we look at the curve with highest response, that starts at either ∂V 1 or ∂V 2 and ends at p 3 , as previously computed at level j +1. We then keep only the k pixels with highest responses. As we prove in Sec. 4, the overall number of operations of this variant is significantly smaller. Our experiments in Sec. 6 indicate that in practice this results in a negligible decrease in edge detection quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">An Optimized Version</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Complexity Analysis</head><p>In this section we study the computational complexity of the beam-curve algorithm of Sec. 3.2. We begin with an analysis of the general scheme. Denote by t(A) the number of operations performed by our algorithm on a tile V of area A. The step of populating the responses of V involves computing responses for every triplet of pixels, p 1 ∈ ∂V 1 , p 2 ∈ ∂V 2 and p 3 ∈ ∂V 1 ∩ ∂V 2 where V 1 and V 2 the children tiles of V . The length of each of these three boundaries is O( √ A), and so the complexity of this step is proportional to A 1.5 . The operation is then repeated for the sub-tiles V 1 and V 2 whose areas are ≈ A/2. Therefore, t(A) satisfies the following recursion,</p><formula xml:id="formula_5">t(A) = 2t(A/2) + O(A 1.5 ).<label>(3)</label></formula><p>The total complexity t(A) can be determined using the master theorem <ref type="bibr" target="#b7">[8]</ref>, which considers recursions of the form</p><formula xml:id="formula_6">t(n) = at(n/b) + f (n).<label>(4)</label></formula><p>The asymptotic behavior of t(n) is obtained by comparing f RPT Space and Time Complexity. Next, for the case of a rectangular partition we now bound the multiplicative constant hidden in the above O notation, and compute its required memory. Recall that in the RPT, the root level j = 0 represents the original n×n image, whereas the next level, j = 1, contains two equal rectangles of size n × n/2. In general, every even level j includes squares of size n/2 j/2 × n/2 j/2 pixels, while every odd level j includes rectangles of size n/2 (j−1)/2 × n/2 (j+1)/2 . We next derive the number of stored responses per level. At every tile of even level j, we store the edge responses of curves that pass from one side of a tile to a different side. The number of stored responses thus equals the product of 4 choose 2 (pairs of rectangle sides) times the tile area,</p><formula xml:id="formula_7">4 2 · n 2 j 2 · n 2 j 2 = 6N 2 j .<label>(5)</label></formula><p>Consequently, multiplying Eq. (5) by the number of tiles, gives that the total number of stored curves at level j is</p><formula xml:id="formula_8">6N 2 j · 2 j = 6N.<label>(6)</label></formula><p>At odd levels, it can be shown that the above equations hold with a constant 6.5 instead of 6. Finally, as the number of levels is bounded by log N and the storage per curve is constant, the total required space is O <ref type="figure">(N log N )</ref>. Stringent Algorithm Complexity. First, recall that at the bottom level, for every leaf we scan all the straight lines that begin on one side of the tile and end on another side. Since the number of operations required to compute each such response is bounded by a constant, the total number of operations at this level is O <ref type="figure">(N )</ref>.</p><p>Next, at every coarser level j, we build each curve by concatenating two shorter curves of level j + 1, that share a common endpoint at the joint interface. The work done at level j is thus bounded by the number of calculated curves times the length of the joint interface. Since the former is 6N , the overall number of operations in an even level is</p><formula xml:id="formula_9">6N × n/2 j/2 = 6N 1.5 /2 j/2 ,<label>(7)</label></formula><p>while the number of operations in an odd level is</p><formula xml:id="formula_10">6N × n/2 (j+1)/2 = 6N 1.5 /2 (j+1)/2 .<label>(8)</label></formula><p>Denote by C(N ) the time complexity of the algorithm that considers all the possible points on the interface. By summing these over all scales we get the following,</p><formula xml:id="formula_11">C(N ) ≈ 6N 1.5   j b j even 2 −j/2 + j b j odd 2 −(j+1)/2   . (9)</formula><p>Consequently,</p><formula xml:id="formula_12">C(N ) ≤ 6N 1.5 ∞ l=0 2 −l + ∞ l=1 2 −l = 18N 1.5 . (10)</formula><p>Optimized Algorithm Complexity. As described in Sec. 3.3, the optimized variant scans, for each of the 6N pairs of start and end points, only the best k pixels in the joint interface. Overall, it goes over 6N k curves at each level j. Additional work is required to select the best k pixels. Since the number of tiles equals 2 j and the interface length is ≈ n/2 j/2 , the number of operations of this step is bounded by log k · 2 j · n/2 j/2 &lt; N for every level j. To conclude, the total number of operations at each level is no more than (6k + 1)N. Thus, the overall complexity is bounded by (6k + 1)N log N , which leads to a significantly faster runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Detection Threshold and Search Space Size</head><p>As described in Sec. 3, our method scans a huge set of candidate curves. For suitable pairs of start and end pixels, the algorithm stores in the data structure BC, the curved edge with highest edge score, as defined by Eq. (12) below. Clearly, for most images, the vast majority of these responses do not trace actual image edges and should be discarded. This task requires the determination of a suitable threshold, possibly dependent on edge length, such that only edge responses above it are retained.</p><p>Previous work <ref type="bibr" target="#b0">[1]</ref> introduced an approximate theoretical formula for this threshold, designed to control the average number of false positive detections. The derivation of the threshold is related to the a-contrario approach, see, e.g., <ref type="bibr" target="#b12">[13]</ref>. To this end, consider a pure noise image I = I noise , where I noise (x, y) ∼ N (0, σ 2 ). By definition, this image contains no real edges, and so, with high probability, all of its edge responses should be discarded. Suppose that there are K L distinct candidate edges of length L. Then, the corresponding threshold, T (L, K L ), is approximately the maximal edge contrast expected in I noise among K L statistically independent curves of length L. Alpert et al. <ref type="bibr" target="#b0">[1]</ref> showed that</p><formula xml:id="formula_13">T (L, K L ) ≈ σ 2 ln K L wL ,<label>(11)</label></formula><p>where w is the width of the matched filter. Thus, to each curve of length L, we assign an edge score ϕ, defined as the difference between its mean contrast and the threshold,</p><formula xml:id="formula_14">ϕ(γ) = C(γ) − T (L, K L ).<label>(12)</label></formula><p>A positive score indicates that the candidate curve traces an edge. Moreover, higher scores represent stronger confidence for this indication.</p><p>To compute the edge score function of Eq. (12), we thus need to know, for each curve length L the size of the corresponding search space size, K L . As shown below in Eq. <ref type="bibr" target="#b19">(20)</ref>, for the RPT construction, this quantity is approximately given by K L ≈ 6N × 2 βL for a suitable constant β. Inserting this expression into Eq. <ref type="bibr" target="#b10">(11)</ref> gives <ref type="figure">Figure 5</ref>. Contrast threshold as a function of curve length. The dashed theoretical curve, based on <ref type="bibr" target="#b12">(13)</ref>, is designed to have few false positive detections. The empirical threshold is produced by applying our algorithm on over 100 pure noise images, and storing the median of the maximal response for each curve length.</p><formula xml:id="formula_15">T (L) = σ 2 ln(6N × 2 βL ) wL .<label>(13)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Minimal Detectable</head><p>Contrast. An interesting question, already raised by <ref type="bibr" target="#b0">[1]</ref>, is how faint can an edge be and still be detected. In our case, note that as N and L tend to infinity, the threshold in Eq. (13) converges to a finite limit,</p><formula xml:id="formula_16">T ∞ = Ω( σ √ w ).<label>(14)</label></formula><p>Namely, due to the exponential size of the search space, our threshold is bounded from below by a positive constant. Hence, our ability to detect faint edges of unknown shape and location in low SNR is limited. <ref type="figure">Fig. 5</ref> compares the theoretical threshold of Eq. (13) to empirical results. The latter was computed by running our algorithm on over 100 pure noise images and storing for each curve length the median of the 100 maximal responses obtained. It can be seen that both curves are close to each other, and that the graphs converge to ≈ 1/2. This value is the asymptotic bound T ∞ for the selected parameters in this simulation: width w = 4, image size N = 129 2 , noise level σ = 1 and β = 0.65.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Search Space Size</head><p>We now compute the size of the search space K L of candidate curves of length L in the RPT. This quantity directly affects the contrast threshold <ref type="bibr" target="#b10">(11)</ref>.</p><p>We first calculate the search space size at level j of the RPT, and then show its connection to K L . Denote by S(j) the upper bound of the total number of candidate curves at level j, and denote by S ′ (j) the same number, but for given fixed start and end points. Since by Eq. (6), the total number of stored curves at any level is approximately 6N , then</p><formula xml:id="formula_17">S(j) = 6N × S ′ (j).<label>(15)</label></formula><p>Next, to compute S ′ (j), recall that in the RPT, we split a tile V of level j into two sub-tiles V 1 , V 2 of level j + 1, by a joint interface ∂V 1 ∩ ∂V 2 , whose length is ≈ n/2 j/2 . For fixed endpoints p 1 , p 2 ∈ ∂V , the quantity S ′ (j) satisfies the following recursive formula S ′ (j) = S ′ (j + 1) × S ′ (j + 1) × n/2 j/2 .</p><p>In order to apply the master theorem <ref type="bibr" target="#b7">[8]</ref>, we take logarithm on both sides log S ′ (j) = 2 log S ′ (j + 1) + 1 2 log(N/2 j ).</p><p>Substitute A = N/2 j , which is exactly the number of pixels in a tile at level j, and defineS(A) = S ′ (j). Then,</p><formula xml:id="formula_20">logS(A) = 2 logS(A/2) + 1 2 log A.<label>(18)</label></formula><p>According to <ref type="formula" target="#formula_6">(4)</ref> </p><formula xml:id="formula_21">S(j) = 6N × 2 O(N/2 j ) .<label>(19)</label></formula><p>To derive an expression for K L , it can be shown, that the average length over all candidate curves in a given tile at level j is proportional to the tile's area: L = O(N/2 j ). Therefore we can approximate K L , by</p><formula xml:id="formula_22">K L ≈ 6N × 2 βL<label>(20)</label></formula><p>for some constant β. As mentioned above, we showed by empirical fitting that β = 0.65. We remark that although the search space is exponential in L, there are nonetheless various curves that cannot be found by the RPT. Examples include closed curves like a circle, self-intersecting curves like a cross, and also any curve that begins and ends in the same side of a tile, like a narrow 'V' shape. Such geometric objects are detected by our algorithm as union of shorter valid curved edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>We tested our algorithm both on simulated artificial images as well as on challenging real images from several application domains. Our code is implemented in Matlab, yet we developed another preliminary implementation in C++. Furthermore, as our tree construction can be easily parallelized, our code utilizes multi-threading. We ran our experiments on a single 8-core Intel i7, 16 GB RAM machine. For an input image of size 129 × 129 pixels the run time in C++ is ≈ 0.6 second for the O(N log N ) version and ≈ 0.9 seconds for the O(N 1.5 ), both including the post processing step of computing the final edge map image E. For an input image of 257×257 pixels the corresponding C++ run-times are ≈ 5 and ≈ 8 seconds respectively. More CPU cores can reduce these run times significantly. The runtime graphs are shown in <ref type="figure" target="#fig_5">Fig. 6</ref>. Note, that our implementation outputs the edge image along with a list of all the curved edges that passed the statistical threshold. We compared our solution to the classical Canny <ref type="bibr" target="#b6">[7]</ref> algorithm, and to several state of  the art algorithms for boundary detection in natural images, including Multiscale-Combinatorial-Grouping (MCG) <ref type="bibr" target="#b3">[4]</ref>, Crisp Pointwise-Mutual-Information (PMI) <ref type="bibr" target="#b14">[15]</ref> and Dollar and Zitnick's Structured-Edges (SE) <ref type="bibr" target="#b9">[10]</ref>.</p><p>Simulations. For the simulations, we used a binary pattern of size 129 × 129 pixels that contains a narrow triangle, straight lines, concentric circles and an 'S' shape, see <ref type="figure" target="#fig_6">Fig. 7</ref>. We then scaled the intensities and added additive Gaussian noise with 0.1 standard deviation to produce images with SNRs between 0 and 2 in intervals of 0.2. In addition, we added very weak salt and pepper noise that affects only 1% of the pixels in the images. We used the result of Canny on the clean binary pattern as the ground truth. We quantitatively compared the various edge detection algorithms by computing their Precision (P ), Recall (R), and F-scores, using the popular F-measure for image segmentation described in <ref type="bibr" target="#b16">[17]</ref>.  <ref type="table">Table 1</ref> shows the average F-scores obtained for each algorithm. A graph of the F-scores as a function of SNR is shown in <ref type="figure" target="#fig_6">Fig. 7</ref>. All methods are tuned to detect no edges when the image includes pure noise (SNR=0). For that sake,  we modified the Canny's thresholds to be [low, high] = [0.28, 0.7]. For the other methods, we used a fixed threshold on the soft edge map. As expected, algorithms geared to detecting boundaries in natural images do not perform well in such noisy conditions. Canny manages to obtain fairly high F-scores. Still, our O(N 1.5 ) algorithm achieves the best F-scores at all SNR levels, while our O(N log N ) variant achieves only slightly lower scores. These results suggest that high quality detections can be obtained by our faster method, in spite of the significant reduction of complexity. <ref type="figure" target="#fig_7">Fig. 8</ref> shows representative results of Canny, PMI and our method at SNR=2 and 3.</p><p>We also made an extensive evaluation of our algorithm on the dataset of 63 artificial images containing various straight and curved edges, as studied by <ref type="bibr" target="#b0">[1]</ref>. On this dataset our O(N 1.5 ) algorithm achieved an average F-score of ≈ 0.79, compared to ≈ 0.74 achieved by <ref type="bibr" target="#b0">[1]</ref>. This demonstrates that our algorithm is not only significantly faster, but also at least as accurate as <ref type="bibr" target="#b0">[1]</ref>.</p><p>We next applied our O(N 1.5 ) to the natural images of the BSDS-500 <ref type="bibr" target="#b16">[17]</ref> to which we added Gaussian noise with σ = 0.1. The performance of the various methods is summarized in <ref type="figure" target="#fig_8">Fig. 9</ref>. Our results are superior to those of PMI <ref type="bibr" target="#b14">[15]</ref> and SE <ref type="bibr" target="#b9">[10]</ref> and are comparable to MCG <ref type="bibr" target="#b3">[4]</ref>. We emphasize that while our method is better suited to deal with noise it is currently not designed to handle natural textures that are ubiquitous in these images.</p><p>Real Images. We further tested our algorithms on various real images taken under relatively poor conditions, see results in <ref type="figure" target="#fig_9">Figure 10</ref>. It can be seen that our method manages to accurately detect details in these challenging images beyond those detected by existing approaches. Specifically, our method depicts nearly all the growth rings of the tree, the branchings of the nerve cell, and the blood vessels in the retina. Accurate detection of such structures can for example facilitate high throughput biomedical research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We presented efficient algorithms for detecting faint curved edges in noisy images that achieve state-of-the-art results at low SNRs. Our novel approach detects curved edges in only O(N log N ) operations. The algorithm is adaptive to various parameters such as edge length, shape, and SNR and can be applied with various filters. Thus it may be applicable in a variety of imaging domains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>Left: The 3 topmost levels of a RPT. Right: The n × n image at level j = 0 is partitioned into two rectangles of size n × n/2 at level j = 1. Each rectangle is then partitioned into two n/2 × n/2 squares at level j = 2. A curve connecting two boundary pixels p1, p2 of level j = 0 is a concatenation of up to 2 curves of level j = 1, and up to 4 curves of level j = 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>Triangle-Partition-Tree, an alternative implementation of the beam-curve binary-tree. Left: The 4 topmost levels of the TPT. Right: The partitioning embedded in the 2D image grid, every triangle is divided into two sub-triangles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>A run-time complexity of O(N 1.5 ) operations may still be too slow when processing large images. Hence, it is of interest to develop even faster algorithms. Below we introduce an efficient variant of our algorithm with an O(N log N ) complexity, at a statistical price of slightly worse detection quality.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(n) to n log b a±ǫ . Specifically, if f (n) = O(n log b a−ǫ ) for some constant ǫ &gt; 0 then t(n) = Θ(n log b a ), while if f (n) = Ω(n log b a+ǫ ) for some constant ǫ &gt; 0 and in addition if af (n/b) ≤ cf (n) for some constant c &lt; 1 then t(n) = Θ(f (n)). In (3), a = b = 2 and A 1.5 = Ω(A log 2 2+0.5 ). In addition, 2f (A/2) = (1/ √ 2)f (A), implying that t(A) = Θ(f (A)) = Θ(A 1.5 ). Finally, as the area of the root tile equals the total number of image pixels N , the overall complexity of the beam-curve binary tree algorithm is O(N 1.5 ) operations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>, denote t(A) = logS(A) and f (A) = 0.5 log(A). Therefore, in this case a = b = 2 and f (A) = O(A log 2 2−0.5 ), and using the master theorem t(A) = logS(A) = Θ(A). Subsequently, S ′ (j) = 2 O(N/2 j ) and combining this with Eq. (15),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Empirical run-time of our implementation compared to the theoretical run-time for both O(N log N ) and O(N 1.5 ) algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Simulation results. Left: A binary pattern used in simulation experiments. Right: F-measures obtained with various edge detection algorithms as a function of SNR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Result of applying various edge detection algorithms to the noisy simulation image, at SNR 2 (top), and SNR 3 (bottom). From left to right: Input image, our O(N 1.5 ), Canny and PMI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>Simulation results with the noisy BSDS-500 images. Left: Precision vs. Recall (PR) of contour detection by various algorithms. Right: Performance table. ODS refers to the F-Measure at the optimal threshold across the entire dataset, OIS to the best per image F-measure, and AP to the area under the PR curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 .</head><label>10</label><figDesc>Real images: Each row shows the original image and a comparison of our binary result, with those obtained by Canny (middle) and by PMI (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Table 1. Average F-measures obtained in simulations computed over images in three SNR ranges.</figDesc><table>Algorithm \ SNR Range 
0.0-0.8 
1.0-1.6 
1.8-2.0 
Our O(N 1.5 ) detector 
0.14 
0.73 
0.85 
Our O(N log N ) detector 
0.12 
0.7 
0.83 
Canny 
0.11 
0.57 
0.71 
BM3D+Canny 
0.04 
0.57 
0.75 
SE 
0.03 
0.09 
0.14 
MCG 
0.02 
0.04 
0.23 
PMI 
0.02 
0.06 
0.09 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Detecting faint curved edges in noisy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Alpert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th European conference on Computer vision: Part IV, ECCV&apos;10</title>
		<meeting>the 11th European conference on Computer vision: Part IV, ECCV&apos;10<address><addrLine>Berlin, Heidelberg; . 2, 6, 8</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="750" to="763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Contour detection and hierarchical image segmentation. pami</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="896" to="916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">From contours to regions: An empirical evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiscale combinatorial grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pont-Tuset</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deployment of an imaging system to investigate fine-scale spatial distribution of early life stages of the ctenophore mnemiopsis leidyi in chesapeake bay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Benfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Houde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Plankton Research</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="270" to="280" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR &apos;05</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A computational approach to edge detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="679" to="698" />
			<date type="published" when="1986-06-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Introduction to algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Cormen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Rivest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>MIT press Cambridge</publisher>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Image denoising with block-matching and 3d filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Electronic ImagingŠ06</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Structured forests for fast edge detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Beamlets and multiscale image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multiscale and Multiresolution Methods</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="149" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multiscale edge detection and fiber enhancement using differences of oriented means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Lsd: A line segment detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grompone Von Gioi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jakubowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Randall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Processing On Line</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="35" to="55" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Detection of long edges on a computational budget: A sublinear approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Horev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arias-Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="458" to="483" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Crisp boundary detection using pointwise mutual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Theory of Edge Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hildreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Royal Society of London. Series B</title>
		<meeting>the Royal Society of London. Series B</meeting>
		<imprint>
			<date type="published" when="1167" />
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="page" from="187" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning to detect natural image boundaries using local brightness, color, and texture cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="530" to="549" />
			<date type="published" when="2004-05-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Camera models and machine perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PhD thesis</title>
		<imprint>
			<date type="published" when="1970" />
		</imprint>
		<respStmt>
			<orgName>Electrical Engineering Department, Stanford University.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bilateral filtering for gray and color images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manduchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth International Conference on</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="839" to="846" />
		</imprint>
	</monogr>
	<note>Computer Vision</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A review of wavelet-based edge detection methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">IJPRAI</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
