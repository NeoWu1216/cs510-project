<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Proposal Flow</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bumsub</forename><surname>Ham</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Inria 2É</orgName>
								<orgName type="institution">cole Normale Supérieure / PSL Research University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Inria 2É</orgName>
								<orgName type="institution">cole Normale Supérieure / PSL Research University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Inria 2É</orgName>
								<orgName type="institution">cole Normale Supérieure / PSL Research University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Ponce</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Inria 2É</orgName>
								<orgName type="institution">cole Normale Supérieure / PSL Research University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Proposal Flow</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Finding image correspondences remains a challenging problem in the presence of intra-class variations and large changes in scene layout. Semantic flow methods are designed to handle images depicting different instances of the same object or scene category. We introduce a novel approach to semantic flow, dubbed proposal flow, that establishes reliable correspondences using object proposals. Unlike prevailing semantic flow approaches that operate on pixels or regularly sampled local regions, proposal flow benefits from the characteristics of modern object proposals, that exhibit high repeatability at multiple scales, and can take advantage of both local and geometric consistency constraints among proposals. We also show that proposal flow can effectively be transformed into a conventional dense flow field. We introduce a new dataset that can be used to evaluate both general semantic flow techniques and region-based approaches such as proposal flow. We use this benchmark to compare different matching algorithms, object proposals, and region features within proposal flow, to the state of the art in semantic flow. This comparison, along with experiments on standard datasets, demonstrates that proposal flow significantly outperforms existing semantic flow methods in various settings.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Classical approaches to finding correspondences across images are designed to handle scenes that contain the same objects with moderate view point variations in applications such as stereo matching <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b46">47]</ref>, optical flow <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b51">52]</ref>, and wide-baseline matching <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b53">54]</ref>. Semantic flow methods, such as SIFT Flow <ref type="bibr" target="#b34">[35]</ref> for example, on the other hand, are designed to handle a much higher degree of variability in appearance and scene layout, typical of images depicting different instances of the same object or scene category. They have proven useful for many tasks such as scene recognition, image registration, semantic segmentation, and image editing and synthesis <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b56">57]</ref>. * indicates equal contribution † WILLOW project-team, Département d'Informatique de l'Ecole Normale Supérieure, ENS/Inria/CNRS UMR 8548.</p><p>‡ Thoth project-team, Inria Grenoble Rhône-Alpes, Laboratoire Jean Kuntzmann.  In this context, however, appearance and shape variations may confuse similarity measures for local region matching, and prohibit the use of strong geometric constraints (e.g., epipolar geometry, limited disparity range). Existing approaches to semantic flow are thus easily distracted by scene elements specific to individual objects and image-specific details (e.g., background, texture, occlusion, clutter). This is the motivation for our work, where we use robust region correspondences to focus on regions containing prominent objects and scene elements rather than clutter and distracting details. Concretely, we introduce an approach to semantic flow computation, called proposal flow, that establishes region correspondences using object proposals and their geometric relations <ref type="figure" target="#fig_1">(Fig. 1)</ref>. Unlike previous semantic flow algorithms <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b56">57]</ref>, that use regular grid structures for local region generation and matching, we leverage a large number of multi-scale object proposals <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b57">58]</ref>, as now widely used in object detection <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b26">27]</ref>. The proposed approach establishes region correspondences by exploiting their visual features and geometric relations in an efficient manner, and generates a region-based semantic flow composed of object proposal matches. We also show that the proposal flow can be effectively transformed into a conventional dense flow field. Finally, we introduce a new dataset that can be used to evalu-ate both general semantic flow techniques and region-based approaches such as proposal flow. We use this benchmark to compare different matching algorithms, object proposals, and region features within proposal flow, to the state of the art in semantic flow. This comparison, along with experiments on standard datasets, demonstrates that proposal flow significantly outperforms existing semantic flow methods in various settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Correspondence problems involve a broad range of topics beyond the scope of this paper. Here we briefly describe the context of our approach, and only review representative works pertinent for ours. Classical approaches to stereo matching and optical flow estimate pixel-level dense correspondences between two nearby images of the same scene <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42]</ref>. While advances in invariant feature detection and description have revolutionized object recognition and reconstruction in the past 15 years, research on image matching and alignment between images have long been dominated by instance matching with the same scene and objects <ref type="bibr" target="#b17">[18]</ref>. Unlike these, several recent approaches to semantic flow focus on handling images containing different scenes and objects. Graph-based matching algorithms <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14]</ref> attempt to find category-level feature matches by leveraging a flexible graph representation of images, but they commonly handle sparsely sampled or detected features due to their computational complexity. Inspired by classic optical flow algorithms, Liu et al. pioneered the idea of dense correspondences across different scenes, and proposed the SIFT Flow <ref type="bibr" target="#b34">[35]</ref> algorithm that uses a multi-resolution image pyramid together with a hierarchical optimization technique for efficiency. Kim et al. <ref type="bibr" target="#b28">[ 29]</ref> extended the approach by inducing a multi-scale regularization with a hierarchically connected pyramid of grid graphs. More recently, Long et al. <ref type="bibr" target="#b35">[ 36]</ref> have investigated the effect of pretrained ConvNet features on the SIFT Flow algorithm, and Bristow et al. <ref type="bibr" target="#b3">[ 4]</ref> have proposed an exemplar-LDA approach that improves the performance of semantic flow. Despite differences in graph construction, optimization, and similarity computation, existing semantic flow approaches share grid-based regular sampling and spatial regularization: The appearance similarity is defined at each region or pixel on (a pyramid of) regular grids, and spatial regularization is imposed between neighboring regions in the pyramid models <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b34">35]</ref>. In contrast, our work builds on generic object proposals with diverse spatial supports <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b57">58]</ref>, and uses an irregular form of spatial regularization based on co-occurrence and overlap of the proposals. We show that the use of local regularization with object proposals yields substantial gains in generic region matching and semantic flow, in particular when handling images with significant clutter and intra-class variations.</p><p>Object proposals <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b57">58]</ref> have originally been developed for object detection, where they are used to reduce the search space as well as false alarms. They are now an important component in many state-of-the-art detection pipelines <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b26">27]</ref>. Despite their success on object detection and segmentation, they have seldom been used in matching tasks <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26]</ref>. In particular, while Cho et al. <ref type="bibr" target="#b8">[9]</ref> have shown that object proposals are useful for region matching due to their high repeatability on salient part regions, the use of object proposals has never been thoroughly investigated in semantic flow computation. The approach proposed in this paper is a first step in this direction, and we explore how the choice of object proposals, matching algorithms, and features affects matching robustness and accuracy.</p><p>Contributions. The contributions of this paper are threefold: (i) We introduce the proposal flow approach to establishing robust region correspondences between related, but not identical scenes using object proposals. (ii) We introduce a benchmark for semantic flow that can be used to evaluate both general semantic flow algorithms and region matching methods. (iii) We demonstrate the advantage of proposal flow over state-of-the-art semantic flow methods through extensive experimental evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposal flow</head><p>Proposal flow can use any type of object proposals <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b57">58]</ref> as candidate regions for matching two images of related scenes. In this section, we introduce a probabilistic model for region matching, and describe three matching strategies including two baselines and a new one using local regularization. We then describe our approach to generating a dense flow field from the region matches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">A Bayesian model for region matching</head><p>Let us suppose that two sets of object proposals R and R 0 have been extracted from images I and I 0 ( <ref type="figure">Fig. 2(a-b)</ref>). A proposal r in R is an image region r =( f, s) with appearance feature f and spatial support s. The appearance feature represents a visual descriptor for the region (e.g., SPM <ref type="bibr" target="#b30">[31]</ref> , HOG <ref type="bibr" target="#b10">[11]</ref>, ConvNet <ref type="bibr" target="#b29">[30]</ref>), and the spatial support describes the set of all pixel positions in the region, that forms a rectangular box in this work. Given the data D =( R, R 0 ), we wish to estimate a posterior probability of the event r 7 ! r 0 meaning that proposal r in R matches proposal r 0 in R 0 :</p><formula xml:id="formula_0">p(r 7 ! r 0 |D)=p(f 7 ! f 0 )p(s 7 ! s 0 |D),<label>(1)</label></formula><p>where we decouple the probabilities of appearance and spatial support matching, and assume that appearance matching is independent of D. In practice, the appearance term p(f 7 ! f 0 ) is simply computed from a similarity between feature descriptors f and f 0 , and the geometric consistency term p(s 7 ! s 0 |D ) is evaluated by comparing the spatial supports s and s 0 in the context of the given data D, as described in the next section. We set the posterior probability (a) Input images.</p><p>(b) Object proposals <ref type="bibr" target="#b50">[51]</ref>.</p><p>(c) Object proposals near the front wheel.</p><p>(d) NAM.</p><p>(e) PHM <ref type="bibr" target="#b8">[9]</ref>. (f) LOM. <ref type="figure">Figure 2</ref>. Top: (a-b) Two images and their object proposals <ref type="bibr" target="#b50">[51]</ref>. (c) Multi-scale object proposals contain the same object or parts, but they are not perfectly repeatable across different images. Bottom: In contrast to NAM (d), PHM <ref type="bibr" target="#b8">[9]</ref> (e) and LOM (f) both exploit geometric consistency, which regularizes proposal flow. In particular, LOM imposes local smoothness on offsets between neighboring regions, avoiding the problem of using a global consensus on the offset in PHM <ref type="bibr" target="#b8">[9]</ref>. The matching score is color-coded for each match (red: high, blue: low). The HOG descriptor <ref type="bibr" target="#b10">[11]</ref> is used for appearance matching in this example. (Best viewed in color.) as a matching score and assign the best match φ(r) for each proposal in R:</p><formula xml:id="formula_1">φ(r)=argmax r 0 2R 0 p(r 7 ! r 0 |D).<label>(2)</label></formula><p>Using a slight abuse of notation, if (f 0 ,s 0 )=φ(f, s), we will write f 0 = φ(f ) and s 0 = φ(s).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Geometric matching strategies</head><p>We now introduce three matching strategies, using different geometric consistency terms p(s 7 ! s 0 |D). Naive appearance matching (NAM). A straightforward way of matching regions is to use a uniform distribution for the geometric term so that</p><formula xml:id="formula_2">p(r 7 ! r 0 |D) / p(f 7 ! f 0 ).</formula><p>(</p><p>NAM considers appearance only, and does not reflect any geometric relationship among regions ( <ref type="figure">Fig. 2(d)</ref>). Probabilistic Hough matching (PHM). The matching algorithm in <ref type="bibr" target="#b8">[9]</ref> can be expressed in our model as follows. First, a three-dimensional location vector (center position and scale) is extracted from the spatial support s. We denote it by a function γ. An offset space X is defined as a feasible set of offset vectors between γ(s) and γ(s 0 ):</p><formula xml:id="formula_4">X = {γ(s) − γ(s 0 ) | r 2R ,r 0 2R 0 }. The geometric consistency term p(s 7 ! s 0 |D) is then defined as p(s 7 ! s 0 |D)= X x2X p(s 7 ! s 0 | x)p(x |D),<label>(4)</label></formula><formula xml:id="formula_5">which assumes that p(s 7 ! s 0 | x, D)=p(s 7 ! s 0 | x).</formula><p>Here, p(s 7 ! s 0 | x) measures an offset consistency between γ(s) − γ(s 0 ) and x by a Gaussian kernel in the threedimensional offset space. From this model, PHM substitutes p(x |D) with a generalized Hough transform score:</p><formula xml:id="formula_6">h(x |D)= X (r,r 0 )2D p(f 7 ! f 0 )p(s 7 ! s 0 | x).<label>(5)</label></formula><p>which aggregates individual votes for offset x, from all possible matches in D = R⇥R 0 . Hough voting imposes a spatial regularizer on matching by taking into account a global consensus on the corresponding offset <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b38">39]</ref>. However, it often suffers from background clutter that distracts the global voting process ( <ref type="figure">Fig. 2</ref>(e)).</p><p>Local offset matching (LOM). Here we propose a new method to overcome this drawback of PHM <ref type="bibr" target="#b8">[9]</ref> and obtain more reliable correspondences. Object proposals often contain a large number of distracting outlier regions from background clutter, and are not perfectly repeatable even for corresponding object or parts across different images ( <ref type="figure">Fig.  2</ref>(c)). The global Hough voting in PHM has difficulties with such outlier regions. In contrast, we optimize a translation and scale offset for each proposal by exploiting only neighboring proposals. That is, instead of averaging p(s 7 ! s 0 |x) over all feasible offsets X in PHM, we use one reliable offset optimized for each proposal. This local approach substantially alleviates the effect of outlier regions in matching as will be demonstrated by our experiment results. The main issue is how to estimate a reliable offset for each proposal r in a robust manner without any information about objects and their locations. One way would be to find the corresponding region of the region r through a multi-scale sliding window search in I 0 as in object detection <ref type="bibr" target="#b15">[16]</ref>, but this is expensive. Instead, we assume that nearby regions have similar offsets. For each region r, we first define its neighborhood N (r) as the regions with overlapping spatial support:</p><formula xml:id="formula_7">N (r)={r | s \ŝ 6 = ;,r 2R}.<label>(6)</label></formula><p>Using an initial correspondence φ(r), determined by the best match according to the appearance term, each neighboring regionr is assigned its own offset, and all of them form a set of neighbor offsets:</p><formula xml:id="formula_8">X (r)={γ(ŝ) − γ(φ(ŝ)) |r 2N(r)}.<label>(7)</label></formula><p>From this set of neighbor offsets, we estimate a local offset x ⇤ r for the region r by the geometric median <ref type="bibr" target="#b36">[37]</ref> 1 :</p><formula xml:id="formula_9">x ⇤ r = argmin x2R 3 X y2X (r) kx − yk 2 ,<label>(8)</label></formula><p>which can be globally optimized by Weiszfeld's algorithm <ref type="bibr" target="#b5">[6]</ref> using a form of iteratively re-weighted least squares. Based on the local offset x ⇤ r optimized for each region, we define the geometric consistency function:</p><formula xml:id="formula_10">g(s 7 ! s 0 |D)=p(s 7 ! s 0 |x ⇤ r ) X r2N (r) p(f 7 ! φ(f )), (9)</formula><p>which means that r in R is likely to match with r 0 in R 0 if their offset is close to the local offset x ⇤ r , and r has many neighboring matches with a high appearance fidelity.</p><p>By using g(s 7 ! s 0 |D) as a proxy for p(s 7 ! s 0 |D), LOM imposes local smoothness on offsets between neighboring regions. This geometric consistency function effectively suppresses matches between clutter regions, while favoring matches between regions that contain objects rather than object parts ( <ref type="figure">Fig. 2(f)</ref>). In particular, the use of local offsets optimized for each proposal regularizes offsets within a local neighborhood that incorporates an overlap relationship between spatial supports of regions. This local regularization avoids a common problem with PHM, where the matching results often depend on a few strong matches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Flow field generation</head><p>The proposal flow gives a set of region correspondences between images, but it can be easily transformed into a conventional dense flow field. Let p denote a pixel in image I (yellow point in <ref type="figure" target="#fig_4">Fig. 3(a)</ref>). For each pixel p, its neighborhood is defined as the region in which it lies, i.e., N (p)={r 2R: p 2 r}. We define an anchor match (r ⇤ ,φ(r ⇤ )) as the region correspondence that has the highest matching score among neighboring regions (red boxes in <ref type="figure" target="#fig_4">Fig. 3</ref>(a)) where</p><formula xml:id="formula_11">r ⇤ = argmax r2N (p) p(r 7 ! φ(r) |D).<label>(10)</label></formula><p>Note that the anchor match contains information on translation and scale changes between objects. Using the geometric relationships between the pixel p and its anchor match (r ⇤ ,φ(r ⇤ )), a correspondence p 0 in I 0 (green point in <ref type="figure" target="#fig_4">Fig.  3(a)</ref>) is obtained by linear interpolation. The matching score for each correspondence is set to the value of its anchor match. When p and q in I are matched <ref type="bibr" target="#b0">1</ref> We found that the centroid and mode of the offset vectors in threedimensional offset space show worse performance than the geometric median. This is because the neighboring regions may include clutter. Clutter causes incorrect neighbor offsets, but the geometric median is robust to outliers <ref type="bibr" target="#b16">[17]</ref>, providing a reliable local offset.   The LOM method is used for region matching with the object proposals <ref type="bibr" target="#b39">[40]</ref> and the HOG descriptor <ref type="bibr" target="#b10">[11]</ref>. (Best viewed in color.)</p><p>to the same pixel p 0 in I 0 , we select the match with the highest matching score and delete the other one. Finally, joint image filtering <ref type="bibr" target="#b20">[21]</ref> is applied under the guidance of the image I to interpolate the flow field in places without correspondences. <ref type="figure" target="#fig_4">Figure 3(b-c)</ref> shows examples of the estimated flow field and corresponding warping result between two images: Using the dense flow field, we warp all pixels in the right image to the left image. Our approach using the anchor match aligns semantic object parts well while handling translation and scale changes between objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">A new dataset for semantic flow evaluation</head><p>Current research on semantic flow lacks an appropriate benchmark with dense ground-truth correspondences. Conventional optical flow benchmarks (e.g., Middlebury <ref type="bibr" target="#b1">[2]</ref> and MPI-Sintel <ref type="bibr" target="#b4">[5]</ref>) do not feature within-class variations, and ground truth for generic semantic flow is difficult to capture due to its intrinsically semantic nature, manual annotation being extremely labor intensive and somewhat subjective. All existing approaches are thus evaluated only with sparse ground truth or in an indirect manner (e.g. mask transfer accuracy) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b56">57]</ref>. Such benchmarks only evaluate a small number of matches, that occur at groundtruth keypoints or around mask boundaries in a point-wise manner. To address this issue, we introduce in this section a new dataset for semantic flow, dubbed proposal flow (PF) dataset, built using ground-truth object bounding boxes and keypoint annotations, <ref type="figure" target="#fig_6">(Fig. 4(a-b)</ref>), and propose new evalu-  ation metrics for region-based semantic flow methods such as proposal flow. Note that while designed for region-based methods, our benchmark can be used to evaluate any semantic flow technique. As will be seen in our experiments, it provides a reasonable (if approximate) ground truth for dense correspondences across similar scenes without an extremely expensive annotation campaign. As shown in the following sections, comparative evaluations on this dataset are also good predictors for performance on other tasks and datasets, further justifying the use of our benchmark. In the following, we describe our ground-truth generation process, evaluation criteria, and datasets. The benchmark data and code are available online: http://www.di.ens.fr/ willow/research/proposalflow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Ground-truth correspondence generation</head><p>We assume that true matches only exist within object bounding boxes. Let us assume two sets of keypoint annotations at positions k i and k 0 i in I and I 0 , respectively, with i =1 ,...,m. Assuming the objects present in the images and their parts may undergo shape deformation, we use thin plate splines (TPS) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13]</ref> to interpolate the sparse keypoints. Namely, the ground truth is approximated from sparse correspondences using TPS warping.</p><p>For each region, its ground-truth match is generated as follows. We assume that true matches only exist between a subset of regions, i.e., regions around object bounding boxes <ref type="figure" target="#fig_6">(Fig. 4(c)</ref>): R s = {r ||b \ r| / |r|≥0.75,r 2R} where b denotes an object bounding box in I, and |r| indicates the area of a region r. For each region r 2R s , the four vertices of the rectangle are warped to the corresponding ones in I 0 by the TPS mapping function. The region formed by the warped points is a correspondence of region r. We fit a tight rectangle for this region and set it as a ground-truth correspondence for the region r <ref type="figure" target="#fig_6">(Fig. 4(d)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation criteria</head><p>We introduce two evaluation metrics for region matching performance in terms of region matching precision and match retrieval accuracy. Basically, the metrics build on the intersection over union (IoU) score between r's correspondence φ(r) and its ground truth r ? :</p><formula xml:id="formula_12">IoU(φ(r),r ? )=|φ(r) \ r ? | / |φ(r) [ r ? |.<label>(11)</label></formula><p>For region matching precision, we propose the probability of correct region (PCR) metric 2 where region r is correctly matched to its ground truth r ? if 1 − IoU(φ(r),r ? ) &lt;τ (e.g., <ref type="figure" target="#fig_8">Fig. 5(a) top)</ref>. We measure the PCR metric while varying the IoU threshold τ from 0 to 1. For match retrieval accuracy, we propose the average IoU of k-best matches (mIoU@k) according to the matching score (e.g., <ref type="figure" target="#fig_8">Fig. 5</ref>(a) bottom). We measure the mIoU@k metric while increasing the number of top matches k. These two metrics exhibit two important characteristics of matching: the PCR reveals the accuracy of overall assignment, and the mIoU@k shows the reliability of matching scores that is crucial in match selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Dataset construction</head><p>To generate our dataset, we start from the benchmark for sparse matching of Cho et al. <ref type="bibr" target="#b7">[8]</ref>, which consists of 5 object classes (Face, Car, Motorbike, Duck, WineBottle) with 10 keypoint annotations for each image. Note that these images contain more clutter and intra-class variation than existing datasets for semantic flow evaluation, e.g., images with tightly cropped objects or similar background <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b56">57]</ref>. We exclude the Face class where the number of generated object proposals is not sufficient to evaluate matching accuracy. The other classes are split into sub-classes 3 according to viewpoint or background clutter. We obtain a total of 10 sub-classes. Given these images and regions, we generate ground-truth data between all possible image pairs within each class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental details</head><p>Object proposals. We evaluate four state-of-the-art object proposal methods: EdgeBox (EB) <ref type="bibr" target="#b57">[58]</ref>, multiscale combinatorial grouping (MCG) <ref type="bibr" target="#b0">[1]</ref>, selective search (SS) <ref type="bibr" target="#b50">[51]</ref>, and randomized prim (RP) <ref type="bibr" target="#b39">[40]</ref>. In addition, we consider three baseline proposals <ref type="bibr" target="#b23">[24]</ref>: Uniform sampling (US), Gaussian sampling (GS), and sliding window (SW). See <ref type="bibr" target="#b23">[24]</ref> for more details. For fair comparison, we use 1,000 proposals for all the methods. To control the number of proposals, we use the proposal score provided by EB, MCG, and SS. For RP, we randomly select among the proposals. Feature descriptors and similarity. We evaluate three popular feature descriptors: SPM <ref type="bibr" target="#b30">[31]</ref>, HOG <ref type="bibr" target="#b10">[11]</ref>, and Con-vNet <ref type="bibr" target="#b29">[30]</ref>. For SPM, dense SIFT features <ref type="bibr" target="#b37">[38]</ref> are extracted every 4 pixels and each descriptor is quantized into a 1,000 word codebook <ref type="bibr" target="#b47">[48]</ref>. For each region, a spatial pyramid pooling <ref type="bibr" target="#b30">[31]</ref> is used with 1⇥1 and 3⇥3 pooling regions. We compute the similarity between SPM descriptors by the χ 2 kernel. HOG features are extracted with 8 ⇥ 8 cells and 31 orientations, then whitened. For ConvNet features, we use each output of the 5 convolutional layers in AlexNet <ref type="bibr" target="#b29">[30]</ref>, which is pre-trained on the ImageNet dataset <ref type="bibr" target="#b11">[12]</ref>. For HOG and ConvNet, the dot product is used as a similarity metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Proposal flow components</head><p>We use the PF benchmark in this section to compare three variants of proposal flow using different matching algorithms (NAM, PHM, LOM), combined with various object proposals <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b57">58]</ref>, and features <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>. <ref type="figure" target="#fig_6">Figure 4</ref>(e-g) shows a qualitative comparison between region matching algorithms on a pair of images and depicts correct matches found by each variant of proposal flow. In this example, at the IoU threshold 0.5, the numbers of correct matches are 16, 5, and 38 for NAM, PHM <ref type="bibr" target="#b8">[9]</ref>, and LOM, respectively. This shows that PHM may give worse performance than even NAM when much clutter exists in background. In contrast, the local regularization in LOM alleviates the effect of such clutter. <ref type="figure" target="#fig_8">Figure 5</ref> summarizes the matching and retrieval performance on average for all object classes with a variety of combination of object proposals, feature descriptors, and matching algorithms. <ref type="figure" target="#fig_8">Figure 5</ref>(a) compares different types of object proposals with fixed matching algorithm and feature descriptor (LOM w/ HOG). RP shows the best matching precision and retrieval accuracy among the object proposals. An upper bound on precision is measured for object proposals (around a given object) in the image I using a corresponding ground truths in image I 0 , that is the best matching accuracy we can achieve with each proposal method. The upper bound (UB) plots show that RP generates more consistent regions than other proposal methods, and is adequate for region matching. RP shows higher matching precision than other proposals especially when the IoU threshold is low. The evaluation results for different features (LOM w/ RP) are shown in <ref type="figure" target="#fig_8">Fig. 5(b)</ref>. The HOG descriptor gives the best performance in matching and retrieval. The CNN features in our comparison come from AlexNet <ref type="bibr" target="#b29">[30]</ref> trained for ImageNet classification. Such CNN features have a task-specific bias to capture discriminative parts for classification, which may be less adequate for patch correspondence or retrieval than engineered features such as HOG. Similar conclusions are found in recent papers <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b42">43]</ref>. See, for example, <ref type="table" target="#tab_2">Table 3</ref> in <ref type="bibr" target="#b42">[43]</ref> where SIFT outperforms all AlexNet features (Conv1-5). Among ConvNet features, the fourth and first convolutional layers (Conv4 and Conv1) show the best and worst performance, respectively, while other layers perform similar to SPM. This confirms the finding in <ref type="bibr" target="#b55">[56]</ref>, which shows that Conv4 gives the best matching performance among ImageNet-trained ConvNet features. <ref type="figure" target="#fig_8">Figure 5</ref>(c) compares the performance of different matching algorithms (RP w/ HOG), and shows that LOM outperforms others in matching as well as retrieval. <ref type="figure" target="#fig_8">Figure 5</ref>(d and e) shows the area under curve (AuC) for PCR and mIoU@k plots, respectively. This suggests that combining LOM, RP, and HOG performs best in both metrics.</p><p>In <ref type="table" target="#tab_1">Table 1</ref>, we show AuCs of PCR plots for each class (LOM w/ RP and HOG). From this table, we can see that 1) higher matching precision is achieved with objects having a similar pose (e.g., mot(S) vs. mot(M)), 2) performance decreases for deformable object matching (e.g., duck(S) vs. car(S)), and 3) matching precision can increase drastically by eliminating background clutters (e.g., win(w/o C) vs. win(w/ C)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Flow field</head><p>To compare our method with state-of-the-art semantic flow methods, we compute a dense flow field from    DeepFlow <ref type="bibr" target="#b45">[46]</ref> 0.20 GMK <ref type="bibr" target="#b13">[14]</ref> 0.27 SIFT Flow <ref type="bibr" target="#b34">[35]</ref> 0.38 DSP <ref type="bibr" target="#b28">[29]</ref> 0.37 our proposal flows (Sec. 3.3), and evaluate image alignment between all pairs of images in each subset of the PF dataset. We test four object proposal methods (MCG, EB, SS, RP) with HOG descriptors. For an evaluation metric, we use PCK between warped keypoints and ground-truth ones <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b54">55]</ref>. Ground-truth keypoints are deemed to be correctly predicted if they lie within αmax(h, w) pixels of the predicted points for α in [0, 1], where h and w are the height and width of the object bounding box, respectively. <ref type="table">Table 2</ref> shows the average PCK (α =0 .1) over all object classes. In our benchmark, all versions of proposal flow significantly outperform SIFT Flow <ref type="bibr" target="#b34">[35]</ref>, DSP <ref type="bibr" target="#b28">[29]</ref>, and Deep-Flow <ref type="bibr" target="#b45">[46]</ref>. LOM with SS or RP outperforms other combination of matching and proposal methods, which coincides with the results in Sec 5.2. <ref type="figure" target="#fig_10">Figure 6</ref> gives a qualitative comparison with the state of the art on the PF dataset. The better alignment found by proposal flow here is typical of our experiments. Specifically, proposal flow is robust to translation and scale changes between objects.</p><p>Matching results on Caltech-101. We also evaluate our approach on the Caltech-101 dataset <ref type="bibr" target="#b14">[15]</ref>. Following the experimental protocol in <ref type="bibr" target="#b28">[29]</ref>, we randomly select 15 pairs   <ref type="bibr" target="#b45">[46]</ref>, (d) GMK <ref type="bibr" target="#b13">[14]</ref>, (e) SIFT Flow <ref type="bibr" target="#b34">[35]</ref>, (f) DSP <ref type="bibr" target="#b28">[29]</ref>, and (g) Proposal Flow (LOM w/ RP and HOG). of images for each object class, and evaluate matching accuracy with three metrics: Label transfer accuracy (LT-ACC) <ref type="bibr" target="#b33">[34]</ref>, the IoU metric, and the localization error (LOC-ERR) of corresponding pixel positions. For LT-ACC, we transfer the class label of one image to the other using dense correspondences, and count the number of correctly labeled pixels. Similarly, the IoU score is measured between the transferred label and ground truth. <ref type="table" target="#tab_2">Table 3</ref> compares quantitatively the matching accuracy of proposal flow to the state of the art. It shows that proposal flow using LOM outperforms other approaches, especially for the IoU score and the LOC-ERR of dense correspondences. Note that compared to LT-ACC, these metrics evaluate the matching quality for the foreground object, separate from irrelevant scene clutter. Our results verify that proposal flow focuses on regions containing objects rather than scene clutter and distracting details, enabling robust image matching against outliers.</p><p>Matching results on PASCAL parts. We use the dataset provided by <ref type="bibr" target="#b56">[57]</ref> where the images are sampled from the PASCAL part dataset <ref type="bibr" target="#b6">[7]</ref>. We first measure part matching accuracy using human-annotated part segments. For this experiment, we measure the weighted IoU score between transferred segments and ground truths, with weights determined by the pixel area of each part <ref type="table">(Table 4</ref>). To evaluate alignment accuracy, we measure the PCK metric (α =0.05) using keypoint annotations for the 12 rigid PAS-CAL classes <ref type="bibr" target="#b52">[53]</ref>  <ref type="table">(Table 4</ref>). We use the same set of images as in the part matching experiment. Proposal flow has an advantage over existing approaches on images that contain cluttering elements (e.g., background, instance-specific texture, occlusion), but in this dataset <ref type="bibr" target="#b56">[57]</ref>, such elements are confined to only a small portion of the images, compared to the PF and the Caltech-101 <ref type="bibr" target="#b14">[15]</ref> datasets. This may be a reason that, for the PCK metric, our approach with SS <ref type="bibr" target="#b50">[51]</ref> gives similar results to other methods. While FlowWeb <ref type="bibr" target="#b56">[57]</ref> gives better results than ours, it relies on a cyclic constraint across multiple images (at least, three images). Thus, directly comparing our pairwise matching to FlowWeb is probably not fair. FlowWeb uses the output of DSP <ref type="bibr" target="#b28">[29]</ref> as initial correspondences, and refines them with the cyclic constraint. Since our method clearly outperforms DSP, using FlowWeb as a post processing would likely increase performance.</p><p>For more examples and qualitative results, see our project webpage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>We have presented a robust region-based semantic flow method, called proposal flow, and showed that it can effectively be mapped onto pixel-wise dense correspondences. We have also introduced the PF dataset for semantic flow, and shown that it provides a reasonable benchmark for semantic flow evaluation without extremely expensive manual annotation of full ground truth. Our benchmark can be used to evaluate region-based semantic flow methods and even pixel-based ones, and experiments with the PF dataset demonstrate that proposal flow substantially outperforms existing semantic flow methods. Experiments with Caltech and the VOC parts datasets further validate these results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Proposal flow generates a reliable semantic flow between similar images using local and geometric consistency constraints among object proposals, and it can be transformed into a dense flow field. (a) Region-based semantic flow. (b) Dense flow field and image warping using the flow field. (Best viewed in color.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>match and pixel correspondence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Flow field generation. (a) For each pixel (yellow point), its anchor match (red boxes) is determined. The correspondence (green point) is computed by the transformed coordinate with respect to the position and size of the anchor match. (b) Based on the flow field, (c) the right image is warped to the left image. The warped object shows visually similar shape to the one in the left image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>(a-d) Generating ground-truth regions and evaluating correct matches. (a) Using keypoint annotations, dense correspondences between images are established using warping<ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13]</ref>. (b) Based on the dense correspondences, all pixels in the left image are warped to the right image. (c) We assume that true matches exist only between the regions near the object bounding box, and thus an evaluation is done with the regions in this subset of object proposals. (d) For each object proposal (red box in the left image), its ground truth is generated automatically by the dense correspondences: We use a tight rectangle (red box in the right image) of the region formed by the warped object proposal (yellow box in the right image) as a ground-truth correspondence. (e-g) Examples of correct matches: The numbers of correct matches are 16, 5, and 38 for NAM (e), PHM<ref type="bibr" target="#b8">[9]</ref> (f), and LOM (g), respectively. Matches with IoU score greater than 0.5 are considered as correct in this example. (Best viewed in color.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 .</head><label>5</label><figDesc>PF benchmark evaluation on (a-c) region matching precision (top, PCR plots) and match retrieval accuracy (bottom, mIoU@k plots), and (d-e) AuCs for different combinations of object proposals, feature descriptors, and matching algorithms: (a) Evaluation for LOM with HOG [11], (b) evaluation for LOM with RP [40], (c) evaluation for RP with HOG [11], (d) AuCs for PCR plots, and (e) AuCs for mIoU@k plots. The AuC is shown in the legend. (Best viewed in color.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 .</head><label>6</label><figDesc>Examples of dense flow field. (a-b) Sourse images are warped to the target images using the dense correspondences estimated by (c) DeepFlow</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 .</head><label>1</label><figDesc>AuC performance for PCR plots on the PF dataset (LOM w/ RP and HOG).Table 2. PCK comparison for dense flow field on the PF dataset.</figDesc><table>Methods 
car(S) car(G) car(M) duck(S) mot(S) mot(G) mot(M) win(w/o C) win(w/ C) win(M) Avg. 

LOM 
0.61 
0.50 
0.45 
0.50 
0.42 
0.40 
0.35 
0.69 
0.30 
0.47 
0.47 
Upper bound 0.75 
0.69 
0.69 
0.72 
0.70 
0.70 
0.67 
0.80 
0.68 
0.73 
0.71 

Methods 
MCG [1] EB [58] SS [51] RP [40] 

NAM 
0.46 
0.50 
0.52 
0.53 
PHM 
0.48 
0.45 
0.55 
0.54 
LOM 
0.49 
0.44 
0.56 
0.55 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 .</head><label>3</label><figDesc>Matching accuracy on the Caltech-101 dataset.Table 4. Matching accuracy on the PASCAL VOC classes.</figDesc><table>Proposals Methods LT-ACC IoU LOC-ERR 

SS [51] 

NAM 
0.68 
0.44 
0.41 
PHM 
0.74 
0.48 
0.32 
LOM 
0.78 
0.50 
0.25 

RP [40] 

NAM 
0.70 
0.44 
0.39 
PHM 
0.75 
0.48 
0.31 
LOM 
0.78 
0.50 
0.26 

DeepFlow [46] 
0.74 
0.40 
0.34 
GMK [14] 
0.77 
0.42 
0.34 
SIFT Flow [35] 
0.75 
0.48 
0.32 
DSP [29] 
0.77 
0.47 
0.35 

Proposals Methods IoU PCK 

SS [51] 

NAM 
0.35 0.13 
PHM 
0.39 0.17 
LOM 
0.41 0.17 

Congealing [32] 
0.38 0.11 
RASL [44] 
0.39 0.16 
CollectionFlow [28] 0.38 0.12 
DSP [29] 
0.39 0.17 

FlowWeb [57] 
0.43 0.26 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">This region-based metric is based on a conventional point-based metric, the probability of correct keypoint (PCK)<ref type="bibr" target="#b54">[55]</ref>. In the case of pixelbased flow, PCK can be adopted instead.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">They are car (S), (G), (M), duck (S), motorbike (S), (G), (M), wine bottle (w/o C), (w/ C), (M), where (S) and (G) denote side and general viewpoints, respectively. (C) stands for background clutter, and (M) denotes mixed viewpoints (side + general) for car and motorbike classes and a combination of images in wine bottle (w/o C + w/ C) for the wine bottle class. The dataset has 10 images for each class, thus 100 images in total.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. This work was supported by the ERC grants VideoWorld and Allegro, and the Institut Universitaire de France.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multiscale combinatorial grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pont-Tuset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A database and evaluation methodology for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Principal warps: Thin-plate splines and the decomposition of deformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">L</forename><surname>Bookstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="567" to="585" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dense semantic correspondence where every pixel is a classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bristow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Valmadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A naturalistic open source movie for optical flow evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<idno>ECCV. 2012. 4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Open questions concerning weiszfeld&apos;s algorithm for the fermat-weber location problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="293" to="295" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Detect what you can: Detecting and representing objects using holistic models and body parts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning graphs to match</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Alahari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unsupervised object discovery and localization in the wild: Part-based matching using bottom-up region proposals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Progressive graph matching: Making a move of graphs via probabilistic voting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<idno>CVPR. 2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno>CVPR. 6</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Approximate thin plate spline mappings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Donato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A graph-matching kernel for object categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Duchenne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">One-shot learning of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>TPAMI</publisher>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="594" to="611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A discriminatively trained, multiscale, deformable part model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Robust statistics on riemannian manifolds via the geometric median</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkatasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Computer vision: A modern approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Forsyth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision: A Modern Approach</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Non-rigid dense correspondence with applications for image enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hacohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOG</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">70</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Robust image filtering using joint static and dynamic guidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On SIFTs and their scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mayzels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Determining optical flow: A retrospective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">G</forename><surname>Schunck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="87" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">What makes for effective detection proposals? TPAMI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hosang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Generalized deformable spatial pyramid: Geometry-preserving dense correspondence estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Ahn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Matching bags of regions in RGBD images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Spatial pyramid pooling in deep convolutional networks for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kaiming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiangyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shaoqing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Collection flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deformable spatial pyramid matching for fast dense correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learned-Miller. Data driven image models through continuous joint alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="236" to="250" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Robust object detection with interleaved categorization and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">IJCV</biblScope>
			<biblScope unit="page" from="259" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Nonparametric scene parsing via label transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2368" to="2382" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">SIFT flow: Dense correspondence across scenes and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="978" to="994" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Do convnets learn correspondence? In NIPS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Breakdown points of affine equivariant estimators of multivariate location and covariance matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Lopuhaa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="229" to="248" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Object detection using a max-margin hough transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Prime object proposals with randomized Prim&apos;s algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Manen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Robust widebaseline stereo from maximally stable extremal regions. Image and vision computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="761" to="767" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A multiple-baseline stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="353" to="363" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Local convolutional features with unsupervised training for image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Rasl: Robust alignment by sparse and low-rank decomposition for linearly correlated images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2233" to="2246" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Scale-space SIFT flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Deepmatching: Hierarchical deformable dense matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Fast cost-volume filtering for visual correspondence and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hosni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bleyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gelautz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Co-localization in real-world images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Dense correspondences across scenes and scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Dense segmentation-aware descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Trulls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanfeliu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Moreno-Noguer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Selective search for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="154" to="171" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Deepflow: Large displacement optical flow with deep matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Beyond pascal: A benchmark for 3d object detection in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Daisy filter flow: A generalized discrete approach to dense correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Articulated human detection with flexible mixtures of parts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Learning to compare image patches via convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">FlowWeb: Joint image set alignment by weaving consistent, pixel-wise correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Edge boxes: Locating object proposals from edges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
