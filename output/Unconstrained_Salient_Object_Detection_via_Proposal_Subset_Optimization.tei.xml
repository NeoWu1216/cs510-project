<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unconstrained Salient Object Detection via Proposal Subset Optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianming</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Boston University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Sclaroff</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Boston University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Lin</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Adobe Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Adobe Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Price</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Adobe Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radomír</forename><surname>Mȇch</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Adobe Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Unconstrained Salient Object Detection via Proposal Subset Optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We aim at detecting salient objects in unconstrained images. In unconstrained images, the number of salient objects (if any) varies from image to image, and is not given. We present a salient object detection system that directly outputs a compact set of detection windows, if any, for an input image. Our system leverages a Convolutional-Neural-Network model to generate location proposals of salient objects. Location proposals tend to be highly overlapping and noisy. Based on the Maximum a Posteriori principle, we propose a novel subset optimization framework to generate a compact set of detection windows out of noisy proposals. In experiments, we show that our subset optimization formulation greatly enhances the performance of our system, and our system attains 16-34% relative improvement in Average Precision compared with the state-of-the-art on three challenging salient object datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In this paper, we aim at detecting generic salient objects in unconstrained images, which may contain multiple salient objects or no salient object. Solving this problem entails generating a compact set of detection windows that matches the number and the locations of salient objects. To be more specific, a satisfying solution to this problem should answer the following questions:</p><p>1. (Existence) Is there any salient object in the image? 2. (Localization) Where is each salient object, if any?</p><p>These two questions are important not only in a theoretic aspect, but also in an applicative aspect. First of all, a compact and clean set of detection windows can significantly reduce the computational cost of the subsequent process (e.g. object recognition) applied on each detection window <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b35">36]</ref>. Furthermore, individuating each salient object (or reporting that no salient object is present) can critically alleviate the ambiguity in the weakly supervised or unsupervised learning scenario <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b54">55]</ref>, where object appearance models are to be learned with no instance level annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>Output <ref type="figure">Figure 1</ref>: Our system outputs a compact set of detection windows (shown in the bottom row) that localize each salient object in an image. Note that for the input image in the right column, where no dominant object exists, our system does not output any detection window.</p><p>However, many previous methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b53">54]</ref> only solve the task of foreground segmentation, i.e. generating a dense foreground mask (saliency map). These methods do not individuate each object. Moreover, they do not directly answer the question of Existence. In this paper, we will use the term salient region detection when referring to these methods, so as to distinguish from the salient object detection task solved by our approach, which includes individuating each of the salient objects, if there are any, in a given input image.</p><p>Some methods generate a ranked list of bounding box candidates for salient objects <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b51">52]</ref>, but they lack an effective way to fully answer the questions of Existence and Localization. In practice, they just produce a fixed number of location proposals, without specifying the exact set of detection windows. Other salient object detection methods simplify the detection task by assuming the existence of one and only one salient object <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b31">32]</ref>. This overly strong assumption limits their usage on unconstrained images.</p><p>In contrast to previous works, we present a salient object detection system that directly outputs a compact set of detections windows for an unconstrained image. Some example outputs of our system are shown in <ref type="figure">Fig. 1</ref>.</p><p>Our system leverages the high expressiveness of a Convolutional Neural Network (CNN) model to generate a set of scored salient object proposals for an image. Inspired by the attention-based mechanisms of <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b34">35]</ref>, we propose an Adaptive Region Sampling method to make our CNN model "look closer" at promising images regions, which substantially increases the detection rate. The obtained proposals are then filtered to produce a compact detection set.</p><p>A key difference between salient object detection and object class detection is that saliency greatly depends on the surrounding context. Therefore, the salient object proposal scores estimated on local image regions can be inconsistent with the ones estimated on the global scale. This intrinsic property of saliency detection makes our proposal filtering process challenging. We find that using the greedy Non-maximum Suppression (NMS) method often leads to sub-optimal performance in our task. To attack this problem, we propose a subset optimization formulation based on the maximum a posteriori (MAP) principle, which jointly optimizes the number and the locations of detection windows. The effectiveness of our optimization formulation is validated on various benchmark datasets, where our formulation attains about 12% relative improvement in Average Precision (AP) over the NMS approach.</p><p>In experiments, we demonstrate the superior performance of our system on three benchmark datasets: MSRA <ref type="bibr" target="#b28">[29]</ref>, DUT-O <ref type="bibr" target="#b50">[51]</ref> and MSO <ref type="bibr" target="#b52">[53]</ref>. In particular, the MSO dataset contains a large number of background/cluttered images that do not contain any dominant object. Our system can effectively handle such unconstrained images, and attains about 16-34% relative improvement in AP over previous methods on these datasets.</p><p>To summarize, the main contributions of this work are:</p><p>• A salient object detection system that outputs compact detection windows for unconstrained images, • A novel MAP-based subset optimization formulation for filtering bounding box proposals, • Significant improvement over the state-of-the-art methods on three challenging benchmark datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>We review some previous works related to our task. Salient region detection. Salient region detection aims at generating a dense foreground mask (saliency map) that separates salient objects from the background of an image <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b24">25]</ref>. Some methods allow extraction of multiple salient objects <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b27">28]</ref>. However, these methods do not individuate each object.</p><p>Salient object localization. Given a saliency map, some methods find the best detection window based on heuristics <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b31">32]</ref>. Various segmentation techniques are also used to generate binary foreground masks to facilitate object localization <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b30">31]</ref>. A learning-based regression approach is proposed in <ref type="bibr" target="#b48">[49]</ref> to predict a bounding box for an image. Most of these methods critically rely on the assumption that there is only one salient object in an image. In <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b30">31]</ref>, it is demonstrated that segmentationbased methods can localize multiple objects in some cases by tweaking certain parts in their formulation, but they lack a principled way to handle general scenarios.</p><p>Predicting the existence of salient objects. Existing salient object/region detection methods tend to produce undesirable results on images that contain no dominant salient object <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b5">6]</ref>. In <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b39">40]</ref>, a binary classifier is trained to detect the existence of salient objects before object localization. In <ref type="bibr" target="#b52">[53]</ref>, a salient object subitizing model is proposed to suppress the detections on background images that contain no salient object. While all these methods use a separately trained background image detector, we provide a unified solution to the problems of Existence and Localization through our subset optimization formulation.</p><p>Object proposal generation. Object proposal methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b11">12]</ref> usually generate hundreds or thousands of proposal windows in order to yield a high recall rate. While they can lead to substantial speed-ups over sliding window approaches for object detection, these proposal methods are not optimized for localizing salient objects. Some methods <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b20">21]</ref> generate a ranked list of proposals for salient objects in an image, and can yield accurate localization using only the top few proposals. However, these methods do not aim to produce a compact set of detection windows that exactly match the ground-truth objects.</p><p>Bounding box filtering and NMS. Object detection and proposal methods often produce severely overlapping windows that correspond to a single object. To alleviate this problem, greedy Non-Maximum Suppression (NMS) is widely used due to its simplicity <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b20">21]</ref>. Several limitations of greedy NMS are observed and addressed by <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b37">38]</ref>. In <ref type="bibr" target="#b4">[5]</ref>, an improved NMS method is proposed for Hough transform based object detectors. Desai et al. <ref type="bibr" target="#b13">[14]</ref> use a unified framework to model NMS and object class co-occurrence via Context Cueing. These methods are designed for a particular detection framework, which requires either part-based models or object category information. In <ref type="bibr" target="#b36">[37]</ref>, Affinity Propagation Clustering is used for bounding box filtering. This method achieves more accurate bounding box localization, but slightly compromises Average Precision (AP). In <ref type="bibr" target="#b37">[38]</ref>, Quadratic Binary Optimization is proposed to recover missing detections caused by greedy NMS. Unlike <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref>, our subset optimization formulation aims to handle highly noisy proposal scores, where greedy NMS often leads to a poor detection precision rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">A Salient Object Detection Framework</head><p>Our salient object detection framework comprises two steps. It first generates a set of scored location proposals using a CNN model. It then produces a compact set of detections out of the location proposals using a subset opti-mization formulation. We first present the subset optimization formulation, as it is independent of the implementation of our proposal generation model, and can be useful beyond the scope of salient object detection.</p><p>Given a set of scored proposal windows, our formulation aims to extract a compact set of detection windows based on the following observations.</p><p>I. The scores of location proposals can be noisy, so it is often suboptimal to consider each proposal's score independently. Therefore, we jointly consider the scores and the spatial proximity of all proposal windows for more robust localization. II. Severely overlapping windows often correspond to the same object. On the other hand, salient objects can also overlap each other to varying extents. We address these issues by softly penalizing overlaps between detection windows in our optimization formulation. III. At the same time, we favor a compact set of detections that explains the observations, as salient objects are distinctive and rare in nature <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">MAP-based Proposal Subset Optimization</head><p>Given an image I, a set of location proposals B = {b i : i = 1 . . . n} and a proposal scoring function S, we want to output a set of detection windows O, which is a subset of B. We assume each proposal b i is a bounding box, with a score s i S(b i , I). Given B, the output set O can be represented as a binary indicator vector</p><formula xml:id="formula_0">(O i ) n i=1 , where O i = 1 iff b i is selected as an output.</formula><p>The high-level idea of our formulation is to perform three tasks altogether: 1) group location proposals into clusters, 2) select an exemplar window from each cluster as an output detection, and 3) determine the number of clusters. To do so, we introduce an auxiliary variable X = (x i ) n i=1 . X represents the group membership for each proposal in B, where x i = j if b i belongs to a cluster represented by b j . We also allow x i = 0 if b i does not belong to any cluster. Alternately, we can think that b i belongs to the background. We would like to find the MAP solution w.r.t. the joint distribution P (O, X|I; B, S). In what follows, we omit the parameters B and S for brevity, as they are fixed for an image. According to Bayes' Rule, the joint distribution under consideration can be decomposed as</p><formula xml:id="formula_1">P (O, X|I) = P (I|O, X)P (O, X) P (I) .<label>(1)</label></formula><p>For the likelihood term P (I|O, X), we assume that O is conditionally independent of I given X. Thus,</p><formula xml:id="formula_2">P (I|O, X) = P (I|X) = P (X|I)P (I) P (X) .<label>(2)</label></formula><p>The conditional independence assumption is natural, as the detection set O can be directly induced by the group membership vector X. In other words, representative windows indicated by X should be regarded as detections windows. This leads to the following constraint on X and O:</p><formula xml:id="formula_3">Constraint 1. If ∃x i s.t. x i = j, j = 0, then b j ∈ O.</formula><p>To comply with this constraint, the prior term P (O, X) takes the following form:</p><formula xml:id="formula_4">P (O, X) = Z 1 P (X)L(O)C(O, X),<label>(3)</label></formula><p>where C(O, X) is a constraint compliance indicator function, which takes 1 if Constraint 1 is met, and 0 otherwise. Z 1 is a normalization constant that makes P (O, X) a valid probability mass function. The term L(O) encodes prior information about the detection windows. The definition of P (O, X) assumes the minimum dependency between O and X when Constraint 1 is met. Substituting Eq. 2 and 3 into the RHS of Eq. 1, we have</p><formula xml:id="formula_5">P (O, X|I) ∝ P (X|I)L(O)C(O, X).<label>(4)</label></formula><p>Note that both P (I) and P (X) are cancelled out, and the constant Z 1 is omitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Formulation Details</head><p>We now provide details for each term in Eq. 4, and show the connections with the observations we made.</p><p>Assuming that the x i are independent of each other given I, we compute P (X|I) as follows:</p><formula xml:id="formula_6">P (X|I) = n i=1 P (x i |I),<label>(5)</label></formula><p>where</p><formula xml:id="formula_7">P (x i = j|I) = Z i 2 λ if j = 0; Z i 2 K(b i , b j )s i otherwise.<label>(6)</label></formula><p>Here Z i 2 is a normalization constant such that</p><formula xml:id="formula_8">n j=0 P (x i = j|I) = 1. K(b i , b j )</formula><p>is a function that measures the spatial proximity between b i and b j . We use window Intersection Over Union (IOU) <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b17">18]</ref> as K. The parameter λ controls the probability that a proposal window belongs to the background. The formulation of P (X|I) favors representative windows that have strong overlap with many confident proposals. By jointly considering the scores and the spatial proximity of all proposal windows, our formulation is robust to individual noisy proposals. This addresses Observation I.</p><p>Prior information about detection windows is encoded in L(O), which is formulated as</p><formula xml:id="formula_9">L(O) = L 1 (O)L 2 (|O|),<label>(7)</label></formula><p>NMS step 1 step 2 step 3 step 4 step 5 where</p><formula xml:id="formula_10">L 1 (O) = i,j:i =j exp − γ 2 O i O j K(b i , b j ) .<label>(8)</label></formula><p>L 1 (O) addresses Observation II by penalizing overlapping detection windows. Parameter γ controls the penalty level. L 2 (|O|) represents the prior belief about the number of salient objects. According to Observation III, we favor a small set of output windows that explains the observation. Therefore, L 2 (.) is defined as</p><formula xml:id="formula_11">L 2 (N ) = exp(−φN ),<label>(9)</label></formula><p>where φ controls the strength of this prior belief. Our MAP-based formulation answers the question of Localization by jointly optimizing the number and the locations of the detection windows, and it also naturally addresses the question of Existence, as the number of detections tends to be zero if no strong evidence of salient objects is found (Eq. 9). Note that L(O) can also be straightforwardly modified to encode other priors regarding the number or the spatial constraints of detection windows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Optimization</head><p>Taking the log of Eq. 4, we obtain our objective function:</p><formula xml:id="formula_12">f (O, X) = n i=1 w i (x i ) − φ|O| − γ 2 i,j∈ O:i =j K ij ,<label>(10)</label></formula><p>where w i (x i = j) log P (x i = j|I) and K ij is shorthand for K(b i , b j ). O denotes the index set corresponding to the selected windows in O. We omit log C(O, X) in Eq. 10, as we now explicitly consider Constraint 1.</p><p>Since we are interested in finding the optimal detection set O * , we can first maximize over X and define our opti-mization problem as</p><formula xml:id="formula_13">O * = arg max O max X f (O, X) ,<label>(11)</label></formula><p>which is subject to Constraint 1. Given O is fixed, the subproblem of maximizing f (O, X) over X is straightforward:</p><formula xml:id="formula_14">X * (O) = arg max X f (O, X) = n i=1 max xi∈ O∪{0} w i (x i ).<label>(12)</label></formula><p>Let h(O) f (O, X * (O)), then Eq. 11 is equal to an unconstrained maximization problem of the set function h(O), as Constraint 1 is already encoded in X * (O).</p><p>The set function h(O) is submodular (see proof in our supplementary material) and the maximization problem is NP-hard <ref type="bibr" target="#b18">[19]</ref>. We use a simple greedy algorithm to solve our problem. Our greedy algorithm starts from an empty solution set. It alternates between an incrementing pass (Alg. 1) and a decrementing pass (Alg. 2) until a local minimum is reached. The incrementing (decrementing) pass adds (removes) the element with maximal marginal gain to (from) the solution set until no more elements can be added (removed) to improve the objective function. Convergence is guaranteed, as h(O) is upper-bounded and each step of our algorithm increases h(O). An example of the optimization process is shown in <ref type="figure" target="#fig_0">Fig. 2</ref>.</p><p>In practice, we find that our greedy algorithm usually converges within two passes, and it provides reasonable solutions. Some theoretic approximation analyses for unconstrained submodular maximization <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b18">19]</ref> may shed light on the good performance of our greedy algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Salient Object Proposal Generation by CNN</head><p>We present a CNN-based approach to generate scored window proposals {(b i , s i )} n i=1 for salient objects. Inspired</p><formula xml:id="formula_15">Alg. 1 IncrementPass(O) V ← B \ O while V = ∅ do b * ← arg max b∈V h(O ∪ {b}) if h(O ∪ {b * }) &gt; h(O) then O ← O ∪ {b * } V ← V \ {b * } else return Alg. 2 DecrementPass(O) while O = ∅ do b * ← arg max b∈O h(O \ {b}) if h(O \ {b * }) &gt; h(O) then O ← O \ {b * } else return</formula><p>by <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b45">46]</ref>, we train a CNN model to produce a fixed number of scored window proposals. As our CNN model takes the whole image as input, it is able to capture context information for localizing salient objects. Our CNN model predicts scores for a predefined set of exemplar windows. Furthermore, an Adaptive Region Sampling method is proposed to significantly enhance the detection rate of our CNN proposal model. Generating exemplar windows. Given a training set with ground-truth bounding boxes, we transform the coordinates of each bounding box to a normalized coordinate space, i.e. (x, y) → ( x W , y H ), where W and H represents the width and height of the given image. Each bounding box is represented by a 4D vector composed of the normalized coordinates of its upper-left and bottom-right corners. Then we obtain K exemplar windows via K-means clustering in this 4D space. In our implementation, we set K = 100.</p><p>Adaptive region sampling. The 100 exemplar windows only provide a coarse sampling of location proposals. To address this problem, the authors of <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b45">46]</ref> propose to augment the proposal set by running the proposal generation method on uniformly sampled regions of an image. We find this uniformly sampling inefficient for salient object detection, and sometimes it even worsens the performance in our task (see Sec. 4).</p><p>Instead, we propose an adaptive region sampling method, which is in a sense related to the attention mechanism used in <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b34">35]</ref>. After proposal generation on the whole image, our model takes a closer glimpse at those important regions indicated by the global prediction. To do so, we choose the top M windows generated by our CNN model for the whole image, and extract the corresponding sub-images after expanding the size of each window by 2X. We then apply our CNN model on each of these sub-images to augment our proposal set. In our implementation, we set M = 5, and only retain the top 10 proposals from each sub-image. This substantially speeds up the subsequent op-timization process without sacrificing the performance.</p><p>The downside of the this adaptive region sampling is that it may introduce more noise into the proposal set, because the context of the sub-images can be very different from the whole image. This makes the subsequent bounding box filtering task more challenging.</p><p>CNN model architecture and training. We use the VGG16 model architecture <ref type="bibr" target="#b41">[42]</ref>, and replace its fc8 layer with a 100-D linear layer followed by a sigmoid layer. Let (c i ) K i=1 denote the output of our CNN model. Logistic loss i −y i log c i − (1 − y i ) log(1 − c i ) is used to train our model, where the binary label y i = 1 iff the i-th exemplar window is the nearest to a ground-truth bounding box in the 4D normalized coordinate space.</p><p>To train our CNN model, we use about 5500 images from the training split of the Salient Object Subitizing (SOS) dataset <ref type="bibr" target="#b52">[53]</ref>. The SOS dataset comprises unconstrained images with varying numbers of salient objects. In particular, the SOS dataset has over 1000 background/cluttered images that contain no salient objects, as judged by human annotators. By including background images in the training set, our model is expected to suppress the detections on this type of images. As the SOS dataset only has annotations about the number of salient objects in an image, we manually annotated object bounding boxes according to the number of salient objects given for each image. We excluded a few images that we found ambiguous to annotate.</p><p>We set aside 1/5 of the SOS training images for validation purpose. We first fine-tune the pre-trained VGG16 model on the ILSVRC-2014 object detection dataset <ref type="bibr" target="#b38">[39]</ref> using the provided bounding box annotations, and then finetune it using the SOS training set. We find this two-stage fine-tuning gives lower validation errors than only finetuning on the SOS training set. Training details are included in our supplementary material due to limited space.</p><p>Our full system and the bounding box annotations of the SOS training set are available on our project website 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Evaluation Metrics. Following <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b42">43]</ref>, we use the PASCAL evaluation protocol <ref type="bibr" target="#b17">[18]</ref> to evaluate salient object detection performance. A detection window is judged as correct if it overlaps with a ground-truth window by more than half of their union. We do not allow multiple detections for one object, which is different from the setting of <ref type="bibr" target="#b20">[21]</ref>. Precision is computed as the percentage of correct predictions, and Recall is the percentage of detected ground-truth objects. We evaluate each method by 1) Precision-Recall (PR) curves, which are generated by varying a parameter for each method (see below), and 2) Average Precision (AP), which is computed by averaging precisions on an interpolated PR curve at regular intervals (see <ref type="bibr" target="#b17">[18]</ref> for details).</p><p>Precision-Recall Tradeoff. As our formulation does not generate scores for the detection windows, we cannot control the PR tradeoff by varying a score threshold. Here we provide a straightforward way to choose an operating point of our system. By varying the three parameters in our formulation, λ, γ and φ, we find that our system is not very sensitive to φ in Eq. 9, but responds actively to changes in λ and γ. λ controls the probability of a proposal window belonging to the background (Eq. 6), and γ controls the penalty for overlapping windows (Eq. 8). Thus, lowering either λ or γ increases the recall. We couple λ and γ by setting γ = αλ, and fix φ and α in our system. In this way, the PR curve can be generated by varying λ. The parameters φ and α are optimized by grid search on the SOS training split. We fix φ at 1.2 and α at 10 for all experiments.</p><p>Compared Methods. Traditional salient region detection methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b24">25]</ref> cannot be fairly evaluated in our task, as they only generate saliency maps without individuating each object. Therefore, we mainly compare our method with two state-of-the-art methods, SC <ref type="bibr" target="#b20">[21]</ref> and LBI <ref type="bibr" target="#b42">[43]</ref>, both of which output detection windows for salient objects. We also evaluate a recent CNN-based object proposal model, MultiBox (MBox) <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b45">46]</ref>, which is closely related to our salient object proposal method. MBox generates 800 proposal windows, and it is optimized to localize objects of certain categories of interest (e.g. 20 object classes in PASCAL VOC <ref type="bibr" target="#b17">[18]</ref>), regardless whether they are salient or not.</p><p>These compared methods output ranked lists of windows with confidence scores. We try different ways to compute their PR curves, such as score thresholding and rank thresholding, with or without greedy NMS, and we report their best performance. For SC and LBI, rank thresholding without NMS (i.e. output all windows above a rank) gives consistently better AP scores. Note that SC and LBI already diversify their output windows, and their confidence scores are not calibrated across images. For MBox, applying score thresholding and NMS with the IOU threshold set at 0.4 provides the best performance.</p><p>We denote our full model as SalCNN+MAP. We also evaluate two baseline methods, SalCNN+NMS and Sal-CNN+MMR. SalCNN+NMS generates the detections by simply applying score thresholding and greedy NMS on our proposal windows. The IOU threshold for NMS is set at 0.4, which optimizes its AP scores. SalCNN+MMR uses the Maximum Marginal Relevance (MMR) measure to rescore the proposals <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b2">3]</ref>. The new score of each proposal is computed as the original score minus a redundancy measure w.r.t. the previously selected proposals. We optimize the parameter for MMR and use score thresholding to compute the AP scores (see our supplementary material for more details). Moreover, we apply our optimization formulation (without tuning the parameters) and other baseline methods (with parameters optimized) on the raw outputs of MBox. In doing so, we can test how our MAP formulation generalizes to a different proposal model.</p><p>Evaluation Datasets. We evaluate our method mainly on three benchmark salient object datasets: MSO <ref type="bibr" target="#b52">[53]</ref>, DUT-O <ref type="bibr" target="#b50">[51]</ref> and MSRA <ref type="bibr" target="#b28">[29]</ref>.</p><p>MSO contains many background images with no salient object and multiple salient objects. Each object is annotated separately. Images in this dataset are from the testing split of the SOS dataset <ref type="bibr" target="#b52">[53]</ref>.</p><p>DUT-O provides raw bounding box annotations of salient objects from five subjects. Images in this dataset can contain multiple objects, and a single annotated bounding box sometimes covers several nearby objects. We consolidate the annotations from five subjects to generate ground truth for evaluation (see supplementary material for details).</p><p>MSRA comprises 5000 images, each containing one dominant salient object. This dataset provides raw bounding boxes from nine subjects, and we consolidate these annotations in the same was as in DUT-O.</p><p>For completeness, we also report evaluation results on PASCAL VOC07 <ref type="bibr" target="#b17">[18]</ref>, which is originally for benchmarking object recognition methods. This dataset is not very suitable for our task, as it only annotates 20 categories of objects, many of which are not salient. However, it has been used for evaluating salient object detection in <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b42">43]</ref>. As in <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b42">43]</ref>, we use all the annotated bounding boxes in VOC07 as class-agnostic annotations of salient objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Results</head><p>The PR curves of our method, baselines and other compared methods are shown in <ref type="figure" target="#fig_1">Fig. 3</ref>. The full AP scores are reported in <ref type="table" target="#tab_0">Table 1</ref>. Our full model SalCNN+MAP significantly outperforms previous methods on MSO, DUT-O and MSRA. In particular, our method achieves about 15%, 34% and 20% relative improvement in AP over the best previous method MBox+NMS on MSO, DUT-O and MSRA respectively. This indicates that our model generalizes well to different datasets, even though it is only trained on the SOS training set. On VOC07, our method is slightly worse than MBox+NMS. Note that VOC07 is designed for object recognition, and MBox is optimized for this dataset <ref type="bibr" target="#b16">[17]</ref>. We find that our method usually successfully detects the salient objects in this dataset, but often misses annotated objects in the background. Sample results are show in <ref type="figure" target="#fig_3">Fig. 5</ref>. More results can be found in our supplementary material.</p><p>Our MAP formulation consistently improves over the baseline methods NMS and MMR across all the datasets for both SalCNN and MBox. On average, our MAP attains more than 11% relative performance gain in AP over MMR for both SalCNN and MBox, and about about 12% (resp. On VOC07, our method is slightly worse than MBox <ref type="bibr" target="#b45">[46]</ref>, but VOC07 is not a salient object dataset.  5%) relative performance gain over NMS for SalCNN (resp. MBox). Compared with NMS, the performance gain of our optimization method is more significant for SalCNN, because our adaptive region sampling method introduces extra proposal noise in the proposal set (see discussion in Section 3.4). The greedy NMS is quite sensitive to such noise, while our subset optimization formulation can more effectively handle it. Detecting Background Images. Reporting the nonexistence of salient objects is an important task by itself <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b48">49]</ref>. Thus, we further evaluate how our method and the competing methods handle background/cluttered images that do not contain any salient object. A background image is implicitly detected if there is no detection output by an algorithm. <ref type="table" target="#tab_1">Table 2</ref> reports the AP score of each method in detecting background images. The AP score of our full model SalCNN+MAP is computed by varying the parameter λ specified before. For SC, LBI, MBox and our proposal model SalCNN, we vary the score threshold to compute their AP scores.</p><p>As shown in <ref type="table" target="#tab_1">Table 2</ref>, the proposal score generated by SC and LBI is a poor indicator of the existence of salient objects, since their scores are not calibrated across images. MBox significantly outperforms SC and LBI, while our proposal model SalCNN achieves even better performance, which is expected as we explicitly trained our CNN model to suppress detections on background images. Our MAP formulation further improves the AP scores of SalCNN and MBox by 1 point. Generating Compact Object Proposals. Object proposal generation aims to attain a high hit rate within a small proposal budget <ref type="bibr" target="#b23">[24]</ref>. When a compact object proposal set is favored for an input image (e.g. in applications like weakly supervised localization <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b43">44]</ref>), how proposals are filtered can greatly affect the hit rate. In <ref type="figure" target="#fig_2">Fig. 4</ref>, we show that using our subset optimization formulation can help improve the hit rate of MBox <ref type="bibr" target="#b45">[46]</ref> when the average proposal number is less than 15 (see MBox+MAP vs MBox+NMS in <ref type="figure" target="#fig_2">Fig. 4)</ref>. The performance of MBox using rank thresholding 2 (MBox+NMS * ), together with SS <ref type="bibr" target="#b46">[47]</ref>, EB <ref type="bibr" target="#b55">[56]</ref> and MCG <ref type="bibr" target="#b2">[3]</ref>, is also displayed for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Component Analysis</head><p>Now we conduct further analysis of our method on the MSO dataset, to evaluate the benefits of the main components of our system.</p><p>Adaptive Region Sampling. We compare our full model with two variants: the model without region sampling (w/o RS) and the model using uniform region sampling (Unif. RS) <ref type="bibr" target="#b16">[17]</ref>. For uniform sampling, we extract In the VOC07 dataset, many background objects are annotated, but our method only detects dominant objects in the scene. In the DUT-O and MSRA datasets, some ground truth windows cover multiple objects, while our method tends to localize each object separately. Note that we are showing all the detection windows produced by our method. More detection results are included in the supplementary material. five sub-windows of 70% width and height of the image, by shifting the sub-window to the four image corners and the image center. The AP scores of our full model and these two variants are displayed in <ref type="table" target="#tab_2">Table 3</ref>. Besides the AP scores computed over the whole MSO dataset, we also include the results on five subsets of images for more detailed analysis: 1) 886 images with salient objects, 2) 611 images with a single salient object, 3) 275 images with multiple salient objects, 4) 404 images with all small objects and 5) 482 images with a large object. An object is regarded as small if its bounding box occupies less than 25% area of the image. Otherwise, the object is regarded as large. The best scores of the two variants are shown in red. The model with uniform region sampling generally outperforms the one without region sampling, especially on images with all small objects or multiple objects. However, on images with a large object, uniform region sampling worsens the performance, as it may introduce window proposals that are only locally salient, and it tends to cut the salient object. The proposed adaptive region sampling substantially enhances the performance on all the subsets of images, yielding over 20% relative improvement on the whole dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MAP-based Subset Optimization.</head><p>To further analyze our subset optimization formulation, we compare our full model with three variants that use different window filtering strategies. We evaluate the rank thresholding baseline (Rank Thresh in <ref type="table" target="#tab_2">Table 3</ref>) and the score thresholding baseline (Score Thresh in <ref type="table" target="#tab_2">Table 3</ref>) with the greedy NMS applied. We also evaluate the Maximum Marginal Relevance basline (MMR in <ref type="table" target="#tab_2">Table 3</ref>) as in the previous experiment.</p><p>The results of this experiment are shown in <ref type="table" target="#tab_2">Table 3</ref>. Our full model consistently gives better AP scores than all of the baselines, across all subsets of images. Even on constrained images with a single salient object, our subset optimization formulation still provides 12% relative improvement over the best baseline (shown in red in <ref type="table" target="#tab_2">Table 3</ref>). This shows the robustness of our formulation in handling images with varying numbers of salient objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We presented a salient object detection system for unconstrained images, where each image may contain any number of salient objects or no salient object. A CNN model was trained to produce scored window proposals, and an adaptive region sampling method was proposed to enhance its performance. Given a set of scored proposals, we presented a MAP-based subset optimization formulation to jointly optimize the number and locations of detection windows. The proposed optimization formulation provided significant improvement over the baseline methods on various benchmark datasets. Our full method outperformed the state-of-the-art by a substantial margin on three challenging salient object datasets. Further experimental analysis validated the effectiveness of our system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>In column 1-5, we show step-by-step window selection results of our greedy algorithm. In the incrementing pass (step 1-4), windows are selected based on their marginal gains w.r.t. Eq. 11. The window proposals of positive marginal gains are shown in the bottom row for each step. Warmer colors indicate higher marginal gains. The final step (step 5) removes the first selected window in the decrementing pass, because our formulation favors a small number of detection windows with small inter-window overlap. To contrast our method with greedy NMS, we show the top 3 output windows after greedy NMS using an IOU threshold of 0.4 (top). The scored proposals are shown in the bottom row of the figure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Precision-Recall curves. Our full method SalCNN+MAP significantly outperforms the other methods on MSO, DUT-O and MSRA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Object proposal generation performance (hit rate vs. average #Prop per image) on VOC07. Our MAP-based formulation further improves the state-of-the-art MBox method when #Prop is small.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Sample detection results of our method when λ = 0.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>AP scores. The best score on each dataset is shown 
in bold font, and the second best is underlined. 

MSO DUT-O 
MSRA 
VOC07 Avg. 
SC[21] 
.121 
.156 
.388 
.106 
.194 
LBI[43] 
.144 
.143 
.513 
.106 
.226 
MBox[46]+NMS 
.628 
.382 
.647 
.374 
.508 
MBox[46]+MMR 
.595 
.358 
.578 
.332 
.466 
MBox[46]+MAP 
.644 
.412 
.676 
.394 
.532 
SalCNN+NMS 
.654 
.432 
.722 
.300 
.527 
SalCNN+MMR 
.656 
.447 
.716 
.301 
.530 
SalCNN+MAP 
.734 
.510 
.778 
.337 
.590 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>AP scores in identifying background images on MSO.</figDesc><table>SalCNN+MAP SalCNN MBox+MAP MBox LBI 
SC 
.89 
.88 
.74 
.73 
.27 
.27 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 :</head><label>3</label><figDesc>AP scores of variants of our method. Reg. Samp. refers to variants with different region sampling strategies. Win. Filtering refers to variants using different window filtering methods. See text for details.</figDesc><table>Reg. Samp. 
Win. Filtering 
Full 
w/o 
Unif 
Rank 
Score 
MMR 
Model 
RS 
RS 
Thresh 
Thresh 
Overall 
.734 
.504 
.594 
.448 
.654 
.656 
with Obj. 
.747 
.513 
.602 
.619 
.668 
.675 
Single Obj. 
.818 
.676 
.671 
.717 
.729 
.721 
Multi. Obj. 
.698 
.338 
.540 
.601 
.609 
.620 
Large Obj. 
.859 
.790 
.726 
.776 
.833 
.804 
Small Obj. 
.658 
.253 
.498 
.488 
.558 
.567 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.cs.bu.edu/groups/ivc/SOD/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Rank thresholding means outputting a fixed number of proposals for each image, which is a default setting for object proposal methods like SS, EB and MCG, as their proposal scores are less calibrated across images.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. This research was supported in part by US NSF grants 0910908 and 1029430, and gifts from Adobe and NVIDIA.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Frequency-tuned salient region detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hemami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Estrada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Susstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Measuring the objectness of image windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Alexe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2189" to="2202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multiscale combinatorial grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pont-Tuset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Multiple object recognition with visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.7755</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">On detection of multiple object instances using hough transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Barinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kholi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1773" to="1784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Salient object detection: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A tight linear time (1/2)-approximation for unconstrained submodular maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Buchbinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Foundations of Computer Science</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">CPMC: Automatic object segmentation using constrained parametric min-cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1312" to="1328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fusing generic objectness and visual saliency for salient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Webly supervised learning of convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Global contrast based salient region detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-M</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="569" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">BING: Binarized normed gradients for objectness estimation at 300fps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Discriminative models for multi-class object layout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Weakly supervised localization and learning with generic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Alexe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="275" to="293" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Neural mechanisms of selective visual attention. Annual review of neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Desimone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duncan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="193" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scalable object detection using deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The PASCAL Visual Object Classes Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<ptr target="http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Maximizing nonmonotone submodular functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Feige</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Mirrokni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1133" to="1153" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Object detection with discriminatively trained partbased models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Salient object detection by composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Random walks on graphs to model saliency in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">How good are detection proposals, really? In BMVC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hosang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Salient object detection: A discriminative regional feature integration approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep visual-semantic alignments for generating image descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to combine foveal glimpses with a third-order boltzmann machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The secrets of salient object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning to detect a salient object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="353" to="367" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning optimal seeds for diffusion-based salient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Salient object detection using concavity context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Saliency density maximization for object detection and localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mairon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ben-Shahar</surname></persName>
		</author>
		<title level="m">A closer look at context: From coxels to the contextual emergence of object saliency</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A framework for visual saliency detection with applications to image thumbnailing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marchesotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cifarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Recurrent models of visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Non-maximum suppression for object detection by passing messages between windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Optimized pedestrian detection for multiple and occluded people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rujikietgumjorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0575</idno>
		<title level="m">Imagenet large scale visual recognition challenge</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Existence detection of objects in images for robot vision using saliency histogram features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scharfenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Waslander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Zelek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Clausi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer and Robot Vision</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A unified approach to salient object detection via low rank matrix recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Looking beyond the image: Unsupervised learning for object saliency and detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Siva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Agapito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Weakly supervised object detector learning with model drift detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Siva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="343" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Automatic thumbnail cropping and its effectiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM symposium on User interface software and technology</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scalable</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.1441</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">high-quality object detection. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Selective search for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="154" to="171" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Image saliency by isocentric curvedness and color</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Valenti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Salient object detection for searched web images via global saliency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Hierarchical saliency detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Saliency detection via graph-based manifold ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">FASA: Fast, Accurate, and Size-Aware Salient Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yildirim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ssstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Salient object subitizing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sameki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Betke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mȇch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Minimum barrier salient object detection at 80 fps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mech</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Unsupervised object class discovery via saliency-guided multiple class learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Edge boxes: Locating object proposals from edges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
