<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hierarchical Gaussian Descriptor for Person Re-Identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsu</forename><surname>Matsukawa</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Kyushu University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takahiro</forename><surname>Okabe</surname></persName>
							<email>okabe@ai.kyutech.ac.jp</email>
							<affiliation key="aff1">
								<orgName type="institution">Kyushu Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Einoshin</forename><surname>Suzuki</surname></persName>
							<email>suzuki@kyushu-u.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Kyushu University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoichi</forename><surname>Sato</surname></persName>
							<email>ysato@iis.u-tokyo.ac.jp</email>
							<affiliation key="aff2">
								<orgName type="institution">The University of Tokyo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Hierarchical Gaussian Descriptor for Person Re-Identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Describing the color and textural information of a person image is one of the most crucial aspects of person reidentification. In this paper, we present a novel descriptor based on a hierarchical distribution of pixel features. A hierarchical covariance descriptor has been successfully applied for image classification. However, the mean information of pixel features, which is absent in covariance, tends to be major discriminative information of person images. To solve this problem, we describe a local region in an image via hierarchical Gaussian distribution in which both means and covariances are included in their parameters. More specifically, we model the region as a set of multiple Gaussian distributions in which each Gaussian represents the appearance of a local patch. The characteristics of the set of Gaussians are again described by another Gaussian distribution. In both steps, unlike the hierarchical covariance descriptor, the proposed descriptor can model both the mean and the covariance information of pixel features properly. The results of experiments conducted on five databases indicate that the proposed descriptor exhibits remarkably high performance which outperforms the state-ofthe-art descriptors for person re-identification.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Appearance matching of person images observed in disjoint camera views, referred to as person re-identification, is receiving increasing attention, mainly because of its broad range of applications <ref type="bibr" target="#b10">[11]</ref>. In this task, the person images are captured from various viewpoints and under different illuminations, resolutions, human poses, and background environments. These large intra-personal variations in person images cause serious difficulties. In addition, similar clothes among different persons add further challenges.</p><p>To address these difficulties, researchers are actively working on appearance descriptors <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47]</ref> and methods for matching them <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b47">48]</ref>. Descriptors characterize the appearance (color and textural) information of human clothes. A good descriptor should be robust against intra-personal variations and at the same time have high discriminative power to distinguish different persons. Person images are low in resolution and have large pose variations; consequently, it has been proved that the most important cue for person re-identification is color information such as color histograms and color name descriptors <ref type="bibr" target="#b42">[43]</ref>. Because they cannot sufficiently differentiate different persons of similar color, textural descriptors such as Local Binary Pattern (LBP) and the responses of filter banks are often combined with color descriptors <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>A covariance descriptor <ref type="bibr" target="#b39">[40]</ref> describes a region of interest as a covariance of pixel features. It provides a natural way to fuse different modalities, e.g., color and texture, of pixel features into a single meta-descriptor. Since the covariance descriptor is obtained by averaging features inside the region, it remedies the effects of noise and spatial misalignments. Consequently, it has been successfully applied to person re-identification <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b43">44]</ref>.</p><p>In this paper, we propose a novel region descriptor based on hierarchical Gaussian distribution of pixel features for person re-identification. More specifically, we densely extract local patches inside a region and regard the region as a set of local patches. We firstly model the region as a set of multiple Gaussian distributions, each of which represents the appearance of one local patch. We refer to such a Gaussian distribution representing each local patch as a patch Gaussian. The characteristics of the set of patch Gaussians are again described by another Gaussian distribution. We refer to this Gaussian distribution as a region Gaussian. The parameters of the region Gaussian are then used as feature vector to represent the region. Our motivation of the use of a hierarchical model stems from the appearance structure of person images. The persons' clothes consist of local parts, each of which has local color/texture structures. The spatial arrangement of these parts determines the global appearance structure. However, most of the existing meta descriptors <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b39">40]</ref> are based on a global distribution of pixel features inside a region. Thereby, the local structure of the person image is lost. In contrast, our proposed descriptor describes the global distribution using the local distribution of the pixel features. Indeed, it can distinguish the textures which have the same global distribution but different local structures, as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>We use the Gaussian distribution as a base component of the hierarchy. The motivation of the use of the distribution comes from the importance of the mean color of local parts. Although the hierarchical representation of covariance descriptors has been proposed <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b35">36]</ref>, the mean information is not included in each hierarchy. The loss of mean information is a crucial problem when they are applied to person re-identification. This is because the clothes a person wears tend to consist of a small number of colors in each local part, and therefore the mean color in the local parts tends to be the major discriminative information of the persons. As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, the mean images of local color contain highly distinguished information of different persons.</p><p>We name the proposed hierarchical method Gaussian Of Gaussian (GOG) descriptor. The GOG descriptor provides a conceptually simple and consistent way to generate discriminative and robust features that describe color and textural information simultaneously. The results of extensive experiments conducted on five public datasets reveal that, despite its simplicity, our proposed descriptor can achieve surprisingly high performance on person re-identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Feature design and distance metric learning are two key components for person re-identification. In the feature design, several works have been conducted by focusing on the characteristic properties of person images. Symmetry-Driven Accumulation of Local Features (SDALF) <ref type="bibr" target="#b5">[6]</ref> exploits the symmetric property of a person through obtaining head, torso, and leg positions to handle view variations. Unsupervised salience learning <ref type="bibr" target="#b45">[46]</ref> estimates rare patches among different images, to perform matching of rare-appearances such as rare-colored coats, baggages and folders. Attribute based descriptors obtain lingual description of person images <ref type="bibr" target="#b16">[17]</ref>. These works have been mainly conducted on unsupervised settings.</p><p>In the recent half decade, a supervised approach, i.e., metric learning, has shown more impressive results in terms of accuracies <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b47">48]</ref>. The features used for metric learning are rather simple compared to the features for the unsupervised settings. For metric learning, the features need not necessarily be robust or discriminative when unsupervised matching is performed, however, it requires to contain enough information within them. For example, high dimensional features composed of densely sampled color histograms, LBPs and SIFTs are often used <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b41">42]</ref>. The design of features would largely affect the matching accuracy of metric learning methods. Nevertheless, most of the previous works focused on algorithm of metric learning <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b47">48]</ref>, and only few works focused on the feature design <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b42">43]</ref>. Our use of two-level (patch/region) statistics for person re-identification is motivated by the recently proposed Local Maximal Occurrence (LOMO) <ref type="bibr" target="#b22">[23]</ref>, which is a high dimensional representation of color and Scale Invariant Local Ternary Pattern (SILTP) histograms. This method locally constructs a histogram of pixel features, and then takes its maximum values within horizontal strips to overcome viewpoint variations while maintaining local discrimination. Indeed, LOMO describes only mean information of pixel features. Covariance-of-Covariance feature <ref type="bibr" target="#b35">[36]</ref>, where region covariance is estimated over local patch covariances of pixel features, motivated us to add covariance information in each hierarchy.</p><p>Making use of mean information to enhance the covariance descriptor is motivated by several works, such as Shape of Gaussians <ref type="bibr" target="#b9">[10]</ref>, Global Gaussian <ref type="bibr" target="#b29">[30]</ref> and Gaussians of Local Descriptors (GOLD) <ref type="bibr" target="#b36">[37]</ref>. By benefitting from the recent advances on Riemannian geometry, we treat a Gaussian distribution on a point of Symmetric Positive Definite (SPD) matrix manifold with the same manner as <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b18">19]</ref> and apply log Euclidean metric and half-vectorization to flatten the manifold-valued data as in the works <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b36">37]</ref>. Though such a Gaussian coding of low level pixel features is introduced into person reidentification <ref type="bibr" target="#b26">[27]</ref>, previous Gaussian descriptors are not constructed on a hierarchal manner.</p><p>Convolutional Neural Network (CNN) is one of the stateof-the art recognition algorithms that leverage hierarchal structure <ref type="bibr" target="#b15">[16]</ref> and CNN has been recently adopted for person re-identification <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21]</ref>. However, their accuracies are not high compared to metric learning approaches, especially in small sampled datasets such as VIPeR <ref type="bibr" target="#b11">[12]</ref>. This is because the CNN requires a large number of labeled train-  ing samples to obtain good performance. Although several descriptors are proposed by focusing on CNN like hierarchy <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b38">39]</ref>, they require learning processes for feature extraction in each hierarchy. In contrast, our descriptor requires no learning process because in each hierarchy, our descriptor describes regions via mean and covariance estimations which are not involved in learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Hierarchical Gaussian Descriptor</head><p>We outline the proposed hierarchal Gaussian descriptor named GOG in <ref type="figure" target="#fig_2">Fig. 3</ref>. To achieve the feature representation of a person image, we adopt a part-based model <ref type="bibr" target="#b34">[35]</ref>. We assume that G regions of a person image are given in advance, which are typically horizontal stripes of the image. The proposed descriptor returns a feature vector of the regions. The rest of this section describes the details of the descriptor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Pixel features</head><p>Let us focus on one of the G regions of a person image. To describe the local structure of the region, we densely extract squared (k × k pixels) patches with the p pixel intervals <ref type="figure" target="#fig_2">(Fig 3 (a)</ref>). In order to characterize each pixel in the patch, we extract d dimensional feature vector f i for every pixel i. The feature vector can be any type of features, such as color, intensity, gradient orientation and filter response.</p><p>Since the number of pixels in each patch is small, the dimension d is preferable to be low for robustly estimating the covariance matrices of patch Gaussians in the next step. In this work, we extract 8-dimensional pixel features defined as:</p><formula xml:id="formula_0">f i = [y, M 0 • , M 90 • , M 180 • , M 270 • , R, G, B] T ,<label>(1)</label></formula><p>where y is the pixel location in the vertical direction, M θ∈{0 • ,...,270 • } are the magnitudes of pixel intensity gra-dient along four orientations, and R, G, B are color channel values. Each dimension of f i is linearly stretched to the range [0, 1] for equalizing the scales of the different feature values.</p><p>The pixel location is introduced to leverage spatial information within each region. The use of only vertical image location comes from the analysis in <ref type="bibr" target="#b26">[27]</ref>; the person images tend to be well aligned in vertical direction while pose/viewpoint change causes a large misalignment in the horizontal direction. Note that one would like to set y i from the top (or center) of the current region as in <ref type="bibr" target="#b8">[9]</ref>. However, each pixel belongs to multiple regions and such a setting increases computational complexity. Since person images are coarsely aligned, we directly set y i from the top of the image.</p><p>The gradient information is introduced to describe textural information of clothes. Gradient orientation O = arctan(I y /I x ) is calculated from x and y derivatives I x , I y of intensity I. We quantize the orientation into four bins;</p><formula xml:id="formula_1">O θ∈{0 • ,90 • ,180 • ,270 • } .</formula><p>To complement the loss of information by the quantization, we use soft voting into nearby two orientation bins. The voting weights are linearly determined from the distances from the quantized orientations as in the GO vector in <ref type="bibr" target="#b14">[15]</ref>. To focus on high gradient edges, we multiply the gradient magnitude M = √ I 2 y + I 2 y to the quantized orientation O θ and obtain the oriented gradient mag-</p><formula xml:id="formula_2">nitude; M θ = M O θ .</formula><p>Color information is the most important cue for person re-identificaiton. We use the color channel values of the most basic color space: RGB. Other color spaces, e.g., Lab, HSV and YCbCr, might be used. In fact, we will extend our pixel features in different color spaces (Sec. 3.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Patch Gaussians</head><p>After we extract the pixel features inside a patch, we then summarize them via the most classical parametric distribution which has mean and covariance as parameters: Gaussian distribution ( <ref type="figure" target="#fig_2">Fig. 3 (b)</ref>). For every patch s, we model feature vectors as the patch Gaussian N (f ; µ s Σ s ) defined as,</p><formula xml:id="formula_3">N (f ; µ s , Σ s ) = exp ( − 1 2 (f − µ s ) T Σ −1 s (f − µ s ) ) (2π) d/2 |Σ s | ,<label>(2)</label></formula><p>where | · | is the determinant of a matrix, µ s is the mean vector and Σ s is the covariance matrix of the sampled patch s. The mean vector and the covariance matrix are respectively estimated by:</p><formula xml:id="formula_4">µ s = 1 ns ∑ i∈Ls f i and Σ s = 1 ns−1 ∑ i∈Ls (f i − µ s )(f i − µ s ) T ,</formula><p>where L s is the area of the sampled patch s and n s denotes the number of pixels in L s .</p><p>Note that the densely sampled mean vectors and covariance matrices can be efficiently calculated through integral images <ref type="bibr" target="#b40">[41]</ref>. Since regions can be overlapped, we construct the integral images of pixel features for an overall person image rather than creating them for each region.</p><p>For a more precise description of distributions, Gaussian Mixture Model (GMM) might be used. Since a local patch is expected to consist of a small number of colors/textures, we assume that the unimodal Gaussian is sufficient for describing the distribution of its pixel features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Tangent space mapping and half vectorization</head><p>As we will explain in the next subsection, our descriptor is a summarized representation of patch Gaussians in a region. For this summarization, mathematical operations such as mean or covariance of the Gaussian are required.</p><p>From the viewpoint of information geometry, the space of probability distribution is considered as a Riemannian manifold where the Euclidean operation cannot be applied directly <ref type="bibr" target="#b1">[2]</ref>. A Riemannian manifold can be locally flatten into a Euclidean space by projecting it into a tangent space endowed with Riemannian metric. The space of the Symmetric Positive Definite (SPD) matrix is also considered as a Riemannian manifold and this space is recently well understood. The log Euclidean metric <ref type="bibr" target="#b2">[3]</ref> for SPD matrix provides a solid way to map a point on the manifold to a Euclidean tangent space via a matrix logarithm.</p><p>To leverage the benefit of the log Euclidean metric, we embed the patch Gaussians in the SPD matrix in the similar manner to the work <ref type="bibr" target="#b18">[19]</ref>. From an analysis in the information geometry literature <ref type="bibr" target="#b24">[25]</ref>, the space of d-dimensional multivariate Gaussians can be embedded into the d + 1 dimensional SPD matrices space denoted by Sym + d+1 . We represent the d-dimensional patch Gaussian N (µ s , Σ s ) into Sym + d+1 as P s :</p><formula xml:id="formula_5">N (f ; µ s , Σ s ) ∼ P s = |Σ s | − 1 d+1 [ Σ s + µ s µ T s µ s µ T s 1 ]</formula><p>.</p><p>(3) For more detailed theory of this embedding, one may refer the literature <ref type="bibr" target="#b24">[25]</ref>.</p><p>The covariance matrix of the local patch often becomes singular due to the lack of sufficient number of pixels within the patch. We avoid this problem by adding the identity matrix I d to Σ s with a small positive constant value, ϵ s , as</p><formula xml:id="formula_6">Σ s ← Σ s + ϵ s I d .</formula><p>In order to describe the region distribution in a Euclidean operation, we then map each of patch Gaussians P s into a tangent space via a matrix logarithm <ref type="figure" target="#fig_2">(Fig. 3 (c)</ref>).</p><p>We then store the upper triangular part of the mapped matrix as a vector since the matrix is symmetric. By considering the off-diagonal entries as being counted twice during the norm computation <ref type="bibr" target="#b40">[41]</ref>, the matrix of patch Gaussian P s becomes m = (d 2 + 3d)/2 + 1 dimensional vector g s , defined as, g s = vec(log(P s )) =</p><formula xml:id="formula_7">[b s(1,1) , √ 2b s(1,2) , · · · , √ 2b s(1,d+1) , b s(2,2) , √ 2b s(2,3) , · · · , b s(d+1,d+1) ] T , where log(·) is the matrix logarithm op- erator and b s(i,j) is the (i, j) element of B s = log(P s ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Region Gaussian on tangent space</head><p>Due to the pose variation of person images, the positions of local parts vary in different observations. Thus we summarize the local patches into an orderless representation of them. More specifically, we summarize the flattened patch Gaussians in the previous section into a region distribution <ref type="figure" target="#fig_2">(Fig.3 (d)</ref>). For this summarization, we also use a Gaussian distribution that can describe not only covariance but also mean. Again, GMM might be used to describe more precise distributions. However, matching among GMMs is not a trivial problem <ref type="bibr" target="#b18">[19]</ref> and will cause complexity to match among region descriptors. The summarization with a Gaussian distribution is performed by considering a spatial property of patches as follows.</p><p>A person image often contains background regions which significantly differ in places. To suppress the effect of background regions, we introduce a weight for each patch in a similar manner as for the weighted color histograms <ref type="bibr" target="#b5">[6]</ref>. In most cases, the person is centered in each image; thus a higher value is assigned to the patches which are closer to the center y axis of an image:</p><formula xml:id="formula_8">w s = exp(−(x s − x c ) 2 /2σ 2 ) where x c = W/2, σ = W/4</formula><p>. Here x s denotes the x coordinate of the center pixel of patch s and W is the image width. Then we define the weighted mean vector and covariance matrix as</p><formula xml:id="formula_9">µ G = 1 ∑ s∈G w s ∑ s∈G w s g s ,<label>(4)</label></formula><formula xml:id="formula_10">Σ G = 1 ∑ s∈G w s ∑ s∈G w s (g s − µ G )(g s − µ G ) T ,<label>(5)</label></formula><p>where G is the region in which the patch Gaussians are summarized. Using the mean vector and covariance matrix, we represent the region as the region Gaussian N (g; µ G , Σ G ).</p><p>For matching among region descriptors, it is convenient to flat the region Gaussian in the Euclidean space since most of the matching methods such as metric learning are designed on a Euclidean space. For this purpose, we embed m dimensional region Gaussian into m + 1 dimensional SPD matrices in the same manner as Eq. <ref type="formula">(3)</ref>:</p><formula xml:id="formula_11">N (g; µ G , Σ G ) ∼ Q where Q is a (m + 1) × (m + 1) SPD matrix.</formula><p>Here the covariance matrix Σ G is regularized as Σ G ← Σ G + ϵ G I m , We then map Q into the tangent space of Sym + m+1 by using matrix logarithm and half-vectorize it to form a (m 2 + 3m)/2 + 1 dimensional feature vector, which we denote z <ref type="figure" target="#fig_2">(Fig.3 (e)</ref>).</p><p>By extracting the region Gaussian for each of G regions, we obtain feature vectors {z g } G g=1 . In order to maintain the spatial location of these vectors, we concatenate them and form a feature vector <ref type="figure" target="#fig_2">(Fig.3(f)</ref>). Then the feature representation of a person image becomes z = [z T 1 , .., z T G ] T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Fusion descriptor of different color spaces</head><p>It has been proved that descriptors extracted from different color spaces have complementary properties, and their fusion improves re-identification accuracies <ref type="bibr" target="#b42">[43]</ref>.</p><p>To extract more color information in GOG descriptors, we replace the RGB channel values in the pixel feature in Eq.(1) with three alternative color channels values {Lab, HSV, nRGB} and fuse their GOG descriptors. Here the nRGB is the normalized color space (e.g., nR = R/(R+G+B)). Since there is a redundancy in this space, we only use {nR, nG} in this color space. Thus We denote the GOG descriptor z extracted from the Eq.(1) as GOG RGB , and the descriptors extracted from the alternative color channels as GOG Lab , GOG HSV and GOG nRnG , respectively. The fusion is simply performed by concatenating GOG descriptors on different pixel features as GOG Fusison = [GOG T RGB , GOG T Lab , GOG T HSV , GOG T nRnG ] T . Therefore, the dimensionality of the fusion descriptor is 3 (color spaces) × 1081 ( = (45 2 + 3 × 45)/2 + 1) × G (regions) + 1 (color space) × 703 ( = (36 2 + 3 × 36)/2 + 1) × G (regions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Normalization of GOG</head><p>For high dimensional features, normalization is an important factor to improve their performance <ref type="bibr" target="#b33">[34]</ref>. Since the GOG descriptor is high dimensional, we normalize the descriptor by using the L2 norm normalization, which is the most widely adopted normalization.</p><p>We observed that there exist dimensions which have commonly high/small values among different images within the GOG descriptor. This is because we use pixel features which has different properties of its distributions, e.g., gradient magnitude distributes sparsely in images, and color intensity distributes more uniformly. In such a case, the cosine distance, i.e., the Euclidean distance after the normalization, would be dominated by the biased dimensions.</p><p>To remedy such biased dimensions, we remove the mean vector of training samples before normalizing the feature vector. The normalization of GOG becomes as follows:</p><formula xml:id="formula_12">z = (z − z)/∥z − z∥ 2 ,<label>(6)</label></formula><p>where z is the sample mean of the GOG descriptors. For the fusion descriptor, we normalize each of the GOG descriptors extracted on four color spaces before concatenating them.</p><p>For the Bag-of-Words representation, similar normalization is proposed to reflect co-missing words for cosine similarity <ref type="bibr" target="#b13">[14]</ref>. In contrast, we employ it to remedy the effect of biased dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Setup</head><p>We evaluate the proposed descriptor on five benchmark datasets: VIPeR <ref type="bibr" target="#b11">[12]</ref>, CUHK01 <ref type="bibr" target="#b19">[20]</ref>, GRID <ref type="bibr" target="#b25">[26]</ref>, PRID450S <ref type="bibr" target="#b32">[33]</ref> and CUHK03 <ref type="bibr" target="#b20">[21]</ref>. We resize each image in the dataset to 128×48 pixels to facilitate the evaluation with the common parameters of the descriptor.</p><p>We extract the GOG descriptor from seven overlapping horizontal strips (G = 7). Each of the strips consists of 32×48 pixels. By considering the trade-off between the computational time and the predictive accuracy, we extract local patches at two-pixel intervals (p = 2) in each region. We set the local patch size to 5 × 5 pixels (k = 5). Following the setting of <ref type="bibr" target="#b12">[13]</ref>, we set the regularization parameter for region Gaussian as ϵ G = ϵ 0 Tr(Σ G ). Here Tr(·) is the trace norm of the matrix. In several patch Gaussians, the trace norm of covariance matrix becomes nearly zero when the patch contains only nearly equal pixel values. Thus, we set a small constant to ϵ s for patch Gaussian, then we have ϵ s = ϵ 0 max(Tr(Σ s ), 10 −2 ). We set ϵ 0 = 10 −3 for both patch and region Gaussians.</p><p>We evaluate the proposed descriptor with a distance metric learning, Cross-view Quadratic Discriminant Analysis (XQDA) <ref type="bibr" target="#b22">[23]</ref>. The KISS Metric learning (KISSME) <ref type="bibr" target="#b32">[33]</ref> is commonly used in person re-identification. However, it is more sensitive to dimensionality of subspace where the distance metric is learned. The XQDA learns a discriminative subspace and a distance metric simultaneously, and is able to select the optimal dimensionality automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Performance analysis on VIPeR</head><p>In this section, we compare the performance within our approach using VIPeR dataset <ref type="bibr" target="#b11">[12]</ref>. The VIPeR is a challenging dataset containing 632 person image pairs from two camera views. The testing protocol is to split the number of the person into half, 316 for training 316 for testing. We conduct the evaluation procedure for 10 splits and report the average Cumulative Matching Characteristic (CMC) curves.</p><p>As a default, we use RGB color space for pixel features (GOG RGB ) and the normalization in Sec. 3.6. Distribution modeling: We compare other distribution models to GOG in <ref type="figure" target="#fig_5">Fig. 4(a)</ref>. The Mean, Cov and Gauss are global distribution descriptors of pixel features within each region. The Cov-of-Cov, Cov-of-Gauss and GOG are hierarchical distribution descriptors. The tangent space mapping using log-Euclidean and half vectorization are applied for all descriptors except Mean. The regularization parameter of the covariance matrix is set as the same manner as GOG. The concatenated feature vector of the 7 regions is used for all descriptors. For a fair comparison, we adopted the weighted pooling for all descriptors.</p><p>First, we compare the global distribution descriptors. The rank-1 rates of Mean and Cov are 11.6% and 23.6%, respectively. By adding the mean and the covariance information, Gauss performs 7.7% better than Cov in rank-1 rate. This result confirms the importance of the use of both mean and covariance information of pixel features.</p><p>We then compare the hierarchical distribution descriptors. The Cov-of-Cov uses covariance matrix in both patch and region modeling, which is similar to <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b35">36]</ref>. It performs 4.2% better than Cov in rank-1 rate. The Cov-of-Gauss uses Gaussian for patch and covariance matrix for region modeling. It improves the performance of Gauss by 9.7% in rank-1 rate. These results confirm the importance of covariance information of patch Gaussians. By adding mean information in region modeling, GOG improves the performance of Cov-of-Gauss by 1.3% in rank-1 rate. Tangent space mapping: We compare the effect of flattening the manifold in <ref type="figure" target="#fig_5">Fig. 4 (b)</ref>. The None shows the results when the tangent space mapping is not applied for constructing the vector of both region and patch Gaussians. The 1st and 2nd map respectively shows the results when the mapping is applied to one of the patch or region Gaussians. When either the 1st or 2nd mapping is applied, rank-1 rates increase by 16.3% and 9.1%, respectively. By applying the both mappings, the rank-1 rate increase by 34.7%. From these results, we can see that the consideration of the underlying geometry of Gaussian is necessity. Normalization: We compare normalization in <ref type="figure" target="#fig_5">Fig. 4 (c)</ref>. Due to the dimensions which have commonly high/small values among samples, the standard L2 norm degrades performance largely, 14.3% in rank-1 rate. We also compare the standardization and PCA whitening. For PCA whitening, we varied the dimension of PCA and the best results are reported. After applying the standardization or the whitening, L2 norms are normalized. The standardization drops rank-1 rate by 1.9% and the improvement by PCA whiting is small, 1.0% in rank-1 rate. We suspect these methods magnify the noise of dimensions where the standard deviations are small. We can set that the proposed normalization is most effective; it increases rank-1 rate by 5.1%. Pixel features: We compare the components within pixel features in <ref type="figure" target="#fig_5">Fig. 4 (d)</ref>. The color channel information, RGB, is more effective than the gradient magnitude information, M θ , when comparing only these two components. By combining these two components, M θ RGB achieves 12.6% better rank-1 rate than RGB alone. The use of vertical pixel location y also improves the performance, e.g., rank-1 rate of yM θ RGB is better than that of M θ RGB by 4.6%. The F usion of GOG descriptors extracted from four color spaces is 7.1% better than yM θ RGB in rank-1 rate 1 . <ref type="bibr" target="#b0">1</ref> We also compared the GOG descriptor with pixel features used in other articles; 11-d <ref type="bibr" target="#b4">[5]</ref> and 7-d <ref type="bibr" target="#b26">[27]</ref> pixel features. In these cases, rank-1 identification rates were 35.4% and 39.7%, respectively.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Performance comparison</head><p>We compare the GOG descriptor with other descriptors using the four datasets: VIPeR <ref type="bibr" target="#b11">[12]</ref>, CUHK01 <ref type="bibr" target="#b19">[20]</ref>, GRID <ref type="bibr" target="#b25">[26]</ref> and PRID450S <ref type="bibr" target="#b32">[33]</ref>, respectively contains 632, 971, 250 and 450 images of individuals captured in two disjoint camera views.</p><p>The VIPeR, GRID and PRID450S datasets contain one image for each person in one camera view and CUHK01 contains two images. We conduct experiments with the single shot setting. Following the conventions <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b42">43]</ref>, we randomly divide each dataset into training and test sets containing half of the available individuals. The number of probe images is equal to the gallery images in all datasets except GRID. For GRID, we add additional 775 images that do not belong to the person of 250 image pairs into the gallery set. We repeat the above evaluation procedure 10 times and obtain the average rank scores and also report the Proportion of Uncertainty Removed (PUR) <ref type="bibr" target="#b31">[32]</ref> which is the measure to evaluate the whole ranks of CMC curve. Other meta descriptors: We compare the GOG descriptor with other meta-descriptors: Heterogeneous Auto-Similarities of Characteristics (HASC) <ref type="bibr" target="#b6">[7]</ref>, Local Descriptors encoded by Fisher Vector (LDFV) <ref type="bibr" target="#b27">[28]</ref>, Second-order Average Pooling (2AvgP) <ref type="bibr" target="#b8">[9]</ref> and GOLD <ref type="bibr" target="#b36">[37]</ref>.</p><p>The HASC is composed of the covariance descriptor and the Entropy and Mutual Information (EMI) descriptor. The EMI descriptor captures the non-linear dependency within pixel features and it has equal dimensionality to the covariance descriptor. The GOLD describes an image region by mean vector and covariance matrix. The covariance matrix is flattened by log-Euclidean and half-vectorization is applied. The vectors of mean and covariance are concatenated into a feature vector. The 2AvgP describes an image  <ref type="table">Table 2</ref>. Comparison of state-of-the-art results (CMC@rank-r). The best and second best scores are respectively shown in red and blue.</p><p>VIPeR</p><formula xml:id="formula_13">CUHK01 (M=1) CUHK01 (M=2) PRID450S GRID Methods</formula><p>Reference r=1 r=5 r=10 r=20 r=1 r=5 r=10 r=20 r=1 r=5 r=10 r=20 r=1 r=5 r=10 r=20 r=1 r=5 r=10 r=20 </p><formula xml:id="formula_14">GOG</formula><formula xml:id="formula_15">- - - - - - - - - - -</formula><p>region by the zero-mean covariance matrix, and applies log-Euclidean and half-vectorization to obtain a feature vector. The LDFV encodes pixel features using Fisher Vector coding, which encodes difference of pixel features from pretrained GMM means. By following the recommended setting <ref type="bibr" target="#b27">[28]</ref>, we set the number of GMM components to 16 2 . We focus on the encoding process of pixel features only, and discard other options on the above descriptors, such as the spatial pyramid in GOLD. We extract each of the metadescriptors from the same horizontal strips as GOG. The descriptor extracted from the 7 regions are concatenated. As well as GOG, we use the fusion approach that concatenates the meta descriptors extracted from 4 pixel feature vectors into one vector. For normalization, the mean removal and the L2 normalization are applied to each descriptor since we found it generally improves their performances.</p><p>We list the performance of GOG and the compared meta descriptors in <ref type="table" target="#tab_2">Table 1</ref> (a) and (b). All the descriptors in (b) except Cov-of-Cov are not hierarchical descriptors, which discard local structures of regions. The descriptors which use single layered distribution (Cov, HASC, LDFV, 2AvgP and GOLD) have similar performances. On the other hand, Cov-of-Cov clearly outperforms them. These results confirm the effectiveness of the hierarchical distribution. The GOG outperforms Cov-of-Cov, since it also contains the mean information, which is absent in covariance.</p><p>Descriptors for metric learning: We compare the GOG descriptor with other descriptors used in metric learning for person re-identification: LOMO <ref type="bibr" target="#b22">[23]</ref>, Color Histogram (CH)+LBP <ref type="bibr" target="#b41">[42]</ref> and gBiCov <ref type="bibr" target="#b28">[29]</ref>. For these descriptors, we use the source codes provided by the authors. The default parameters of the codes are used for LOMO and gBiCov. Xiong et al. <ref type="bibr" target="#b41">[42]</ref> conducted experiments using different region numbers to extract 28 bin color histogram and 2 uniform LBPs. Among them, we use 75 regions that was the best setting. For a fair comparison, the same normalization as GOG and XQDA metric learning are commonly applied.</p><p>The experimental results are shown in the <ref type="table" target="#tab_2">Table 1</ref> (c). It can be shown that GOG Fusion clearly outperforms LOMO with nearly equal dimensionality. The rank-1 identification rates of GOG Fusion are 8.6%, 8.6%, 5.8% and 8.1% better in VIPeR, CUHK01, PRID450s and GRID datasets, respectively. Although, LOMO and CH+LBP use more spatial regions and high dimensional pixel features, the GOG descriptor outperforms these descriptors by a large margin. When the patch weights are used, GOG RGB , which is extracted from pixel features with only RGB color information, outperforms LOMO with a much smaller dimensionality. The superiority of the GOG descriptor comes from its hierarchal use of the mean and covariance information of pixel features, whereas LOMO uses only the mean information. State-of-the-arts: In <ref type="table">Table 2</ref>, we compare the performance of the reported results on the state-of-the-art methods, including MidLevel Filter Learning (MLFL) <ref type="bibr" target="#b46">[47]</ref>, Salience Matching (SalMatch) <ref type="bibr" target="#b44">[45]</ref> , SCNCD <ref type="bibr" target="#b42">[43]</ref>, Semantic attribute representation <ref type="bibr" target="#b37">[38]</ref>, Metric Ensemble <ref type="bibr" target="#b30">[31]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Comparison on automatic detected dataset</head><p>To show the generality of the GOG descriptor on a large and automatic detected dataset, we compare the performances on CUHK03 dataset <ref type="bibr" target="#b20">[21]</ref>. The CUHK03 dataset includes 13,164 images of 1,360 persons, captured by disjoint camera views. Each person in the dataset has in average 4.8 images in each view. In addition to manually cropped person images, the dataset contains images detected by the state-of-the-art person detector. Therefore, realistic variations such as misalignment, occlusions and missing body parts are contained in person images. <ref type="figure">Fig. 5</ref> shows some example images of the dataset.</p><p>We evaluate the GOG descriptor with the common setting to previous works <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b30">31]</ref>. Namely, we divide the images of the dataset into 1,160 persons for the train set and 100 persons for the test set. The random division are repeated 20 times and we report the average results. <ref type="table" target="#tab_4">Table 3</ref> lists the performance comparison with the stateof-the-art results. The GOG Fusion achieves 67.3% and <ref type="table">Table 4</ref>. Time of feature extraction (seconds/image).</p><p>LOMO <ref type="bibr" target="#b22">[23]</ref> Cov RGB GOG RGB GOG Fusion gBiCov <ref type="bibr" target="#b28">[29]</ref> 0.016 0.021 0.34 1. <ref type="bibr">34 7.8</ref> 65.5% rank-1 identification rates with the labeled and the automatically detected bounding boxes, respectively, which clearly outperforms the state-of-the-art LOMO features <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref> and deep learning methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21]</ref> by a large margin. The performance decrease in rank-1 rate between labeled and detected data is 1.8% in the case of GOG, which is more than three times smaller than 5.95% of LOMO+XQDA. This might be because the LOMO feature is extracted from narrower horizontal stripes than regions of GOG. High dimensionality of LOMO is partially due to such a large number of narrow horizontal strips. In contrast, the high dimensionality of GOG is due to the Gaussian matrix, which is composed of the mean vector and the covariance matrix. Such a dimension enhancement of pixel features does not decrease the robustness to misalignment, and thus the GOG descriptor is more preferable in realistic situations with misalignments of person images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Running time</head><p>The GOG descriptor is implemented in Matlab 4 with MEX function for calculation of covariance matrices, and run on a PC equipped with Intel Xeon E5-2687W @3.1GHz CPU. The running times of the descriptors are shown in Table 4. The listed times are the average of all images of the VIPeR dataset. The matching cost of GOG Fusion is nearly equal to LOMO since their dimensionalities are almost the same. The GOG descriptor is about 16 times slower than the covariance descriptor when the same pixel feature is used, and GOG Fusion is about 84 times slower than LOMO. However, it is 5.8 times faster than gBiCov. Considering other methods which require more computational cost <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47]</ref>, the running time of the GOG descriptor is still appealing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We have proposed a novel hierarchical Gaussian descriptor for person re-identification. The proposed descriptor models both mean and covariance information of pixel features in each of the patch and region hierarchies. The results of our extensive experiments revealed that the proposed descriptor can achieve surprisingly high performance which improves the state-of-the-art performances on five public datasets.</p><p>In our future work, we plan to investigate the deep hierarchy of Gaussian descriptors to describe more in-depth the hierarchical structure of person appearances. In addition, we would like to test ensembles of the GOG descriptors extracted from different kinds of pixel features for further improvements of identification accuracies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Importance of hierarchal distribution: (a) Regions that have the same distribution (mean/covariance) of pixel features (each color indicates the same feature vector). (b) Local patches inside the regions which have different pixel feature distribution. (c) Regions can be distinguished via distributions of patch level distributions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Importance of mean: (a) Original images. (b) Images that show mean RGB values of 10 × 10 pixel patches of (a). (c) Mean removed images (each RGB value is scaled over the range [0,255] for visualization). It is easy to determine the same persons from (b), whereas it is hard from (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>GOG descriptor: (a) For each region, we extract local patches densely. (b) We then describe each of local patches via a Gaussian distribution of pixel features, we refer to these Gaussians as patch Gaussians. (c) Each of patch Gaussians is flattened and vectorized by considering the underlining geometry of Gaussians. (d) Then the patch Gaussians inside a region are summarized into a region Gaussian. (e) We further flatten the region Gaussian and create a feature vector. (f) Finally, the feature vectors extracted from all regions are concatenated into one vector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>, the pixel feature dimension of each {RGB, Lab, HSV, nRnG} color space is d = {8, 8, 8, 7} and therefore the dimension of patch Gaussian vector is m = {45, 45, 45, 36}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Performance analysis of the GOG descriptor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 1 .</head><label>1</label><figDesc>Comparison with XQDA metric learning (CMC@rank-r and PUR). (a) GOG descriptor. (b) Other meta descriptors. (c) Other descriptors for person re-identification. The best scores on (a) are shown in red, (b) and (c) are shown in blue.</figDesc><table>Pixel 
# of 
Patch 
VIPeR 
CUHK01 
PRID450S 
GRID 
Methods 
feature Region Dim. Weight r=1 r=10 r=20 PUR r=1 r=10 r=20 PUR r=1 r=10 r=20 PUR r=1 r=10 r=20 PUR 

(a) 

GOG Fusion 
Fusion 
7 27,622 Y 
49.7 88.7 94.5 63.6 57.8 86.2 92.1 66.8 68.4 94.5 97.8 73.9 24.7 58.4 69.0 45.9 
GOG RGB 
yM θ RGB 7 
7,567 
Y 
42.3 85.3 92.8 58.8 55.8 85.5 91.3 65.8 63.6 91.5 96.2 69.8 22.8 52.3 64.1 43.1 
GOG Fusion 
Fusion 
7 27,622 N 
47.0 89.2 94.8 62.6 54.4 83.2 89.7 63.3 61.6 91.1 96.5 68.6 24.6 53.8 63.8 44.1 

Cov-of-Cov [36] Fusion 
7 16,828 N 
33.9 76.6 87.7 50.9 40.9 72.5 81.1 52.1 47.0 83.4 91.6 56.8 16.6 45.0 55.2 36.2 

(b) 

GOLD [37] 
Fusion 
7 
1,169 
N 
27.1 66.5 77.7 41.9 35.3 65.2 74.2 44.5 40.5 73.8 82.2 46.7 10.9 29.2 37.4 25.9 
2AvgP [9] 
Fusion 
7 
952 
N 
28.8 68.5 79.2 43.3 36.1 68.1 76.3 46.2 44.7 75.8 83.8 49.8 12.9 36.7 47.4 30.3 
HASC [7] 
Fusion 
7 
1,904 
N 
30.9 70.6 81.8 46.0 38.6 68.7 77.1 48.4 41.8 76.3 85.2 49.5 12.9 35.6 47.3 31.2 
LDFV [28] 
Fusion 
7 
6,944 
N 
25.3 66.8 79.4 42.4 36.4 71.0 80.3 49.1 32.1 66.9 77.6 40.3 16.2 41.9 53.1 35.1 
Cov [40] 
Fusion 
7 
952 
N 
26.9 65.8 77.1 41.2 34.5 64.5 73.6 43.8 40.4 73.4 82.1 46.4 10.6 29.0 36.7 25.5 

(c) 

LOMO [23] CH+SILTP 40 26,960 N 
41.1 82.2 91.1 56.8 49.2 84.2 90.8 62.4 62.6 92.0 96.6 69.4 17.9 46.3 56.2 36.9 
CH+LBP [42] CH+LBP 75 32,250 N 
27.7 69.3 82.4 45.0 31.3 70.4 81.5 48.8 21.5 60.8 74.4 35.0 16.2 45.0 57.1 36.7 
gBiCov [29] 
BIF 
-
5940 
N 
22.8 64.0 77.8 40.4 24.1 55.6 67.2 37.6 27.9 67.2 76.8 38.6 10.6 30.4 41.4 28.2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 .</head><label>3</label><figDesc>State-of-the-art results on CUHK03 (CMC@rank-r).Figure 5. Example images from CUHK03 dataset<ref type="bibr" target="#b20">[21]</ref>. Images in the same column represent the same person. and LOMO<ref type="bibr" target="#b22">[23]</ref> 3 . It can be observed that the GOG descriptor achieves the new state-of-the-art results, 49.7%, 57.8%, 67.3%, 68.4% and 24.7% of rank-1 rate on VIPeR, CUHK01 (M=1), CUHK01 (M=2), PRID450S and GRID dataset, respectively. Since GOG and LOMO adopt the common metric learning, it is clear that the success of our approach comes from our design of a better feature descriptor. The metric ensemble<ref type="bibr" target="#b30">[31]</ref> uses four base metrics, each of them is learned on SIFT, color histogram + LBP, covariance descriptor and CNN. Our descriptor also outperforms such an ensemble of different descriptors.</figDesc><table>Labeled 
Detected 
Methods 
Reference 
r=1 r=5 r=10 r=1 r=5 r=10 
GOG Fusion +XQDA 
Ours 
67.3 91.0 96.0 65.5 88.4 93.7 
MetricEmsemble CVPR2015 [31] 62.1 89.1 94.3 
-
-
-
LOMO+MLAPG ICCV2015 [24] 58.0 -
-
51.2 -
-
LOMO+XQDA CVPR2015 [23] 52.2 -
-
46.3 -
-
ImprovedDeep 
CVPR2015 [1] 54.7 88.3 93.3 45.0 75.7 83.0 
DeepReID 
CVPR2014 [21] 20.7 51.7 68.3 19.9 49.0 64.3 

(a) Labeled 
(b) Detected 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">It is reported that their 7-d pixel feature produces much better results than FV on the SIFT descriptors which is widely used in image classification<ref type="bibr" target="#b33">[34]</ref>. When their pixel features were adopted to the LDFV in our settings, the rank1 recognition rates were 24.8%, 28.2%, 20.2% and 10.5% in VIPeR, CUHK01, PRID450s and GRID dataset, respectively.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The experimental setting of CUHK01 (M=1) is the single shot setting, which is common to<ref type="bibr" target="#b30">[31]</ref> and CUHK01 (M=2) is the multi shot setting in<ref type="bibr" target="#b22">[23]</ref>. The results of the CUHK01(M=1) and PRID450S datasets of LOMO are obtained from the code provided by the author.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">http://www.i.kyushu-u.ac.jp/˜matsukawa/ReID/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An improved deep learning architecture for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Marks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3908" to="3916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Methods of Information Geometry. volume 191 of Translations of mathematical monographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Amari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nagaoka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>American Mathematical Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Geometric means in a novel vector space structure on symmetric positive-definite matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Arsigny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Matrix Analysis Applications</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="328" to="347" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to match appearances by correlations in a covariance metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Charpiat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Corvée</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Brémond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thonnat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">7574</biblScope>
			<biblScope unit="page" from="806" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Boosted human re-identification using Riemannian manifolds. Image Vision Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Corvée</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Brémond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thonnat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Symmetry-driven accumulation of local features for human characterization and re-identification. Computer Vision and Image Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bazzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="130" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Heterogeneous auto-similarities of characteristics (HASC): exploiting relational information for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Biagio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Crocco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Martelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Object recognition with hierarchical kernel descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1729" to="1736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Freeform region description with second-order pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Shape of Gaussians as feature descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2366" to="2371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Person Re-Identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Viewpoint invariant pedestrian recognition with an ensemble of localized features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Log-Euclidean metric learning on symmetric positive definite manifold with application to image set classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Negative evidences and cooccurences in image retrieval: The benefit of PCA and whitening</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="774" to="787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Image feature extraction using gradient local auto-correlations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Otsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="346" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Person reidentification by attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Layne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference, (BMVC)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Local log-Euclidean covariance matrix (L2ECM) for image representation and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A novel earth mover&apos;s distance methodology for image matching with Gaussian mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Human reidentification with transferred metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision (ACCV)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deepreid: Deep filter pairing neural network for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="152" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning locally-adaptive decision functions for person verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3610" to="3617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Person re-identification by local maximal occurrence representation and metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2197" to="2206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient PSD constrained asymmetric metric learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3685" to="3693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multivariate normal distributions parametrized as a Riemannian symmetric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lovrić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Min-Oo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ruh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Time-delayed correlation analysis for multi-camera activity understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Gaussian descriptor based on local features for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision (ACCV) Workshop</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Local descriptors encoded by Fisher vectors for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV) Workshop</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Covariance descriptor based on bio-inspired features for person re-identification and face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="379" to="390" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Global Gaussian approach for scene categorization using information geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nakayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kuniyoshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2336" to="2343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to rank in person re-identification with metric ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paisitkriangkrai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1846" to="1855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Boghossian. Local Fisher discriminant analysis for pedestrian reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pedagadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Orwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Mahalanobis distance learning for person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hirzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Köstinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beleznai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Person Re-Identification</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Image classification with the Fisher vector: Theory and practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Appearance descriptors for person re-identification: a comprehensive review. CoRR, abs/1307</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Satta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">5748</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Covariance of covariance features for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Serra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Manfredi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Multimedia Retrieval (ICMR)</title>
		<meeting>International Conference on Multimedia Retrieval (ICMR)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">GOLD: Gaussians of local descriptors for image representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Serra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Manfredi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Transferring a semantic representation for person re-identification and search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4184" to="4193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep Fisher networks for large-scale image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="163" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Region covariance: A fast descriptor for detection and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="589" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Pedestrian detection via classification on Riemannian manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Person reidentification using kernel-based metric learning methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Camps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sznaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Salient color names for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficient person re-identification by hybrid spatiogram and covariance descriptor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="48" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Person re-identification by salience matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2528" to="2535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised salience learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3586" to="3593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning mid-level filters for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="144" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Reidentification by relative distance comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="653" to="668" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
