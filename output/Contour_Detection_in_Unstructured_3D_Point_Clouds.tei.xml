<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Contour detection in unstructured 3D point clouds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Hackel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">D</forename><surname>Wegner</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><forename type="middle">Schindler</forename><surname>Photogrammetry</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remote</forename><surname>Sensing</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eth</forename><surname>Zürich</surname></persName>
						</author>
						<title level="a" type="main">Contour detection in unstructured 3D point clouds</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe a method to automatically detect contours, i.e. lines along which the surface orientation sharply changes, in large-scale outdoor point clouds. Contours are important intermediate features for structuring point clouds and converting them into high-quality surface or solid models, and are extensively used in graphics and mapping applications. Yet, detecting them in unstructured, inhomogeneous point clouds turns out to be surprisingly difficult, and existing line detection algorithms largely fail. We approach contour extraction as a two-stage discriminative learning problem. In the first stage, a contour score for each individual point is predicted with a binary classifier, using a set of features extracted from the point's neighborhood. The contour scores serve as a basis to construct an overcomplete graph of candidate contours. The second stage selects an optimal set of contours from the candidates. This amounts to a further binary classification in a higher-order MRF, whose cliques encode a preference for connected contours and penalize loose ends. The method can handle point clouds &gt; 10 7 points in a couple of minutes, and vastly outperforms a baseline that performs Canny-style edge detection on a range image representation of the point cloud.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>By and large, modern 3D reconstruction techniques like dense multi-view matching, laser scanning or structured light projection deliver 3D point clouds as primary output. But raw point clouds are of limited use for most applications, and mostly serve as a basis for further processing. Either they are triangulated into an unstructured surface model, e.g. a triangle mesh, for low-level tasks such as visualization; or they are processed into more compact and structured CAD-like higher-level structures, e.g. <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b31">32]</ref>. Perhaps the most widely used approach in this context, especially for indoor applications, is to locally fit parametric surfaces or solids to the data. Line features then follow as a last step, by intersecting surface primitives. Such an approach can work well for schematic surface geometries, but quickly reaches its limits when portions of the scene are not covered by the primitive library. <ref type="figure">Figure 1</ref>: Given an unstructured 3D point cloud (black), our method detects contours (red). Challenges include strongly varying point density (e.g., front facade vs. roof of the church); occlusions and missing data (e.g., dormer on the left); and sheer data volume (here, ≈ 3 · 10 7 points).</p><p>Here, we propose to proceed the other way round. Our goal is to extract contours in outdoor point clouds such as those acquired by terrestrial laser scanners, see <ref type="figure">Fig. 1</ref>. By contours we mean linear features along which the orientation (normal) of the underlying surface exhibits an unusual discontinuity. Arguably, such wireframe-like line features are a lower-level representation than CAD surfaces or solids, in the sense that humans can "see" them in the raw data -the point cloud alone is sufficient to draw contours, even for relatively unconstrained surfaces that cannot be represented with a small library of primitives.</p><p>In that sense, it seems natural to detect contours before surface reconstruction, and use them to drive the segmentation and/or to fit surface patches -which is in fact how interactive modelling systems operate, both in graphics and vision <ref type="bibr" target="#b24">[25]</ref> and in commercial mapping <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b5">6]</ref>.</p><p>At first sight, it may seem quite simple to detect crease edges in point clouds. In practice, it turns out to be surprisingly challenging, for several reasons. On the conceptual side, the definition of what constitutes a contour is not as clear-cut as it seems, and hard to formalise. While it should certainly have one high and one relatively low principal curvature at some (not necessarily fixed) scale, there are fur-ther relevant properties like sufficient length, few sudden changes of the line direction, etc. Informally speaking, it is "where a CAD operator would draw a line or curve."</p><p>On a more technical note, scanners and cameras are lineof-sight sensors, hence real point clouds inherently suffer from occlusions and incomplete data, and exhibit extreme variations in point density (depending on the distance to the sensor and the surface orientation). Both effects are a lot stronger outdoors, where they are not mitigated by the limited size and constrained shape of rooms. See <ref type="figure">Figs. 1, 3</ref>.</p><p>The contribution of the present paper is a contour detector, which casts the problem as a two-level discriminative learning task. First, a binary classifier is trained which, for each 3D point, predicts the likelihood of lying on a contour, given the geometry in a local neighborhood and the point's latent semantic class probabilities. Based on these contour scores, we design a hypothesize-and-verify framework that takes into account the line structure: points with high score serve as seed points to construct an overcomplete contour graph; an optimal subset of the graph edges is then selected in another binary labeling task on a higher-order random field, to obtain the final contours. The first step can be interpreted as a discriminative version of classical multiscale point set analysis such as <ref type="bibr" target="#b21">[22]</ref>. By using supervised learning, the detector implicitly learns which properties define (in the eyes of the users who labeled the training data) a point on a contour. In practice this gives much improved scores compared to simple curvature values, especially in terms of precision. The second step can be seen as a global model for linking individual edge points to an contour network, while taking into account evidence collected along longer (candidate) lines; rather than greedily linking individual points, as for example in the classical Canny detector <ref type="bibr" target="#b3">[4]</ref>. We are not aware of any comparable method for 3D contour extraction.</p><p>In experiments on several laser scans each containing on the order of 10 7 -10 8 points the method delivers highquality contours. In a quantitative comparison on a real outdoor scan, the proposed method achieves an average F 1score of 80%, whereas a 3D range image variant of the Canny edge detector badly fails.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The task of 3D contour extraction is related to the elementary image processing task of line detection. In this context it is important to note that even in 2D images (respectively, regularly sampled 3D image stacks) line extraction is surprisingly difficult, if one adopts a more highlevel definition of what a "line" is. Although low-level algorithms like the Canny edge detector <ref type="bibr" target="#b3">[4]</ref> are widely used to detect and link adjacent high-contrast pixels, the extraction of structured line information is still an active research topic, for example in medical imaging <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b27">28]</ref>, stereo reconstruction <ref type="bibr" target="#b6">[7]</ref> and topographic mapping <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b18">19]</ref>. These more recent works have in common that they rely on a hypothesize-and-verify strategy: (i) find points that are likely to lie on lines with low-level image processing; (ii) link those points to candidate lines, with shortest-path search or minimum spanning trees; (iii) use context features extracted along their entire length and/or CRF-type connectivity priors to reassess the candidate lines, and retain only an optimal subset.</p><p>When working on the basis of images, one possible solution is to extract line features in 2D and then triangulate them to 3D lines. Still, even that approach has in practice largely been limited to "clouds" of disconnected, straight line segments <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b12">13]</ref>. The problem becomes even more difficult when moving to 3D point clouds, with strongly varying point density and no regular neighborhood structure. A possible approach is to first turn the point cloud into a triangle mesh with all-purpose methods like Poisson reconstruction <ref type="bibr" target="#b14">[15]</ref>, and then analyze the mesh to find contours. Unfortunately, such approaches tend to wash out sharp edges and struggle to distinguish them from less pronounced regions of relatively high curvature. This is indeed not surprising, because surface reconstruction from noisy data typically involves a prior that smoothes the surface, which contradicts the goal to find sharp contours. Solutions have been developed which attempt to identify sharp creases before or during mesh generation. This is in accordance with our claim that line features should be identified early and used to support surface modelling. However, existing approaches <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b20">21]</ref> work locally, without taking into account long-range line structure, and use only basic surface features. Thus they struggle to distinguish between contours and areas of high surface roughness (e.g. vegetation), which renders them unsuitable for outdoor scenarios.</p><p>An alternative to triangle meshes are parametric 3D primitives like boxes, spheres, or cylinders. Several authors fit such primitives to point cloud data and combine them with simple set operations like union and intersection, leading to CAD or CSG (constructive solid geometry) models <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b31">32]</ref>. Again, it appears that fitting solids works best if the line structures have been made explicit beforehand <ref type="bibr" target="#b15">[16]</ref>. That work again uses a rather simplistic, purely local definition of lines. Moreover, a small library of CSG primitives is too limited to faithfully represent realistic scenes, which is why high-quality reconstructions fall back to filling the gaps with triangle meshes <ref type="bibr" target="#b15">[16]</ref>.</p><p>The starting point of the present work is the recurring need for complete and accurate contours to support subsequent processing steps. We do not commit to any particular surface or solid modelling technique, rather our aim is to generate wireframe (WF) models. Their greater flexibility makes them applicable to both parametric and free-form surface regions, and they can even serve to select the most suitable representation for a given point cloud or region, and to optimally fit it to the data. It has been suggested to extract line segments with robust model fitting algorithms like RANSAC or the Hough transform, and then link the soup of segments into wireframes <ref type="bibr" target="#b11">[12]</ref>. Such a strategy will however restrict the geometry of the lines to a small set of predefined parametric models, and thereby lose much of the advantage of wireframes compared to solid-based representations. Early work on contour extraction, often from the more isotropic point clouds captured by aerial laser scanners, used rule-based expert systems to exhaustively cover all expected types of contours, e.g. <ref type="bibr" target="#b1">[2]</ref>. The higher complexity of close-range point clouds renders it infeasible to design and tune such expert systems by hand, which calls for a machine learning approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>Our method to extract wireframe edges consists of three main steps as shown in <ref type="figure" target="#fig_0">Fig. 2</ref>. Starting from the raw point cloud without any preprocessing, we proceed as follows:</p><p>• for each individual point, discriminatively predict the probability of lying on a contour;</p><p>• find regularly spaced points with high contour scores, and link them into a graph of candidate contours.</p><p>• select an optimal subset of those candidates as final wireframe edges, by approximate inference in a higher-order random field defined over the graph edges and their adjacency relations.</p><p>This pipeline bears some similarity to recent work that aims to extract curvilinear networks from images <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b10">11]</ref>.</p><p>Other than those works, we operate on irregular 3D point clouds rather than regular 2D or 3D image rasters. But like them, we greatly improve over classical Canny-type detectors by following three recurrent lessons of modern computer vision research: (i) use discriminative learning with rich feature sets, rather than raw differential geometry, to obtain low-level evidence at the scale of points/pixels; (ii) aggregate the points/pixels into higher-level primitives and use orientation statistics over the entire neighborhood to describe those primitives; (iii) include a prior about the expected neighborhood structure to capture long-range relations between primitives. In the following, we describe in detail how we implement those principles for contour extraction in unstructured point clouds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Pointwise contour scores</head><p>The first step of the proposed pipeline is to compute low-level evidence for the presence of a contour. At each 3D point, we predict the likelihood that it lies on a contour with a binary, discriminative classifier, based on multiscale surface properties in the point's local neighborhood. In that sense the method can be seen as a discriminative extension of early methods for feature extraction from point clouds <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b21">22]</ref>. Those methods relied on (possibly multiscale) curvature values computed from the point neighborhood. We found that, unsurprisingly, curvature alone is not a very good feature to identify contours. The definition of what constitutes a contour is unsharp and ill-posed, and includes properties like that the line should separate two regions of different, but well-defined surface orientation; or, that it should be part of of a sparse wireframe network. This clearly goes beyond individual curvature values, e.g. rough surfaces and volumes such as bushes and tree crowns in outdoor scans exhibit high per-point curvature, but are not perceived as contours. We thus rely on an extended feature set to describe the point neighborhood, including those proposed in <ref type="bibr" target="#b30">[31]</ref> for semantic labeling of 3D point clouds, as well as newly developed features that emphasize occlusion boundaries and transitions between smooth surfaces.</p><p>In our framework we avoid using color and/or intensity values, which, depending on the recording technology, are not always available; and often also unreliable because of strong lighting effects. Thus, we face a purely geometric classification problem: learn a binary classifier for the two classes contour (c i = 0) and non-contour (c i = 1). With that classifier, predict a contour score p(c i |x i ) for each individual point p i , given the point's feature vector x i . Several authors <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b30">31]</ref> have proposed geometric features for point cloud classification (usually into semantic object classes) that are based on the covariance tensor Σ i ,</p><formula xml:id="formula_0">Sum λ1 + λ2 + λ3 Omnivariance (λ1 · λ2 · λ3) 1 3 Eigenentropy − 3 i=1 λi · ln(λi) Anisotropy (λ1 − λ3)/λ1 Planarity (λ2 − λ3)/λ1 Linearity (λ1 − λ2)/λ1 Surface Variation λ3/(λ1 + λ2 + λ3) Sphericity λ3/λ1 First Order Moment O, see Eq. (2) Line Feature Q, see Eq. (3) Orientation Feature R, see Eq. (4) Verticality 1 − | [0 0 1], e3 |</formula><formula xml:id="formula_1">Σ i = 1 N n∈P N i (p n − p)(p n − p) ⊤ ,<label>(1)</label></formula><p>where P N denotes the set comprising the N nearest neighbours of p i , and p = med n∈P N (p n ) is the medoid. The features are, by and large, based on different arithmetic combinations of the eigenvalues λ 1 ≥ λ 2 ≥ λ 3 ≥ 0 and eigenvectors e 1 , e 2 , e 3 of the covariance tensor. We use the features of <ref type="bibr" target="#b30">[31]</ref>, see <ref type="table" target="#tab_0">Table 1</ref>.</p><p>The original feature vector lacks information about occlusion boundaries. We thus add an additional feature dimension based on the first order moment m↑ of p i around the first eigenvector e 1 of the structure tensor,</p><formula xml:id="formula_2">O = m 2 ↑ m⇑ with m↑ = n∈P N i p n − p i , e 2 , m⇑ = n∈P N i p n − p i , e 2 2 ,<label>(2)</label></formula><p>where ., . denotes the scalar product. The normalization with the second order moment m⇑ ensures O ∈ [0, 1], to suppress the effects of varying point density. Moreover, the standard eigenvalue features do not explicitly capture the fact that contour points should (i) be arranged along locally smooth 1D paths of consistently high curvature and (ii) separate surface areas with different orientations. We thus design two more feature dimensions for those properties. The first one is similar to a 3D line detector: we approximate the tangent of the putative contour with the first moment and split the points in the neighborhood into a subset C near of size ⌈α · N ⌉ which are closest to the tangent, and the remaining points C far (reusing the projections d i,n = | p n −p i , e 2 | from the previous feature). For each point we examine the local surface variation γ n = λ 3 /(λ 1 +λ 2 +λ 3 ). The ratio between the average surface variations of the two subsets serves as feature</p><formula xml:id="formula_3">Q = mean n∈Cnear (γ n ) mean n∈C far (γ n ) .<label>(3)</label></formula><p>Empirically we found the best split to be α = 0.2. The second feature targets the change in surface normal along the tangent. Again the N neighbours in P N i are split into two subsets, one set P l for the points on the "left" side of the tangent and the other P r for the "right" side. The feature is then the angle between the left and right medoid normal,</p><formula xml:id="formula_4">P l = {p n ∈ P N | p n , e 3 &lt; 0} , P r = P N \ P l R = med n∈P l (n n ), med n∈P r (n n ) .<label>(4)</label></formula><p>It is well-known that methods which rely on the local orientation and curvature in general benefit from multiscale representations, and this is even more true for unevenly sampled 3D point clouds. Like <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b2">3]</ref> we therefore vary the size of the neighborhood P N and extract all geometric features at 9 different scales, by voxel-grid down-sampling of the raw point cloud with voxel sizes s ∈ {0.01, 0.05, 0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4} <ref type="bibr">[m]</ref>.</p><p>It is reasonable to assume that the definition of a contour also depends on the semantic object class(es) one is looking at, e.g. the transition from man-made ground surface to building wall is rather likely to form a contour, and on buildings an occluding contour is more likely to be a contour than on a tree. Moreover, it has been shown by several authors that geometric features of the type described above perform reasonably well also for the task of semantic point cloud labeling. We thus run a random forest classifier on the geometric feature set described above, with seven possible class labels natural ground, man-made ground, low vegetation, high vegetation, buildings, scanning artifacts, and a rejection class for other objects. The estimated class probabilities per point are also included in the feature vector for contour detection. Note that, although the geometric features are the same, this step does add the information that is contained in the semantic labels of the training data.</p><p>Given the complete feature set described so far, we train another, binary random forest to predict the contour score p(c i |x i ) of a point p i , see <ref type="figure" target="#fig_0">Fig. 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Contour candidate generation</head><p>Given point-wise scores, we identify contour points and link them to contours following a hypothesize-and-verify strategy, i.e. we generate an over-complete set of contour candidates that is pruned to an optimal subset. The idea <ref type="figure">Figure 3</ref>: If the horizontal point density decreases more rapidly than the vertical density, "scan lines" become visible (on the left).</p><p>is that explicitly processing contour segments (instead of points) delivers more expressive, long-range evidence along the entire line length. Also, they allow one to impose connectivity constraints to favor longer, connected contours.</p><p>Candidate generation consists of (i) local non-maxima suppression (NMS) to find seed points with high contour probability p(c i = 0|x i ); and (ii) linking seed points into an over-complete graph of putative contour segments.</p><p>Voxel-grid non-maxima suppression. Traditional line detectors like Canny select points with high scores as seeds to bootstrap line tracing. However, contour likelihoods of 3D point clouds are very unevenly distributed. Consequently, simple thresholding tends to either miss contours (if set too high), or to generate too many seeds (if too low), which in turn would lead to a huge candidate set that defies further processing. Note that both cases will also result in candidate segments of greatly varying length. We therefore opt for an adaptive NMS that produces a more uniform distribution of seed points: we discard only points below a conservative threshold p(c i = 0|x i ) &lt; 0.5, then perform voxel-grid filtering (with s = 0.1 [m] spacing). Only the point with the highest score per voxel is retained. Of those remaining, points that have a neighbor in P N with a higher score are removed, except for neighbors along the local tangent (approximated by the eigenvector e 1 of the covariance tensor). Furthermore, the less confident of two points along the tangent is removed if their distance is &lt; 0.5 · s. With the described NMS rules, seed points will have a spacing &lt; 2·s if they lie on potential contours, and &lt; 3 · s otherwise.</p><p>Graph construction. Next, seed points must be locally connected to a neighborhood graph. Recall that outdoor laserscan point clouds have a very anisotropic point distribution <ref type="figure">(Fig. 3)</ref> due to quadratic decrease in point density with increasing distance from the sensor. Voxel-grid filtering can partially reduce this effect in high-density areas, but is less efficient in the far-field. Another characteristic property that complicates neighborhood graph construction is varying point spacing in horizontal and vertical direction on slanted surfaces. Previous works usually connect points across large neighborhoods, which however quickly becomes intractable in terms of memory and computation time when dealing with millions of points. An al-ternative strategy is to sample random points on (estimated) surfaces <ref type="bibr" target="#b17">[18]</ref>. This strategy seems inappropriate for contour delineation because it risks to alter lines by hallucinating points in low-density regions.</p><p>Our method first connects seed points p i ∈ P into a knearest neighbor graph with a low number of neighbors k 1 = 5, to obtain an initial edge set E 1 . Second, a larger neighborhood k 2 = 50 is constructed per point and reduced to a minimum spanning tree (MST) with Prim's method. MST edges of all points are added to E 1 to yield the complete edge set E. Finally, edge set E is reduced to a set of candidate contours, defined as chains of adjacent edges, by searching for up to β = 15 minimum-cost paths that connect a seed point to its neighbors within a radius r link = 0.85 m. We define graph edge costs as</p><formula xml:id="formula_5">e ij = 2 − p(c i |x i ) + p(c j |x j ) 2 − d * p i − p j ,<label>(5)</label></formula><p>with p i − p j the Euclidean length of the edge between p i , p j , and d * the smallest distance from either of the two endpoints p i , p j to all other points. In practice it is not necessary to run Dijkstra's algorithm globally over long distances, but only within the local neighborhood 2 · r link thus keeping computation efficient. Edges that are not part of any shortest path are discarded. All (overlapping) shortestpath edge chains form the set of candidate contours. We point out that more sophisticated methods have been proposed to remove unwanted edges from the raw neighbourhood graph, e.g. ant colony optimisation in <ref type="bibr" target="#b28">[29]</ref>. For large graphs with millions of points such methods are computationally demanding and this step quickly becomes a bottleneck of the overall system. Local shortest-path search is a pragmatic compromise that, in our experience, gives very similar results in much less time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Contour edge labeling</head><p>The final step of the proposed contour detector is to select a subset of the candidate edges, such that it best covers the actual contours. This is another binary labelling problem, this time on a Markov Random Field defined by the candidate graph, in which the candidate contours (rather than the original 3D points) are the variables. To that end we design a novel unary term that takes into account both the contour scores of the associated points and their spatial layout. The expectation that contours should mostly form a connected wireframe is encoded via higher-order terms that discourage free endpoints.</p><p>Unary Term. The unary term encodes statistics about both the per-point scores and the point distribution along a putative contour. For the point distribution we introduce a new descriptor, cumulative shape context, based on the pointwise shape context of <ref type="bibr" target="#b0">[1]</ref>. The original shape context captures the relative locations of points in an image, by picking one point p i as the origin of a local coordinate system and building a polar histogram over the relative positions v ij = p j − p i of other points in its neighbourhood. The procedure to gather statistics about the distribution of discrete points makes the method appealing for our data. Compared to the original application, we require statistics about an entire contour candidate, which consists of a sequence of points. Moreover, the descriptor in our case should be invariant to rotation and scale. To achieve scale invariance and at the same time simplify the descriptor to 1D, we discard relative distance and encode only directions, by normalising the vectors. Rotation invariance is achieved by projecting them onto the canonical direction v se = p e −p s defined by the start point p s and end point p e of the contour candidate. To collect the directional statistics from all points along the candidate, we simply add their histograms together into a single one. Taken together, we visit each point p i along the putative contour, and let each of the other points p j generate a scalar value</p><formula xml:id="formula_6">v ij = v se v se , v ij v ij ∀ i, j ∈ {s, . . . , e} : i = j . (6)</formula><p>The v ij are then quantised into 5 equally spaced bins to form a 1D histogram z 1 . To also include information about the overall straightness/curvature of the contour candidate, we repeat the computation of the cumulative shape context descriptor, but this time normalise the rotation w.r.t. the local tangent (first eigenvector) e 1,i :</p><formula xml:id="formula_7">w ij = e 1,i , v ij v ij ∀ i, j ∈ {s, . . . , e} : i = j ,<label>(7)</label></formula><p>to obtain a second histogram z 2 .</p><p>To retain the pointwise contour likelihoods p(c i |x i ) from section 3.1, they are again histogrammed over the points on the candidate contour, in two different ways. The first histogram simply quantises the scores directly into 5 bins to obtain z 3 . For the second one the candidate is chopped into b segments of equal length, and the mean probabilities of the segments form a further set of features z 4 , which captures the variation of the score along a candidate. Overall, a much stronger descriptor can be obtained by aggregating information along contour candidates (i.e. edge chains), rather than looking only locally at the level of points. In that sense the approach is similar in spirit to recent work on line feature extraction in medical imaging, e.g. <ref type="bibr" target="#b27">[28]</ref> compute HOGstyle features along similar candidate edges.</p><p>To obtain a discriminative unary, the descriptors z = [z 1 , z 2 , z 3 , z 4 ] are again fed into a two-class random forest to obtain a class-conditionals p(g|z) for being (g i = 1) or not being (g i = 0) a contour. For the subsequent MRF inference the class-conditional probabilities are converted to log-likelihoods ("energies") in the usual manner, h i = − log p(g i |z i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Markov Random Field.</head><p>To obtain a wireframe-type model in which the contours are long, and if possible form closed contours, we encourage contours that meet at their endpoints. Perhaps the simplest way to do so is to embed the candidate contours as variables (nodes) in an MRF. Each contour candidate l i defines a clique ℓ i together with all other candidates with which it shares either the start node or the end node. <ref type="bibr" target="#b0">1</ref> Denoting the set of contours that connect to l i at the start node as L s i , and similarly those which meet l i at the end node L e i , we have</p><formula xml:id="formula_8">ℓ i =                              γ g i = 1 AND ∀ l j ∈ L s i , L e i : g j = 0 (isolated contour)</formula><p>δ g i = 1 AND (∃ l j ∈ L s i : g j = 1 XOR ∃ l j ∈ L e i : g j = 1) (continuation only on one side) 0 g i = 1 AND ∃ l j ∈ L s i : g j = 1 AND ∃ l j ∈ L e i : g j = 1 (continuation on both sides)</p><formula xml:id="formula_9">0 g i = 0</formula><p>(candidate is not a contour) (8) The cliques are of varying order, depending on how many candidates meet at the start/end points of l i ; but there are only as many cliques as variables, and each clique depends only on the direct neighbours and can be computed efficiently. There are MRF formulations that enforce connectivity over long distances, but they need known foreground seeds and are computationally a lot more demanding <ref type="bibr" target="#b29">[30]</ref>.</p><p>The overall energy in our MRF simply reads E = i h i + i ℓ i . We minimize it with Iterated Conditional Modes (ICM), because of its low computational cost <ref type="bibr" target="#b13">[14]</ref>. Stronger inference methods like loopy believe propagation yield comparable results, with much higher runtime.</p><p>Note that there is no penalty for selecting overlapping candidates. In our setting it does not hurt if multiple contours overlap, since they are based on the same points and can be unambiguously repaired in post-processing. On the contrary, a pairwise potential that suppresses overlapping contours would be harmful, because wireframe junctions are not known in advance, and it can happen that candidates extend past a junction. In such cases, overlapping contours are necessary to recover the junction correctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We evaluate the proposed contour detector on a large database of laserscans with a total of more than one billion 3D points. The scans were captured in different cities and villages across Europe and Asia, using professional, surveying-grade laser scanners. Visually, the results on 16 different point clouds demonstrate that our method generalises well across different scenes and locations, see  for examples. One of the scans was hand-labeled to serve as ground truth, comprising 101 ′ 614 points on contours and 7 ′ 681 ′ 061 background points. Trees and clutter caused by moving occluder were left unlabeled to allow for a fair comparison against methods that do not have access to semantically annotated training data. This is a bias against our proposed method. Our contour scores (Sec. 4.1) can handle these object classes, largely thanks to the semantic classconditionals included in the feature vector. On the contrary, methods based only on curvature, like the Canny baseline, would generate massive amounts of false positives on them, hence we exclude them from the comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Pointwise Classification</head><p>As quality metrics for quantitative evaluation, we use precision-recall curves, evaluated over individual 3D points. The pointwise contour detector (Sec. 4.1) is trained on 48 ′ 964 positive and 85 ′ 853 negative examples taken from other cities than the test set. Our Random Forests always consist of 50 trees, their tree depth is determined automatically by grid search, with 5-fold cross-validation over the training set. <ref type="figure">Figure 5</ref> shows the performance of our pointwise contour score, as well as standard baselines. Most related methods, which also perform some sort of edge or line detection in point clouds, threshold either curvature values or a combination of curvature and occlusion features. In particular, single-scale curvature and occlusion form the ba-sis of RGB-D edge detection in <ref type="bibr" target="#b4">[5]</ref>, while multi-scale curvature is the descriptor used by <ref type="bibr" target="#b21">[22]</ref>. Our goal is to compare the power of different feature sets, thus we do not set thresholds, but instead learn Random Forest classifiers also for the baseline feature sets. Together with the cross-validation described above this is more or less guaranteed to perform at least as well as a single threshold per feature dimension. In the comparison there are several interesting observations. Single-scale detectors are practically useless in large-scale outdoor point clouds, because of the strongly varying point density. Even in the multi-scale version, curvature alone is not suitable, because outdoor point clouds are never complete, thus many contours appear as occlusion edges with data only on one side. And even multi-scale curvature and contour features do not capture all important information: our full feature set still performs significantly better than the best baseline, over the entire precision-recall curve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Linewise Classification</head><p>We go on to separately evaluate the proposed features at the level of entire contour candidates, i.e., the unary term of our MRF (Sec. 3.2). Since a contour candidate spans many points, the training set for lines has only 1862 contours and 832 negatives (automatically generated contour candidates that do not coincide with ground truth contours) The Random Forest was trained with the same settings as above. <ref type="figure">Figure 5</ref> shows the results on the test set (2227 posi- <ref type="figure">Figure 6</ref>: (left) Connected contour segments on our test set; (middle) Histogram of contour lengths; (right) A failure case: if objects with strong geometric structure did not appear in the training set, then they tend to get high contour scores.</p><p>tives, 1013 negatives). As expected, simply aggregating the pointwise scores as evidence for a contour already works reasonably well. Adding information about the shape of the contour, in the form of cumulative shape context features, improves the performance further, most notably is the highprecision regime (up to ≈20 percent points).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Full Framework</head><p>We do not have access to any direct competitor that also extracts contours in 3D point clouds. The closest independent baseline that we could find is the 3D Canny variant of <ref type="bibr" target="#b4">[5]</ref>. That detector requires a so-called "organised point cloud", i.e. a depthmap with regular neighbourhood structure, both to compute low-level evidence such as depth discontinuities and to link the edge points into lines. We thus convert our test set, which stems from a single scan position and therefore comes in a regular (angular) grid, into a depth image on a cubemap.</p><p>At this point the evaluation faces a subtle, but important problem: the Canny baseline does not return line segments, but only a list of all points that form part of a line. Hence, we can only evaluate against the pointwise ground truth. Our method, on the other hand, aims to find lines. To that end it suppresses many of the individual points along a contour through non-maxima suppression (NMS), which would all be flagged as false negatives.</p><p>As a compromise, we emulate the NMS during evaluation, based on the detection result. On the one hand, we do not count false negatives that are less than 3 cm away from the nearest true positive. On the other hand, we identify false negatives in the detection results, and ignore additional false negatives within 3 cm in the ground truth. This filtering approximately corrects for point dropped by NMS during candidate generation. Still, it counts gaps of &gt; 6 cm in the contour network as false negatives, and it also counts false positives not present in the ground truth, with their expected point count after NMS. We believe that for a relative comparison the approximation is meaningful, however note that the absolute precision/recall values cannot be compared to the one for pointwise classification. As can be seen in <ref type="figure">Fig. 5</ref>, the proposed detector vastly improves over a sim-ple Canny edge detector on range images, which essentially fails. We have tried to tune the two thresholds of Canny for seed generation and linking separately, so as to maximize the performance on our test set, but did not manage to improve over the depicted curve.</p><p>Recall that our contours are ordered sequences of 3D data points. Colour-coded example contours are shown in <ref type="figure">Fig. 6</ref>. We currently do not break up contours at points of high curvature ("corners") or where more than two segments meet ("junctions"), since there is no need to do so in our application. In this setting the detected contours' median and average lengths are 28, respectively 187 points. For our specific data -urban outdoor scans in metric world units -this corresponds to 0.5 m, respectively 3.7 m. The full histogram of contour lengths is also shown in <ref type="figure">Fig. 6.</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Failure cases</head><p>We have observed two main sources of failure for our contour detector. The main type of error happens at disconnected contours that are very close to each other. If the distance between two contours is less than the voxel size s of our NMS, then the candidate generation as well as the MRF prior will tend to hallucinate spurious connections.</p><p>Another problem comes from the machine learning backbone of our method. Regions that have a large amount of geometric structure, but have not been seen in the (negative) training data, tend to get high contour scores and induce false positives. <ref type="figure">Figure 6</ref> shows a case with window blinds that were never seen during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have proposed a novel approach to detect contours in unorganized 3D point clouds, which is able to handle data from complex outdoor environments. In our experiments the proposed detector work robustly across a range of laser-scanning datasets, whereas a standard Canny-like baseline badly fails. Our method is also computationally efficient enough for practical application: processing ten million points only takes a couple of minutes an a single desktop PC.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of our contour detection pipeline. (left) A binary classifier predicts pointwise contour scores (red: high contour probability, blue: low contour probability); (middle) Seed points with high contour scores are linked into an overcomplete graph of contour candidates; candidates are rescored with another round of classification; (right) candidates are pruned to an optimal set of contours by MRF inference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4</head><label>4</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Contour detection results at different locations. (left) Bildstein; (middle) Munich; (right) Singapore. Precision-Recall Curves. Please note, each stage requires different ground truth, so values are not comparable across diagrams. See text for details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Geometric features based on the eigenvalues and eigenvector of the structure tensor.</figDesc><table></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">"Start" and "end" are used for convenience, the graph is undirected.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Shape matching and object recognition using shape contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Three-dimensional modelling of breaklines from airborne laser scanner data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Briese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Archives</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">B3</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">3d terrestrial lidar data classification of complex natural scenes using a multi-scale dimensionality criterion: Applications in geomorphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Brodu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJPRS</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="121" to="134" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A computational approach to edge detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">RGB-D edge detection and edge-based registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Trevor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">I</forename><surname>Christensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
				<ptr target="http://www.photomodeler.com/index.html" />
	</analytic>
	<monogr>
		<title level="m">Photomodeler</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">3d curve sketch: Flexible curvebased stereo reconstruction and calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fabbri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kimia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Robust moving least-squares fitting with sharp features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fleishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM ToG</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Feature extraction from point clouds. Int&apos;l Meshing Roundtable</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gumhold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcleod</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Relevance of airborne lidar and multispectral image data for urban scene classification using random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chehata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mallet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boukir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJPRS</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A multistage approach to curve extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kimia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Extracting wire-frame models of street facades from 3d point clouds and the corresponding cadastral map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hammoudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dornaika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Soheilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Paparoditis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Archives</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3A</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Line3d: Efficient 3d scene abstraction for the built environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A comparative study of modern inference techniques for discrete energy minimization problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Kappes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schnörr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">X</forename><surname>Kausler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lellmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Screened poisson surface reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM ToG</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Creating large-scale city models from 3d-point clouds: a robust approach with hybrid representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lafarge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Globfit: Consistently fitting primitives by discovering global relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chrysathou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM ToG</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">On fast surface reconstruction methods for large and noisy point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Beetz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>ICRA</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Mind the gap: modeling local and global context in (road) networks. GCPR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Montoya-Zegarra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Wegner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ladickỳ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Matching of straight line segments from aerial stereo images of urban areas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">O</forename><surname>Ok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Wegner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Heipke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rottensteiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Soergel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Toprak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJPRS</title>
		<imprint>
			<biblScope unit="page">74</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Feature preserving point set surfaces based on non-linear kernel regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Öztireli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Guennebaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multi-scale feature extraction on point-sampled surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pauly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Keiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Automatic line matching across views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient RANSAC for point-cloud shape detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Reconstructing polyhedral models of architectural scenes from photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Debevec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inpho</forename><surname>Trimble</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Geo-Modeling Module</surname></persName>
		</author>
		<ptr target="http://www.trimble.com/imaging/inpho.aspx?tab=Geo-Modeling_Module" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Detection of linear features in SAR images: application to road network extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tupin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Maitre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-F</forename><surname>Mangin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Nicolas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pechersky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TGRS</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Automated reconstruction of tree structures using path classifiers and mixed integer programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Türetken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Benmansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Automated reconstruction of dendritic and axonal trees by global optimization with geometric priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Türetken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Graph cut based image segmentation with connectivity priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Feature relevance assessment for the semantic interpretation of 3d point cloud data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weinmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jutzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Annals</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">W2</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Reconstructing the world&apos;s museums</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Furukawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
