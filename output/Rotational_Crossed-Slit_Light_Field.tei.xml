<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rotational Crossed-Slit Light Fields</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianyi</forename><surname>Li</surname></persName>
							<email>nianyi@eecis.udel.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiting</forename><surname>Lin</surname></persName>
							<email>haiting@eecis.udel.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilin</forename><surname>Sun</surname></persName>
							<email>sunbilin@eecis.udel.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyuan</forename><surname>Zhou</surname></persName>
							<email>mzhou@eecis.udel.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyi</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">ShanghaiTech University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Rotational Crossed-Slit Light Fields</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Light fields (LFs) are image-based representation that records the radiance along all rays along every direction through every point in space. Traditionally LFs are acquired by using a 2D grid of evenly spaced pinhole cameras or by translating a pinhole camera along the 2D grid using a robot arm. In this paper, we present a novel LF sampling scheme by exploiting a special non-centric camera called the crossed-slit or XSlit camera. An XSlit camera acquires rays that simultaneously pass through two oblique slits. We show that, instead of translating the camera as in the pinhole case, we can effectively sample the LF by rotating individual or both slits while keeping the camera fixed. This leads a "fixed-location" LF acquisition scheme. We further show through theoretical analysis and experiments that the resulting XSlit LFs provide several advantages: they provide more dense spatial-angular sampling, are amenable multi-view stereo matching and volumetric reconstruction, and can synthesize unique refocusing effects.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Light fields are image-based representation that records the amount of light (radiance) falling in every direction through every point in space. The original light field representation can be described using the 5D plenoptic function (3D for location and 2D for directions). If we assume that the radiance remains constant from point to point along the ray, the plenoptic field is redundant in one dimension and it is possible to describe the light field using a 4D representation. Most notable example for representation such a 4D function is to use the two-plane parametrization or 2PP where a pair of parallel planes Π st and Π uv are given in prior 3D space and each ray is represented by its intersection with the planes as (s, t, u, v) <ref type="bibr" target="#b12">[13]</ref>.</p><p>One of the most important tasks in image-based modeling and later computational photography and imaging is to conduct efficient sampling of the 4D light field. Early examples include capturing the scene using a camera array. The MIT LF camera array uses a grid of 64 1.3 megapixel usb webcams whereas the Stanford array is a two-dimensional grid composed of 128 1.3 megapixel Firewire cameras. At each camera location (s, t), it samples a uv slice that corresponds the image captured camera. Yu and McMillan <ref type="bibr" target="#b26">[27]</ref> have shown that each sampled image actually corresponds to a 2D planar slice in the 4D field. The camera array, in essence, samples the 4D space using a sequence of 2D slices. More recent designs such as the light field camera <ref type="bibr" target="#b15">[16]</ref> follows the same sampling strategy using a microlenslet array. Compared with the camera array, they can sample more densely on the st dimension due to small microlenslet baselines but sacrifices the uv resolution.</p><p>In this paper, we demonstrate an alternative LF sampling scheme. Specifically, we exploit the non-centric crossedslit or XSlit camera for acquiring the LF. An XSlit camera captures rays that simultaneously pass through two oblique (neither parallel nor intersecting) slits in 3D space <ref type="bibr" target="#b29">[30]</ref>. If the two slits are parallel to the 2PP, the captured rays lie on a 2D planar surface in the 4D ray space <ref type="bibr" target="#b23">[24]</ref>. In fact, the pin- hole camera can be viewed as a special XSlit camera where the two slits intersect. Although XSlit geometry has been thoroughly studied <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b26">27]</ref>, only recently practical designs <ref type="bibr" target="#b23">[24]</ref> have put them into uses for computer vision tasks such as scene understanding and reconstruction <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>We adopt the design by Ye et al. <ref type="bibr" target="#b23">[ 24]</ref> that relays two cylinderical lenses with slit apertures as the XSlit camera. To sample the LF, our approach is to rotate the XSlit camera along its optical axis, and we show the resulting Rotational XSlit (or RXSlit) sampling scheme provides substantial benefits. On the acquisition front, our new sampling scheme can achieve "fixed-location" light field acquisition. By rotating rather than translating the camera, we eliminate the need of building the camera array or moving the camera along the grid. On the reconstruction front, we show that the new sampling pattern enables more effective view synthesis and dynamic refocusing. Recall that the previous camera array samples uv slices at discrete st locations. Therefore, a new uv slice at an undersampled s ′ t ′ location does not contain any samples and brute-force interpolation leads to severe ghosting or aliasing <ref type="bibr" target="#b27">[28]</ref>, as shown in <ref type="figure" target="#fig_1">Fig. 2(a)</ref>. In contrast, we show under the rotational XSlit sampling scheme every perspective view will contain some minimum number of samples, as presented in <ref type="figure" target="#fig_1">Fig. 2</ref></p><formula xml:id="formula_0">(b).</formula><p>We further validate our analysis on using the R-XSlit light field for dynamic refocusing and volumetric reconstruction. Analogous to refocusing with a camera array, we specify a proxy geometry plane and then project all XSlit views onto the plane. The refocused results exhibit some unique effects: defocus blurs become more severe on pixels farther away from the image center. This leads to a novel refocusing effects that we call "Conic Blur". For 3D reconstruction, we discretize the scene into voxels and apply the XSlit back-projection to map the voxels onto each XSlit view. Finally, we apply the graph-cut algorithm to optimize the 3D embedded voxel graph. Experiments on synthetic and real scenes show that our schemes are robust and reliable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Most related to our work are the emerging approaches on light field acquisition and multi-perspective imaging and reconstruction.</p><p>The concept of light fields can be back dated to 1936 by Gershun to describe radiometric properties of lights in 3D space <ref type="bibr" target="#b8">[9]</ref>. Adelson <ref type="bibr" target="#b0">[1]</ref> first introduced notation to the field of computer vision and graphics via the 5D plenoptic function, which later became the foundation to imagebased modeling and rendering. The plenoptic function expresses the image of a scene from all possible viewing positions and directions but its high dimensionality has prohibited it from practical uses. Levoy and Hanranhan <ref type="bibr" target="#b12">[13]</ref> introduced a practical LF representation using two-planeparametrization or 2PP where each plane describes a 2D subset and the overall LF is 4D.</p><p>By far most commonly used devices of acquiring light fields include a moving held camera or robotically controlled camera <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b20">21]</ref>, a 1D array of cameras <ref type="bibr" target="#b28">[29]</ref>(as used in capturing the bullet time effect used in the film The Matrix), a dense array of cameras <ref type="bibr" target="#b20">[21]</ref>, and most recently handheld light field cameras <ref type="bibr" target="#b15">[16]</ref> based on the lenslet array or coded apertures <ref type="bibr" target="#b21">[22]</ref>. It is also possible, with the help of registration, to capture an unstructured light field by waving a camera 3D space. Nearly all existing solutions use (e.g., in camera array) or emulate (as in lenslet array) perspective cameras as the main acquisition apparatus. The sampling theory under perspective camera sampling has also been well studied, in both spatial and frequency domains <ref type="bibr" target="#b6">[7]</ref>. In this paper, we explore a completely different LF sampling scheme based on non-perspective cameras.</p><p>While the pinhole camera has long served as workhorses for imaging (including acquiring the light fields), there is an emerging on adopting a non-centric cameras. Classic examples include the pushbroom camera <ref type="bibr" target="#b26">[27]</ref> which collects rays along parallel planes from points swept along a linear trajectory and the crossed-slit camera which collects all rays passing through two oblique lines. The General Linear Camera framework <ref type="bibr" target="#b25">[26]</ref> discovers that rays collected by both pushbroom and XSlit, along with the classical perspective and orthographic cameras, correspond to 2D planar slices in the 4D light field space. The GLC framework, however, does not discuss the sampling difference when using multi-perspective for acquiring the light field, which is the focus of this paper.</p><p>Finally, our work is related to 3D reconstruction. The two most widely adopted reconstruction frameworks are stereo matching and volumetric reconstruction, both can be conducted using multi-perspective cameras. For the former, Seitz <ref type="bibr" target="#b19">[20]</ref> and Pajdla <ref type="bibr" target="#b17">[18]</ref> independently classified all possible stereo pairs in terms of their epipolar geometry. Their results show that beyond perspective camera pairs whose epipolar geometry is a plane, two more varieties of epipolar geometry exist: hyperboloids, and hyperbolic-paraboloids, both corresponding to double ruled surfaces. Ye et al. <ref type="bibr" target="#b23">[24]</ref> developed a rotational XSlit stereo matching based on hyperboloids and validated the Seitz's theory. For the latter, most adopted solution falls into the category of space carving framework where an initial bounding volume is divided into regular grids and voxels inconsistent with the observation are then pruned. In this paper, we demonstrate that this scheme can be effectively extended to non-centric cameras such as our R-XSlit light fields. The rest of the paper is structured as follows. Section 3 presents rotational XSlit LF acquisition scheme, discussing its LF sampling pattern, the blur kernel and exploring the epipolar geometry problem. Section 4 discusses the rendering technique and 3D reconstruction method used in rotational XSlit light field. In Section 5, we present the new refocusing and volumetric reconstruction based stereomatching results on real scene data. Section 6 concludes our work and presents future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Rotational XSlit LF</head><p>In this section, we discuss how to acquire an LF through rotations using an XSlit camera. Before proceeding, we explain our notation. An XSlit camera collects rays that simultaneously pass through two oblique (neither parallel nor coplanar) slits in 3D space <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b26">27]</ref>. In this paper, we adopt the light field two-plane parametrization <ref type="bibr" target="#b12">[13]</ref> for its simplicity. Specifically, we choose two planes Π uv and Π st parallel to both slits but containing neither slits.</p><p>We will also use position-direction parametrization [u, v, σ, τ ] where σ = s − u and τ = t − v to simplify certain analysis. We choose Π uv as the default image (sensor) plane so that (u, v) can be directly used as the pixel coordinate and (σ, τ, 1) can be viewed as the direction of the ray. Ye et al. <ref type="bibr" target="#b24">[25]</ref> assumed that the origin of the coordinate system is the intersection point of two slits' projected lines on Π uv . In this paper, we explore a more general case, i.e., the origin biases that intersection point and two slits rotate along z-axis. We assume that the two slits, l 1 and l 2 , lie at z = Z 1 and z = Z 2 and have angle θ 1 and θ 2 w.r.t. the x-axis, and distance of their projected lines on Π uv to origin point are d 1 and d 2 , where Z 1 &gt;Z 2 &gt; 0 and θ 1 = θ 2 ,a s shown in <ref type="figure" target="#fig_2">Fig. 3</ref>. Each XSlit camera can be represented as C(Z 1 ,Z 2 ,θ 1 ,θ 2 ,d 1 ,d 2 ). We applied this notation for sampling the LF by changing θ 1 and/or θ 2 . Under this representation, each pixel (u, v) in C maps to a ray with direction (σ, τ, 1) (see Appendix I) as:</p><formula xml:id="formula_1">σ =(Au + Bv + F )/E τ =(Cu + Dv + G)/E (1) where A = Z 2 cos θ 2 sin θ 1 − Z 1 cos θ 1 sin θ 2 , B =(Z 1 − Z 2 )cosθ 1 cos θ 2 , C =(Z 2 − Z 1 )sinθ 1 sin θ 2 , D = Z 1 cos θ 2 sin θ 1 − Z 2 cos θ 1 sin θ 2 , E = Z 1 Z 2 sin(θ 2 − θ 1 ), F =(d 1 · Z 2 )cosθ 2 − (d 2 · Z 1 )cosθ 1 , G =(d 1 · Z 2 )sinθ 2 − (d 2 · Z 1 )sinθ 1 .</formula><p>To capture R-XSlit LF, we simultaneously rotate both slits while maintaining their relative angle. To simplify our model, we assume POX-Slit camera where the angle between the two slits remains as 90 • . <ref type="bibr" target="#b24">[ 25]</ref> captured two such images by rotating the camera by 90 degrees to conduct stereo matching. We characterize ray sampling pattern when exhausting all possible rotation angles and denote the LF sampling scheme as C(Z 1 ,Z 2 ,θ+90 • ,θ,d 1 ,d 2 ) (abbreviated as C θ for simplicity), for all θ. A major advantage of such sampling scheme is that we can rotate the XSlit camera or the XSlits lens set as a unit instead of rotating individual slits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Sampling Pattern</head><p>To analyze the LF sampling pattern, we fix pixel p = (u 0 ,v 0 ) on the sensor plane Π uv and then analyze the sampled rays that pass through p. Specifically, we characterize the sampling function with respect to Π st , i.e., the plane recording the angular information of all rays when rotating the camera. Our analysis assumes l 1 and l 2 have an infinite length. By Eqn. 1, we compute (σ, τ ) for (u 0 ,v 0 ) in camera C θ . Since s = σ + u, t = τ + v, we have: We prove (see supplementary materials) that the collect rays form a ring on the st plane as: s = c s + r αs cos(θ + α s )+r βs cos(2θ − β s ) t = c t + r αs sin(θ + α s )+r βs sin(2θ − β s ) where</p><formula xml:id="formula_3">c s = u 0 (1 − 1 2Z1 − 1 2Z2 ), c t = v 0 (1 − 1 2Z1 − 1 2Z2 ), r αs = ( d1 Z1 ) 2 +( d2 Z2 ) 2 , r βs = u 2 0 + v 2 0 ( 1 2Z2 − 1 2Z1 )</formula><p>, α s =a r c t a n d2Z1 d1Z2 and β s =a r c t a n ( v 0 /u 0 ). This reveals that all (s, t) lie on a Limacon of Pascal curve, as shown in <ref type="figure" target="#fig_3">Fig. 4</ref>. It is important to note that when</p><formula xml:id="formula_4">d 1 = d 2 =0the</formula><p>Limacon of Pascal will degrade to a circle.</p><p>Compared with LF acquisition using a projective camera array, such rotation-based sampling scheme has a few advantages. Our scheme can acquire many more angular samples. The angular resolution in the projective camera array corresponds to the number of cameras whereas it corresponds to the number of different rotation angles in our case. Mechanically, it would be much easier to rotate the slits than to build a camera array or translation stage for controlling the camera. What is more important is that rotational XSlit light field provides a much denser angular sampling. In the camera array case, its density depends on the spacing (baseline) between cameras and generally it is difficult to make the baseline small enough to avoid undersampling (aliasing). In contrast, In the rotational XSlit, we can make the rotation step very small to acquire a highly dense LF. Although the emerging light field camera can potentially do the same by using tailored optical unit (e.g., a microlenslet array), our sampling scheme will not require using any special optical device. <ref type="figure" target="#fig_1">Fig. 2</ref> shows the sampling differences between the traditional perspective camera array and our rotational XSlit camera. We show a 2D slice su from a 4D light field captured by conventional camera/lenticular array. Under this sampling, each image captured by a camera maps to a 2D parallel slice. Since the space between adjacent slices are "empty", any new perspective view (which corresponds to a slice in between) will not contain any sampled rays and traditional approaches rely on geometry-guided ray interpolation <ref type="bibr" target="#b10">[11]</ref>. In contrast, the LF captured under our rotational XSlit camera setup samples the space in a different way:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R-XSlit LF Refocusing</head><p>Camera array LF Refocusing each XSlit camera also maps to a 2D slice <ref type="bibr" target="#b26">[27]</ref> but under the rotational setup the recorded slices are not axis-aligned in the 4D ray space. As a result, if we render a new perspective view (2D slice), it is guaranteed to intersect with the sampled XSlit slices and therefore contain some minimal number of ray samples. A detailed analysis can be found in the Appendix III.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Blur Kernel</head><p>Given a Rotational LF that captured by C θi , i =1, ..., N , and a 3D point P =( x 0 ,y 0 ,z 0 ) in the world, we set out to analyze the shape and size of blur kernel by finding the pattern of all the projections of P on a plane Π f at z = f parallel to the sensor plane. We compute the projection (u f ,v f ) as:</p><formula xml:id="formula_5">u f =(1− f/z 0 )u + x 0 f/z 0 v f =(1− f/z 0 )v + y 0 f/z 0 (3)</formula><p>with (u, v) computed as:</p><formula xml:id="formula_6">u = c u + r α b cos(θ + α b )+r β b cos(2θ − β b ) v = c v + r α b sin(θ + α b )+r β b sin(2θ − β b )<label>(4)</label></formula><p>where</p><formula xml:id="formula_7">c u = − x0 2 ( Z1 z0−Z1 + Z2 z0−Z2 ), c v = − y0 2 ( Z1 z0−Z1 + Z2 z0−Z2 ), r α b = z 0 ( d1 z0−Z1 ) 2 +( d2 z0−Z2 ) 2 , r β b = √ x 2 0 +y 2 0 2 ( Z2 z0−Z2 − Z1 z0−Z1 )</formula><p>, α b =a r c t a n d2(z0−Z1) d1(z0−Z2) and β b =arctan(y 0 /x 0 ) Details of this derivation shows in the appendix.</p><p>According to Eqn. 3 and 4, the projection trajectory of P on plane Π f is a Limacon of Pascal. The kernel size, depends on the spatial location of P . Getting Closer to the center optical axis or further away from the slits will result in smaller blur kernel size. This dependency of blur size on depth and spatial center is consistent with our vision habit: we focus at an important object and make it centered in the view. Previous studies in biology <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b18">19]</ref> have shown that human eyes capture a much higher resolution near the center of the retina than near the boundary. This resembles our XSlit light field acquisition system where rays are much more densely sampled (angularly) near the center. Consequently, when we conduct LF refocusing via ray blending, our uneven ray sampling leads to non-uniform refocusing. Such a phenomena is very common to the human perception system <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b5">6]</ref> and <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b1">2]</ref> have already explored this "Conic Blur" property in video extrapolation. From above reasons, we believe that the refocusing rendering from the R-XSlit will naturally pleases our vision system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Epipolar Geometry Existency</head><p>The image sequence captured by rotating both slits generally does not form valid epipolar geometry. In fact, Ye et al. <ref type="bibr" target="#b24">[ 25]</ref> have shown that the necessary and sufficient condition for two XSlit cameras to form valid epipolar geometry is when the directions of the two slits get switched, i.e. between C(Z 1 ,Z 2 , 0, 90 • , 0, 0) and C(Z 1 ,Z 2 , 90 • , 0, 0, 0). However, in the special POX-Slit case, where the two slits are perpendicular, every image in the captured sequence can form epipolar geometry with the other in the sequence (i.e., the one whose slit directions are flipped) if we rotate the camera to cover 360 degrees. Finally, it is worth noting that even for cases when valid epipolar geometry does not exist, we can conduct efficient volumetric reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Applications</head><p>In this section, we demonstrate applications of our rotational XSlit light field acquisition scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Image-based Rendering</head><p>The original goal of acquiring a LF is to conduct imagebased rendering, e.g., to synthesizing new refocused (perspective) images. For LFs acquired by a pinhole camera array, the refocusing results are synthesized by interpolating between the sampled images. This can be done by first imposing a geometry proxy, e.g., a 3D plane (as shown in the lumigraph <ref type="bibr" target="#b9">[10]</ref>), then projecting rays from a reference view to intersect with the proxy, and finally tracing the intersections back to the sampled images to fetch the recorded radiances. Alternatively, one can use a disparity value, if epipo-lar geometry exists, to directly represent the proxy geometry and to query corresponding pixels from the LF views. As discussed in Section 3.3, there's no homogenous epipolar geometry in R-XSlit LF, we adopt the first scheme to render focus stacks.</p><p>XSlit Refocusing. For the rotational XSlit LF {C θ |θ ∈ Ω θ = {β 1 ,β 2 ...β N }}, we render refocusing result J f β corresponding to XSlit view C β , where superscript f indicates that the focal depth is z f = f . Specifically, we first specify a geometry proxy plane and conduct backward tracing for view blending. Alternatively, we can forward project each XSlit image onto the proxy plane and then combine all images via multi-texturing using the graphics pipeline. In fact, the forward projection of an XSlit image to an arbitrary 2D plane corresponds to a collineation that can be efficiently computed. We can further control the aperture size by varying the number of views involved in the blending . Using a small number of views will result in an image of deep depth-of-field. While a large number will result in shallow depth-of-field effects.</p><p>Perspective Refocusing. Using this rotational XSlit LF, we can also render a new perspective image focusing at some focal depth z f = f . We sample a grid of voxels on the plane z f to render a perspective image. For each voxel P =( x, y, z f ), we trace the rays back to all the XSlit views to fetch the recorded radiances. According to the projection Eqn. 3, we can compute the pixel location q θ at I θ corresponding to P . Thus the refocusing image J f P can be rendered as:</p><formula xml:id="formula_8">J f P (p)= 1 N θ∈Ω θ I θ (q θ ).<label>(5)</label></formula><p>The most notable difference between perspective over R-XSlit LF is the defocus blur kernel. <ref type="figure" target="#fig_5">Fig. 6(b)</ref> shows examples of perspective view refocusing. In particularly, refo-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) Motor Control System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Power Cords</head><p>Step signal  cused images exhibit a "conic blur" effect ,i.e., the blurriness is much more severe near the boundary and is nearly invisible near the center as shown in <ref type="figure" target="#fig_5">Fig. 6(b)</ref>. In <ref type="figure" target="#fig_5">Fig. 6</ref>,we conduct real refocusing on a double-slit rotation LF. From which we can see nice blurring due to dense angular sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Volumetric Reconstruction</head><p>Recall that R-XSlit camera does not have epipolar geometry across all views. The only case that there're epipolar pairs existing is when d 1 = d 2 =0 . Such a sampling scheme can be viewed as multiple stereo pairs although no uniform epipolar geometry exists across all pairs. In this case, we can adopt the volumetric reconstruction scheme for both 3D recovery and rendering.</p><p>The problem of reconstruction can be formulated as a variation to the foundational space carving framework by Kutulakos and Seitz <ref type="bibr" target="#b11">[12]</ref>, in which a set of N perspective input camera views are used to recover a 3D volumetric representation of the scene. In classical volumetric reconstruction, the scene is first discretized into voxels of size coherent with the input image resolution. In our case, we first position a virtual perspective camera whose Center-of-Projection lies at (0, 0,Z), where Z = (Z 1 + Z 2 )/2 with the size of its view frustum matching the extent of both horizontal and vertical slits. To measure the color consistency, we need to first determine the projection of the voxel in each XSlit view. We use the XSlit projection Eqn. 3 to map every voxel to all individual XSlit cameras.</p><p>The voxel depth assignment problem is solved via the graph-cut algorithm <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b3">4]</ref>. Specifically, we traverse the spatial voxels through plane sweeping. For each voxel, we fetch corresponding pixels from respective XSlit images and compute their color variance as the data cost. We also adopt color weighted smooth prior for depth estimation. <ref type="figure" target="#fig_0">Fig. 11</ref> shows the reconstruction results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We validate our proposed Rotational XSlit light field scheme on both synthetic and real scenes. In this section, we first talk about our acquisition devices and our camera structure. Next, we address the calibration problem of R-XSlit LF and also evaluate the practicability of our scheme. We show both the rendering and stereo matching results using different sampling densities. <ref type="figure" target="#fig_7">Fig. 7</ref> illustrates our prototype R-XSlit camera. We mount the XSlit lens on a commodity interchangeable lens camera (e.g. Sony NEX-5T). We align the two cylindrical lenses orthogonally using two lens tube. Each tube contains a rotation ring, with which we can control the rotation degree of each slit precisely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Camera Construction</head><p>In <ref type="bibr" target="#b24">[25]</ref>, R-XSlit pairs are acquired though rotating XSlit camera. However, this methods only works when capturing small amount of data. To form valid light field, we need capture large numbers of images as accurate as possible. Nevertheless, it is hard to eliminate or even evaluate the slight bias of rotation axis when rotating the camera, and those small errors are accumulated and can lead to huge inaccuracy. To overcome this, we mount each slit to lens tube with a rotation ring which can rotate 360 • freely without affecting the tube. In stead of rotating the camera, we rotate the lens tube. Moreover, to minimize the inaccuracy, we adopt a stepper motor to control the rotation procedure. The lens tube and the motor lever are connected by a flat ribbon to make sure that stepper motor and the lens tube are rotating equally in the same speed. To control the rev rate, we employ a Arduino Uno R3 board, i.e., a board that can control the rotation mode of stepper motor by an uploaded program from computer. By applying the stepper motor to the XSlit camera, we are capable of capturing R-XSlit LF through video mode. In this way, we can therefore minimize the manual errors and capture R-XSlit light field without moving the camera. Another advantage of adopting  stepper motor is that it is easy for us to control the density of the light field. In our implement, we set the rotation rate at 12 • per second, the frame rate at 30. Typically, we can capture about 900 images for each light field, i.e., when rotating the lens tube 360 • .</p><p>To ensure the stability of the rotation, we also adopted an additional calibration step beforehand: we captured 3 LFs of a checkerboard calibration target, each with a different rotating speed of the motor and extracted their corners for verification. We found that the LF views align almost perfectly with the theoretical computation. In fact, if they were missed aligned due to uneven rotation speed, the results could also be used to adjust the sequence in the following experiments. The wiggle of axis also seems to marginally affect the results. We suspect this is due to the rigidity of between the camera and stepper motor which make the jiggles nearly negligible. Finally, the lens tube sets were sealed to the camera body and we did not observe obvious changing stray light patterns during the acquisition.</p><p>On improving light accumulation, we adopted the dual cylindrical lens design and focus adjustment schemes <ref type="bibr" target="#b22">[23]</ref> which has significantly improved the light throughput.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Calibration</head><p>Rather than trying to align the optical axis (i.e., the central ray), we set out to calibrate the camera by finding out the bias d 1 , d 2 of l 1 and l 2 . The two slits' position w.r.t. the image sensor are Z 1 =6 2 mm and Z 2 =2 6 mm and have width of 2mm. For a 3D point P =( x, y, z) in a scene, we capture it three times by rotating the lens tube by 90 • on a rotation ring to generate 3 XSlit images. According to Eqn. 4, the projection locations of P on image sensor should be:</p><formula xml:id="formula_9">⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ u 0 = Z 1 x − d 1 z Z 1 − z v 0 = Z 2 y − d 2 z Z 2 − z u 90 = Z 2 x + d 2 z Z 2 − z v 90 = Z 1 y − d 1 z Z 1 − z u 180 = Z 1 x + d 1 z Z 1 − z v 180 = Z 2 y + d 2 z Z 2 − z<label>(6)</label></formula><p>By solving Eqn. 6 we can get that:</p><formula xml:id="formula_10">⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ d 1 = − (u 90 + v 0 )(u 0 − u 180 )(Z 1 − Z 2 ) 2Z 2 (u 90 − u 180 + v 0 − v 90 ) d 2 = (u 0 + v 90 )(v 0 − v 180 )(Z 1 − Z 2 ) 2Z 1 (u 0 − u 90 − v 90 + v 180 )<label>(7)</label></formula><p>We therefore choose 30 calibration points on I 0 and find their corresponding points on I 90 and I 180 respectively. From Eqn. 6 and Eqn. 7, we derive 30 sets of (d 1 ,d 2 ). d 1 =0 .05mm, d 2 =0 .28mm are the average value of those 30 results. <ref type="figure" target="#fig_8">Fig. 8</ref> illustrates that a slight bias of l 1 and l 2 will have significant impact on the rendering performance. It is worth noting that the average value doesn't guarantee the optimal solution. To find out the correct (d 1 ,d 2 ), we first use the average d 1 and d 2 to generate a focus stack using Eqn. 5. Next, we pick out a slice that focusing on a highly textured object at depth f . Note that the slice might still be a little blur due to the incorrect d 1 , d 2 value. We then crop 10 8x8 patches from the object, and use the focusness detection methods in <ref type="bibr" target="#b13">[14]</ref> to measure the patches' focusness degree when varying d 1 and d 2 respectively. A focuss degree for a (d 1 ,d 2 ) pair is computed by averaging all the pixels value in those 10 focusness maps, (d 1 ,d 2 ) that achieve the highest degree is regarded as the optimal solution. After the optimization procedure, we derive the best solution d 1 = −0.07mm, d 2 =0.26mm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Results</head><p>We conduct 3D reconstruction and refocusing rendering on both synthetic and real data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Synthetic Data</head><p>We first test our scheme on synthetic data rendered by the POV-Ray ray tracer. <ref type="figure" target="#fig_0">Fig. 10</ref> presents the refocusing effects rendered by the R-XSlit camera C 1 (−2, −6,θ +90 • ,θ,−0.2, 0.1) and C 2 (−2, −6,θ + 90 • ,θ,0, 0). We collected 360 views by C 1 and C 2 with equal angular interval ∆θ =1 • .I nC 2 case, I θ = I θ+180 • . In the refocusing results from C 2 , the center portion is always in focus. This is because that when d 1 = d 2 =0 , the image centers of all sub-XSlit images corresponds to a same ray. In contrast, C 1 captured multiple rays for every pixels. The Conic Blur effect of C 2 is more obvious than C 1 . It is worth noting that for the same reason, C 1 achieves better reconstruction results than C 2 for the center portion. <ref type="figure" target="#fig_0">Fig. 11</ref> shows the depth reconstruction result of a synthetic example (first row) using C 2 .</p><p>Real Data Next, we validate our LF model on scenes acquired by our R-XSlit prototype C θ (62, 26,θ + 90 • ,θ,−0.07, 0.26) (Section 5.1). The R-XSlit LF is captured through video recording. For each captured light field, we can extract about 900 XSlit images at resolution 1920×1080 when two slits rotate 360 • . <ref type="figure" target="#fig_9">Fig. 9</ref> presents the refocusing using different numbers of XSlit images and we can see that by incorporating more sub-XSlit images, some alias such as the black lines caused by insufficient sampling can be eliminated. However, the out-of-focus region is overall smooth even using a small number of sub-XSlit images. <ref type="figure" target="#fig_0">Fig. 11</ref> shows the depth reconstruction results of some real scenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussions and Future Work</head><p>We have presented a new framework on acquiring light fields of a scene by using an XSlit camera. Different from previous pinhole based approaches that require translating the cameras in 3D space, we keep the XSlit camera fixed in 3D space but rotate both slits. We have demonstrated that such acquisition scheme exhibits a significantly different sampling pattern of the light field. In particular, under this sampling pattern, any virtual perspective camera is guaranteed to contain a minimal number of acquired samples. The acquired light fields can be further used for effective 3D reconstruction (stereo matching and space carving) and for image-based rendering (new view synthesis and dynamic refocusing). We have also derived defocus blur kernels for R-XSlit LF and validated our theories through comprehensive experiments on synthetic and real data.</p><p>On the requirement of mechanically rotating the slit to acquire a light field, we admit that this is a limitation in this initial study, although compared with regular pinhole LF acquisition, our scheme has two major advantages. First, if we fix one slit but rotate the other, we will be able to acquire a 3D LF that has the same ray sampling pattern as translating a pinhole camera along a line. However, rotating the lens/camera is much easier to mechanically implement than translating the camera along a line. Second, in cases such as endoscopic imaging, it would be very difficult to translate a camera. Our rotation scheme however overcomes this limitation.</p><p>There are a number of exciting directions that we plan to explore. Our immediate future work is to conduct experiments that individually rotate each slit to acquire the complete 4D light field. There are many interesting questions regarding the resulting light field including the ray density distribution when compared with the light field camera based on microlenslet array, its effects on refocusing quality (aliasing vs. blur kernel), its usefulness in depth inference, etc.</p><p>Our work also reveals a previously overlooked property: a light field acquired by a multi-perspective camera is potentially better for rendering perspective images. This is illustrated in the ray density analysis in image-based rendering. Conversely, the same argument can be made that a light field acquired by a perspective camera (e.g., a camera array) can better render a multi-perspective virtual view. Such phenomenon can be interpreted in terms of ray geometry in the 4D space as an image, perspective or multiperspective, is a 2D planar cut (the General Linear Camera) in the ray space where ray samples can be viewed as intersections of the GLC plane with the sampling camera planes. In the future, we plan to study the corresponding theories and validate them through experiments using various light field acquisition solutions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Acquiring a Rotational XSlit Light Field (LF). Top left: The XSlit camera. Top right: The slit rotation scheme. Bottom right: Sample acquired views. Bottom left: Dynamic refocusing effects.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>The LF sampling pattern using a pinhole camera array (a) and using rotational XSlit camera (b). A new perspective view (blue line) may not contain any samples in the pinhole case but is guaranteed to contain samples in the XSlit case.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Illustration of our XSlit camera models. The center ray drifts off the image center.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>The (s,t) locus of (up,vp) when varying θ from 0 to 2π.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Refocusing rendering comparison between the R-XSlit LF and regular camera array LF.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Dynamic refocusing images rendered form R-XSlit Light Field. (a) The Sub-XSlit images are captured by our prototype R-XSlit LF camera. (b) Two different rendering effects. The first row shows the a focus stack using a sub-XSlit image as a reference image; The second row shows refocusing rendering from a perspective view.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Our rotational XSlit LF acquisition system prototype. (a) The control circuit for the rotation motor. (b) System setup overview.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>The refocusing images under different d1, d2. (a)(b) have 0.1 difference in d1, (a)(c) have 0.1 difference in d2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 .</head><label>9</label><figDesc>Refocusing rendering results using different sampling density along the rotation angle. In this example, we focus at the head of the tiger. The out-of-focus region is smooth even using a small number of sub-XSlit images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 .Figure 11 .</head><label>1011</label><figDesc>Refocusing effect using different R-XSlit LF camera settings. The first and second rows show the results correspond to C1 and C2 respectively. (See text for details.) Depth reconstruction from R-XSlit light field on a synthetic example (a) and real examples (b)(c). The first row presents XSlit images and the second row shows their corresponding depth maps.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research is supported by National Science Foundation Grant RI-1422477 and CRI-1513031.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The plenoptic function and the elements of early vision. Computational models of visual processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Bergen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multiscale ultrawide foveated video extrapolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Avraham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Schechner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Photography (ICCP), 2011 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ultrawide foveated video extrapolation. Selected Topics in Signal Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Avraham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Schechner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="321" to="334" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Graph cuts and efficient nd image segmentation. IJCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Funka-Lea</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision. TPAMI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A physiological correlate of the&apos;spotlight&apos;of visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Brefczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Deyoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="370" to="374" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Plenoptic sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-X</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th annual conference on Computer graphics and interactive techniques</title>
		<meeting>the 27th annual conference on Computer graphics and interactive techniques</meeting>
		<imprint>
			<publisher>C M Press/Addison-Wesley Publishing Co</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Influence of scene-based properties on visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Enns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">247</biblScope>
			<biblScope unit="issue">4943</biblScope>
			<biblScope unit="page" from="721" to="723" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The light field. moscow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gershun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematics and Physics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The lumigraph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gortler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grzeszczuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH. ACM</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dynamically reparameterized light fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Isaksen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcmillan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gortler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH. ACM</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A theory of shape by space carving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Kutulakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Light field rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIG-GRAPH</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Saliency detection on light field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mechanisms of interpolation in human spatial vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Watt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">299</biblScope>
			<biblScope unit="issue">5883</biblScope>
			<biblScope unit="page" from="553" to="555" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Light field photography with a handheld plenoptic camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brédif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Duval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science Technical Report CSTR</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Geometry of two-slit camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
		<idno>CTU-CMP-2002-02</idno>
		<imprint>
			<date type="published" when="2002" />
			<pubPlace>Prague</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Center for Machine Perception, Czech Technical University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Rapport Technique</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Stereo with oblique cameras. IJCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bioastronautics data book: Nasa sp-3006</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Parker</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NASA Special Publication</title>
		<imprint>
			<biblScope unit="volume">3006</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The space of all stereo images. IJCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The (new) stanford light field archive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>University</surname></persName>
		</author>
		<ptr target="http://lightfield.stanford.edu/.2" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dappled photography: Mask enhanced cameras for heterodyned light fields and coded aperture refocusing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veeraraghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tumblin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOG</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Depth-of-field and coded aperture imaging on xslit lens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2014</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="753" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Manhattan scene understanding via xslit imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<editor>CVPR. IEEE</editor>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A rotational stereo model based on xslit imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<editor>ICCV. IEEE</editor>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">General linear cameras: theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">General linear cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcmillan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Line assisted light field triangulation and stereo matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lumsdaine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">High-quality video view interpolation using a layered representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Uyttendaele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Winder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TOG. ACM</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Mosaicing new views: The crossed-slits projection. TPAMI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zomet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weinshall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
