<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Information Bottleneck Learning Using Privileged Information for Visual Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Motiian</surname></persName>
							<email>samotiian@mix.wvu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University Morgantown</orgName>
								<address>
									<postCode>26508</postCode>
									<region>WV</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Piccirilli</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University Morgantown</orgName>
								<address>
									<postCode>26508</postCode>
									<region>WV</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
							<email>daadjeroh@mix.wvu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University Morgantown</orgName>
								<address>
									<postCode>26508</postCode>
									<region>WV</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Doretto</surname></persName>
							<email>gidoretto@mix.wvu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University Morgantown</orgName>
								<address>
									<postCode>26508</postCode>
									<region>WV</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Information Bottleneck Learning Using Privileged Information for Visual Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We explore the visual recognition problem from a main data view when an auxiliary data view is available during training. This is important because it allows improving the training of visual classifiers when paired additional data is cheaply available, and it improves the recognition from multi-view data when there is a missing view at testing time. The problem is challenging because of the intrinsic asymmetry caused by the missing auxiliary view during testing. We account for such view during training by extending the information bottleneck method, and by combining it with risk minimization. In this way, we establish an information theoretic principle for leaning any type of visual classifier under this particular setting. We use this principle to design a large-margin classifier with an efficient optimization in the primal space. We extensively compare our method with the state-of-the-art on different visual recognition datasets, and with different types of auxiliary data, and show that the proposed framework has a very promising potential.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Large amounts of good quality labeled data for training visual classifiers are hard to obtain because they might be expensive, or require too much time to be collected, or because of other reasons. Typically, this problem is addressed by injecting domain, or prior knowledge, into the modeling framework to regularize the learning, and obtain a better classifier <ref type="bibr" target="#b21">[22]</ref>. On the other hand, there are situations where training labeled samples might be easily augmented with extra information. For instance, in object recognition, a labeled image sample, representing the main data view, might have been annotated also with attributes describing semantic properties of depicted objects, or with a bounding box that specifies the location of the target object, or with image tags describing the context of the image. This extra information can be seen as an auxiliary data view of the image sample. In this work, we aim at improving visual  <ref type="figure">Figure 1</ref>. Visual recognition with auxiliary data. Visual recognition entails learning classifiers based on a main data view (e.g., motion information for recognizing actions, or image information for recognizing animals and objects, or video information for gesture recognition). We extend the information bottleneck method to leverage an auxiliary data view during training (e.g., color for actions, skeleton data for gestures, attributes for animals, and bounding boxes for objects), for learning a better visual classifier.</p><p>recognition based on a main data view, by leveraging the auxiliary view available only during training, thus mitigating the lack of good quality labeled data. See <ref type="figure">Figure 1</ref>. The problem outlined above has received limited attention. It is different from domain adaptation and transfer learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b31">32]</ref>, where the source and target domains are closely related but statistically different. Here instead, the main view used for testing is present also in training, along with the paired auxiliary view to form the source domain. Indeed, our problem is more related to multi-view and multi-task learning <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b44">45]</ref>. However, rather than having all views or task labels available or predicted during testing, here one view is missing and a single task label is predicted. The fact that the auxiliary view is missing is what makes this problem challenging, because it cannot be combined like the others in multi-view learning.</p><p>We address the auxiliary view problem from an information theoretic perspective, where we learn how to extract information from the main data view, in a way that is optimal for visual recognition, and that speaks also on behalf of the missing auxiliary view. The information bottleneck (IB) method <ref type="bibr" target="#b35">[36]</ref> is a tool for extracting latent information from the main view, in a way that satisfies two complementary goals. The first is to compress the data as much as possible. The second is to preserve all the information that is relevant for the task at hand (e.g., predicting the labels of a visual recognition task). However, the IB method is not directly applicable to our problem because the latent information is not extracted in a way that speaks also on behalf of the auxiliary view. Therefore, our first contribution is to extend the IB method to take that aspect into account. Since the auxiliary view is not available at testing time, it was named privileged in <ref type="bibr" target="#b37">[38]</ref>, which first formalized this learning paradigm. Thus, we refer to our IB extension as the information bottleneck method with privileged information (IBPI).</p><p>The IBPI method is a sound information theoretic principle for explicitly extracting relevant latent information, but gives an implicit, hence computationally hard, way for learning a visual classifier based on such information. Our second contribution is a modified version of IBPI that allows learning explicitly any type of visual classifier based on risk minimization. Our third contribution is the application of the modified IBPI method for learning a largemargin classifier, called large-margin IBPI (LMIBPI), for which it is possible to use kernels, and for which we provide an optimization procedure guaranteed to converge in the primal space for improved computational efficiency.</p><p>Our fourth contribution is an extensive validation of LMIBPI against the state-of-the-art. We perform experiments where we improve visual recognition of gestures by training with auxiliary 3D joint information, we improve object classification with auxiliary object bounding box information, we improve animal recognition with auxiliary attribute information, and we improve action recognition with auxiliary visual features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>In computer vision auxiliary information has been incorporated into the learning process in several forms. For example, in attribute based approaches <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b7">8]</ref> labeled data is used for training extra attribute classifiers to extract midlevel features. Similarly, <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b22">23]</ref> learn to extract mid-level features by training data from additionally annotated concepts. Our framework differs from those because the auxiliary information can be generic, and because it is used for improving the classifier performance in a single optimization framework, whereas attribute classifiers may be disconnected from the main classification task. Another form of auxiliary information is given by the structure of the hidden domain of latent models for object detection and gesture recognition <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b29">30]</ref>. Compared to those approaches we use information from auxiliary labeled data.</p><p>More related to our framework are the approaches that consider the auxiliary information to be supplied by a teacher during training. This is the learning using privi-leged information (LUPI) paradigm introduced in <ref type="bibr" target="#b37">[38]</ref>. One LUPI implementation is the SVM+ <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b20">21]</ref>, which uses the privileged data as a proxy for predicting the slack variables. This is equivalent to learning an oracle that tells which sample is easy and which one is hard to predict. The same idea has been used in the learning to rank approach introduced in <ref type="bibr" target="#b32">[33]</ref>, where it is shown that different types of privileged information, such as bounding boxes, attributes, text, and annotator rationales <ref type="bibr" target="#b6">[7]</ref> can be used for learning a better classifier for object recognition.</p><p>Our approach exploits the privileged information differently. An information theoretic framework learns how to compress the source domain for doing prediction in a way that is as informative of the privileged source domain as possible, regardless of the type of classifier used, and without tying privileged information to slack variables. This is done by extending the original IB method <ref type="bibr" target="#b35">[36]</ref>, often used for clustering <ref type="bibr" target="#b34">[35]</ref>, and also used in <ref type="bibr" target="#b2">[3]</ref> for incorporating "negative information" that is irrelevant for the task at hand, and that should not be learned by the representation. This is similar to <ref type="bibr" target="#b43">[44]</ref>, where negative information is used for face recognition with discounted pose-induced similarity.</p><p>The LUPI paradigm has recently been used for boosting <ref type="bibr" target="#b3">[4]</ref>, for object localization in a structured prediction framework <ref type="bibr" target="#b11">[12]</ref>, for facial feature detection <ref type="bibr" target="#b32">[33]</ref>, for metric learning <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b45">46]</ref>, in a logistic classification framework <ref type="bibr" target="#b42">[43]</ref>, in a max-margin latent variable model <ref type="bibr" target="#b40">[41]</ref>, and in support of domain adaptation applications <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b23">24]</ref>. In the above methods, either the problem settings, or the approaches taken are significantly different from the information theoretic principles that are driving our program. Other recent approaches include <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b48">49]</ref>, which focus on the missing view problem by discriminatively learning projections to a shared latent subspace. This approach relates more to multiview learning, but only the main view pipeline is used for testing, without considering the intrinsic asymmetry of the LUPI framework, as pointed out in <ref type="bibr" target="#b41">[42]</ref>. There they propose two principles to learn with auxiliary information based on looking at it as additional features, or as additional labels, where they make assumptions on its informative content. We also introduce a new principle that shares the benefits of their framework, but by using an information theoretic approach we have no need to make distinctions between the types of auxiliary information, and we have no need to state requirements on the information content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Learning using privileged information</head><p>Traditional supervised learning assumes that a training dataset made of N pairs (x 1 , y 1 ), · · · , (x N , y N ) is given, where the feature x i ∈ X is a realization from a random variable X, the label y i ∈ Y is a realization from a random variable Y , and the pairs are i.i.d. samples from a joint probability distribution p(X, Y ). Under this setting the goal is to learn a prediction function f : X → Y by searching The Learning Using Privileged Information (LUPI) paradigm as defined in <ref type="bibr" target="#b37">[38]</ref> assumes that every training data pair comes with auxiliary information, augmenting the training dataset to (x 1 , x * 1 , y 1 ), · · · , (x N , x * N , y N ). The auxiliary feature x * i ∈ X * is a realization from the random variable X * . The triplets are now i.i.d. samples from the joint distribution p(X, X * , Y ). Under LUPI settings, the goal is to learn a prediction function f * : X → Y by searching F . Note that in order to predict a label y, at testing time f * uses only data from the main space X . Therefore, the data from the auxiliary space X * is only available during training, which is why it is called privileged. From the same amount of training samples N , the LUPI classifier f * will improve the performance of the traditional classifier f <ref type="bibr" target="#b28">[29]</ref>. On the other hand, how to best exploit privileged information for learning f * remains an open problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The information bottleneck method</head><p>We summarize the information bottleneck (IB) method <ref type="bibr" target="#b35">[36]</ref> that was extended to the multivariate case in <ref type="bibr" target="#b33">[34]</ref>. We are given a set of random variables X = {X 1 , · · · , X n }, distributed according to a known p(X), a set of latent variables T = {T 1 , · · · , T k }, and a Bayesian network with graph G in over X ∪ T, defining which subset of X is compressed by which subset of T. Another Bayesian network, G out , also defined over X ∪ T, is given and represents which conditional dependencies and independencies we desire T to be able to generate. The joint distribution q(X, T) . = q(T|X)p(X) is unknown. The compression requirements defined by G in , and the desired independencies defined by G out , are incompatible in general. Therefore, the multivariate IB method computes the optimal T by searching for the distribution q(T|X), where T compresses X as much as possible, while the distance from q(X, T) to the closest distribution among those consistent with the structure of G out is minimal. This idea is implemented with the multi-information of X, which is the information shared by X 1 , · · · , X n , i.e.,</p><formula xml:id="formula_0">I(X) = D KL [p(X) p(X 1 ) · · · p(X n )] ,<label>(1)</label></formula><p>where D KL indicates the Kullback-Leibler divergence <ref type="bibr" target="#b5">[6]</ref>. Therefore, the multivariate IB method looks for q(T|X) that minimizes the functional where γ strikes a balance between compression and the ability to satisfy the independency requirements of G out . The multi-information I G with respect to a Bayesian network G defined over X ∼ p(X) is computed as in <ref type="bibr" target="#b33">[34]</ref>, i.e.,</p><formula xml:id="formula_1">L[q(T|X)] = I Gin (X, T) + γ(I Gin (X, T) − I Gout (X, T)) (2) X T Y G in X * X T Y G out X *</formula><formula xml:id="formula_2">I G (X) = i I(X i ; Pa G Xi ) ,<label>(3)</label></formula><p>where I(X i ; Pa G Xi ) is the mutual information between X i and Pa G Xi , the set of variables that are parents of X i in G. Let us refer to <ref type="figure" target="#fig_0">Figure 2</ref> for an example, where X = {X, Y }, and T = T . We interpret X as the main data we want to compress, and from which we would like to predict the relevant information Y . This is achieved by first compressing X into T , and then predicting Y from T . In G in the edge X → Y indicates the relation defined by p(X, Y ). Moreover, since T will compress X, this is indicated by the edge X → T , establishing that T is completely determined given the variable it compresses. The graph G out instead, reflects the idea that we would like T to capture from X all the necessary information to perform the best possible prediction of Y . This means that knowing T makes X and Y independent, or equivalently that I(X; Y |T ) = 0. To evaluate (2), instead, we obtain I Gin = I(T ; X) + I(Y ; X), and I Gout = I(X; T )+I(Y ; T ), and since I(Y ; X) is constant, (2) collapses to the original two-variable IB method <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">IB with privileged information</head><p>Here we combine the ideas of Sections 3 and 4 for developing a new information bottleneck principle, which accounts for privileged information. Specifically, let us assume that X, X * , and Y are three random variables with known distribution p(X, X * , Y ). Also, it is assumed that both X and X * contain information about Y . If properly extracted, such information could be used for predicting Y . However, we assume that only the information carried by X can be used to predict Y . We pose the question of whether by doing so it is still possible to learn a model capable of exploiting the information carried by X * .</p><p>If we apply the two-variable IB method, we proceed by compressing X into a latent variable T as much as possible, while making sure that information about Y is retained. These two competing goals are depicted by the two graphs G in and G out in <ref type="figure" target="#fig_0">Figure 2</ref>. On the other hand, since X * has knowledge about Y , a more complete Bayesian network representing all the variables and the compression requirements, is the graph G in in <ref type="figure" target="#fig_1">Figure 3</ref>, which includes the connection X * → Y . Therefore, the optimal representation computed by the two-variable IB method would be given by q(X, X * , Y, T ) = q(T |X)p(X, X * , Y ), where q(T |X) is such that I(X; Y |T ) is as close to zero as possible.</p><p>We note that the approach outlined above does not make any effort to exploit the information carried by X * . Indeed, I(X * ; Y |T ) could be arbitrarily high, i.e., knowing T still leaves with X * substantial knowledge about Y . On the other hand, the multivariate IB method allows us to consider more complex independency structures. In particular, we define G out like in <ref type="figure" target="#fig_1">Figure 3</ref>, where knowing T not only makes X and Y independent, but X * and Y too. In this way, q(T |X) not only minimizes I(X; Y |T ), but also I(X * ; Y |T ). More precisely, the multi-informations of G in and G out in <ref type="figure" target="#fig_1">Figure 3</ref> are given by</p><formula xml:id="formula_3">I Gin = I(T ; X) + I(Y ; X, X * ) ,<label>(4)</label></formula><formula xml:id="formula_4">I Gout = I(T ; X) + I(T ; X * ) + I(T ; Y ) . (5)</formula><p>By plugging <ref type="formula" target="#formula_3">(4)</ref> and <ref type="formula">(5)</ref> into <ref type="formula">(2)</ref>, since I(Y ; X, X * ) is constant, the functional for learning the optimal representation for T is given by</p><formula xml:id="formula_5">L[q(T |X)] = I(T ; X) − γI(X * ; T ) − γI(T ; Y )<label>(6)</label></formula><p>where γ strikes a balance between compressing X and imposing the independency requirements. Similarly to the LUPI framework, since it is not possible to directly compress X * for predicting Y , we can think of X * as carrying privileged information about Y . Therefore, we call learning representations by minimizing (6) as the information bottleneck method with privileged information (IBPI).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">IBPI for visual recognition</head><p>We are interested in designing a framework for visual recognition, where we need to perform a classification task based on a main view X of the visual data. However, at training time, for some training samples an auxiliary view X * is also available. We pose no restrictions on the type of auxiliary data available. The task at hand falls into the LUPI category defined in Section 3, except that we also admit training samples with missing auxiliary view.</p><p>We want to leverage the IBPI method (6) because it provides a sound principle, grounded on information theory, for extracting information T from the main view X that is not only the most relevant for predicting Y (representing class labels), but also minimizes I(X * ; Y |T ), which means that knowing T leaves with X * minimal information about Y . This suggests that T is the representation of choice for predicting Y . However, similarly to the IB method <ref type="bibr" target="#b33">[34]</ref>, while IBPI explicitly defines the compression map, T , by searching for q(T |X), the computation of q(Y |T ) is much harder</p><formula xml:id="formula_6">Algorithm 1 Projected gradient minimization for F 1: Chose 0 &lt; η &lt; 1, 0 &lt; ν &lt; 1. 2: Initialize F 1 . Set ρ = 1. 3: for k = 1, 2, · · · do 4:</formula><p>if ρ satisfies (11) then</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Repeatedly increase it by ρ ← ρ/η until either ρ does not satisfy <ref type="bibr" target="#b10">(11)</ref> or F (ρ/η) = F (ρ) 6: else 7:</p><p>Repeatedly decrease ρ by ρ ← ρ/η until ρ satisfies <ref type="bibr" target="#b10">(11)</ref> 8:</p><formula xml:id="formula_7">end if 9: Set F k+1 = max{0, F k − ρ∇F DKL(X F kX * )}</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>10:</head><p>Normalize to 1 the columns of F k+1 11: end for in general. For this reason, we introduce a modified IBPI method that is tailored to visual recognition.</p><p>We observe that by interpreting γ as a Lagrange multiplier, the last term in (6) corresponds to the constraint I(T ; Y ) ≥ constant, enforcing T of carrying at least a certain amount of information about Y . Ultimately, such information should be used for classification purposes, by predicting Y through a functionf : T → Y. Therefore, we replace the constraint on I(T ; Y ) with the risk associated tof (T ) according to a loss function ℓ. Thus, for visual recognition, (6) is modified into</p><formula xml:id="formula_8">L[q(T |X),f ] = I(T ; X) − γI(X * ; T ) + βE[ℓ(f (T ), Y )] (7)</formula><p>where E[·] denotes statistical expectation, and β balances the risk versus the compression requirements. Note that the modified IBPI criterion <ref type="formula">(7)</ref> is general, and could be used with any classifier. Obviously, a practical implementation of (7) would be based on the empirical risk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Large-margin IBPI</head><p>We use <ref type="formula">(7)</ref> to develop a large-margin classifier. We focus on the binary case to prove the validity of the framework by comparing it with the state-of-the-art, which also focussed on the binary case. In particular, we restrict the search space for q(T |X) by assuming T = φ(X; A), where A is a suitable set of parameters. Moreover,f (T ) is a binary decision function given by Y = sign( w, T + b), where ·, · identifies a dot product, w defines the margin, and b is an offset. Therefore, by using the hinge loss function, from (7) we derive the following classifier learning formulation, which we refer to as the large-margin IBPI (LMIBPI)</p><formula xml:id="formula_9">min A,w,b,ξi I(T ; X) − γI(X * ; T ) + β 2 w 2 + C N N i=1 ξ i s.t. y i ( w, φ(x i , A) + b) ≥ 1 − ξ i ,<label>(8)</label></formula><formula xml:id="formula_10">ξ i ≥ 0 , ∀i ∈ {1, · · · , N } .</formula><p>where C is the usual parameter to control the slackness. Kernels. We set T = φ(X, A) = Aφ(X), where we require φ(X) to have positive components and be normalized to 1, and A to be a stochastic matrix, made of conditional probabilities between components of φ(X) and T . Algorithm 2 FALM for LMIBPI <ref type="bibr" target="#b0">1</ref>: Chose µ f &gt; 0 and µg &gt; 0 and A 0 = B 0 = E 1 , set t1 = 1 2: for k = 1, 2, · · · do 3:</p><formula xml:id="formula_11">A k = arg min 0≤A≤1 Qg (A, E k ) 4: B k = arg min 0≤B≤1 Q f (B, A k ) 5: t k+1 = (1 + 1 + 4t 2 k )/2 6: E k+1 = B k + t k −1 t k+1 (B k − B k−1 )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7: end for</head><p>This assumption greatly simplifies computing mutual informations. X can be mapped to a feature space with ψ(X). In this case we set φ(X) = ρ(Ψψ(X)) ⊤ , where Ψ = [ψ(x 1 ), · · · , ψ(x N )], and ρ(·) is the additive logistic transformation that maps u ∈ R N to the N + 1 dimen-</p><formula xml:id="formula_12">sional simplex v = e u 1 1+ i e u i , · · · , e u N 1+ i e u i , 1</formula><p>1+ i e u i , with positive components and normalized to 1. Thus, without loss of generality, in the sequel we set T = AX. X * can be mapped to a feature space ϕ(X * ) with the same strategy.</p><p>Mutual informations. I(T ; X) is given by</p><formula xml:id="formula_13">I(T ; X) = E i,j A(i, j)X(j) log A(i,j) T (i)<label>(9)</label></formula><p>where A(i, j) is the entry of A in position i, j, whereas T (i) and X(j) are the components in position i and j of T and X respectively. Obviously, during training the expectation is replaced by the empirical average. To compute I(T ; X * ), let t(i), x * (j), and x(h) be histogram realizations for T , X * , and X, where i, j, and h index the histogram bins. The mutual information I(t, x * ) is given by i,j p(i, j) log p(i,j) t(i)x * (j) . By the low of total probability, p(i, j) is rewritten as h p(i|j, h)p(h|j)x * (j), where p(i|j, h) = p(i|h) = A(i, h) because t(i) is completely defined by x(h). In addition, we call F (h, j) = p(h|j), from which it follows that X = F X * , where F is also a stochastic matrix. Therefore, I(T ; X * ) is given by</p><formula xml:id="formula_14">I(T ; X * ) = E i,j A(i, ·)F (·, j)X * (j) log A(i,·)F (·,j) T (i)<label>(10)</label></formula><p>Learning F . F is learned from training data. Specifically, let's indicate withX = [x 1 , · · · , x N ] andX * = [x * 1 , · · · , x * N ] the training data points corresponding to the main and privileged domains, then F is learned by solving the following constrained optimization problem: min F D KL (X FX * ) s.t. F is a stochastic matrix with normalized columns. We compute F with Algorithm 1, which is a projected gradient method <ref type="bibr" target="#b25">[26]</ref> with Armijo's condition</p><formula xml:id="formula_15">D KL (X F k+1X * ) − D KL (X F kX * )<label>(11)</label></formula><formula xml:id="formula_16">≤ ν ∇ F D KL (X F kX * ), F k+1 − F k</formula><p>where k is the iteration index. The computation of ∇ F D KL (X FX * ) is fairly simple, and can be found as a special case in <ref type="bibr" target="#b46">[47]</ref>.</p><p>Algorithm 3 Projected gradient minimization for Q f or Q g 1: Chose 0 &lt; η &lt; 1, 0 &lt; ν &lt; 1. 2: Initialize A 1 for Qg (or B 1 for Q f ). Set ρ = 1. 3: for k = 1, 2, · · · do 4:</p><p>if ρ satisfies <ref type="bibr" target="#b15">(16)</ref> for Qg (or <ref type="bibr" target="#b16">(17)</ref> for Q f ) then</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Repeatedly increase it by ρ ← ρ/η until either ρ does not satisfy (16) (or <ref type="formula" target="#formula_0">(17)</ref>) or A(ρ/η) = A(ρ) (or B(ρ/η) = B(ρ)) 6: else 7:</p><p>Repeatedly decrease ρ by ρ ← ρ/η until ρ satisfies (16) (or <ref type="formula" target="#formula_0">(17))</ref> 8:</p><formula xml:id="formula_17">end if 9: Set A k+1 = max{0, A k − ρ∇AQg (A k , B)} 10: (Set B k+1 = max{0, B k − ρ∇B Q f (B k , A)})</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>Normalize to 1 the columns of A k+1 (or B k+1 ) 12: end for Missing auxiliary views. Training samples with missing auxiliary view affect only I(T ; X * ). The issue is seamlessly handled by estimating F and the average in (10) by using only the samples that have the auxiliary view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Optimization</head><p>When A is known, (8) is a soft-margin SVM problem. Instead, when the SVM parameters are known, <ref type="bibr" target="#b7">(8)</ref> becomes</p><formula xml:id="formula_18">min A I(T ; X) − γI(X * ; T ) + C N N i=1 ξ i (12) s.t. ξ i = max {0, 1 − y i ( w, φ(x i , A) + b)} .</formula><p>Since the soft-margin problem is convex, if also (12) is convex, then an alternating direction method is guaranteed to converge. In general, the mutual informations in <ref type="bibr" target="#b11">(12)</ref> are convex functions of q(T |X) <ref type="bibr" target="#b5">[6]</ref>. The last term is also convex, however, the constraints define a non-convex set due to the discontinuity of the hinge loss function. Smoothing the hinge loss turns <ref type="formula" target="#formula_0">(12)</ref>  For smoothing the hinge loss we use the Nesterov smoothing technique <ref type="bibr" target="#b26">[27]</ref>, used also in <ref type="bibr" target="#b50">[51]</ref>, which requires choosing a proximal function, and then computing the smoothed slack variables in this way</p><formula xml:id="formula_19">ξ i,σ = max 0≤ui≤1 u i (1 − y i w ⊤ Ax i )− σ 2 wx ⊤ i ∞ u 2 i , which gives ξ i,σ =          0 y i w ⊤ Ax i &gt; 1 , (1 − y i w ⊤ Ax i ) − σ 2 wx ⊤ i ∞ y i w ⊤ Ax i &lt; 1 −σ wx ⊤ i ∞ , (1−yiw ⊤ Axi) 2 2σ wx ⊤ i ∞ otherwise.<label>(13)</label></formula><p>where σ is a smoothing parameter. In this way, the minimization can be carried out with the Fast Alternating Linearization Method (FALM) <ref type="bibr" target="#b14">[15]</ref>. This allows simpler computations, and has performance guarantees when ∇f and ∇g are Lipschitz continuous, which is the case, given the smoothing technique that we used. FALM splits the minimization of the augmented Lagrangian function into two simpler functions to be minimized alternatively, which are given by</p><formula xml:id="formula_20">Q g (A, B) = f (A) + g(B) + ∇g(B), A − B + 1 µg D KL (A||B) (14) Q f (B, A) = f (A) + g(B) + ∇f (A), B − A + 1 µg D KL (B||A) (15)</formula><p>The FALM iteration is given in Algorithm 2. Since A is a stochastic matrix, the KL-divergence regularization is used in place of the squared Frobenius norm.</p><p>Note that lines 3 and 4 of Algorithm 2 are constrained optimizations, requiring A and B to be stochastic matrices with normalized columns. They are implemented by Algorithm 3, a projected gradient method <ref type="bibr" target="#b25">[26]</ref> with Armijo's rule that for Q g and Q f is given by</p><formula xml:id="formula_21">Q g (A k+1 , B) − Q g (A k , B) ≤ ν ∇ A Q g (A k , B), A k+1 − A k (16) Q f (B k+1 , A) − Q f (B k , A) ≤ ν ∇ B Q f (B k , A), B k+1 − B k (17)</formula><p>where k is the iteration index. From (13), (9), (10) it is straightforward to compute ∇ A Q g , and ∇ B Q f . We leave those expressions out due to the limited space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Experiments</head><p>We have performed experiments with four different datasets. With each dataset we train and test the following binary classifiers. Single-view classifiers: Using only the main view, we train the SVM-Light <ref type="bibr" target="#b16">[17]</ref> (indicated as SVM), the SVM-Rank <ref type="bibr" target="#b17">[18]</ref> (indicated as SVM-R), and LMIBPI where we eliminate the use of auxiliary information by setting γ = 0 (indicated as LB-LMIBPI). LUPI classifiers: We train the SVM+ <ref type="bibr" target="#b37">[38]</ref> (indicated as SVM+, implemented by <ref type="bibr" target="#b24">[25]</ref>), the Rank Transfer <ref type="bibr" target="#b32">[33]</ref> (indicated as RankTr, and reimplemented by us), and our LMIBPI approach (indicated as LMIBPI). We also train the SVM2k <ref type="bibr" target="#b8">[9]</ref> and test only the SVM that uses the main view (indicated as SVM2k-LUPI), and we perform kernel CCA (KCCA) <ref type="bibr" target="#b15">[16]</ref> between main and auxiliary views, map the main view in feature space and train an SVM (indicated as KCCA-LUPI). Two-view classifiers: Using main and auxiliary views, we train the SVM2k (indicated as SVM2k), and we also use KCCA between views to map them in feature space, train   <ref type="figure">Figure 4</ref>. Linear vs. non-linear kernel. Plots representing the differences between the classification accuracy of the winner LUPI method against the average accuracy over the following methods: RankTr (yellow), SVM+ (magenta), SVM2k-LUPI (cyan), KCCA-LUPI (red), and LMIBPI (green). The linear kernel was used on the left plots, and the histogram intersection kernel on the right plots. The top row come from the HMDB dataset, the middle row from ImageNet, and the last row from CGD2011.</p><p>two SVMs and average the outputs (indicated as KCCA). Finally, we also extend LMIBPI (details are omitted for lack of space) to fuse main and auxiliary views (indicated as UB-LMIBPI). Note that for these classifiers main and auxiliary views are used also during testing. So, their performances represent the upper bound for the corresponding LUPI versions. Model selection: We use the same joint cross validation and model selection procedure described in <ref type="bibr" target="#b32">[33]</ref>, based on 5-fold cross-validation to select the best parameters and use them to retrain on the complete set. The main parameters to select are C, β, γ, and m, the number of columns of A. Performance: For each binary classification experiment we  <ref type="figure">Figure 4</ref> (top row). Time complexity: LMIBPI estimates F only once, and then iterates between optimizing A and a SVM. Both components are fast, also thanks to the derivation in the primal space. In addition, <ref type="figure" target="#fig_7">Figure 5</ref> shows the accuracy convergence for the drink class of the HMDB dataset for different m's. We observed that less than 10 iterations were enough to reach convergence most of the time. ImageNet dataset: We use the ImageNet <ref type="bibr" target="#b30">[31]</ref> object categories of the 2012 challenge, also used in <ref type="bibr" target="#b32">[33]</ref>. This subset has bounding box annotations, and we test whether they can improve recognition when used as auxiliary information. We use the group of snakes, which has 17 classes, for a total of 7746 images (some bounding boxes did not have images). For each sample we extracted a BoW from the entire image to be used as main view, and a BoW from the image portion in the bounding box to be used as auxiliary view. The descriptor used was dense SIFT <ref type="bibr" target="#b38">[39]</ref> with a vocabulary size of 400. The classification task is between one snake class versus all the others. We use 200 samples per class for training and the rest for testing. <ref type="table">Table 2</ref> summarizes the classification accuracy results. Even here LUPI classifiers improve upon single-view, and LMIBPI outperforms the others 10 out of 17 times in the linear case, and 13 times with HIK. See <ref type="figure">Figure 4</ref> (middle row). CGD2011 dataset: The CGD2011 dataset <ref type="bibr" target="#b1">[2]</ref> contains 20 gesture classes, each of which has about 400 RGB-D videos, along with skeleton tracking data. Since skeleton tracking is typically more expensive to obtain, we test whether by using it as auxiliary data it can boost performance. We perform one-vs-all classification with 100 samples per class for training and 90 for testing. We used a BoW with dictionary size 100 based on HOF features as main view. For the auxiliary view, from a video we extract a histogram of the joint positions, accumulated over all the frames of the sequence. Specifically, at every frame we place a spatial grid aligned with the head position of an individual and bin the position of each of the joints with respect to the grid. The resulting count is normalized and produces a histogram with 100 bins <ref type="table">Table 3</ref> shows the classification accuracies. The LUPI classifiers improve upon single-view, and LMIBPI outperforms the others 11 out of 20 times in the linear case, and all the times with HIK. See <ref type="figure">Figure 4</ref> (bottom row). AwA dataset: We use the Animals with Attributes (AwA) dataset <ref type="bibr" target="#b19">[20]</ref>, which contains images of animal categories, and repeat the same experiment performed in <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b41">42]</ref>. We use the 10 test classes for which the attribute annotations are provided, for a total of 6180 images. The attributes capture 85 properties of the animals. We use the same set of features used in <ref type="bibr" target="#b32">[33]</ref>. The main view is given by L 1 normalized 2000 dimensional SURF descriptors, and the attributes are the auxiliary view obtained from the DAP model <ref type="bibr" target="#b19">[20]</ref>. We train 45 binary classifiers for each class pair combination.  <ref type="table">Table 3</ref>.  We use 50 and 200 samples per class for training and testing, respectively. The train/test split is repeated 20 times. For fair comparison with <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b41">42]</ref> we use the linear kernel. Due to the limited space <ref type="table" target="#tab_5">Table 4</ref> reports only the average precision (AP) results for our approach, where we have indicated in bold when LMIBPI has improved the AP, which happens 20 times out of 45, and 12 times the improvement is significant according to the z-test. The table including the results of the other approaches can be found in <ref type="bibr" target="#b41">[42]</ref>. <ref type="figure" target="#fig_7">Figure 5</ref> shows that SVM has the highest AP 3 times, SVM+ 1 time, RankTr 9 times, and LIR [42] 12 times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusions</head><p>In order to develop a general approach for improving visual recognition when auxiliary information is available at training time, we have taken an information theoretic approach, and have extended the IB principle to IBPI. In addition, we have expanded it further for learning any type of classifier based on risk minimization, where training samples with missing auxiliary view can be handled seamlessly. We have applied this new IBPI principle to derive LMIBPI,  <ref type="table" target="#tab_5">1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45</ref> SVM wins SVM+ wins RankTr wins LIR wins LMIBPI wins a large-margin classifier for which we provide an optimization procedure in the primal space (which takes about 10 iterations to converge). The experiments show that the IBPI principle can leverage several types of auxiliary information, like supplemental visual features, bounding box annotations, 3D skeleton tracking data, and animal attributes, and uses them for improving visual recognition, by learning a classifier that is better than the corresponding singleview version. The experiments also show that the proposed approach is more effective than just reducing a multi-view method to work with a missing view. Finally, the proposed LMIBPI outperforms all the state-of-the-art LUPI classifiers on the examined datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Information Bottleneck. Structural representation of Gin and Gout used by the original two-variable information bottleneck method<ref type="bibr" target="#b35">[36]</ref>. over a space of admissible functions F .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Information Bottleneck with Privileged Information. Structural representation of Gin and Gout used by the information bottleneck method with privileged information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>into a convex problem, and allows to use an alternating direction method with variable splitting combined with the augmented Lagrangian method. This is done by setting f (A) = I(T ; X) − γI(X * ; T ), g(B) = C N N i=1 ξ i , and then solving min A {f (A) + g(B) : A − B = 0}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>The C's and β's were searched in the range {10 −3 , · · · , 10 3 }, the γ's in the range {0.1, 0.3, 0.5}, and the m's in the range {50, 70, 90}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>CGD2011 dataset. Classification accuracies for one-vs-all binary classifications. The HOF features are used as main view, and histograms of joint positions are used as auxiliary view. Best accuracies are highlighted in boldface.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Rate of convergence and AwA dataset. Left: Plot showing the convergence rate for different m's for the drink class of the HMDB dataset. Right: Plot showing the differences between the AP of the winner LUPI method against the average accuracy over the following methods: SVM (yellow), SVM+ (magenta), RankTr (cyan), LIR (red), and LMIBPI (green).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>Table 1. HMDB dataset. Classification accuracies for one-vs-all binary classifications. The HOF features represent the main view, and the HOG features the auxiliary view. Best accuracies are highlighted in boldface.</figDesc><table>LB-LMIBPI 

SVM 
SVM-R 
RankTr 
SVM+ 
SVM2k-LUPI KCCA-LUPI 
LMIBPI 
UB-LMIBPI 
SVM2k 
KCCA 
brush hair 78.49 ± 4.99 78.50 ± 6.68 79.67 ± 4.25 78.16 ± 4.40 79.17 ± 6.40 
77.50 ± 5.78 
77.00 ± 6.79 80.66 ± 4.85 84.48 ± 5.03 85.00 ± 5.93 78.00 ± 8.08 
dive 
78.83 ± 4.23 80.66 ± 3.00 73.63 ± 4.11 79.66 ± 7.97 79.83 ± 3.64 
82.50 ± 2.63 
83.00 ± 2.33 83.16 ± 5.23 90.79 ± 5.94 87.16 ± 3.14 85.00 ± 2.07 
drink 
69.37 ± 6.62 69.16 ± 6.00 68.5 ± 5.43 
75.50 ± 6.18 69.17 ± 5.80 
69.50 ± 6.13 
68.50 ± 5.41 72.36 ± 5.83 81.98 ± 7.48 74.33 ± 7.16 69.83 ± 6.20 
eat 
67.04 ± 5.86 67.66 ± 4.00 69.63 ± 5.00 75.08 ± 2.10 71.00 ± 5.16 
71.50 ± 6.35 
67.50 ± 6.58 74.85 ± 4.61 81.98 ± 4.95 76.00 ± 6.62 69.00 ± 6.19 
golf 
78.83 ± 3.68 81.50 ± 4.11 70.43 ± 4.02 74.66 ± 3.01 80.67 ± 7.25 
80.00 ± 6.23 
78.66 ± 4.76 85.47 ± 5.66 90.45 ± 3.68 85.33 ± 6.92 78.16 ± 5.29 
hug 
80.66 ± 3.35 81.83 ± 4.18 80.43 ± 4.66 82.82 ± 3.90 81.50 ± 3.72 
83.33 ± 5.03 
81.33 ± 4.83 85.97 ± 3.44 91.11 ± 5.61 87.83 ± 3.93 82.66 ± 4.91 
jump 
74.16 ± 3.70 74.16 ± 4.30 69.90 ± 2.87 75.66 ± 2.81 76.33 ± 6.42 
77.00 ± 6.17 
76.16 ± 6.03 79.83 ± 2.65 84.52 ± 3.62 81.16 ± 4.90 78.33 ± 7.37 
pick 
65.59 ± 3.88 63.83 ± 5.42 67.53 ± 3.67 78.33 ± 3.56 66.83 ± 4.19 
65.16 ± 5.52 
63.83 ± 5.15 79.83 ± 3.56 85.42 ± 3.79 68.50 ± 3.88 64.33 ± 6.09 
punch 
83.76 ± 3.20 83.66 ± 4.10 81.20 ± 5.72 87.33 ± 4.90 84.33 ± 5.89 
84.83 ± 4.47 
83.33 ± 4.37 92.06 ± 3.54 95.38 ± 3.54 86.16 ± 4.30 83.83 ± 4.23 
sit 
75.33 ± 3.10 75.16 ± 4.83 71.66 ± 9.8 
76.33 ± 3.67 74.00 ± 4.60 
75.16 ± 5.95 
73.50 ± 5.05 76.99 ± 3.58 85.29 ± 4.05 77.50 ± 5.78 75.33 ± 5.92 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>89 ± 1.98 49.72 ± 4.96 52.83 ± 6.24 52.11 ± 4.83 50.27 ± 4.20 51.16 ± 4.50 48.33 ± 4.84 54.00 ± 1.32 56.50 ± 5.06 50.72 ± 2.99 52.66 ± 3.38 prendere 53.95 ± 4.23 52.39 ± 3.00 56.38 ± 4.10 54.50 ± 3.87 58.05 ± 2.34 54.83 ± 3.16 52.44 ± 3.34 57.28 ± 4.18 61.61 ± 8.32 56.50± 3.54 57.50 ± 2.72 sonostufo 55.95 ± 2.56 52.27 ± 3.97 57.00 ± 4.61 57.11 ± 4.19 59.44 ± 3.74 54.05 ± 4.29 51.33 ± 3.56 59.28 ± 2.19 66.33 ± 7.25 58.88± 4.47 57.00 ± 4.55 chevuoi 60.00 ± 5.62 57.55 ± 4.16 57.72 ± 5.12 55.22 ± 3.16 54.77 ± 4.24 59.22 ± 4.22 57.00 ± 3.45 61.11 ± 2.84 65.83 ± 6.10 67.05± 2.12 61.11 ± 2.27 daccordo 61.53 ± 5.25 65.83 ± 3.34 67.00 ± 3.87 63.61 ± 2.34 65.50 ± 5.28 67.00 ± 3.59 63.27 ± 3.40 64.86 ± 3.94 67.33 ± 8.25 74.83± 3.54 65.66 ± 4.69 perfetto 66.61 ± 4.05 64.55 ± 4.54 62.05 ± 3.46 60.11 ± 4.60 64.16 ± 2.40 64.94 ± 4.79 65.83 ± 4.26 67.72 ± 7.71 68.11 ± 7.23 64.05± 3.78 66.16 ± 5.14 vattene 61.83 ± 7.02 65.66 ± 3.19 62.27 ± 2.16 61.83 ± 5.43 64.55 ± 4.07 65.72 ± 1.88 63.88 ± 3.24 65.11 ± 5.07 68.70 ± 4.21 67.44± 3.47 66.83 ± 2.63.80 ± 3.72 67.27 ± 3.25 70.83± 3.22 65.33 ± 2.74 messidaccordo 54.83 ± 1.34 53.49 ± 8.88 57.15 ± 4.47 59.05 ± 4.67 59.05 ± 2.98 58.44 ± 2.39 55.66 ± 3.43 55.94 ± 3.17 59.05 ± 5.23 54.50± 4.76 58.50 ± 4.92 ok 53.06 ± 2.98 51.83 ± 2.95 56.50 ± 10.2 53.44 ± 3.62 52.50 ± 2.78 53.88 ± 3.39 50.22 ± 2.79 56.39 ± 2.19 60.75 ± 6.35 51.27± 3.43 52.77 ± 3.16</figDesc><table>SVM 
SVM-R 
RankTr 
SVM+ 
SVM2k-LUPI KCCA-LUPI 
LMIBPI 
UB-LMIBPI 
SVM2k 
KCCA 
vieniqui 
52.74 
basta 
67.00 ± 6.56 65.11 ± 5.18 65.44 ± 3.35 63.38 ± 4.37 64.11 ± 2.55 
65.27 ± 3.91 
62.72 ± 5.42 68.11 ± 4.28 69.22 ± 6.32 74.94± 6.21 72.11 ± 4.87 
buonissimo 
56.56 ± 8.02 52.44 ± 12.1 58.64 ± 6.57 58.55 ± 5.18 55.94 ± 5.17 
56.05 ± 5.82 
54.50 ± 4.52 57.67 ± 5.71 61.50 ± 2.35 65.38± 6.76 55.11 ± 5.00 
cheduepalle 
63.89 ± 2.01 66.27 ± 2.29 66.44 ± 2.82 65.83 ± 2.87 67.33 ± 3.33 
66.66 ± 1.81 
64.94 ± 2.47 67.72 ± 2.01 68.11 ± 3.05 76.05± 2.67 70.72 ± 2.85 
cosatifarei 
58.78 ± 6.20 61.99 ± 3.29 62.33 ± 4.03 61.50 ± 4.17 61.61 ± 4.40 
64.50 ± 3.55 
61.50 ± 5.25 62.11 ± 4.98 67.17 ± 6.24 64.88± 4.40 63.94 ± 5.75 
fame 
61.11 ± 5.23 59.55 ± 2.98 60.66 ± 2.87 61.38 ± 3.34 62.66 ± 3.90 
63.38 ± 3.47 
58.33 ± 1.50 60.55 ± 2.35 66.61 ± 7.22 65.94± 3.52 61.44 ± 4.40 
noncenepiu 
53.83 ± 1.99 52.61 ± 4.39 53.11 ± 3.55 53.83 ± 2.70 52.94 ± 3.21 
54.94 ± 4.71 
51.33 ± 3.73 54.94 ± 3.01 58.55 ± 5.23 55.83± 5.57 56.44 ± 4.21 
furbo 
63.39 ± 5.06 67.27 ± 3.56 65.22 ± 3.65 63.00 ± 3.10 66.33 ± 1.53 
68.66 ± 3.30 
66.05 ± 2.93 68.70 ± 4.65 72.22 ± 4.31 73.05± 1.87 70.22 ± 4.71 
combinato 
56.67 ± 7.26 56.33 ± 2.41 59.83 ± 3.73 58.55 ± 4.55 61.05 ± 3.38 
58.83 ± 2.61 
55.83 ± 2.43 62.11 ± 2.26 65.83 ± 6.32 75.00± 2.83 64.05 ± 3.66 
freganiente 
55.00 ± 4.25 52.38 ± 3.21 58.77 ± 3.28 56.94 ± 4.56 54.05 ± 6.20 
56.94 ± 3.74 
53.00 ± 3.12 59.28 ± 4.89 64.16 ± 3.95 58.05± 4.77 54.44 ± 4.59 
seipazzo 
60.61 ± 6.52 57.16 ± 4.58 55.50 ± 4.89 55.00 ± 3.92 53.55 ± 3.90 
60.05 ± 3.23 
58.05 ± 4.37 61.72 ± 5.02 65.44 ± 6.03 70.77± 2.97 61.94 ± 5.92 
tantotempo 
59.89 ± 5.15 61.50 ± 2.95 60.75 ± 3.75 59.27 ± 3.63 63.66 ± 1.96 
62.22 ± 2.35 
61.27 ± 2.75 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 .</head><label>4</label><figDesc>AwA dataset. AP results for one-vs-one classification. Bold numbers represent the cases where LMIBPI improves performance upon SVM, SVM+, RankTr, and LIR<ref type="bibr" target="#b41">[42]</ref>.</figDesc><table></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the Area Chair and the Reviewers for providing constructive feedback. This material is based upon work supported, in part, by the Center for Identification Technology Research and the National Science Foundation under Grant No. 1066197.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="151" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">ChaLearn gesture dataset (CGD2011). California</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chalearn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Extracting relevant structures with side information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chechik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Boosting with side information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="563" to="577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Recognizing RGB images by learning from RGB-D data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1418" to="1425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Elements of Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>Wiley and Sons, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Annotator rationales for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1395" to="1402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Describing objects by their attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Endres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1778" to="1785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Two view learning: SVM-2K, theory and practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Farquhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Hardoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Szedmak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Object detection with discriminatively trained partbased models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning visual attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Object localization based on structural SVM using privileged information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feyereisl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Incorporating privileged information through metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fouad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Raychaudhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1086" to="1098" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On feature combination for multiclass object classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast alternating linearization methods for minimizing the sum of two convex functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Goldfarb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Scheinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="page" from="349" to="382" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Canonical correlation analysis: An overview with application to learning methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Hardoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Szedmak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">26392664</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Making large-scale SVM learning practical</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Kernel Methods -Support Vector Learning</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Training linear svms in linear time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">HMDB: a large video database for human motion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Garrote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Serre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Attributebased classification for zero-shot visual object categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="453" to="465" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning using privileged information: SVM+ and weighted SVM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Incorporating prior knowledge in support vector machines for classification: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">7-9</biblScope>
			<biblScope unit="page" from="1578" to="1594" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Harvesting mid-level visual concepts from large-scale internet images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="851" to="858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Exploiting privileged information from web data for image categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="437" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Connection between svm+ and multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cherkassky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNN</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2048" to="2054" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Projected gradient methods for nonnegative matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2756" to="2779" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Smooth minimization of non-smooth functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="127" to="152" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<title level="m">Multimodal deep learning. In ICML</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the theory of learning with privileged information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pechyony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hidden conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Quattoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1848" to="1852" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ImageNet Large Scale Visual Recognition Challenge. IJCV</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning to rank using privileged information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sharmanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Quadrianto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="825" to="832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multivariate information bottleneck</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Slonim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1739" to="1789" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Agglomerative information bottleneck</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Slonim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The information bottleneck method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bialek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Allerton Conference on Communication, Control, and Computing</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="368" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Efficient object category recognition using classemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Szummer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="776" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A new learning paradigm: Learning using privileged information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vashist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="544" to="557" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">VLFeat: An open and portable library of computer vision algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fulkerson</surname></persName>
		</author>
		<ptr target="http://www.vlfeat.org/" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multiple kernels for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gulshan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009-09" />
			<biblScope unit="page" from="606" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning with hidden information using a max-margin latent variable model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1389" to="1394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Classifier learning with hidden information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4969" to="4977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning with hidden information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="238" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The SVM-Minus similarity score for video face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3523" to="3530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Large-margin multi-view information bottleneck</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1559" to="1572" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Distance metric learning using privileged information for face verification and person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Kullback-Leibler divergence for nonnegative matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICANN</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="250" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Boosting for transfer learning with multiple sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1855" to="1862" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multi-view visual recognition of imperfect testing data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="561" to="570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Can visual recognition benefit from auxiliary information in training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="65" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">NESVM: A fast gradient method for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="679" to="688" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
