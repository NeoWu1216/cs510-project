<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust Tensor Factorization with Unknown Noise</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xi&amp;apos;ai Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Robotics</orgName>
								<orgName type="institution" key="instit1">Shenyang Institute of Automation</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Robotics</orgName>
								<orgName type="institution" key="instit1">Shenyang Institute of Automation</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Robotics</orgName>
								<orgName type="institution" key="instit1">Shenyang Institute of Automation</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
							<email>dymeng@mail.xjtu.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Tang</surname></persName>
							<email>ytang@sia.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Robotics</orgName>
								<orgName type="institution" key="instit1">Shenyang Institute of Automation</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Robust Tensor Factorization with Unknown Noise</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Because of the limitations of matrix factorization, such as losing spatial structure information, the concept of tensor factorization has been applied for the recovery of a low dimensional subspace from high dimensional visual data. Generally, the recovery is achieved by minimizing the loss function between the observed data and the factorization representation. Under different assumptions of the noise distribution, the loss functions are in various forms, like L 1 and L 2 norms. However, real data are often corrupted by noise with an unknown distribution. Then any specific form of loss function for one specific kind of noise often fails to tackle such real data with unknown noise. In this paper, we propose a tensor factorization algorithm to model the noise as a Mixture of Gaussians (MoG). As MoG has the ability of universally approximating any hybrids of continuous distributions, our algorithm can effectively recover the low dimensional subspace from various forms of noisy observations. The parameters of MoG are estimated under the EM framework and through a new developed algorithm of weighted low-rank tensor factorization (WLRTF). The effectiveness of our algorithm are substantiated by extensive experiments on both of synthetic data and real image data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The problem of recovering a low dimensional linear subspace from high dimensional visual data naturally arises in the fields of computer vision, machine learning and statistics, and has drawn increasing attention in the recent years. Typical examples include representation and recognition of faces <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b0">1]</ref>, structure from motion <ref type="bibr" target="#b20">[21]</ref>, recognition of 3D objects under varying pose <ref type="bibr" target="#b14">[15]</ref>, motion segmentation <ref type="bibr" target="#b22">[23]</ref>.In such contexts, the data to be analyzed usually can be formulated as high-order tensors, which are natural generalization of vectors and matrices. Existing approach-*Corresponding author. <ref type="figure" target="#fig_1">Figure 1</ref>. High-order data represented by tensorization better preserves the essential data structure compared with matricizaiton. es, including LRMF and RPCA, proceed by unfolding tensors into matrices and then applying common matrix techniques to deal with tensor problems. However, as shown in <ref type="bibr" target="#b9">[10]</ref>, such matricization fails to exploit the essential tensor structure and often leads to suboptimal procedure. <ref type="figure" target="#fig_1">Figure 1</ref> illustrates the difference between the matrix based method and tensor based method in dealing with the high-order tensor data. The upper row is the matrix based factorization method, which needs to preliminarily unfold or vectorize the tensor; the lower row is the tensor based method which directly factorize the tensor without destroying the spatial structures. Given a high-order tensor data, an efficient way to extract the underlying useful information is low-rank tensor factorization (LRTF), which aims to extract low-rank subspaces underlying those vector spaces so that the original tensor can be suitably expressed through reasonably affiliating these subspaces. In the recent years, the application of LRTF has been extended to a wide range of fields throughout science and engineering <ref type="bibr" target="#b6">[7]</ref>.</p><p>The notation in this paper are defined as follows. Scalars are denoted by lowercase letters (a, b, ...) and vectors are denoted by bold lowercase letters (a, b, ...) with elements (a i , b j , ...). Matrices are represented by uppercase letters (A, B, ...) with column vectors (a :j , b :j , ...) and elements (a ij , b ij , ...). The calligraphic letters (A, B, ...) stand for the the high-order tensors. A K-order tensor X ∈ R I1×I2×···×IK is a rank-1 tensor, if it can be written as the outer product of K vectors, i.e., X = a 1 •a 2 •···•a K . Then the element of the tensor can be represented as: x i1i2···iK = a 1 i1 a 2 i2 · · · a K iK . The slice of a K-order tensor is a matrix defined by fixing every index but two. Therefore the slice of a 3-order tensor X ∈ R I×J×K has the form: frontal slices X ::k , lateral slices X :j: , horizontal slices X i:: .</p><p>As discussed in <ref type="bibr" target="#b6">[7]</ref>, although there are several tensor factorization forms, our framework for LRTF is based on the CANDECOMP/PARAFAC (CP) decomposition. The main reason is that the CP decomposition can be viewed as a higher-order generalization of the matrix singular value decomposition <ref type="bibr" target="#b1">[2]</ref> and has been widely used in many real applications <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b16">17]</ref>. Mathematically, a K-order tensor X ∈ R I1×I2×···×I K , with the integer I k (1 ≤ k ≤ K) indicating the dimension of X along the k-th order, is represented in the CP decomposition form as:</p><formula xml:id="formula_0">X = r ∑ d=1 u d • v d • · · · • t d ,<label>(1)</label></formula><p>where r is assumed to be the rank of the tensor X . Then each element of the tensor has the following form:</p><formula xml:id="formula_1">x ij...k = r ∑ d=1 u d i v d j · · · t d k .<label>(2)</label></formula><p>It is known that the canonical fit function for the CP LRTF is based on the Frobenius norm function which assumes the noise to follow a Gaussian distribution. However, for many real data, such as the fMRI neuroimaging data <ref type="bibr" target="#b4">[5]</ref> and the video surveillance data <ref type="bibr" target="#b7">[8]</ref>, a relative large perturbation in magnitude only affects a relatively small fraction of data points, which often violates the Gaussian assumption and instead follows a Laplacian distribution.</p><p>Therefore, it is necessary to consider other loss function that is robust to Laplacian noise. To alleviate this problem, one commonly used strategy is to replace the Frobenius norm function (say, L F norm) by the L 1 -type norm <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b2">3]</ref>, which is known to be robust to gross Laplacian perturbations. Unfortunately, in many real applications, the noise often exhibits very complex statistical distributions rather than a single purely Gaussian or Laplacian noise <ref type="bibr" target="#b28">[29]</ref>. This motivates us to consider more flexible modeling strategies to tackle such complex noise cases.</p><p>Under the framework of low-rank matrix factorization (LRMF), Meng and De la Torre <ref type="bibr" target="#b12">[13]</ref> firstly proposed to model the noise as Mixture of Gaussians (MoG). They showed that the MoG model is a universal approximator to any continuous distribution, and hence could be capable of modeling a wider range of noise distributions. Along this line, Zhao et al. <ref type="bibr" target="#b29">[30]</ref> further extended the MoG model to deal with robust PCA (RPCA) problem. Extensive experiments on synthetic data, face modeling and background subtraction demonstrated the merits of MoG model.</p><p>As such, to share the same light of matrix MoG model, we aim to introduce a novel MoG model to the tensor case for the LRTF task to overcome the drawbacks of existing models, which only model one simple Gaussian or Laplacian noise.</p><p>The contributions of this paper can be summarized as follows: (1) We propose a new low-rank subspace learning approach called weighted low-rank tensor factorization (WLRTF), which preserves the essential tensor structure;</p><p>(2) We apply MoG to the proposed WLRTF called weighted low-rank tensor factorization based on MoG (MoG WLRTF); (3) For solving the proposed model, we propose efficient algorithms to estimate the parameters under the EM framework and through the proposed algorithm of WLRTF. Our strategy is different from not only the traditional EM algorithm for solving matrix/tensor decomposition models, but also conventional alternative least squares (ALS) techniques for solving other tensor decomposition problems. A series of synthetic and real data experiments are then provided to validate the effectiveness of our method. The source codes of our algorithm are published online: http://vision.sia.cn/our%20team/Hanzhihomepage/vision-ZhiHan(English).html.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Weighted low-rank tensor factorization based on MoG</head><p>In this section, a new tensor model for modeling complex noise is proposed. Firstly, MoG is applied to model the noise element of the input tensor and thus have the loglikelihood optimization objective. Then through assuming a latent variable with higher dimension, we solve the problem iteratively under the EM framework. Finally, based on CP decomposition, we design a new algorithm that is different from ALS to solve the weighted low-rank tensor factorization in order to update each factorized tensor component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">CP decomposition with MoG</head><p>Taking the noise part (denoted as ε ijk ) into consideration, each element x ijk (i = 1, 2, ..., I, j = 1, 2, ..., J, k = 1, 2, ..., K) of the 3-order tensor X in CP decomposition can be written as:</p><formula xml:id="formula_2">x ijk = r ∑ d=1 u d i v d j t d k + ε ijk .<label>(3)</label></formula><p>As MoG has the ability to universally approximate any hybrids of continuous distributions, it is adopted for modeling the unknown noise in the original data. Hence every ε ijk follows an MoG and the distribution p(ε) is defined as:</p><formula xml:id="formula_3">p(ε) ∼ N ∑ n=1 π n N (ε|µ n , σ 2 n ),<label>(4)</label></formula><p>where π n is the mixing proportion with π n ≥ 0 and N ∑ n=1 π n = 1. N (ε|µ n , σ 2 n ) denotes the Gaussian distribution with mean µ n and variance σ 2 n . Then every x ijk in Eq. (3) follows a MoG distribution</p><formula xml:id="formula_4">with mean Λ n = r ∑ d=1 u d i v d j t d k + µ n and variance σ 2 n .</formula><p>The probability of each element x ijk in the input tensor X can thus be represented as:</p><formula xml:id="formula_5">p(x ijk | Π, Λ, Σ) = N ∑ n=1 π n N (x ijk |Λ n , σ 2 n ),<label>(5)</label></formula><p>where</p><formula xml:id="formula_6">Π = {π 1 , π 2 , ..., π N } , Λ = {Λ 1 , Λ 2 , ..., Λ n }, Σ = {σ 1 , σ 2 , ..., σ N }.</formula><p>We then define the likelihood of X as</p><formula xml:id="formula_7">p(X |Π, Λ, Σ ) = ∏ i,j,k∈Ω N ∑ n=1 π n N (x ijk |Λ n , σ 2 n ),<label>(6)</label></formula><p>where Ω is the index set of the non-missing entries of X . The goal is to maximize the log-likelihood function with respect to the parameters Π, Λ, Σ, i.e.</p><formula xml:id="formula_8">max Π,Λ,Σ L(Π, Λ, Σ) = ∑ i,j,k∈Ω log N ∑ n=1 π n N (x ijk |Λ n , σ 2 n ).<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">EM algorithm</head><p>EM algorithm <ref type="bibr" target="#b3">[4]</ref> is proven to be effective for solving the maximization problem of the log-likelihood function. Therefore, for solving Eq. (7), we assume a higher dimensional latent variable under the EM framework. Then the original problem can be viewed as a Gaussian Scale Mixtures (GSM) with µ n assumed to be 0, which has been widely used in previous works <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b23">24]</ref>. De-</p><formula xml:id="formula_9">fine U = {u 1 , u 2 , ..., u r }, V = {v 1 , v 2 , ..., v r }, T = {t 1 , t 2 , .</formula><p>.., t r }, and then Eq. (7) can be rewritten as:</p><formula xml:id="formula_10">max U,V,T,Π,Σ L(U, V, T, Π, Σ) = ∑ i,j,k∈Ω log N ∑ n=1 π n N (x ijk r ∑ d=1 u id v jd t kd , σ 2 n ).<label>(8)</label></formula><p>In the model, the variables U, V, T are shared by all the clusters of MoG and the mean for each cluster of the standard EM algorithm is represented by them. Thus our proposed algorithm will iterate between computing responsibilities of all Gaussian components (E Step) and maximizing the parameters Π, Σ and U, V, T in the model (M Step). </p><formula xml:id="formula_11">E(z ijkn ) = γ ijkn = π n N (x ijk r ∑ d=1 u id v jd t kd , σ 2 n ) N ∑ n=1 π n N (x ijk r ∑ d=1 u id v jd t kd , σ 2 n ) .<label>(9)</label></formula><p>The M step maximizes the upper bound given by the E step with regard to U, V, T, Π, Σ:</p><formula xml:id="formula_12">E Z p(X , Z|U, V, T, Π, Σ) = ∑ i,j,k∈Ω N ∑ n=1 γ ijkn (logπ n − log √ 2πσ n − (x ijk − r ∑ d=1 u id v jd t kd ) 2 2πσ 2 n ).<label>(10)</label></formula><p>This maximization problem can be solved by alternatively updating the MoG parameters Π, Σ and the factorized matrices U, V, T as follows:</p><p>M</p><p>Step to update Π, Σ: The closed-form updates for the MoG parameters are:</p><formula xml:id="formula_13">m n = ∑ i,j,k γ ijkn , π n = m n ∑ n m n , σ 2 n = 1 m n ∑ i,j,k γ ijkn (x ijk − r ∑ d=1 u id v jd t kd ) 2 .<label>(11)</label></formula><p>M</p><p>Step to update U, V, T: Re-write Eq. (10) only with regard to the unknown components U, V, T as follows:</p><formula xml:id="formula_14">∑ i,j,k∈Ω N ∑ n=1 γ ijkn (− (x ijk − r ∑ d=1 u id v jd t kd ) 2 2πσ 2 n ) = − ∑ i,j,k∈Ω N ∑ n=1 ( γ ijkn 2πσ 2 n )(x ijk − r ∑ d=1 u id v jd t kd ) 2 = − W ⊙ (X − r ∑ d=1 u :d • v :d • t :d ) 2 L F .<label>(12)</label></formula><p>Here ⊙ denotes the Hadamard product (component-wise multiplication) and the element w ijk of W ∈ R I×J×K is</p><formula xml:id="formula_15">w ijk =      √ N ∑ n=1 γ ijkn 2πσ 2 n , i, j, k ∈ Ω 0, i, j, k / ∈ Ω.<label>(13)</label></formula><p>The whole MoG WLRTF optimization process is summarized in Algorithm 1. Note that in the M Step, U, V and T are evaluated by solving the WLRTF model min</p><formula xml:id="formula_16">U,V,T W ⊙ (X − r ∑ d=1 u :d • v :d • t :d ) 2 LF</formula><p>, which will be introduced in details in the following section. </p><formula xml:id="formula_17">W ⊙ (X − r ∑ d=1 u :d • v :d • t :d ) 2 LF ,</formula><p>where W is calculated by Eq. (13). 6: end while</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Weighted low-rank tensor factorization</head><p>The WLRTF error model of the three-dimensional tensor X ∈ R I×J×K is written as</p><formula xml:id="formula_18">min U,V,T W ⊙ (X − r ∑ d=1 u :d • v :d • t :d ) LF ,<label>(14)</label></formula><p>where U ∈ R I×r , V ∈ R J×r , T ∈ R K×r are lowdimensional matrix with rank r. W ∈ R I×J×K is the weighted tensor which is composed by the standard variance of the input tensor elements. Because of the effectiveness and implementation convenience of ALS, we adopt its idea to update U, V, T of the tensor one at a time.</p><p>Suppose I 0 1 , ..., I 0 n ∈ R w×h are data matrices. In order to stack each of the above matrix as a vector, we define the operator vec : R w×h → R wh .</p><p>For each slice of the higher-order tensor, it can be viewed as a linear combination of the corresponding slices of all the rank-1 tensors. Different from other methods for solving the problem of LRTF, we stack each frontal slice of the higherorder tensor as a vector of a new matrix denoted as M F . Correspondingly, the vectorized horizontal slices and lateral slices are represented as M H and M L , respectively.</p><p>Firstly we have</p><formula xml:id="formula_19">X new = W ⊙ X .<label>(15)</label></formula><p>Then taking term T as an example, the vectorized frontal slice M F of the higher-order tensor can be written as follows:</p><formula xml:id="formula_20">M F = [vec(X new ::1 )|...|vec(X new ::K )] ∈ R IJ×K .<label>(16)</label></formula><p>For the i-th frontal slice of the higher-order tensor, the vectorized corresponding slices of all the rank-1 tensors can be viewed as the i-th element of the cell F which can be represented as:</p><formula xml:id="formula_21">F i = [vec(W ::i ⊙(u :1 • v :1 ))|... |vec(W ::i ⊙ (u :r • v :r ))] ∈ R IJ×r .<label>(17)</label></formula><p>Then the i-th vector of term T can be updated as follows:</p><formula xml:id="formula_22">T i: = (F † i M F :i ) T ∈ R 1×r ,<label>(18)</label></formula><p>where A † represents the pseudo-inverse matrix of matrix A, and B T denotes the transposed matrix of matrix B. Similarly, we have the term V and U updated as following: </p><formula xml:id="formula_23">M L = [vec(X new :1: )|...|vec(X new :J: )] ∈ R IK×J ,<label>(19)</label></formula><formula xml:id="formula_24">L i = [vec(W :i: ⊙(t :1 • u :1 ))|... |vec(W :i: ⊙ (t :r • u :r ))] ∈ R IK×r ,<label>(20)</label></formula><formula xml:id="formula_25">V i: = (L † i M L:i ) T ∈ R 1×r .<label>(21)</label></formula><formula xml:id="formula_26">H i = [vec(W i:: ⊙(v :1 • t :1 ))|... |vec(W i:: ⊙ (v :r • t :r ))] ∈ R JK×r ,<label>(22)</label></formula><formula xml:id="formula_27">U i: = (H † i M H :i ) T ∈ R 1×r .<label>(23)</label></formula><p>The WLRTF optimization process is summarized in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 (WLRTF)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input:</head><p>The input tensor X , initialized tensor factors U, V, T , weighted tensor W, number of iteration and the threshold ϵ.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>In this section, we conduct extensive experiments on both synthetic data and real applications to validate the effectiveness of the proposed MoG WLRTF algorithm compared with MC ALM <ref type="bibr" target="#b8">[9]</ref>, MoG LRMF <ref type="bibr" target="#b12">[13]</ref>, HaLRTC <ref type="bibr" target="#b9">[10]</ref>, BM4D <ref type="bibr" target="#b11">[12]</ref>, LRTA <ref type="bibr" target="#b17">[18]</ref>, PARAFAC <ref type="bibr" target="#b10">[11]</ref>, MSI DL <ref type="bibr" target="#b15">[16]</ref>, CWM LRTF <ref type="bibr" target="#b13">[14]</ref> and our proposed tensor factorization algorithm WLRTF without MoG. For the matrix based methods, the tensor is firstly unfolded into matrix structure before processing. The synthetic experiments are designed to quantitatively assess our method from: i) predictive performance over missing entries given an incomplete tensor; ii) reconstruction performance given a both incomplete and noisy tensor. The three real data applications are image inpainting, multispectral image recovery and real hyperspectral image restoration for evaluating the robust completion performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Synthetic Experiments</head><p>The synthetic tensor is generated as follows: firstly, matrices {U, V, T } are drawn from a standard normal distribution, i.e., ∀i, j, k, the vectors u i , v j , t k of the matrices {U, V, T } comply with a standard normal distribution N (0, I R ); Secondly, construct the true tensor by X gt = [[U, V, T ]], and set the size to 10 × 10 × 10 and CP rank r = 5. Then we conduct two synthetic experiments: i) for validating the predictive performance, we vary the true tensor missing entries rate (20%, 40%, 60%) ; ii) for verifying the reconstruction performance, we randomly choose 20% missing entries of the true tensor and further add certain type of noise to it as the following procedure: (1) Gaussian noise N (0, 0.1); (2) Sparse noise: 20% of the non-missing entries with the uniformly distribution over <ref type="bibr">[-5,5]</ref>; (3) Mixture noise: 20% of the non-missing elements with the uniformly distribution over <ref type="bibr">[-5,5]</ref>, and 20% of the rest nonmissing with Gaussian noise N (0, 0.2) and the rest with N (0, 0.01). The performance of each method is quantitatively assessed by the following measurements as used in <ref type="bibr" target="#b12">[13]</ref>:</p><formula xml:id="formula_29">E1 = ∥W ⊙ (X no − X rec )∥ L1 , E2 = ∥W ⊙ (X no − X rec )∥ L2 E3 = ∥X gt − X rec ∥ L1 , E4 = ∥X gt − X rec ∥ L2 ,</formula><p>where X no and X rec are used to denote the noisy tensor and the recovered tensor, respectively. As mentioned in <ref type="bibr" target="#b12">[13]</ref>, E1 and E2 are the optimization objectives of existing methods, which assess how the reconstruction complies with the noisy input, but E3 and E4 are more meaningful for evaluating the correctness of the clean subspace recoveries. Therefore, we pay more attention to the quantitative indices of E3 and E4. In the tables, the first and second best performances are marked out with bold and underline, respectively.</p><p>The performance of each method in the synthetic experiments are summarized in <ref type="table" target="#tab_0">Table 1 and Table 2</ref>, respectively. From the tables, we can see that our methods perform better in terms of E3 and E4 in most cases. Specifically, the application of MoG makes the matrix based MoG LRMF outperform MC ALM, and the tensor based MoG WLRT-F outperform WLRTF. This validates that MoG is able to model a wider range of noise distributions as a universal approximator. Besides, the superiority of MoG WLRTF over MoG LRMF indicates that it better preserves the individual structure of the tensor data.      </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Real image restoration</head><p>The images used in this section to evaluate the performance of the competing methods in image restoration are chosen as follows: (1) the benchmark image: the colorful building facade image; (2) a well-known data set: Columbia Multispectral Image Database <ref type="bibr" target="#b26">[27]</ref> 1 ; (3) real hyperspectral image: a HYDICE urban image 2 . Note that each real image used here can be viewed as a 3-order tensor.</p><p>Three quantitative image quality indices are adopted to evaluate the performance of each method: peak signal-tonoise ratio (PSNR), relative standard error (RSE) and feature similarity (FSIM) <ref type="bibr" target="#b27">[28]</ref>. Larger values of PSNR and FSIM and smaller values of RSE mean a better restoration results.</p><p>Simulated image restoration. Firstly, the facade image is randomly sampled with 20% missing entries and added with a relative small scale mixture noise: 20% of the non-missing pixels with the uniformly distribution over <ref type="bibr">[−35, 35]</ref>, 20% of the rest non-missing pixels with Gaussian noise N (0, 20) and the rest with another uniformly distribution N (0, 10). Both the visual and the quantitative results are demonstrated in <ref type="figure" target="#fig_4">Figure 2</ref> and <ref type="table" target="#tab_2">Table 3</ref> (the upper row). For better visual comparison, we have also provided a zoom-in version of a local region in <ref type="figure" target="#fig_4">Figure 2</ref>. It demonstrates that our method performs better in details than the other competing methods when the mixture noise is not very Secondly, in order to further compare the reconstruction ability of each method, we add a larger mixture noise to the facade and multispectral images. Each image is resized to half for all channels/bands and rescaled to [0,1]. The larger mixture noise are added as in the synthetic experiments: 20% missing entries, 20% of the non-missing pixels with the uniformly distribution over <ref type="bibr">[−5, 5]</ref>, 20% of the rest nonmissing pixels with Gaussian noise N (0, 0.2) and the rest with another uniformly distribution N (0, 0.01).</p><p>The facade reconstruction results are shown in <ref type="figure" target="#fig_5">Figure 3</ref> and <ref type="table" target="#tab_2">Table 3</ref> (the lower row). In <ref type="figure" target="#fig_5">Figure 3</ref>, we also show a zoom-in version of a local region for comparison. We can see that our MoG WLRTF is more robust to larger mixture noise than other methods.</p><p>For better visual demonstration of the multispectral image restoration result, we randomly choose ten selected bands of strawberries as shown in <ref type="figure" target="#fig_7">Figure 4</ref>. Meanwhile, we select the 31st band of these multispectral images to show our restoration results compared with other competing methods as shown in <ref type="figure" target="#fig_8">Figure 5</ref> and <ref type="table" target="#tab_3">Table 4</ref>. The superiority of the proposed MoG WLRTF method can be observed in multispectral image restoration.</p><p>Real Hyperspectral image restoration. Here we use a HYDICE urban image for demonstration. This real hyperspectral image contains several bands seriously polluted by the atmosphere and water absorption, and traditional methods generally discarded these seriously polluted bands before processing <ref type="bibr" target="#b28">[29]</ref>. <ref type="figure" target="#fig_9">Figure 6</ref> shows the restoration results of four seriously polluted bands in HYDICE urban image. It can be observed that MoG WLRTF can still have a good performance in dealing with such real gross noise. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>In this paper, we propose a new MoG based weighted low-rank tensor factorization method to estimate subspaces from high-dimensional data which are disturbed by noises with a complex distribution. Compared with the existing matrix methods, which lose the salient structure of the individual data, our method is capable of better preserving this information and performing better when the data are polluted with a large percentage. Additionally, our method also performs better than other tensor methods which are just optimal for Gaussian or Laplace noise. Both synthetic experiments and the real applications demonstrate the effectiveness of our method under complex noisy tensor data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>E Step: A latent variable z ijkn is assumed in the model, with z ijkn ∈ {0, 1} and N ∑ n=1 z ijkn = 1, representing the assigned value of the noise ε ijk to each component of the mixture. Here we denote Z = {z ijkn |i = 1, 2, ..., I; j = 1, 2, ..., J; k = 1, 2, ..., K; n = 1, 2, ..., N }. The posterior responsibility of the n-th mixture for generating the noise of x ijk can be calculated by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 (M</head><label>1</label><figDesc>EM algorithm for MoG WLRTF) Input: X ∈ R I×J×K , each image size is I × J and the number of images is K. Output: U, V, T 1: Initialize Π, Σ, U, V, T , MoG number N, small threshold ϵ. 2: while not converged do 3: E Step: Evaluate γ ijkn for i = 1, 2, ...I; j = 1, 2, ..., J; k = 1, 2, ..., K; n = 1, 2, ..., N by Eq.Step for Π, Σ: Evaluate π n , σ 2 n for n = 1, 2, ..., N by Eq.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>M</head><label></label><figDesc>H = [vec(X new 1:: )|...|vec(X new I:: )] ∈ R JK×I ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>V with Eq. (19), (20), (21); 4: update U with Eq. (22), (23), (24). 5: end while</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 .</head><label>2</label><figDesc>Facade with small mixture noise. (a) Noisy image. (b)-(k) Restored images obtained by competing methods. (l) Original image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 .</head><label>3</label><figDesc>Facade with large mixture noise. (a) Noisy image. (b)-(k) Restored images obtained by competing methods. (l) Original image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 .</head><label>4</label><figDesc>Ten randomly selected bands of strawberries. (a) Noisy bands. (b) Original bands. (c) Bands recovered by MoG WLRTF.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 .</head><label>5</label><figDesc>The 31st band of multispectral images. (a) Noisy band. (b)-(i) Restored bands obtained by competing methods. (l) Original band.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 .</head><label>6</label><figDesc>Real hyperspectral image restoration. (a) Original polluted bands. (b) Corresponding bands recovered by MoG WLRTF.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 .</head><label>1</label><figDesc>Predictive performance of competing methods with varied missing rate.</figDesc><table>MC ALM 
MoG LRMF 
HaLRTC 
BM4D 
LRTA 
PARAFAC 
MSI DL 
CWM LRTF 
WLRTF 
MoG WLRTF 
E1 
7.37 
0.08 
2.55e+02 
7.67e+02 
4.40e+02 
4.38e+02 
2.98e+02 
3.51e+02 
8.79e-05 
1.61e-08 
20% 
E2 
5.40 
1.08e-04 
6.50e+04 
1.47e+03 
6.47e+02 
6.47e+02 
3.70e+02 
3.93e+02 
2.11e-11 
6.82e-19 
E3 
7.25e+02 
0.09 
2.68e+04 
9.69e+02 
6.07e+02 
5.95e+02 
4.10e+02 
4.63e+02 
1.20e-04 
2.03e-08 
E4 
2.96e+02 
0.57 
3.76e+06 
1.90e+03 
9.62e+02 
9.48e+02 
5.82e+02 
5.34e+02 
3.69e-11 
8.85e-19 
E1 
8.28 
1.24 
2.55e+02 
7.77e+02 
5.28e+02 
5.30e+02 
3.58e+02 
4.38e+02 
0.25 
8.84e-09 
40% 
E2 
10.9 
0.02 
6.50e+04 
2.06e+03 
1.24e+03 
1.23e+03 
7.95e+02 
8.07e+02 
2.10e-04 
3.18e-19 
E3 
1.82e+03 
7.36e+02 
5.20e+04 
1.29e+03 
9.93e+02 
9.78e+02 
6.54e+02 
8.00e+02 
0.51 
1.90e-08 
E4 
6.08e+02 
1.41e+02 
7.06e+06 
3.23e+03 
2.28e+03 
2.22e+03 
1.50e+03 
1.56e+03 
5.87e-04 
9.63e-19 
E1 
40.8 
5.01 
2.55e+02 
8.31e+02 
7.11e+02 
6.63e+02 
4.85e+02 
5.57e+02 
6.93 
2.49e-07 
60% 
E2 
90.2 
0.66 
6.50e+04 
2.99e+03 
2.34e+03 
2.21e+03 
1.67e+03 
1.90e+03 
0.21 
2.77e-16 
E3 
2.86e+03 
1.51e+04 
7.89e+04 
2.03e+03 
1.86e+03 
1.81e+03 
1.25e+03 
1.73e+03 
34.6 
1.12e-06 
E4 
8.99e+02 
1.57e+03 
1.09e+07 
7.20e+03 
6.26e+03 
6.21e+03 
4.32e+03 
6.22e+03 
5.42 
4.21e-15 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 .</head><label>2</label><figDesc>Reconstruction performance of competing methods with unknown noise.</figDesc><table>MC ALM 
MoG LRMF 
HaLRTC 
BM4D 
LRTA 
PARAFAC 
MSI DL 
CWM LRTF 
WLRTF 
MoG WLRTF 
E1 
6.36 
32.3 
2.55e+02 
1.00e+03 
6.31e+02 
6.41e+02 
4.42e+02 
4.69e+02 
59.4 
54.2 
Gaussian 
E2 
11.9 
2.44 
6.50e+04 
2.74e+03 
1.55e+03 
1.57e+03 
1.17e+03 
7.04e+02 
7.00 
5.84 
Noise 
E3 
8.62e+02 
11.4 
1.05e+05 
1.27e+03 
8.59e+02 
8.53e+02 
6.02e+02 
6.09e+02 
32.2 
29.2 
E4 
3.57e+02 
72.0 
1.41e+07 
3.38e+03 
2.10e+03 
2.07e+03 
1.53e+03 
8.81e+02 
1.77 
1.52 
E1 
15.5 
4.20e+02 
5.10e+02 
1.15e+03 
1.05e+03 
9.63e+02 
7.70e+02 
8.86e+02 
7.00e+02 
6.93e+02 
Sparse 
E2 
24.3 
4.96e+02 
1.30e+05 
3.47e+03 
2.96e+03 
2.63e+03 
2.24e+03 
2.47e+03 
1.30e+03 
1.42e+03 
Noise 
E3 
1.87e+03 
5.25e+03 
1.02e+05 
1.12e+03 
1.02e+03 
1.05e+03 
7.47e+02 
8.41e+02 
7.08e+02 
5.10e+02 
E4 
6.70e+02 
1.04e+03 
1.33e+07 
2.64e+03 
2.17e+03 
2.34e+03 
1.64e+03 
1.77e+03 
9.22e+02 
4.33e+02 
E1 
17.4 
4.63e+02 
5.10e+02 
1.39e+03 
1.19e+03 
1.15e+03 
8.17e+02 
1.07e+03 
7.35e+02 
6.68e+02 
Mixture 
E2 
26.3 
6.05e+02 
1.30e+05 
4.77e+03 
3.90e+03 
3.70e+03 
2.58e+03 
3.31e+03 
1.43e+03 
1.37e+03 
Noise 
E3 
1.99e+03 
1.23e+04 
1.06e+05 
1.34e+03 
1.13e+03 
1.17e+03 
7.85e+02 
1.10e+03 
6.45e+02 
4.59e+02 
E4 
7.15e+02 
1.46e+03 
1.50e+07 
3.69e+03 
2.84e+03 
2.94e+03 
1.93e+03 
2.91e+03 
7.70e+02 
3.83e+02 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 .</head><label>3</label><figDesc>Facade reconstruction performance of competing methods with mixture noise.</figDesc><table>Facade 
MC ALM 
MoG LRMF 
HaLRTC 
BM4D 
LRTA 
PARAFAC 
MSI DL 
CWM LRTF 
WLRTF 
MoG WLRTF 
PSNR 
24.61 
24.34 
23.43 
12.00 
13.59 
13.37 
13.53 
24.80 
24.73 
25.65 
small scale noise 
RSE 
0.1133 
0.1169 
0.1298 
0.4838 
0.4026 
0.4129 
0.4062 
0.1109 
0.1118 
0.1005 
FSIM 
0.9091 
0.8954 
0.9407 
0.8371 
0.8318 
0.7402 
0.8258 
0.9435 
0.9473 
0.9539 
PSNR 
22.09 
22.18 
14.20 
9.204 
18.51 
16.95 
16.71 
22.82 
17.14 
23.69 
large scale noise 
RSE 
0.1515 
0.1499 
0.3755 
0.6673 
0.2287 
0.2737 
0.2817 
0.1393 
0.2679 
0.1260 
FSIM 
0.8627 
0.8525 
0.6003 
0.7619 
0.7667 
0.7101 
0.7310 
0.9117 
0.7033 
0.9268 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 4 .</head><label>4</label><figDesc>Multispectral image restoration performance of competing methods with mixture noise.</figDesc><table>MoG LRMF 
HaLRTC 
BM4D 
LRTA 
PARAFAC 
MSI DL 
CWM LRTF 
MoG WLRTF 
PSNR 
8.559 
8.444 
20.09 
16.51 
15.84 
18.47 
19.94 
22.17 
Jelly beans 
RSE 
1.749 
1.773 
0.4637 
0.7003 
0.7565 
0.5588 
0.4720 
0.3652 
FSIM 
0.5450 
0.5312 
0.7778 
0.7025 
0.6487 
0.8213 
0.8506 
0.8864 
PSNR 
6.342 
8.725 
20.96 
18.76 
16.26 
19.20 
21.75 
27.29 
Paints 
RSE 
1.757 
1.336 
0.3267 
0.4209 
0.5607 
0.3998 
0.2983 
0.1576 
FSIM 
0.4997 
0.4750 
0.8016 
0.7827 
0.6367 
0.8182 
0.9165 
0.9514 
PSNR 
9.032 
7.480 
21.65 
18.40 
16.54 
19.15 
22.72 
26.17 
Flowers 
RSE 
2.110 
2.522 
0.4937 
0.7173 
0.8888 
0.6583 
0.4364 
0.2933 
FSIM 
0.7690 
0.4172 
0.7833 
0.8073 
0.5271 
0.8220 
0.9126 
0.9153 
PSNR 
9.187 
7.109 
22.04 
18.59 
17.01 
19.43 
23.20 
25.22 
Egyptian statue 
RSE 
3.028 
3.847 
0.6898 
1.026 
1.231 
0.9308 
0.6032 
0.4779 
FSIM 
0.8538 
0.3696 
0.7861 
0.8245 
0.4243 
0.8142 
0.9187 
0.9439 
PSNR 
4.728 
7.911 
20.77 
18.29 
16.23 
18.95 
21.46 
23.95 
Chart and stuffed toy 
RSE 
2.003 
1.388 
0.3160 
0.4201 
0.5327 
0.3895 
0.2919 
0.2191 
FSIM 
0.7303 
0.4534 
0.7857 
0.7729 
0.5366 
0.8092 
0.8901 
0.9221 
PSNR 
11.88 
11.56 
23.65 
19.92 
17.14 
21.33 
21.92 
25.07 
Beers 
RSE 
0.7858 
0.8150 
0.2027 
0.3114 
0.4287 
0.2646 
0.2474 
0.1722 
FSIM 
0.7875 
0.4155 
0.8035 
0.7535 
0.4423 
0.8214 
0.9430 
0.9200 
PSNR 
8.782 
8.380 
20.90 
18.74 
16.49 
18.89 
21.66 
26.66 
Glass tiles 
RSE 
1.933 
2.025 
0.4793 
0.6140 
0.7961 
0.6038 
0.4389 
0.2467 
FSIM 
0.5692 
0.4690 
0.7267 
0.7726 
0.5738 
0.7287 
0.9075 
0.9475 
PSNR 
8.068 
7.762 
22.10 
19.22 
16.78 
19.54 
18.99 
24.80 
Strawberries 
RSE 
2.074 
2.149 
0.4123 
0.5745 
0.7607 
0.5534 
0.5900 
0.3021 
FSIM 
0.7474 
0.3997 
0.7721 
0.8059 
0.4932 
0.8128 
0.9229 
0.9283 

large. 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www1.cs.columbia.edu/CAVE/databases/multispectral 2 http://www.tec.army.mil/hypercube</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>We thank Lin Lin for the helpful discussions on experiments. This work was supported by the National Natural Science Foundation of China (Grant No. 61303168, 61333019, 11501440, 61373114).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Eigenfaces vs. fisherfaces: Recognition using class specific linear projection. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Hespanha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="711" to="720" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Analysis of individual differences in multidimensional scal ing via an n-way generalization of &quot;eckart-young decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="283" to="319" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Making tensor factorizations robust to non-gaussian noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1010.3043</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the em algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of the royal statistical society. Series B (methodological)</title>
		<imprint>
			<date type="published" when="1977" />
			<biblScope unit="page" from="1" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Movement-related effects in fmri time-series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Frackowiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magnetic Resonance in Medicine</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="346" to="355" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Robust tensor factorization using r1-norm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tensor decompositions and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="500" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Statistical modeling of complex backgrounds for foreground object detection. Image Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I.-H</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1459" to="1472" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The augmented lagrange multiplier method for exact recovery of corrupted low-rank matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1009.5055</idno>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Tensor completion for estimating missing values in visual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Musialski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wonka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="208" to="220" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Denoising of hyperspectral images using the parafac model and statistical performance analysis. Geoscience and Remote Sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bourennane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fossati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3717" to="3724" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nonlocal transform-domain filter for volumetric data denoising and reconstruction. Image Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maggioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="133" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robust matrix factorization with unknown noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D L</forename><surname>Torre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2013 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1337" to="1344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Robust low-rank tensor factorization by cyclic weighted median</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science China Information Sciences</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning and recognition of 3d objects from appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Murase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Workshop on</title>
		<meeting>IEEE Workshop on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="39" to="50" />
		</imprint>
	</monogr>
	<note>Qualitative Vision</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Decomposable nonlocal tensor dictionary learning for multispectral image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2949" to="2956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scalable bayesian low-rank decomposition of incomplete multiway tensors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dunson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML-14)</title>
		<meeting>the 31st International Conference on Machine Learning (ICML-14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1800" to="1808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Denoising and dimensionality reduction using multilinear tools for hyperspectral images. Geoscience and Remote Sensing Letters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Renard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bourennane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blanc-Talon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="138" to="142" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Wavelet denoising of multicomponent images using gaussian scale mixture models and a noise-free image as priors. Image Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Scheunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S. De</forename><surname>Backer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1865" to="1872" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Low-dimensional procedure for the characterization of human faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sirovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kirby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOSA A</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="519" to="524" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Shape and motion from image streams under orthography: a factorization method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Face recognition using eigenfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings CVPR&apos;91., IEEE Computer Society Conference on</title>
		<meeting>CVPR&apos;91., IEEE Computer Society Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1991" />
			<biblScope unit="page" from="586" to="591" />
		</imprint>
	</monogr>
	<note>Computer Vision and Pattern Recognition</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multiframe motion segmentation with missing data using powerfactorization and gpca</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="85" to="105" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scale mixtures of gaussians and the statistics of natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="855" to="861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Robust principal component analysis: Exact recovery of corrupted low-rank matrices via convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2080" to="2088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Temporal collaborative filtering with bayesian probabilistic tensor factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="211" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Generalized assorted pixel camera: postcapture control of resolution, dynamic range, and spectrum. Image Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yasuma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitsunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Iso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2241" to="2253" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fsim: a feature similarity index for image quality assessment. Image Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2378" to="2386" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A novel sparsity measure for tensor recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Robust principal component analysis with complex noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML-14)</title>
		<meeting>the 31st International Conference on Machine Learning (ICML-14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Bayesian cp factorization of incomplete tensors with automatic rank determination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cichocki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis &amp; Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1751" to="1763" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
