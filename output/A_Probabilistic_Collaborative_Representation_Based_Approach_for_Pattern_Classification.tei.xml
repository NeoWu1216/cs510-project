<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Probabilistic Collaborative Representation based Approach for Pattern Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijia</forename><surname>Cai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<email>cslzhang@comp.polyu.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangchu</forename><surname>Feng</surname></persName>
							<email>xcfeng@mail.xidian.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Applied Mathematics</orgName>
								<orgName type="institution">Xidian University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Probabilistic Collaborative Representation based Approach for Pattern Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conventional representation based classifiers, ranging from the classical nearest neighbor classifier and nearest subspace classifier to the recently developed sparse representation based classifier (SRC) and collaborative representation based classifier (CRC), are essentially distance based classifiers. Though SRC and CRC have shown interesting classification results, their intrinsic classification mechanism remains unclear. In this paper we propose a probabilistic collaborative representation framework, where the probability that a test sample belongs to the collaborative subspace of all classes can be well defined and computed. Consequently, we present a probabilistic collaborative representation based classifier (ProCRC), which jointly maximizes the likelihood that a test sample belongs to each of the multiple classes. The final classification is performed by checking which class has the maximum likelihood. The proposed ProCRC has a clear probabilistic interpretation, and it shows superior performance to many popular classifiers, including SRC, CRC and SVM. Coupled with the CNN features, it also leads to state-of-the-art classification results on a variety of challenging visual datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Pattern classification is one of the fundamental problems in computer vision and machine learning. Given a set of training samples X = [X 1 , X 2 , . . . , X K ], where X k , k = 1, 2, . . . , K, is the sample matrix of class k, pattern classification aims to predict the class label of a query sample y. Many pattern classification schemes have been proposed in the past decades. Generally speaking, there are two categories of pattern classification methods <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b3">4]</ref>: parametric methods and non-parametric methods. The parametric pattern classification methods (e.g., SVM) focus on how to learn the parameters of a hypothesis classification model from the training data. The learned parametric model is then used to predict the class labels of unknown data. In contrast, the non-parametric pattern classification methods (e.g., nearest neighbor) do not learn a parametric model for classification but use the training samples directly to predict the class labels of unknown data. Though non-parametric methods bear some weaknesses in computational efficiency, recent works have revealed their advantages (e.g., avoid over-fitting) over the parametric based methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b52">53]</ref>.</p><p>A popular type of non-parametric classifiers which are widely used in various visual recognition tasks are the distance based classifiers, e.g., the nearest subspace classifier (NSC) <ref type="bibr" target="#b9">[10]</ref>. The principle of such classifier is to assign a test sample to the class which has the shortest distance to it. However, the distance based non-parametric classifiers rely heavily on the pre-determined distance or similarity metrics. Though some commonly used metrics, such as Euclidean distance, manifold distance and principal angle based correlation <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b17">18]</ref>, are intuitive to describe the variations among samples, they have limitations in accurately reflecting the intrinsic similarity among objects <ref type="bibr" target="#b27">[28]</ref>. In order to better characterize the similarity, a promising choice is to introduce the uncertainties of the outputs of a classifier for decision making, as what has been done in probabilistic SVMs <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b13">14]</ref>. Probabilistic SVM estimates the posterior probabilities of class labels by the calibration techniques, such as Platt's scaling <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b25">26]</ref> which transforms the classifier's scores into the calibrated probabilities over classes by fitting a sigmoid posterior model.</p><p>An alternative approach to probabilistic SVM is the probabilistic subspace methods, e.g., probabilistic principal component analysis (PPCA) <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b24">25]</ref> and probabilistic linear discriminant analysis (PLDA) <ref type="bibr" target="#b35">[36]</ref>, which reformulate the subspace methods as a latent variable model and op-timize the parameters via maximum likelihood estimation. Therefore, the probabilistic subspace methods can be used to better model the class-conditional densities in classification. <ref type="bibr">Moghaddam</ref> and Pentland <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref> proposed to utilize a probabilistic similarity measure to model the probability distribution of subspace spanned by the changes of an object's appearance. Wang et al. <ref type="bibr" target="#b46">[47]</ref> further extended the probabilistic distance measure from two images to two linear subspaces (image sets), and formulated it as a Bayesian face recognition framework <ref type="bibr" target="#b28">[29]</ref>. However, most probabilistic subspace methods make strong assumptions on the distribution of noise and do not provide a straightforward procedure for multi-subspace cases.</p><p>How to represent the test sample is a key issue in distance based non-parametric classifiers. In the sparse representation based classifier (SRC) proposed by Wright et al. <ref type="bibr" target="#b47">[48]</ref>, a test sample is approximated by a linear combination of training samples from all classes with ℓ 1 -norm sparsity regularization on the representation coefficients. In <ref type="bibr" target="#b54">[55]</ref>, Zhang et al. argued that the success of SRC should be largely attributed to the collaborative representation of a test sample by the training samples across all classes. They further proposed an effective collaborative representation based classifier (CRC) by utilizing ℓ 2 -norm regularizer. The SRC/CRC classifiers can be regarded as distance based classifiers since they classify a test sample based on the shortest Euclidean distance from it to each class. Many modifications of SRC/CRC have been proposed for face recognition and other visual recognition tasks <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b53">54]</ref>. Chi and Porikli <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> suggested a collaborative representation optimized classifier (CROC) to combine NSC and SRC/CRC for multi-class classification. Despite the fact that many variants, improvements and applications of SRC/CRC have been proposed, there still lacks a substantial understanding of the classification mechanism of them. Though an inspiring geometric interpretation of CRC has been given in <ref type="bibr" target="#b54">[55]</ref>, this interpretation is not informative enough to reveal the intrinsic reason of CRC's success.</p><p>Motivated by the work of probabilistic subspace methods <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b27">28]</ref>, in this paper we analyze the classification mechanism of CRC from a probabilistic viewpoint and propose a probabilistic collaborative representation based approach for pattern classification. First, we present a probabilistic collaborative representation framework, where the probability that a test sample belongs to the collaborative subspace of all classes can be well defined and computed. Very interestingly, this probabilistic collaborative representation framework explains clearly the ℓ 2 -norm regularized representation scheme used in CRC. Consequently, we present a probabilistic collaborative representation based classifier (ProCRC), which jointly maximizes the likelihood that a test sample belongs to each of the multiple classes. <ref type="figure">Figure 1</ref>. Illustration of probabilistic collaborative subspace. x1 has a smaller ℓ2-norm of its representation vector, and is more likely to be a face image than x2.</p><p>The final classification is performed by checking which class has the maximum likelihood. Our extensive experiments on various visual classification tasks demonstrate that ProCRC outperforms many commonly used classifiers, including SVM, kernel SVM, SRC, CRC and CROC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Probabilistic Collaborative Subspace Representation 2.1. Probabilistic Collaborative Subspace</head><p>Suppose that we have a collection of training samples from K classes X = [X 1 , · · · , X K ], where X k is the data matrix of class k and each column of X k is a sample vector. We view X as the data matrix of an expanded class, and denote by l X the label set of all candidate classes in X. Denote by S the linear subspace collaboratively spanned by all samples in X. Then for each data point x in the collaborative subspace S, it can be represented as a linear combination of samples in X: x = Xα, where α is the representation vector.</p><p>Since X involves many samples from all classes, the collaborative subspace S is much bigger than the subspace spanned by each individual class X k . Therefore, though all data points Xα fall into S, we argue that their confidences to be labeled as l X should be different, depending on how the representation vector α is composed. Let us use an example to explain the idea. As illustrated in <ref type="figure">Fig.  1</ref>, X is a collection of face images from different subjects, and then l X is a label set of face subjects. With vector α 1 = [0.24, 0.22, 0.11, 0.21, 0.13, 0.10], a face image x 1 = Xα 1 is composed, and with vector α 2 = [−0.65, 0.46, 0.58, 0.65, − 0.42, 0.36], another face image x 2 = Xα 2 is composed. Clearly, x 1 is more likely to be a face image than x 2 , and it should have higher confidence to be labeled as l X .</p><p>From the example in <ref type="figure">Fig. 1</ref>, we can see that the representation vector α determines the confidence that x belongs to l X . With a more detailed look of vectors α 1 and α 2 , we can see that α 1 contains smaller coefficients (in terms of magnitude), which make x 1 approach to the center area of subspace S, while α 2 has relatively bigger coefficients, making x 2 approach to the boundary area of S. Based on these observations, we propose to formulate S as a probabilistic collaborative subspace; that is, different data points x have different probabilities of l(x) ∈ l X , where l(x) means the label of x, and P (l(x) ∈ l X ) should be higher if the ℓ 2 -norm of α is smaller, vice versa. One intuitive choice is to use a Gaussian function to define such a probability:</p><formula xml:id="formula_0">P l(x) ∈ l X ∝ exp(−c α 2 2 ),<label>(1)</label></formula><p>where c is a constant. With Eq. (1), we call the subspace S a probabilistic collaborative subspace, whose data points are assigned different probabilities based on α.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Probabilistic Representation of Samples Outside the Collaborative Subspace</head><p>Eq. (1) defines the probability of a data point inside the collaborative subspace S. In practice, the test sample y usually lies outside the subspace S. In order to measure the probability that y belongs to l X , i.e., P (l(y) ∈ l X ), we could find a data point x in S, and then compute two probabilities: P (l(x) ∈ l X ) and the probability that y has the same class label as x, i.e., P (l(x) = l(y)). With P (l(x) ∈ l X ) and P (l(x) = l(y)), we can readily have:</p><formula xml:id="formula_1">P l(y) ∈ l X = P l(y) = l(x)|l(x) ∈ l X · P l(x) ∈ l X . (2)</formula><p>P (l(x) ∈ l X ) has been defined in Eq. (1). P l(x) = l(y)|l(x) ∈ l X can be measured by the similarity between x and y. Here we adopt the Gaussian kernel (a.k.a heat/radial basis function kernel) to define it:</p><formula xml:id="formula_2">P l(y) = l(x)|l(x) ∈ l X ∝ exp(−κ y − x 2 2 ),<label>(3)</label></formula><p>where κ is a constant. Gaussian kernel is a widely used measure to characterize the neighbor-based similarity of two vertices in graph, and its advantages have been observed in many real-world applications such as data reduction <ref type="bibr" target="#b16">[17]</ref>, face analysis <ref type="bibr" target="#b18">[19]</ref> and image clustering <ref type="bibr" target="#b55">[56]</ref>.</p><formula xml:id="formula_3">With Eq. (1)∼Eq. (3), we have P l(y) ∈ l X ∝ exp(−(κ y − Xα 2 2 + c α 2 2 )). (4)</formula><p>In order to maximize the probability P (l(y) ∈ l X ), we can apply the logarithmic operator to Eq. (4). There is:</p><formula xml:id="formula_4">max P l(y) ∈ l X = max ln(P l(y) ∈ l X ) = min α κ y − Xα 2 2 + c α 2 2 = min α y − Xα 2 2 + λ α 2 2<label>(5)</label></formula><p>where λ = c/κ. The above equation gives a probabilistic representation of y over the collaborative subspace S. Interestingly, Eq. (5) shares the same formulation of the representation formula of CRC <ref type="bibr" target="#b54">[55]</ref>, but it has a clear probabilistic interpretation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Probabilistic Collaborative Representation based Classifier</head><p>Our formulation in Section 2 provides a way to estimate the probability of l(y) ∈ l X with the collaborative subspace S. However, it cannot indicate which specific class k the sample y belongs to. To perform classification, SRC/CRC simply uses the reconstruction error of y by each classspecific subspace to determine the class label. This classification rule is heuristic and lacks sufficient interpretation. Based on the proposed probabilistic collaborative subspace, in this section we present a probabilistic collaborative representation based classifier (ProCRC) to classify y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Probability to Each Class-specific Subspace</head><p>A sample x ∈ S can be collaboratively represented as:</p><formula xml:id="formula_5">x = Xα = K k=1 X k α k , where α = [α 1 ; α 2 ; . . . ; α K ]</formula><p>and α k is the coding vector associated with X k . Note that x k = X k α k is a data point falling into the subspace of class k. Again by using the Gaussian kernel, the probability that x has the same class label as x k can be defined as</p><formula xml:id="formula_6">P l(x) = k|l(x) ∈ l X ∝ exp(−δ x − X k α k 2 2 ) (6)</formula><p>where δ is a constant.</p><p>For a query sample y outside the space S, we can compute the probability that l(y) = k as:</p><formula xml:id="formula_7">P l(y) = k = P l(y) = l(x)|l(x) = k · P (l(x) = k) = P l(y) = l(x)|l(x) = k · P l(x) = k|l(x) ∈ l X · P l(x) ∈ l X .(7)</formula><p>Since the probability definition in Eq. (3) is independent of k as long as k ∈ l X , we have P l(</p><formula xml:id="formula_8">y) = l(x)|l(x = k) = P l(y) = l(x)|l(x) ∈ l X . With Eq. (5)∼Eq. (7), we have P l(y) = k = P l(y) ∈ l X · P l(x) = k|l(x) ∈ l X ∝ exp(−( y − Xα 2 2 + λ α 2 2 + γ Xα − X k α k 2 2 )),<label>(8)</label></formula><p>where γ = δ/κ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The ProCRC Model</head><p>By maximizing the probability defined in Eq. (8), we can find some data point x inside S (or equivalently the representation vector α) such that P (l(y) = k) achieves its maximum. However, if we maximize P (l(y) = k) individually for each class k, their corresponding data point x will be different. This makes the classification by the maximal P (l(y) = k) (w.r.t. k) unstable and less discriminative.</p><p>Alternatively, a better strategy is that we find a common data point x inside S, which could maximize the joint probability P (l(y) = 1, . . . , l(y) = K). Once the common x is found, we can then check which probability P (l(y) = k) is the highest to determine the class label of y. By assuming that the events l(y) = k are independent, we have</p><formula xml:id="formula_9">max P (l(y) = 1, . . . , l(y) = K) = max k P (l(y) = k) ∝ max exp(−( y − Xα 2 2 + λ α 2 2 + γ K K i=1 ( Xα − X i α i 2 2 ))).<label>(9)</label></formula><p>Applying the logarithmic operator to Eq. (9) and ignoring the constant term, we have:</p><formula xml:id="formula_10">(α) = arg min α { y − Xα 2 2 + λ α 2 2 + γ K K k=1 Xα − X k α k 2 2 }.<label>(10)</label></formula><p>In Eq. <ref type="formula" target="#formula_0">(10)</ref>, the first two terms y − Xα 2 2 + λ α 2 2 form a collaborative representation term, which encourages to find a point x = Xα that is close to y in the collaborative subspace S. The last term K k=1 Xα−X k α k 2 2 attempts to find inside each subspace of class k a point X k α k which is close to the common point x. The parameters γ and λ balance the role of the three terms, which can be set based on the prior knowledge of the problem, or we can use the crossvalidation technique to determine γ and λ from the training data. When the regularization parameter γ = 0, Eq. (10) will degenerate to CRC, and the term y − Xα 2 2 + λ α 2 2 will play a dominant role in determining α. When the regularization parameter γ &gt; 0, the term Xα − X k α k 2 2 is introduced to further adjust α k by X k , which results in a more robust and stable solution to α.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">The ProCRC Classifier</head><p>With the model in Eq. (10), a solution vectorα is obtained. The probability P (l(y) = k) can be computed by:</p><formula xml:id="formula_11">P (l(y) = k) ∝ exp(−( y − Xα 2 2 + λ α 2 2 + γ K Xα − X kαk 2 2 )).<label>(11)</label></formula><p>Note that ( y − Xα 2 2 + λ α 2 2 ) is the same for all classes, and thus we can omit it in computing P (l(y) = k). Let</p><formula xml:id="formula_12">p k = exp(−( Xα − X kαk 2 2 )).<label>(12)</label></formula><p>The classification rule can then be formulated as</p><formula xml:id="formula_13">l(y) = arg max k {p k }.<label>(13)</label></formula><p>We call the above classifier probabilistic collaborative representation based classifier (ProCRC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">The Robust ProCRC Model</head><p>In visual classification, partial corruption or occlusion often degrade the performance. It is well-known that the robustness of classification tasks can be enhanced by using ℓ 1norm to characterize the loss function <ref type="bibr" target="#b47">[48]</ref>. Our proposed probabilistic collaborative representation in Section 2.2 can be easily extended to its robust version. In Eq. (3), we can choose to use the Laplacian kernel, instead of the Gaussian kernel, to measure the probability:</p><formula xml:id="formula_14">P (l(y) = l(x)|l(x) ∈ l X ) ∝ exp(−κ y − x 1 ). (14)</formula><p>With similar derivations to ProCRC, we can have the following robust ProCRC (R-ProCRC) model:</p><formula xml:id="formula_15">(α) = arg min α { y − Xα 1 + λ α 2 2 + γ K K k=1 Xα − X k α k 2 2 }.<label>(15)</label></formula><p>The classification rule is the same as that in Eq. (13).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Solutions to ProCRC and R-ProCRC Models</head><p>The proposed ProCRC model has closed form solution, while the proposed R-ProCRC model can be easily solved by the iterative reweighted least square (IRLS) technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1">ProCRC</head><p>Refer to Eq. (15), let X ′ k be a matrix which has the same size as X, while only the samples of X k will be assigned to X ′ k at their corresponding locations in X, i.e., X ′ k = [0, . . . , X k , . . . , 0]. Let X ′ k = X − X ′ k . We can then compute the following projection matrix offline:</p><formula xml:id="formula_16">T = (X T X + γ K K k=1 (X ′ k ) T X ′ k + λI) −1 X T ,<label>(16)</label></formula><p>where I denotes the identity matrix. With T , the solution to α can be obtained efficiently:</p><formula xml:id="formula_17">α = T y.<label>(17)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2">R-ProCRC</head><p>Though the proposed R-ProCRC model is convex, there is no closed form solution to it, and we adopt an IRLS algorithm to compute α. Based on the current estimation of α, we introduce the diagonal weighting matrix W X :</p><formula xml:id="formula_18">W X (i, i) = 1/|X(i, :)α − y i |,<label>(18)</label></formula><p>where X(i, :) refers to the ith row of X. Given W X , the problem in Eq. (15) can be reformulated as:</p><formula xml:id="formula_19">(α) = arg min α { γ K K k=1 Xα − X k α k 2 2 + λ α 2 2 + (Xα − y) T W X (Xα − y)}.<label>(19)</label></formula><p>Then the coefficient vector α can be updated by:</p><formula xml:id="formula_20">α = (X T W X X+ γ K K k=1 (X ′ k ) T X ′ k +λI) −1 X T W X y.<label>(20)</label></formula><p>We alternatively update the weighting matrices W X and the coefficient vector α, and stop until convergence or after a fixed number of iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results</head><p>In this section, we comprehensively evaluate the proposed method from different aspects. In 4.1, by using the (MNIST <ref type="bibr" target="#b19">[20]</ref> and USPS <ref type="bibr" target="#b19">[20]</ref>) datasets, we compare Pro-CRC with state-of-the-art representation based classifiers along this line, including NSC <ref type="bibr" target="#b9">[10]</ref>, SRC <ref type="bibr" target="#b47">[48]</ref>, CRC <ref type="bibr" target="#b54">[55]</ref> and CROC <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>. The linear support vector machine (SVM) classifier <ref type="bibr" target="#b12">[13]</ref> is also compared. In 4.2, we compare R-ProCRC with robust SRC <ref type="bibr" target="#b49">[50]</ref> on robust face recognition using the AR <ref type="bibr" target="#b26">[27]</ref> and Extended Yale B <ref type="bibr" target="#b14">[15]</ref> datasets. In 4.3, we evaluate the running time of ProCRC. Finally, in 4.4 we evaluate ProCRC on several challenging visual classification datasets, including Stanford 40 Actions dataset <ref type="bibr" target="#b50">[51]</ref>, Caltech-UCSD Birds-200-2011 dataset <ref type="bibr" target="#b44">[45]</ref>, Oxford 102 Flowers dataset <ref type="bibr" target="#b33">[34]</ref>, Caltech-256 dataset <ref type="bibr" target="#b15">[16]</ref> and Im-ageNet ILSVRC 2012 dataset <ref type="bibr" target="#b37">[38]</ref>.</p><p>The proposed ProCRC has two parameters, λ and γ. In the experiments, we set λ = 10 −3 for handwritten digit datasets and face datasets, and λ = 10 −2 for other datasets. For the parameter γ, we set it by 5-fold cross validation on the training set. For those competing classifiers, their source codes are from the original authors, and we tune their parameters to achieve their best classification accuracy in each experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Handwritten Digit Recognition</head><p>MNIST dataset: The MNIST <ref type="bibr" target="#b19">[20]</ref> dataset contains a training set of 60,000 samples and a test set of 10,000 samples. There are 10 classes, and the size of each image is 28 × 28. We randomly selected 50, 100, 300, and 500 samples from each class for training, and we used all the samples in the test set for testing.</p><p>USPS dataset: The USPS <ref type="bibr" target="#b19">[20]</ref> dataset also contains a training sample set and a test sample set, and the size of each image is 16 × 16. We randomly selected 50, 100, 200, and 300 samples from each class for training, and used all the samples in the test set for testing. <ref type="table">Table 1</ref> and <ref type="table">Table 2</ref> list the classification rates on the two datasets, respectively. We can see that ProCRC outperforms all the competing classifiers. With the increase of the number of training samples, the classification accuracy of ProCRC increases consistently; however, the classification rate of NSC drops with the increase of training samples, while the rate of CRC first jumps and then increases a little. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Face Recognition with Corruption</head><p>We then evaluate R-ProCRC for face recognition (FR) with partial occlusion or corruption. The AR <ref type="bibr" target="#b26">[27]</ref> and Extended Yale B <ref type="bibr" target="#b14">[15]</ref> datasets are used since they are commonly used to in the original papers to evaluate SRC, CRC and CROC. Three types of corruptions are considered: random pixel corruption, random block occlusion, and disguise. In the experiments of random pixel corruption, for each test image we randomly select a certain percentage of pixels and replace them with uniformly distributed values within [0, 255]. In the experiments of block occlusion, for each test image we randomly select a square block and replace it with an unrelated image. For real disguise, we use the images with sunglasses or scarf in the AR dataset.</p><p>Since the SVM, NSC, CRC and CROC classifiers do not consider the robustness to outliers in design, we only compare R-ProCRC with the robust version (ℓ 1 -norm loss function and regularizer) of SRC, denoted by R-SRC <ref type="bibr" target="#b49">[50]</ref>.</p><p>Random corruption: We use the Extended Yale B dataset to evaluate R-ProCRC against random corruption. We randomly selected 30 images from each subject to construct the training dataset, and used the remaining images for testing. Random corruption is added to each test image. <ref type="table" target="#tab_1">Table 3</ref> lists the recognition rates of R-SRC and R-ProCRCr under different ratios of random corruption. One can see that R-ProCRC is much better than R-SRC for FR with random corruption.</p><p>Block occlusion: We then compare R-SRC with R-ProCRC for FR with block occlusion. The same experiment setting as in the random corruption experiment is used by changing random corruption to random corruption. The results are listed in <ref type="table">Table 4</ref>. One can see that block occlusion will cause more significant performance degradation than random corruption, while R-ProCRC still significantly outperforms R-SRC under different ratios of block occlusion. Disguise: At last, we use the face images with disguise in the AR dataset to evaluate R-ProCRC. We used the 700 non-occluded images in the first session for training, and used the 600 images with sunglasses and the 600 images with scarf for testing. <ref type="table">Table 5</ref> lists the experimental results. Again, R-ProCRC is consistently superior to R-SRC. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Running time comparison</head><p>We evaluate the running time of ProCRC and the competing representation based classifiers by processing one test image on the MNIST dataset (5,000 samples for training), and evaluate the running time of R-ProCRC and R-SRC by processing one image on the AR dataset (we test the disguise problem on 600 images with scarf). All methods are implemented in Matlab, and run on a PC with Intel (R) Core (TM) i7-5930K 3.50 GHz CPU and 32 GB RAM. <ref type="table" target="#tab_2">Table 6</ref> lists the running time of different methods.</p><p>Since ProCRC and CRC have analytical solutions and the resolved projection matrices have the same size, they have the same speed, which is faster than CROC and much faster than SRC. R-ProCRC employs ℓ 1 -norm only for loss function, while R-SRC employs ℓ 1 -norm for both loss and regularization. Therefore, R-ProCRC is faster than R-SRC. To more comprehensively assess the performance of Pro-CRC, we apply it to four challenging classification datasets: Stanford 40 Actions dataset <ref type="bibr" target="#b50">[51]</ref> for action recognition, Caltech-UCSD Birds-200-2011 <ref type="bibr" target="#b44">[45]</ref> and Oxford 102 Flowers datasets <ref type="bibr" target="#b33">[34]</ref> for fine-grained object recognition, and Caltech-256 dataset <ref type="bibr" target="#b15">[16]</ref> for large-scale object recognition. We do not evaluate R-ProCRC since corruption is not the main problem in these datasets. Stanford 40 Actions dataset <ref type="bibr" target="#b50">[51]</ref> is composed of 40 human actions, e.g., brushing teeth, cleaning the floor, reading book, throwing a Frisbee. It contains 9352 images, with 180∼300 images per class. We follow the training-test split settings suggested by the authors <ref type="bibr" target="#b50">[51]</ref>, using 100 images from each class for training and the remaining for testing.</p><p>Caltech-UCSD Birds (CUB200-2011) dataset <ref type="bibr" target="#b44">[45]</ref> is a widely-used benchmark for fine-grained image recognition, which contains 11,788 images of 200 bird species. Due to the high degree of similarity among species, this dataset is very challenging. We used the split setting provided in the dataset without part or bounding box annotations. There are around 30 training samples for each species.</p><p>Oxford 102 Flowers dataset <ref type="bibr" target="#b33">[34]</ref> is another fine-grained image classification benchmark which contains 8,189 images from 102 categories, and each category has at least 40 images. The flowers appear at different scales, pose and lighting conditions. This dataset is challenging since there exist large variations within the category but small difference across several categories.</p><p>Caltech-256 dataset <ref type="bibr" target="#b15">[16]</ref> consists of 256 object categories with at least 80 images per category. This dataset has a total number of 30,608 images. Following the common experimental settings, we randomly selected 15, 30, 45 and 60 images from each category for training, respectively, and used the remaining images for testing. For fair comparison, we run ProCRC 10 times for each partition and report the average classification accuracy.</p><p>On the four datasets, we employ two types of features to demonstrate the effectiveness of ProCRC. First, we use VLFeat <ref type="bibr" target="#b43">[44]</ref> to extract the Bag-of-Words feature based on SIFT (refer to BOW-SIFT feature). The square patch size and stride are set as 16 × 16 and 8 pixels, respectively. The codebook is trained by the k-means method, and the size is 1,024. We use a 2-level spatial pyramid representation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Evaluation of different classifiers with the BOW-SIFT features and CNN feature</head><p>To verify that ProCRC is an effective classifier, we present a detailed comparison between ProCRC and several widelyused classifiers, including softmax, linear SVM, kernel SVM with χ 2 kernel, CRC, SRC and CORC. The classification rates on the four datasets with BOW-SIFT features and VGG19 features are listed in <ref type="table" target="#tab_3">Table 7</ref> (the results on Caltech-256 dataset are obtained by using 30 training images per category). From <ref type="table" target="#tab_3">Table 7</ref>, we can see that ProCRC almost always achieves the best accuracy with either BOW-SIFT features or VGG19 features among all the classifiers. Specifically, with the powerful CNN features, ProCRC obtains at least 1.5% performance gains over all the other classifiers. These results clearly demonstrate the effectiveness of ProCRC as a visual classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Comparison to state-of-the-art methods</head><p>Furthermore, we compare ProCRC (using the VGG19 features) with the state-of-the-art methods on each dataset in <ref type="table" target="#tab_4">Table 8</ref>. Note that many of the comparison methods are CNN based methods and their features are even stronger than VGG19. The classification accuracies on Standford 40 Actions dataset are from SPM <ref type="bibr" target="#b48">[49]</ref>, LLC <ref type="bibr" target="#b45">[46]</ref>, EPM <ref type="bibr" target="#b39">[40]</ref>, Sparse-Bases <ref type="bibr" target="#b50">[51]</ref>, CF <ref type="bibr" target="#b21">[22]</ref>, SMP <ref type="bibr" target="#b22">[23]</ref> and ASPD <ref type="bibr" target="#b38">[39]</ref>. We see that ProCRC achieves at least 5.5% improvement over others. As can be seen in <ref type="table" target="#tab_3">Table 7</ref>, using the same VGG19 features, kernel SVM leads to an accuracy of 79.8%, which is 1.1% lower than ProCRC.</p><p>The classification accuracies on Caltech-UCSD Birds-200-2011 dataset are from POOF <ref type="bibr" target="#b1">[2]</ref>, FV-CNN <ref type="bibr" target="#b10">[11]</ref>, PN-CNN <ref type="bibr" target="#b4">[5]</ref> and NAC <ref type="bibr" target="#b40">[41]</ref>. Again, ProCRC outperforms all methods except for NAC. However, please note that NAC further constructs a part-model based on the VGG19 feature for recognition, while ProCRC performs classification directly using the VGG19 feature. Compared with the other three methods which all use a specially designed CNN architecture for bird specie recognition, the improvement by ProCRC is obvious.</p><p>The classification accuracies on Oxford 102 Flowers dataset are from BiCos seg <ref type="bibr" target="#b5">[6]</ref>, DAS <ref type="bibr" target="#b0">[1]</ref>, GMP <ref type="bibr" target="#b32">[33]</ref>, Over-Feat <ref type="bibr" target="#b36">[37]</ref> and NAC <ref type="bibr" target="#b40">[41]</ref>. ProCRC improves 8% over Over-Feat and is only 0.5% lower than NAC, which uses an additional part-model VGG19 feature. The performance gain is significant compared with BiCos seg, DAS and GMP (increase by 15.4%, 14.1% and 10.2%, respectively).</p><p>The average classification accuracies (over 10 runs) on Caltech-256 dataset are from ScSPM <ref type="bibr" target="#b48">[49]</ref>, LLC <ref type="bibr" target="#b45">[46]</ref>, M-HMP <ref type="bibr" target="#b2">[3]</ref>, ZF <ref type="bibr" target="#b51">[52]</ref>, CNN-S <ref type="bibr" target="#b6">[7]</ref>, VGG19 <ref type="bibr" target="#b41">[42]</ref> and NAC <ref type="bibr" target="#b40">[41]</ref>. The symbol "-" means that the result is not reported in the original work. ProCRC has at least 12% performance gain over ZF, and has more significant improvements over Sc-SPM, LLC, M-HMP. When 60 images per class are used for training, ProCRC achieves 1% improvement compared with VGG19 + linear SVM (85.1%), and 2% improvement compared with NAC, while the latter even uses an additional part-model based on VGG19 feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.4">The scalability of ProCRC</head><p>In the proposed ProCRC model, a matrix inversion operation (see Eq. (16)) will be involved to obtain the projection matrix T . The dimensionality of this matrix inverse depends on the number of training samples in the dataset. Therefore, one potential problem of ProCRC is its scalability on very large scale datasets which have millions of training samples (e.g., ImageNet <ref type="bibr" target="#b37">[38]</ref>). It might not be fea- Fortunately, the scalability problem of ProCRC can be solved by using the dictionary learning (DL) techniques. More specifically, for a dataset which has a large number of samples per class, we can learn a compact dictionary D k , which has only a small number of atoms, from the original samples X k . The ProCRC classifier can then be applied by replacing X k by D k . One simple DL model is</p><formula xml:id="formula_21">min {D k ,A k } X k − D k A k 2 F + τ A k 2 F</formula><p>, where τ is a trade-off parameter and each column of D k has unit length. This DL model can be easily solved by using an alternating optimization procedure to update D k and A k .</p><p>With the above mentioned DL strategy, we test ProCRC (and other representation based classifiers) on the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2012 dataset <ref type="bibr" target="#b37">[38]</ref>, which consists of 1.2M+ training images from 1,000 categories (about 1,300 images per category) and 50K validation images (50 images per category). We compare ProCRC with other classifiers using two baseline visual features: BOW-SIFT extracted by VLFeat (we use a codebook of 1,000 visual words to perform the k-means method, and the feature dimension is 1,000 since 0-level spatial pyramid representation is adopted here for simplicity) and AlexNet features extracted by Caffe (as described in <ref type="bibr" target="#b23">[24]</ref>, the feature dimension is 4,096). For each category, a dictionary with 50 atoms is learned from the about 1,300 samples.</p><p>The top-1 and top-5 classification accuracies are listed in <ref type="table" target="#tab_5">Table 9</ref>. With the handcraft BOW-SIFT feature, the top-1 accuracy of ProCRC is at least 1.1% higher than all the other competitive classifiers. With the AlexNet based CNN feature, ProCRC outperforms SVM (0.5%) and other representation based classifiers (2%), but is 1.1% and 0.3% lower than Softmax on top-1 and top-5 accuracies, respectively. This is mainly because of the fact that AlexNet features are trained with the Softmax output layer. In summary, DL is effective to solve the scalability issue of ProCRC. In the future, we will explore other methods (e.g., a hierarchical structure) to further improve the performance and scalability of ProCRC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We presented a probabilistic collaborative representation based classifier, namely ProCRC, which employs a probabilistic collaborative representation framework to jointly maximize the probability that a test sample belongs to each class. ProCRC effectively makes use of the training samples from all classes to deduce the class label of a test sample. It possesses a clear probabilistic interpretation, and is very efficient to solve. Our experiments on handwritten digit recognition, face recognition, and other visual classification tasks validated its superiority to popular representation based classifiers, including NSC, CRC, SRC and CROC, as well as benchmark classifiers such as SVM and kernel SVM. Coupled with CNN features (e.g., VGG19), ProCRC demonstrated state-of-the-art performance on challenging visual datasets such as Stanford 40 Actions, CUB200-2011, Oxford 102 Flowers, and Caltech-256. We also demonstrated that ProCRC can be applied to larger-scale dataset such as ImageNet ILSVRC-2012 by introducing a simple dictionary learning pre-processing stage.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Classification rate (%) on the MNIST dataset. Classification rate (%) on the USPS dataset.This shows that ProCRC has good robustness to the number of training samples by considering all the classes collaboratively while double checking each individual class. It has the smallest performance variation under different number of training samples.</figDesc><table>Num. 
50 
100 
300 
500 
SVM 
89.35 92.10 94.88 95.93 
NSC 
91.06 92.86 85.29 78.26 
CRC 
72.21 82.22 86.54 87.46 
SRC 
80.12 85.63 89.30 92.70 
CROC 
91.06 92.86 89.93 89.37 
ProCRC 91.84 94.00 95.48 95.88 

Num. 
50 
100 
200 
300 
SVM 
93.46 95.31 95.91 96.30 
NSC 
93.48 93.25 90.21 87.85 
CRC 
89.89 91.67 92.36 92.79 
SRC 
92.58 93.99 95.63 95.86 
CROC 
93.48 93.25 91.40 91.87 
ProCRC 93.84 95.62 96.03 96.43 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 3 .</head><label>3</label><figDesc>Recognition rate (%) on face images with random corruption on the Extended Yale B dataset.</figDesc><table>Corruption ratio 
10% 
20% 
40% 
60% 
R-SRC [50] 
97.49 95.60 90.19 76.85 
R-ProCRC 
98.45 98.20 93.25 82.42 

Table 4. Recognition rate (%) on face images with block occlusion 
on the Extended Yale B dataset. 

Corruption ratio 
10% 
20% 
30% 
40% 
R-SRC [50] 
90.42 85.64 78.89 70.09 
R-ProCRC 
98.12 92.62 86.42 77.16 

Table 5. Recognition rate (%) on face images with disguise on the 
AR dataset. 

Corruption ratio Sunglasses Scarf 
R-SRC [50] 
69.17 
69.50 
R-ProCRC 
70.50 
69.83 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 6 .</head><label>6</label><figDesc>Running time (s) of different methods.</figDesc><table>Method 
NSC 
CRC 
SRC 
CROC 
Time (s) 
0.0003 
0.0005 
0.22 
0.0009 
Method 
ProCRC R-SRC R-ProCRC 
Time (s) 
0.0005 
3.57 
1.81 

4.4. Other Challenging Visual Classification Tasks 

4.4.1 Datasets and settings 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 7 .</head><label>7</label><figDesc>Accuracies (%) of different classifiers with BOW-SIFT features and VGG19 features.</figDesc><table>Classifier 
Standford 40 
CUB200-2011 
Flower 102 
Caltech 256 
BOW-SIFT VGG19 BOW-SIFT VGG19 BOW-SIFT VGG19 BOW-SIFT(30) VGG19(30) 
Softmax 
21.1 
77.2 
8.2 
72.1 
46.5 
87.3 
25.8 
75.3 
SVM 
24.0 
79.0 
10.2 
75.4 
50.1 
90.9 
28.5 
80.1 
Kernel SVM 
26.3 
79.8 
10.5 
76.6 
51.0 
92.2 
28.7 
81.3 
NSC 
22.1 
74.7 
8.4 
74.5 
46.7 
90.1 
25.8 
80.2 
CRC 
24.6 
78.2 
9.4 
76.2 
49.9 
93.0 
27.4 
81.1 
SRC 
24.2 
78.7 
7.7 
76.0 
47.2 
93.2 
26.9 
81.3 
CROC 
24.5 
79.1 
9.1 
76.2 
49.4 
93.1 
27.9 
81.7 
ProCRC 
28.4 
80.9 
9.9 
78.3 
51.2 
94.8 
29.6 
83.3 

The final feature dimension of each image is 5,120 for all 
datasets. Second, we use VGG-verydeep-19 [42] to extract 
CNN features (refer to VGG19 features). We use the acti-
vations of the penultimate layer as local features, which are 
extracted from 5 scales {2 s , s = −1, −0.5, 0, 0.5, 1}. We 
pool all local features together regardless of scales and lo-
cations. The final feature dimension of each image is 4,096 
for all datasets. Both BOW-SIFT and VGG19 features are 
ℓ 2 normalized. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 8 .</head><label>8</label><figDesc>Comparsions to state-of-the-arts on different datasets (Standford 40, CUB200-2011, Flower 102 and Caltech-256).sible to load millions of samples into memory and solve a matrix inverse problem with dimensionality of millions.</figDesc><table>Dataset 
Split 
Methods &amp; Accuracies (%) 

Standford 40 
fixed 
ProCRC ASPD 
SMP 
CF 
SparBases 
EPM 
LLC ScSPM 
80.9 
75.4 
53.0 
51.9 
45.7 
42.2 
35.2 
34.9 

CUB200-2011 
fixed 
ProCRC NAC 
PN-CNN FV-CNN 
POOF 
78.3 
81.0 
75.7 
66.7 
56.9 

Flower 102 
fixed 
ProCRC NAC 
OverFeat 
GMP 
DAS 
BiCos seg 
94.8 
95.3 
86.8 
84.6 
80.7 
79.4 

Caltech-256 

random ProCRC NAC 
VGG19 
CNN-S 
ZF 
M-HMP 
LLC ScSPM 
15 
80.2 
-
-
-
65.7 
42.7 
34.4 
27.7 
30 
83.3 
-
-
-
70.6 
50.7 
41.2 
34.0 
45 
84.9 
-
-
-
72.7 
54.8 
45.3 
37.5 
60 
86.1 
84.1 
85.1 
77.6 
74.2 
58.0 
-
-

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 9 .</head><label>9</label><figDesc>Accuracies (%) on ImageNet ILSVRC-2012.</figDesc><table>Classifier 
BOW-SIFT 
AlexNet 
top-5 top-1 top-5 top-1 
Softmax 
28.8 
7.4 
80.4 
57.4 
SVM 
29.1 
7.2 
79.7 
55.8 
NSC 
27.4 
6.6 
77.4 
53.2 
CRC 
28.3 
7.3 
78.5 
54.3 
SRC 
28.6 
6.9 
78.7 
54.1 
CROC 
28.5 
7.2 
78.8 
54.4 
ProCRC 
29.7 
8.5 
80.1 
56.3 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Efficient object detection and segmentation for fine-grained recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Angelova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="811" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Poof: Part-based one-vs.-one features for fine-grained categorization, face verification, and attribute estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="955" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multipath sparse coding using hierarchical matching pursuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="660" to="667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">In defense of nearest-neighbor based image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Boiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bird species categorization using pose normalized deep convolutional nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tech</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bicos: A bi-level co-segmentation method for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2579" to="2586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Return of the devil in the details: Delving deep into convolutional nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Connecting the dots in multi-class classification: From nearest subspace to collaborative representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3602" to="3609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Classification and boosting with multiple collaborative representations. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1519" to="1531" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Discriminant waveletfaces and nearest feature classifiers for face recognition. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-T</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1644" to="1649" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep filter banks for texture recognition and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cimpoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3828" to="3836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Extended src: Undersampled face recognition via intraclass variant dictionary. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1864" to="1870" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R.-E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Support vector machines as probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Franc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="665" to="672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">From few to many: Illumination cone models for face recognition under variable lighting and pose. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Georghiades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="643" to="660" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Caltech-256 object category dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A kernel view of the dimensionality reduction of manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21 International Conference on Machine Learning</title>
		<meeting>the 21 International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page">47</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Grassmann discriminant analysis: a unifying view on subspace-based learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hamm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning</title>
		<meeting>the 25th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="376" to="383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Face recognition using laplacianfaces. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="328" to="340" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sparse and dense hybrid representation via dictionary decomposition for face recognition. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1067" to="1079" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Coloring action recognition in still images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Anwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van De Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Bagdanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="205" to="221" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semantic pyramids for gender and action recognition. Image Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van De Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Anwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gatta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3633" to="3645" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Probabilistic non-linear principal component analysis with gaussian process latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1783" to="1816" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A note on platt&apos;s probabilistic outputs for support vector machines. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Weng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The ar face database. CVC Technical Report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Martinez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Principal manifolds and probabilistic subspaces for visual recognition. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Moghaddam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="780" to="788" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Bayesian face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Moghaddam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jebara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1771" to="1782" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Probabilistic visual learning for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Moghaddam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="786" to="793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Probabilistic visual learning for object representation. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Moghaddam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="696" to="710" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Machine learning: a probabilistic perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Generalized max pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2473" to="2480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automated flower classification over a large number of classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-E</forename><surname>Nilsback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, Graphics &amp; Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="722" to="729" />
		</imprint>
	</monogr>
	<note>ICVGIP&apos;08. Sixth Indian Conference on</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in large margin classifiers</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="61" to="74" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Probabilistic linear discriminant analysis for inferences about identity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Elder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cnn features off-the-shelf: an astounding baseline for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Azizpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="512" to="519" />
		</imprint>
	</monogr>
	<note>2014 IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Recognizing actions through action-specific person detection. Image Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shahbaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van De Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bagdanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4422" to="4432" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Expanded parts model for human attribute and action recognition in still images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="652" to="659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Neural activation constellations: Unsupervised part model discovery with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1143" to="1151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Probabilistic principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Tipping</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="611" to="622" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Vlfeat: An open and portable library of computer vision algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fulkerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on Multimedia</title>
		<meeting>the international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1469" to="1472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">The caltech-ucsd birds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Locality-constrained linear coding for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3360" to="3367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Manifold-manifold distance with application to face recognition based on image set</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2008 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Linear spatial pyramid matching using sparse coding for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2009 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1794" to="1801" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Alternating direction algorithms for ℓ1-problems in compressive sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM journal on scientific computing</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="250" to="278" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Human action recognition by learning bases of action attributes and parts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1331" to="1338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2014</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Svm-knn: Discriminative nearest neighbor classification for visual category recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2006 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2126" to="2136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Close the loop: Joint blind image restoration and recognition with sparse representation prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="770" to="777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Sparse representation or collaborative representation: Which helps face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="471" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Locality preserving clustering for image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th annual ACM international conference on Multimedia</title>
		<meeting>the 12th annual ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="885" to="891" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
