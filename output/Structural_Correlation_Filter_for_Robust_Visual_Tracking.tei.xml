<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structural Correlation Filter for Robust Visual Tracking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="laboratory">State Key Laboratory Of Information Security</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianzhu</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochun</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="laboratory">State Key Laboratory Of Information Security</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changsheng</forename><surname>Xu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Structural Correlation Filter for Robust Visual Tracking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose a novel structural correlation filter (SCF) model for robust visual tracking. The proposed SCF model takes part-based tracking strategies into account in a correlation filter tracker, and exploits circular shifts of all parts for their motion modeling to preserve target object structure. Compared with existing correlation filter trackers, our proposed tracker has several advantages:</p><p>(1) Due to the part strategy, the learned structural correlation filters are less sensitive to partial occlusion, and have computational efficiency and robustness.</p><p>(2) The learned filters are able to not only distinguish the parts from the background as the traditional correlation filters, but also exploit the intrinsic relationship among local parts via spatial constraints to preserve object structure. (3) The learned correlation filters not only make most parts share similar motion, but also tolerate outlier parts that have different motion. Both qualitative and quantitative evaluations on challenging benchmark image sequences demonstrate that the proposed SCF tracking algorithm performs favorably against several state-of-the-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Visual tracking is one of the most fundamental problems in computer vision with various applications in video surveillance, human computer interaction and vehicle navigation. Although great progress has been made in recent years, it remains a challenging problem due to factors such as illumination changes, geometric deformations, partial occlusions, fast motions and background clutters.</p><p>Tracking algorithms can be generally categorized as either generative or discriminative methods. Generative trackers typically formulate tracking problem as searching for the best image regions which are similar to the tracked targets <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b33">34]</ref>. Different from generative trackers, discriminative approaches cast tracking as a classification problem that distinguishes tracked targets from back- * Indicates corresponding author <ref type="figure" target="#fig_2">Figure 1</ref>. Comparisons of our approach with state-of-the-art correlation filter trackers in challenging situations of partial occlusion on the Lemming sequence <ref type="bibr" target="#b29">[30]</ref>. Our SCF tracker takes part-based tracking strategy into account for translation estimation, and performs robustly to partial occlusion after the 361th frame than the DSST <ref type="bibr" target="#b6">[7]</ref> and KCF <ref type="bibr" target="#b12">[13]</ref> methods. grounds <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b31">32]</ref>. Recently, correlation filter based discriminative tracking methods have been proven to be able to achieve fairly high speed and robust tracking performance <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b18">19]</ref>. Conventionally, correlation filters are designed to produce correlation peaks for each interested target in the scene while yielding low responses to background, which are usually used to detect expected patterns. As proved by Convolution Theorem, the correlation in time domain corresponds to an element-wise multiplication in Fourier domain. Thus, the intrinsic idea of correlation filter is that the correlation can be calculated in Fourier domain in order to avoid the time-consuming convolution operation. Due to its computational efficiency, correlation filters have attracted considerable attention to visual tracking. Although achieved the appealing results both in accuracy and robustness, these correlation filter based trackers cannot deal with partial occlusion well. <ref type="figure" target="#fig_2">Figure 1</ref> shows one example about the tracking results on the lemming sequence of two correlation filter based trackers, namely DSST <ref type="bibr" target="#b6">[7]</ref> and KCF <ref type="bibr" target="#b12">[13]</ref>, which have achieved state-of-art results and have beaten all other attended track-(a) The KCF tracker (b) The SCF tracker <ref type="figure">Figure 2</ref>. Comparisons of our approach with the KCF on the Jogging sequence <ref type="bibr" target="#b29">[30]</ref> for part position estimation. The (m, n) is circular shift with the maximal value of the response map of each part, which exploits the motion information of each part. ers in terms of accuracy in the VOT challenge <ref type="bibr" target="#b19">[20]</ref>. However, these two trackers fail to track the target object when partial occlusion happens.</p><p>To deal with the above issues, <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21]</ref> have made successful attempts to apply part-based tracking strategy to correlation filter tracking. In general, part-based tracking strategy models object appearance based on multiple parts of target. Obviously, when target is partially occluded, remaining visible parts can still provide reliable cues for tracking. Therefore, this strategy can be helpful to gain robustness against partial occlusions. In <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21]</ref>, object parts are independently tracked by the KCF tracker <ref type="bibr" target="#b12">[13]</ref>, and these trackers fail to exploit spatial constraints among object parts. As a result, as shown in <ref type="figure">Figure 2</ref>, object parts move independently and have different directions, which eventually leads the tracker to drift away. In fact, there is little change between two consecutive frames as the time interval is small <ref type="bibr" target="#b21">[22]</ref>, and most parts should have similar directions to preserve object structure. Moreover, in <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21]</ref>, experimental results have shown that the relationships among parts are effective.Therefore introducing structural constraints among parts in correlation filter is supposed to be advantageous. Motivated by the above observations, we propose a novel Structural Correlation Filter (SCF) for object appearance modeling, which has the following advantages: <ref type="bibr" target="#b0">(1)</ref> The proposed SCF appearance model has the advantages of both part based trackers and correlation filter trackers, such as, less sensitive to partial occlusion, computational efficiency and robustness. (2) The proposed SCF appearance model exploits spatial layout structure among object parts, which is ignored by all the previous correlation filter trackers <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b18">19]</ref> to the best of our knowledge. Due to this advantage, our proposed model not only exploits the intrinsic relationship among object parts to learn their correlation filters jointly, but also preserves the spatial layout structure among object parts. <ref type="bibr" target="#b2">(3)</ref> The proposed SCF appearance model is robust for outlier parts, which have different motion from most of other parts.</p><p>As shown in <ref type="figure">Figure 2</ref>, the jointly learned correlation filters of all parts not only make most parts have similar motion, but also tolerate outlier parts that have different motion.</p><p>Based on the above structural appearance model, we propose a robust and efficient SCF tracking approach. In the proposed tracker, an object is made up of a set of parts, each with an associated correlation filter. We learn the parameters of correlation filters for all parts jointly. The learned correlation filters not only distinguish object part from background, but also exploit spatial constraints among parts to preserve object structure. During tracking, the correlation filter of each part has a response map, which can help predict the part state (position) by searching for the location of the maximal value of the map. Then, the target object location is estimated as a weighted average of translations of all parts. Here, the weight of each part is the maximum value of its response map. In the experimental results, we show that it is practical and robust to exploit the intrinsic relationship among parts to learn their correlation filters jointly by preserving object structure, and it helps locate target object more accurately and is less sensitive to partial occlusion. As a result, the incorporation of structural constraints leads to substantial performance improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Visual tracking has been extensively studied <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28]</ref>. In this section, we introduce the methods closely related to this work: correlation filter trackers, part based trackers, and the KCF tracker <ref type="bibr" target="#b12">[13]</ref> in detail.</p><p>Correlation Filter Trackers: Correlation filters have attracted considerable attention recently to visual tracking due to its computational efficiency and robustness. Bolme et al. encode target appearance by learning an adaptive correlation filter <ref type="bibr" target="#b4">[5]</ref>. Heriques et al. exploit the circulant structure of adjacent image patches <ref type="bibr" target="#b11">[12]</ref>, and is further improved using HOG features <ref type="bibr" target="#b12">[13]</ref>. Danelljan et al. exploit adaptive color attributes in <ref type="bibr" target="#b7">[8]</ref>, and use adaptive multi-scale correlation filters to handle scale variations in <ref type="bibr" target="#b6">[7]</ref>. Zhang et al. <ref type="bibr" target="#b32">[33]</ref> incorporate context information into filter learning. Hong et al. <ref type="bibr" target="#b13">[14]</ref> propose a biology-inspired framework with shortterm processing and long-term processing. In <ref type="bibr" target="#b21">[22]</ref>, Ma et al. introduce online random fern classifier for long-term tracking. In <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b18">19]</ref>, part based strategy is used in correlation filter. Different from the existing correlation filter trackers, we propose a novel structural correlation filter to preserve object structure for object appearance modeling.</p><p>Part based Trackers: Instead of learning a holistic appearance model, various part-based tracking algorithms have been proposed to gain robustness against partial occlusions <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b38">39]</ref>. The Frag tracker <ref type="bibr" target="#b0">[1]</ref> models object appearance with histograms of local parts. Kwon et al. <ref type="bibr" target="#b17">[18]</ref> represent a non-rigid target object by a number of local patches with color histograms. Ce-hovin et al. <ref type="bibr" target="#b28">[29]</ref> uses the global and local appearance based on object parts. Godec et al. <ref type="bibr" target="#b9">[10]</ref> extend the Hough forest for online object tracking. Different from the existing part based trackers, we introduce part-based tracking strategy in correlation filter to model the relationships among parts and preserve object structure. Due to correlation filter, motion information of parts can be effectively exploited.</p><p>The KCF Tracker: The KCF tracker <ref type="bibr" target="#b12">[13]</ref> achieves very impressive results on Tracking Benchmark <ref type="bibr" target="#b29">[30]</ref>. The key idea is that many negative samples are employed to enhance the discriminative ability of the track-by-detector scheme while exploring the structure of circulant matrix for high efficiency. In the following, we briefly introduce the main idea. Readers may refer to <ref type="bibr" target="#b12">[13]</ref> for more details.</p><p>The KCF tracker models object appearance using a correlation filter w trained on an image patch x of M × N pixels, where all the circular shifts of x m,n , (m, n) ∈ {0, 1, . . . , M − 1} × {0, 1, . . . , N − 1}, are generated as training samples with Gaussian function label y m,n . The goal is to find the optimal weights w in <ref type="formula">(1)</ref>.</p><formula xml:id="formula_0">w = arg min w m,n | φ(x m,n ), w − y m,n | 2 + λ w 2 . (1)</formula><p>Here, φ denotes the mapping to a kernel space and λ is a regularization parameter. Using the fast Fourier transformation (FFT) to compute the correlation, the objective function <ref type="formula">(1)</ref> is minimized as w = m,n α(m, n)φ(x m,n ), and the coefficient α is calculated as in <ref type="formula" target="#formula_1">(2)</ref>.</p><formula xml:id="formula_1">α = F −1 ( F(y) F( φ(x), φ(x) ) + λ )<label>(2)</label></formula><p>Where y = {y(m, n)}, F and F −1 denote the Fourier transform and its inverse.Given the learned α and target appearance modelx, the tracking task is carried out on an image patch z in the new frame with the search window size M ×N by computing the response map as in <ref type="formula" target="#formula_2">(3)</ref>. Here, ⊙ is the Hadamard product. Then, the target position is detected by searching for the location of the maximal value ofȳ.</p><formula xml:id="formula_2">y = F −1 (F(α) ⊙ F( φ(z), φ(x) )).<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Structural Correlation Filter Tracking</head><p>In this section, we give a detailed description of our structural correlation filter based tracking method that makes use of the structural correlation filter model to learn correlation filters of all parts jointly to preserve target object structure. Next, we will sequentially introduce the structural correlation filter and SCF tracker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Structural Correlation Filter Model</head><p>The objective function of the KCF tracker (1) can equivalently be expressed in its dual form <ref type="bibr" target="#b3">(4)</ref>.</p><formula xml:id="formula_3">min α 1 4λ α ⊤ XX ⊤ α + 1 4 α ⊤ α − α ⊤ y<label>(4)</label></formula><p>Here, the vector α contains M × N dual optimization variables α m,n , and X = [x 0,0 , . . . , x m,n , . . .</p><formula xml:id="formula_4">x M −1,N −1 ] ⊤ .</formula><p>The two solutions are related by w = X ⊤ α 2λ . The KCF tracker (4) is to learn a holistic appearance model, which is not robust for partial occlusion. To deal with this issue, we apply part-based tracking strategy to the correlation filter. Given a target object, its K parts with M × N pixels can be sampled. Then, our goal is to learn K optimal weights w k or α k via <ref type="bibr" target="#b4">(5)</ref>.</p><formula xml:id="formula_5">min {u k } K k=1 K k=1 1 4λ u ⊤ k G k u k + 1 4 u ⊤ k u k − u ⊤ k y<label>(5)</label></formula><p>Here, for clarity, we adopt u k to denote the dual optimization variables, and G k = X k X k ⊤ . The X k is all training samples of the k-th part, where k = 1, . . . , K.</p><p>Note that, the basic idea of (4) is to select discriminative training samples x m,n via α m,n to distinguish the target object from the background. Here, the training samples x m,n , (m, n) ∈ {0, 1, . . . , M − 1} × {0, 1, . . . , N − 1} are the all possible circular shifts, which represent the possible motion of the target object. Therefore, selecting training samples x m,n via α m,n can predict the motion or state of target object. Ideally, the individual parts should stay close to each other to cover the entire target. As shown in <ref type="figure">Figure 2</ref>, most parts of target object move in the same way between two consecutive frames. Therefore, they should select the similar circular shifts to make them have similar motion. Considering that some parts may have different motions, and they may select different discriminative training samples. Based on the above observation, it is clear that most parts have similar u k to make them move in the same direction to preserve target object structure, and some parts may have separate motion. Therefore, in <ref type="formula" target="#formula_5">(5)</ref>, we assume all u k can be written as u k = u 0 + v k , where the vectors v k are small when the selected circular shifts of all parts are similar to each other. That is to say, u 0 carries the information of the commonality, and v p carries the information of the specialty (outlier) and should be sparse.</p><formula xml:id="formula_6">min {u k } K k=1 K k=1 1 4λ u ⊤ k G k u k + 1 4 u k ⊤u k − u ⊤ k y + γ v k 1 s.t. u k = v k + u 0 , k = 1, . . . , K<label>(6)</label></formula><p>Motivated by the above points, the part based correlation filters (5) can be reformulated as structural correlation filter model <ref type="bibr" target="#b5">(6)</ref>, which can learn the correlation filters of all parts jointly, and distinguish the parts from the background. Moreover, the SCF model is less insensitive to partial occlusion, but has computational efficiency and robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The Proposed SCF Tracker</head><p>Based on the structural correlation filter model, we propose a novel SCF tracker with several important modules, including model updating, target state estimation, kernel selection, and feature representation.</p><p>Model Updating: In tracking, object appearance will change because of a number of factors such as illumination and pose changes. Hence it is necessary to update part classifiers over time. In the proposed tracker, the model consists of the learned target appearancex k and the transformed classifier coefficients u k . Moreover, different parts of targets may suffer from different appearance changes, illumination variation or partial occlusion. If we simply combine all parts with the same weight, their correlations filters may be unfairly emphasized. Therefore, for each part, we have its weight π k to emphasize its importance. For each part, its model parameters at time t are updated as in <ref type="formula" target="#formula_7">(7)</ref>.</p><formula xml:id="formula_7">F(u k ) t = (1 − η)F(u k ) t−1 + ηF(u k ) F(x k ) t = (1 − η)F(x k ) t−1 + ηF(x k ) π t k = (1 − η)π t k + ηπ k<label>(7)</label></formula><p>Where η is a learning rate parameter. The u k is computed by simple linear interpolation, and thex k is updated by taking the current appearance into account. The π k is the maximal value of the response map of the k-th part. Target State Estimation: The target state estimation includes position prediction and scale decision. (1) Position Estimation. Given the learned modelx k , u k of part k, its new position is detected by searching for the location of the maximal value ofȳ k as in <ref type="bibr" target="#b2">(3)</ref>. Then, we can obtain its translation s k . For simplicity, the translation of the target object is calculated as s = k π k s k , which shows more robust tracking parts with larger detection scores have higher effect on the target position estimation. (2) Scale Handling. To handle scale variation, windows with different sizes are sampled around the target, and are correlated with the learned filter. Subsequently, the window with the highest correlation score can be predicted as the new state. This searching strategy is also used in the DSST <ref type="bibr" target="#b6">[7]</ref>.</p><p>Kernel Selection: Inspired by the effectiveness of the Gaussian kernel in the existing correlation filter trackers, the G k is computed with the same kernel κ(x 1 ,</p><formula xml:id="formula_8">x 2 ) = exp(− |x1−x2| 2 δ 2 ), which is defined as κ(x 1 , x 2 ) = φ(x 1 ), φ(x 2 )</formula><p>with a mapping φ. We compute the full kernel correlation for each part in <ref type="formula" target="#formula_5">(5)</ref> and <ref type="formula" target="#formula_6">(6)</ref> efficiently in the Fourier domain. The details are discussed in Section 4.</p><p>Feature Representation: Similar to <ref type="bibr" target="#b12">[13]</ref>, we use HOG features with 31 bins. However, our tracker is quite generic and any dense feature representation with arbitrary dimensions can be incorporated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Optimization</head><p>In this section, we present how to solve the optimization problem (6) using the fast first order Alternating Direction Method of Multipliers (ADMM) <ref type="bibr" target="#b5">[6]</ref> approach. By introducing augmented Lagrange multipliers to incorporate the equality constraints into the objective function, we obtain the Lagrangian function in (8) that can be optimized through a sequence of simple closed form update operations in <ref type="bibr" target="#b8">(9)</ref> where θ k and β k &gt; 0 are Lagrange multipliers and penalty parameters, respectively.</p><formula xml:id="formula_9">L({u k , v k , θ k , β k } K k=1 , u 0 ) = K k=1 1 4λ u ⊤ k G k u k + 1 4 u ⊤ k u k − u ⊤ k y + γ v k 1 + θ ⊤ k (u k − v k − u 0 ) + β k 2 u k − v k − u 0 2 (8) ⇒ min {u k ,v k ,θ k ,β k } K k=1 ,u0 L({u k , v k , θ k , β k } K k=1 , u 0 ) (9)</formula><p>The ADMM method iteratively updates one of the variables u 0 , {v k } K k=1 , {u k } K k=1 , and the Lagrange multiplier {θ k } K k=1 by minimizing <ref type="formula">(9)</ref>, while keeping the others fixed to their most recent values. By updating these variables iteratively, the convergence can be guaranteed <ref type="bibr" target="#b5">[6]</ref>. Consequently, we have four update steps corresponding to all the variables with closed form solutions as follows.</p><p>Step 1: Update u 0 (with others fixed): The u 0 is updated by solving the optimization problem (10) with the closed form solution <ref type="bibr" target="#b10">(11)</ref>.</p><formula xml:id="formula_10">u 0 = arg min u0 K k=1 −θ T k u 0 + β k 2 u k − v k − u 0 2 (10) ⇒ u 0 = 1 K K k=1 u k − v k + 1 β k θ k<label>(11)</label></formula><p>Step 2: Update v k (with others fixed): The minimization problem (8) with respect to {v k } K k=1 is decomposed into K independent subproblems. The k-th subproblem to update v k can be equivalently rewritten as <ref type="bibr" target="#b11">(12)</ref>.</p><formula xml:id="formula_11">v k = arg min v k γ v k 1 + θ ⊤ k (u k − v k − u 0 ) + β k 2 u k − v k − u 0 2<label>(12)</label></formula><p>The solution of (12) can be obtained by rearranging it into the optimization problem <ref type="bibr" target="#b12">(13)</ref> with the closed form solution <ref type="bibr" target="#b13">(14)</ref>.</p><formula xml:id="formula_12">v k = arg min v k γ β k v k 1 + 1 2 v k − (u k + 1 β k θ k − u 0 ) 2 (13) ⇒ v k = S γ β k (u k + 1 β k θ k − u 0 )<label>(14)</label></formula><p>Here, S λ (x i ) = sign(x i ) max(0, |x i | − λ) is the softthresholding operator for a vector x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1:</head><p>The optimization for (9) via ADMM. Input : Training Data: G k and y. Initialization of λ, γ, u k = 0, u 0 = 0, v k = 0, θ = 0, and β &gt; 0. Output: Correlation filters u k , k = 1, . . . , K. 1 while not converged do <ref type="bibr" target="#b1">2</ref> Update u 0 via (11); 3 for k = 1 to K do <ref type="bibr" target="#b3">4</ref> Update v k via <ref type="formula" target="#formula_3">(14)</ref>; <ref type="bibr" target="#b4">5</ref> Update u k as in <ref type="formula" target="#formula_6">(16)</ref>; <ref type="bibr" target="#b5">6</ref> Update θ k as in <ref type="formula" target="#formula_7">(17)</ref>; 7 end 8 end</p><p>Step 3: Update u k (with others fixed): The minimization problem (8) with respect to {u k } K k=1 is decomposed into K independent subproblems. The k-th subproblem to update u k can be equivalently rewritten as <ref type="bibr" target="#b14">(15)</ref>.</p><formula xml:id="formula_13">u k = arg min u k 1 4λ u ⊤ k G k u k + 1 4 u ⊤ k u k − u ⊤ k y + θ ⊤ k (u k − v k − u 0 ) + β k 2 u k − v k − u 0 2<label>(15)</label></formula><p>Then, for each u k , it is updated by solving the optimization problem <ref type="bibr" target="#b14">(15)</ref> with the closed form solution <ref type="bibr" target="#b15">(16)</ref>.</p><formula xml:id="formula_14">u k = ( 1 2λ G k + 1 2 I + β k I) −1 (y − θ k + β k v k + β k u 0 ) (16) Here, I is a M N × M N identity matrix.</formula><p>Step 4: Update Multiplier θ k : The Lagrange multipliers are updated as in <ref type="formula" target="#formula_7">(17)</ref>, where ρ &gt; 1,</p><formula xml:id="formula_15">θ k = θ k + β k (u k − v k − u 0 ); β k = ρβ k<label>(17)</label></formula><p>The ADMM algorithm that solves (9) is shown in Algorithm 1, where convergence is reached when the change in the objective function or solution u k is below a pre-defined threshold (e.g., τ = 10 −3 in this work). In addition, we set β 1 = · · · β k = · · · = β K = β. Here, we note that other penalty update rules and stopping criteria can be used for this optimization problem as discussed in <ref type="bibr" target="#b5">[6]</ref>. As shown in Algorithm 1, the major computation cost is the fifth step to update u k with matrix inverse and multiplication in spatial domain. However, it can be calculated very efficiently in the Fourer domain by considering the circulant structure property of X k . Assume x is the base sample of X k , the u k can be updated with only the base sample as <ref type="bibr" target="#b17">(18)</ref>.</p><formula xml:id="formula_16">u k =ŷ −θ k + β kvk + β kû0 1 2λx * ⊙x + 1 2 + β k<label>(18)</label></formula><p>Here, the fraction denotes element-wise division, x * is the complex-conjugate of x,x denotes the Discrete Fourier Transform (DFT) of the generating vectorx = F(x), and ⊙ denotes the element-wise product. Finally, the u k can be obtained via u k = F −1 (û k ). Moreover, to make the SCF tracker faster, the Algorithm 1 can be implemented in matrix form without the for loop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Results</head><p>We first introduce experimental setup including parameters, datasets, and evaluation metrics. Then, we provide both quantitative and qualitative comparisons with state-ofthe-art trackers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Setup</head><p>Parameters: The γ in (6) is set to 0.01. All the other parameters are set to the same values as the KCF tracker. To generate the parts, we use the spatial layout as shown in <ref type="figure" target="#fig_0">Figure 3</ref> to sample 3 parts based on the target's height-width ratio. Note that, any other part sampling methods can also be adopted. We use the same parameter values and initialization for all the sequences. All the parameter settings are available in the source code to be released for accessible reproducible research. Datasets and Evaluation Metrics: We evaluate the proposed method on a large benchmark dataset <ref type="bibr" target="#b29">[30]</ref> that contains 50 videos with comparisons to state-of-the-art methods. The performance of our approach is quantitatively validated by three metrics used in <ref type="bibr" target="#b29">[30]</ref> including distance precision (DP), centre location error (CLE) and overlap precision (OP). The DP is computed as the relative number of frames in the sequence where the centre location error is smaller than a certain threshold. As in <ref type="bibr" target="#b29">[30]</ref>, the DP values at a threshold of 20 pixels are reported. The CLE is computed as the average Euclidean distance between the groundtruth and the estimated centre location of the target. The OP is defined as the percentage of frames where the bounding box overlap surpasses a threshold. We report the results at a threshold of 0.5, which correspond to the PASCAL evaluation criteria. We provide results using the average DP, CLE and OP over all 50 sequences. In addition, we plot the <ref type="table">Table 1</ref>. Comparison with state-of-the-art trackers on the 50 benchmark sequences. Our approach performs favorably against existing methods in overlap precision (OP) (%) at an overlap threshold 0.5, distance precision (DP) (%) at a threshold of 20 pixels and centre location error (CLE) (in pixels). The top rank 3 values are highlighted by bold and different colors: red, blue, and green, respectively.  precision and success plots as in <ref type="bibr" target="#b29">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Comparison with State-of-the-Art</head><p>We evaluate the proposed tracker on the benchmark with comparisons to 34 trackers including 29 trackers in <ref type="bibr" target="#b29">[30]</ref> including SCM <ref type="bibr" target="#b40">[41]</ref>, MTT <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>, and TLD <ref type="bibr" target="#b15">[16]</ref>, and other 5 recently published state-of-the-art trackers with their shared source code: MEEM <ref type="bibr" target="#b31">[32]</ref>, TGPR <ref type="bibr" target="#b8">[9]</ref>, RPT <ref type="bibr" target="#b18">[19]</ref>, MUSTer <ref type="bibr" target="#b13">[14]</ref>, DSST <ref type="bibr" target="#b6">[7]</ref>. The details of the 29 trackers in the benchmark can be found in <ref type="bibr" target="#b29">[30]</ref>. We present the results using average OP, DP and CLE over all sequences in <ref type="table">Table 1</ref>, and report the results in one-pass evaluation (OPE) using the distance precision and overlap success rate in <ref type="figure" target="#fig_1">Figure 4</ref> and attribute-based evaluation in <ref type="figure" target="#fig_3">Figure 5</ref>. <ref type="table">Table 1</ref> shows that our algorithm performs favorably against state-of-the-art methods. Among the trackers in the literature, the MUSTer method achieves the best results with an average OP of 78.4%, DP of 86.5%, and CLE of 17.3 pixels. Our algorithm performs well with OP of 79.7%, DP of 86.6%, and CLE of 22.5 pixels. These results show the proposed SCF tracker achieves slightly better tracking performance than the MUSTer. Note that, the proposed SCF tracker can be improved more by considering other tracking strategy, such as, long-term strategy, and keypoint matching strategy in the MUSTer tracker <ref type="bibr" target="#b13">[14]</ref>. Overall, our SCF tracker achieves significantly improvement than other existing trackers. The details are as follows. Compared with the correlation filter trackers, the proposed SCF method performs well against the KCF (by 17.4%) and DSST (by 13%) methods in terms of average OP, and achieves performance gain of 12.6% and 12.9% in term of average DP. In term of average CLE, the proposed SCF method has about 13.0 pixels and 18.8 pixels improvement. <ref type="figure" target="#fig_1">Figure 4</ref> contains the precision and success plots illustrating the mean distance and overlap precision over all the 50 sequences. In both precision and success plots, our approach shows comparable results as the MUSTer and significantly outperforms the best existing correlation filter methods (DSST and KCF). Note that, when overlap threshold is from 0.2 to 0.6, the proposed SCF method achieves slightly better than the MUSTer in success plots of OPE. In summary, the precision plot demonstrates that our approach performs well against the existing methods (KCF, MEEM, TGPR, SCM, Struck).In <ref type="figure" target="#fig_3">Figure 5</ref>, We analyze the tracking performance based on attributes of image sequences <ref type="bibr" target="#b29">[30]</ref>, which annotates 11 attributes to describe the different challenges in the tracking problem, e.g., occlusions or out-ofview. These attributes are useful for analyzing the performance of trackers in different aspects. Due to space constraints, we present the success and precision plots of OPE for 4 attributes in <ref type="figure" target="#fig_3">Figure 5</ref> and more results can be found in the supplementary material. For presentation clarity, we present the top 10 performing methods in each plot. We note that the proposed tracking method performs well in dealing with challenging factors including deformation, occlusion, out-of-plane rotation, and out of view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Qualitative Comparison</head><p>We compare our algorithm with the top 9 existing trackers in our evaluation (MUSTer <ref type="bibr" target="#b13">[14]</ref>, RPT <ref type="bibr" target="#b18">[19]</ref>, MEEM <ref type="bibr" target="#b31">[32]</ref>, DSST <ref type="bibr" target="#b6">[7]</ref>, KCF <ref type="bibr" target="#b12">[13]</ref>, TGPR <ref type="bibr" target="#b8">[9]</ref>, SCM <ref type="bibr" target="#b40">[41]</ref>, Struck <ref type="bibr" target="#b10">[11]</ref>, and TLD <ref type="bibr" target="#b15">[16]</ref>) on 10 challenging sequences in <ref type="figure">Figure 6</ref>. Overall, these trackers perform well, but the existing trackers have the following issues: The MUSTer drifts when fast motion happens (couple). The RPT does not perform well in scale variation (singer2, walking2, lemming, and tiger1), fast motion (couple), and partial occlusion (jogging-2). The MEEM cannot handle partial occlusion well (suv, walking2, and jogging-2). The KCF, DSST, and Struck methods drift when target objects undergo heavy occlusion (jogging-2) and fast motion (couple). The SCM and TLD methods do not follow targets undergoing significant deformation and fast motion (tiger1 and lemming) well. The TGPR does not perform well in fast motion (couple) and partial occlusion (suv). Overall, the proposed SCF tracker performs well in tracking objects on these challenging sequences. In addition, we compare the center location error frame-byframe on the 10 sequences in <ref type="figure" target="#fig_4">Figure 7</ref>, which shows that our method performs well against existing trackers. More results can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we propose a novel structural correlation filter namely SCF to model target appearance for robust visual tracking. The proposed SCF model fuses part-based tracking strategy into correlation filter tracker, and exploits circular shifts of all parts for their motion modeling to preserve target object structure. As a result, it not only has the advantages of existing correlation filter trackers, such as, computational efficiency and robustness, but also can be less sensitive to partial occlusion, preserve object structure, and enable the capture of outlier parts to have different motion. Both qualitative and quantitative evaluations on challenging benchmark image sequences demonstrate that the proposed SCF tracking algorithm performs favorably against several state-of-the-art methods. In the future, we will evaluate the proposed SCF model on more datasets and make use of co-learning algorithm <ref type="bibr" target="#b39">[40]</ref> to obtain more improvement. <ref type="figure">Figure 6</ref>. Tracking results of the top 10 trackers (denoted in different colors and lines) in our evaluation on 10 challenging sequences (from left to right and top to down are shaking, singer2, jumping, suv, lemming, skating1, tiger1, couple, walking2, and jogging-2, respectively). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>The generated 3 parts based on the target's ratio.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>Precision and success plots over all the 50 sequences using one-pass evaluation (OPE). The legend contains the areaunder-the-curve score for each tracker. The proposed SCF method performs favorably against the state-of-the-art trackers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( 1 )</head><label>1</label><figDesc>MEEM and RPT are top 2 existing methods with average OP of 69.8% and 70.7% respectively. Our approach achieves better tracking performance by 9.8% and 9%. (2) The proposed SCF method performs well against the MUSTer (by 0.1%), MEEM (by 3.6%), and RPT (by 4.7%) methods in terms of average DP. (3) Among the other existing trackers, MEEM provides the best results with an average CLE of 21.4 pixels. Our approach achieves comparable results with an average CLE of 22.5 pixels. (4)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>The precision and success plots of OPE over four tracking challenges of out-of-plane rotation, deformation, out-of-view, and occlusion. The legend contains the AUC score for each tracker. Our SCF method performs favorably against the state-of-the-art trackers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 .</head><label>7</label><figDesc>Comparison of center location errors (in pixels) on 10 challenging sequences. Generally, our method achieves better.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust fragmentsbased tracking using the integral histogram</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shimshoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="798" to="805" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ensemble tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="494" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visual tracking with online multiple instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Babenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Real time robust l1 tracker using accelerated proximal gradient approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Visual object tracking using adaptive correlation filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Bolme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Beveridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Draper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">M</forename><surname>Lui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2544" to="2550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peleato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eckstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Accurate scale estimation for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptive color attributes for real-time visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van De Weijer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1090" to="1097" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Transfer learning based visual tracking with gaussian process regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hough-based tracking of non-rigid objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Godec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Struck: Structured output tracking with kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Exploiting the circulant structure of tracking-by-detection with kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Highspeed tracking with kernelized correlation filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="583" to="596" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-store tracker (muster): A cognitive psychology inspired approach to object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Prokhorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Visual tracking via adaptive structural local sparse appearance model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tracking-learningdetection. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Visual tracking decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Highly non-rigid object tracking via patch-based dynamic appearance modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2427" to="2441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Reliable patch trackers: Robust visual tracking by exploiting reliable patches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The visual object tracking vot2014 challenge results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Real-time part-based visual tracking via adaptive correlation filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4902" to="4912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Long-term correlation tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5388" to="5396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Locally orderless tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bar-Hillel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Levi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1940" to="1947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Finding the best from the second bests -inhibiting subjective bias in evaluation of visual tracking algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R.-S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<title level="m">Incremental Learning for Robust Visual Tracking. IJCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="125" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adaptive appearance modeling for video tracking: Survey and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Salti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Stefano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4334" to="4348" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Distribution fields for tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sevilla-Lara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1910" to="1917" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Visual tracking: an experimental survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smeulder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Calderara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Deghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1442" to="1468" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Robust visual tracking using an adaptive coupled-layer visual model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Čehovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PA-MI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Online object tracking: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Part-based visual tracking with online latent structural learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">MEEM: Robust tracking via multiple experts using entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fast visual tracking via dense spatio-temporal context learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">8693</biblScope>
			<biblScope unit="page" from="127" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Low-rank sparse learning for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Robust visual tracking via multi-task sparse learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Robust visual tracking via structured multi-task sparse learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="367" to="383" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Partial occlusion handling for visual tracking via robust part matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Robust Visual Tracking via Consistent Low-Rank Sparse Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="190" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Structural sparse tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Cross-domain multi-event tracking via co-pmht</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Multimedia Comput. Commun. Appl</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Robust object tracking via sparsity-based collaborative model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1838" to="1845" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
