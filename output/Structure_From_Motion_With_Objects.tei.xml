<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structure from Motion with Objects</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Crocco</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Analysis and Computer Vision Department (PAVIS) Visual Geometry and Modelling Lab (VGM) Istituto Italiano di Tecnologia Via Morego 30</orgName>
								<address>
									<postCode>16163</postCode>
									<settlement>Genova</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cosimo</forename><surname>Rubino</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Analysis and Computer Vision Department (PAVIS) Visual Geometry and Modelling Lab (VGM) Istituto Italiano di Tecnologia Via Morego 30</orgName>
								<address>
									<postCode>16163</postCode>
									<settlement>Genova</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessio</forename><forename type="middle">Del</forename><surname>Bue</surname></persName>
							<email>alessio.delbue@iit.it</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Analysis and Computer Vision Department (PAVIS) Visual Geometry and Modelling Lab (VGM) Istituto Italiano di Tecnologia Via Morego 30</orgName>
								<address>
									<postCode>16163</postCode>
									<settlement>Genova</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Structure from Motion with Objects</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper shows for the first time that is possible to reconstruct the position of rigid objects and to jointly recover affine camera calibration solely from a set of object detections in a video sequence. In practice, this work can be considered as the extension of Tomasi and Kanade factorization method using objects. Instead of using points to form a rank constrained measurement matrix, we can form a matrix with similar rank properties using 2D object detection proposals. In detail, we first fit an ellipse onto the image plane at each bounding box as given by the object detector. The collection of all the ellipses in the dual space is used to create a measurement matrix that gives a specific rank constraint. This matrix can be factorised and metrically upgraded in order to provide the affine camera matrices and the 3D position of the objects as an ellipsoid. Moreover, we recover the full 3D quadric thus giving additional information about object occupancy and 3D pose. Finally, we also show that 2D points measurements can be seamlessly included in the framework to reduce the number of objects required. This last aspect unifies the classical point-based Tomasi and Kanade approach with objects in a unique framework. Experiments with synthetic and real data show the feasibility of our approach for the affine camera case.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Factorization methods for Structure from Motion (SfM) deliver highly efficient solutions for the simultaneous calibration and 3D reconstruction using image point trajectories/matches. The seminal paper of Tomasi and Kanade <ref type="bibr" target="#b18">[19]</ref> was based on the intuition that if we form a matrix containing matched 2D image points, such resulting matrix is rank constrained. This property can be used to obtain an initial affine solution with Singular Value Decomposition (SVD) for the camera matrices and 3D points. Such solution can be then linearly upgraded to metric by imposing orthogonality constraints on the camera matrices, giving a closed-form solution to the SfM problem. Even if modern 3D reconstruction pipelines from images have reached impressive results through non-linear optimization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b17">18]</ref>, factorization methods still entails a theoretical appealing solution to the SfM problem. Such approaches have been further updated to more complex camera models <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b20">21]</ref>, to deal with the case of missing data <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17]</ref> and multiple moving objects <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6]</ref>, or to model articulated <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b19">20]</ref> and deformable <ref type="bibr" target="#b4">[5]</ref>) objects, demonstrating that the research on this type of methods is still very active and promising. As a peculiar aspect, up to now, every factorization method for 3D reconstruction mostly deals with points, while very few exceptions exist in the literature using different geometrical entities such as lines <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b13">14]</ref> and conic features <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b15">16]</ref>. The limit of these methods is that they can reconstruct geometric primitives starting from projected outlines only, but they cannot deal with image object detections and their gross inaccuracies over size and position.</p><p>This work takes a different direction from previous SfM methods by showing that it is possible to solve simultaneously for affine camera calibration and 3D structure in a closed-form using multi-view relations given only by the location of a set of objects in an image sequence (see <ref type="figure">Fig 1 for</ref> a graphical representation). Instead of considering points as an input of our method, here we use as measurements the output of an object detector, i.e. a set of bounding boxes. We show that, by fitting the bounding boxes with 2D ellipsoids, it is possible to form a measurement matrix that contains the matrices of each 2D conics. If the collection of conics is expressed in the dual space, the resulting matrix C will show a specific rank constraint since the matrix of the dual conics can be decomposed in terms of two factors as C = G V where G contains the parameters of the affine camera and V the 3D quadrics whose reprojection gives the 2D <ref type="figure">Figure 1</ref>. Given multiple views with a set of objects detected in every image, the proposed factorization approach can simultaneously recover the affine camera calibration and the 3D quadrics describing the location and pose of the objects in the scene.</p><p>conics stored in C. Then, given this initial affine solution of the system, it is possible to find a metric upgrade that solves for both the camera matrices and the 3D quadrics. In practice this provides a self-calibration of the camera and 3D location of the objects with just a set of object detections. Moreover it is straightforward to show that image points can still be included in the formulation as degenerate conics in dual space thus obtaining a joint objects/points factorisation. Furthermore, since the framework recovers a 3D quadric related to an object, this information can be used to infer the coarse pose and size of the object shape in 3D. The rest of the paper is structured as follows. Section 2 defines the problem and the related mathematical formalisation. Section 3 presents the factorization problem in the dual space while Section 4 describes how to perform the metric upgrade. Experiments on real and synthetic data are discussed in Section 5 and then followed by concluding remarks in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">From bounding boxes to conics in dual space</head><p>Let us consider a set of image frames f = 1 . . . F representing a 3D scene under different viewpoints. A set of i = 1 . . . N rigid objects is placed in arbitrary positions and each object is detected in each of the F images. Each object i in each image frame f is identified by a 2D bounding box given by a generic object detector. In order to ease the mathematical formalization of the problem, we move from a bounding box representation of an object to an ellipsoid one. This is done by associating at each bounding box an ellipse fitting D f i that inscribes the bounding box. The aim of our problem is to find the 3D ellipsoids E i whose projections onto the image planes, associated to each frame f = 1 . . . F , best fit the 2D ellipses D f i . This will solve for both the 3D localisation and occupancy of each object starting from image detections in the different views. In the following, we represent each ellipse using the homogeneous quadratic form of a conic equation:</p><formula xml:id="formula_0">u ⊤ D f i u = 0,<label>(1)</label></formula><p>where u ∈ R 3 is the homogeneous vector of a generic 2D point belonging to the conic defined by the symmetric matrix D f i ∈ R 3×3 . The conic has five degrees of freedom, given by the six elements of the lower triangular part of the symmetric matrix D f i except one for the scale, since Eq. (1) is homogeneous in u. Similarly to the ellipses, we represent the ellipsoids in the 3D space with the homogeneous quadratic form of a quadric equation:</p><formula xml:id="formula_1">x ⊤ E i x = 0,<label>(2)</label></formula><p>where x ∈ R 4 represents an homogeneous 3D point belonging to the quadric defined by the symmetric matrix E i ∈ R 4×4 . The quadric has nine degrees of freedom, given by the ten elements of the symmetric matrix E i up to one for the overall scale.</p><p>Since the relationship between D f i and E i is not straightforward in the primal space, i.e. the Euclidean space of 3D points (2D points in the images), it is convenient to reformulate it in dual space, i.e. the space of the planes (lines in the images) <ref type="bibr" target="#b6">[7]</ref>. In particular, the conics in 2D can be represented by the envelope of all the lines tangent to the conic curve, while the quadrics in 3D can be represented by the envelope of all the planes tangent to the quadric surface.</p><p>Hence, the dual quadric is defined by the matrix Q i = adj(E i ), where adj is the adjoint operator, and the dual conic is defined by C f i = adj(D f i ) <ref type="bibr" target="#b8">[9]</ref>.</p><p>Each quadric Q i , when projected onto the image plane, gives a conic denoted with C f i ∈ R 3×3 . The relationship between Q i and C f i is defined by the orthographic projection matrix P f ∈ R 3×4 as:</p><formula xml:id="formula_2">P f = R f t f 0 ⊤ 3 1 =   p 11 p 12 p 13 p 14 p 21 p 22 p 23 p 24 0 0 0 1   (4) where R f ∈ R 2×3 is an orthographic camera matrix such that R f R ⊤ f = I 2×2 ,</formula><p>the vector t f is the camera translation and 0 m denotes a vector of m zeros.</p><p>The dual conic C f i and the dual quadric Q i are defined up to an overall scale factor that can be arbitrarily fixed by setting the elements (3,3) of C f i and (4,4) of Q i to −1. After such normalization, the relation between a dual quadric and its dual conic projections can be written as:</p><formula xml:id="formula_3">C f i = P f Q i P ⊤ f .<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Dual conic matrix factorization</head><p>In order to recover Q i in closed form from the set of dual conics {C f i } f =1...F , we have to re-arrange Eq. (5)</p><formula xml:id="formula_4">G f =               p11 2 2 p12p11 2 p13p11 2 p14p11 p12 2 2 p13p12 2 p14p12 p13 2 2 p13p14 p14 2</formula><p>p21p11 p21p12 + p22p11 p23p11 + p21p13 p24p11 + p21p14 p22p12 p22p13 + p23p12 p22p14 + p24p12 p23p13 p23p14 + p24p13 p24p14</p><formula xml:id="formula_5">0 0 0 p11 0 0 p12 0 p13 p14 p21 2 2 p22p21 2 p23p21 2 p24p21 p22 2 2 p23p22 2 p24p22 p23 2 2 p23p24 p24 2 0 0 0 p21 0 0 p22 0 p23 p24 0 0 0 0 0 0 0 0 0 1              <label>(3)</label></formula><p>into a linear system. Let us define v i = vech(Q i ) and c f i = vech(C f i ) as the vectorization of symmetric matrices Q i and C f i respectively 1 .</p><p>Then, let us arrange the products of the elements of P f and P ⊤ f in a unique matrix G f ∈ R 6×10 as follows <ref type="bibr" target="#b9">[10]</ref>:</p><formula xml:id="formula_6">G f = Y(P f ⊗ P f )W<label>(6)</label></formula><p>where ⊗ is the Kronecker product and matrices Y ∈ R 6×9 and W ∈ R 16×10 are two matrices such that vech(X) = Y vec(X) and vec(X) = W vech(X) respectively, where X is a symmetric matrix 2 . Given G f , we can rewrite Eq. <ref type="formula" target="#formula_3">(5)</ref> as:</p><formula xml:id="formula_7">c f i = G f v i ,<label>(7)</label></formula><p>The set of equations for each frame and object can be rewritten in a global matrix system by stacking all the equations for each frame and view such that:</p><formula xml:id="formula_8">C =    c 11 · · · c 1N . . . . . . . . . c F 1 · · · c F N    =    G 1 . . . G F    v 1 · · · v N<label>(8)</label></formula><p>with</p><formula xml:id="formula_9">G ⊤ = G ⊤ 1 · · · G ⊤ F ⊤ V = v 1 · · · v N ,<label>(9)</label></formula><p>with the dual conic matrix C being clearly rank constrained since being the product of two rank constrained matrices (i.e. rank(C) ≤ 10) given the dimensionality of the matrix factors G 6F ×10 and V 10×N . The explicit form of G f , function of the entries p mn of P f , as in Eq. 3, although complex, shows that the matrix is strongly structured. Now, starting solely from the image measurements, i.e. the dual conics stored in C, it is now possible to obtain an initial, affine, solution by performing SVD over C and truncating to the first 10 components thus obtaining:</p><formula xml:id="formula_10">C =GṼ.<label>(10)</label></formula><p>This factorization is not unique, since it is possible to define a 10 × 10 full-rank transformation matrix such that C = G V =GZ Z −1Ṽ . Finding the transformation matrix Z that enforces the correct matrix structure of G or V is the core problem of any factorization methods. <ref type="bibr" target="#b0">1</ref> The operator vech serializes the elements of the lower triangular part of a symmetric matrix, such that, given a symmetric matrix X ∈ R n×n , the vector x, defined as x = vech(X), is x ∈ R g with g = n(n+1) 2 . <ref type="bibr" target="#b1">2</ref> The operator vec serializes all the elements of a generic matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Upgrading to metric</head><p>Unlike the classical Tomasi and Kanade factorization method, where Z is a 3 × 3 symmetric matrix, the solution of the transformation matrix in our problem has a higher dimensionality. However in the literature of factorization methods there are several examples with increasing complexity: Photometric stereo <ref type="bibr" target="#b2">[3]</ref> solves for a 4 × 4 and 9 × 9 matrix while the non-rigid structure from motion problem <ref type="bibr" target="#b4">[5]</ref> has an increasing dimensionality given the complexity of the shape (i.e. 3K ×3K where K are the modes of deformation of the shape). Regardless this, our problem entails interesting differences that departs from the classical solution in structure from motion. In particular, we will show that there is a feasible solution without computing the full Z 10×10 . First of all, the orthographic camera matrix constraints, i.e. R f R ⊤ f = I 2×2 , have to be enforced for the solution of the matrix Z. However, the reshuffling of the components of R f in the matrix G f complicates further the problem. Yet, a key observation is that it is possible to re-arrange some of the entries of G f in a new matrix that expresses a rank-3 constraint. This sub-problem can be solved and leads to the computation of the ortographic camera matrices, as well as translation parameters of the quadrics. Given this solution, by re-substituting into the original problem and with a careful normalization, it is possible to compute the quadrics shape and size linearly. Notice that this approach requires a minimum number of just three objects, linked to the rank 3 constraint, instead of ten objects required by the rank 10 factorization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Solving for camera parameters and quadrics translation</head><p>A key step to reduce the complexity of the problem consists in enforcing a translation of each image frame according to the average of the ellipses coordinate centers. To do this, let us define t c f i ∈ R 2×1 as the center of ellipse i in frame f and t q i ∈ R 3×1 as the center of ellipsoid i in 3D space, and the related translation matrices T c f i and T q i as:</p><formula xml:id="formula_11">T c f i = I 2×2 t c f i 0 ⊤ 2 1 , T q i = I 3×3 t q i 0 ⊤ 3 1 . (12) Ḡ f =               p11 2 2 p12p11 2 p13p11 p12 2 2 p13p12 p13 2 0 0 0 0 p21p11 p21p12 + p22p11 p23p11 + p21p13 p22p12 p22p13 + p23p12 p23p13 0 0 0 0 p21 2 2 p22p21 2 p23p21 p22 2 2 p23p22 p23 2 0 0 0 0 0 0 0 0 0 0 p11 p12 p13 0 0 0 0 0 0 0 p21 p22 p23 0 0 0 0 0 0 0 0 0 0 1              <label>(11)</label></formula><p>It is easy to demonstrate that:</p><formula xml:id="formula_12">(T c f ) −1 C f i (T c f ) −⊤ =P f (T q ) −1 Q i (T q ) −⊤P⊤ f ,<label>(13)</label></formula><formula xml:id="formula_13">whereT c f = 1 N N i=1 T c f i ,T q = 1 N N i=1 T q i ,<label>(14)</label></formula><formula xml:id="formula_14">P f = R f 0 2 0 ⊤ 3 1 =   p 11 p 12 p 13 0 p 21 p 22 p 23 0 0 0 1   .<label>(15)</label></formula><p>Thus, centering every frame on the average of ellipses centers is equivalent to center the 3D space on the average of ellipsoids centers, removing at the same time the translation components t f of each projection matrix related to the cameras. Therefore, the relationship between quadrics and conics in Eq. (5) can be recast in the following way:</p><formula xml:id="formula_15">C f i =P fQiP ⊤ f ,<label>(16)</label></formula><p>given that</p><formula xml:id="formula_16">C f i = (T c f ) −1 C f i (T c f ) −⊤ ,Q i = (T q ) −1 Q i (T q ) −⊤ . (17)</formula><p>An interesting fact arises here: If we calculate the matrices G f starting fromP f , according to Eq. <ref type="formula" target="#formula_6">(6)</ref>, we see that all the entries of G f containing p 14 and p 24 are zeroed, since p 14 = p 24 = 0 in Eq. <ref type="bibr" target="#b14">(15)</ref>. Now let us permute the matrix G f taking its rows and columns in the order given by the index sets {1, 2, 4, 3, 5, 6} for the rows and {1, 2, 3, 5, 6, 8, 4, 7, 9, 10} for the columns, so defining a new matrixḠ f as in Eq. <ref type="bibr" target="#b10">(11)</ref>. The matrixḠ f has a block diagonal structure, in which the 3×6 upper left block groups all the entries quadratic in the p mn terms, the 2 × 3 middle block groups the entries linear in p mn and the lower right block is a constant scalar. Given this structure, the bilinear factorization problem based on the rank 10 constraint can be decoupled into two sub-problems with rank 6 and 3 constraints respectively. The last block of size 1 × 1 does not provide any additional information and can be discarded 3 .</p><p>In particular, let us isolate the middle block ofḠ f , named here G l f : <ref type="bibr" target="#b2">3</ref> Given that the last elements of all quadrics and conics are fixed to −1, it is easy to see that the last row ofḠ f provides a redundant constraint −1 = −1 for every frame and object.</p><formula xml:id="formula_17">G l f = p 11 p 12 p 13 p 21 p 22 p 23 ,<label>(18)</label></formula><p>where the index l recalls the linearity of G l f with respect to the terms p ij . Next, let us pick up the corresponding entries of vectorsc f i andv i , defined asc f i = vech(C f i ) and v i = vech(Q i ), so obtaining the new reduced and permuted vectors:</p><formula xml:id="formula_18">v l i =v i{4,7,9} , c l f i =c f i{3,5} .<label>(19)</label></formula><p>Finally let us group together all the frames and objects, similarly as Eqs. <ref type="formula" target="#formula_8">(8)</ref> and <ref type="formula" target="#formula_9">(9)</ref>, obtaining the following matrices:</p><formula xml:id="formula_19">G l ⊤ = G l 1 ⊤ · · · G l F ⊤ ⊤ , V l = v l 1 · · · v l N ,<label>(20)</label></formula><formula xml:id="formula_20">C l =    c l 11 · · · c l 1N . . . . . . . . . c l F 1 · · · c l F N    .<label>(21)</label></formula><p>In this way we end up with the following bilinear relationship:</p><formula xml:id="formula_21">C l = G l V l ,<label>(22)</label></formula><p>where C l ∈ R 2F ×N , G l ∈ R 2F ×3 and V l ∈ R 3×N . By performing an SVD on C l and truncating to the third singular value we obtain:</p><formula xml:id="formula_22">G l V l =G l Z l Z l−1Ṽ l .<label>(23)</label></formula><p>The 3 × 3 mixing matrix Z l can be found by exploiting the orthogonality and norm constraints of an orthographic camera matrix. In this way we are able to find the whole camera parameters and the elements 4, 7 and 9 of the vectorized quadrics, given the measured elements 3 and 5 of the vectorized conics, by simply selecting the proper elements of the recovered matrices G l and V l .</p><p>Geometrical interpretation. In order to gain more insights into the geometrical meaning of this solution, the relation between conics and quadrics will be made explicit.</p><p>Every dual conic C f i can be expressed as a conic with coordinate center <ref type="figure">(0, 0)</ref>, denoted withC f i , pre-and postmultiplied by a translation matrix T c f i defined according to Eq. <ref type="bibr" target="#b11">(12)</ref>. A similar property holds for quadrics, thus giving:</p><formula xml:id="formula_23">C f i = T c f iCf i T c⊤ f i , Q i = T q iQi T q⊤ i ,<label>(24)</label></formula><p>where:</p><formula xml:id="formula_24">C f i =   c 11 c 12 0 c 12 c 22 0 0 0 −1   ,Q i =     q 11 q 12 q 13 0 q 12 q 22 q 23 0 q 13 q 23 q 33 0 0 0 0 −1     .</formula><p>(25) Given Eqs. (24) and (25), the vectorized dual conics and dual quadrics assume the following form:</p><formula xml:id="formula_25">c f i =               c 11 − t c 1 2 c 12 − t c 1 t c 2 −t c 1 c 22 − t c 2 2 −t c 2 −1               v i =                           q 11 − t q 1 2 q 12 − t q 1 t q 2 q 13 − t q 1 t q 3 −t q 1 q 22 − t q 2 2 q 23 − t q 2 t q 3 −t q 2 q 33 − t q 3 2 −t q 3 −1                           .<label>(26)</label></formula><p>Notice that the translation parameters t c 1 , t c 2 and t q 1 , t q 2 , t q 3 of conic and quadric appear linearly in entries 3 and 5 of c f i and 4, 7 and 9 of v i . Since these entries are the ones picked up to form the matrices C l and V l we can conclude that ellipsoid centers can be recovered from ellipses centers by decoupling them from the ellipsoid shape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Solving for the ellipsoid shape</head><p>As can be seen from Eqs. (26), the terms describing shape and size are contained in the elements {1, 2, 3, 5, 6, 8} of the vectorized quadric v i and the elements {1, 2, 4} of the vectorized conic c f i . Therefore, it is possible to express the vectorized conics elements {1, 2, 4} as a product of the 3 × 6 upper left block ofḠ f times the vectorized quadrics elements {1, 2, 3, 5, 6, 8} and exploit the rank-6 constraint to find such quadric elements. However three drawbacks make this option not so appealing.</p><p>First, the terms of the vectorized quadrics are mixed with the quadratic component related to the translation, as can be seen in Eq. (26). In the case of small ellipses far from the image center, a likely case in many scenarios, the terms related to the ellipse size and shape become negligible with respect to the translation terms, and consequently even small errors on c f i affect negatively the reconstruction of the ellipsoid. This is because the information on the ellipsoid shape, embedded in the elements c 11 , c 12 and c 22 do not prevail over the translation errors on t c 1 and t c 2 .</p><p>Second, by exploiting the rank-6 constraint, one can reconstruct the six ellipsoid terms up to a 6 × 6 invertible matrix. However doing a metric upgrade is not trivial involving quadratic equality constraints drawn from the structure ofḠ f , thus leading to a nonlinear optimization procedure with the risk to obtain a local solution. Finally, at least six objects have to be visible in every frame in order to be able to use a rank-6 constraint.</p><p>To fix these drawbacks, we propose a different procedure. First of all, it is possible to remove the quadratic translation terms by considering the centered ellipses and ellipsoids. In fact, if Eq. (16) holds, then also:</p><formula xml:id="formula_26">C f i =P fQiP ⊤ f (27)</formula><p>holds, i.e. in the affine case centering every single ellipse to the image center is equivalent to center every ellipsoid in the 3D coordinates origin. The vectorized versions of centered conics and quadrics, defined asv i = vech(Q i ) and c f i = vech(C f i ) do not contain translation terms, while the shape terms c mn and q mn have been left unchanged.</p><p>Therefore we can select the rows and columns accounting for shape inḠ f ,v i andc f i as follows:</p><formula xml:id="formula_27">G s f =Ḡ f {1,2,3}×{1,2,3,4,5,6} ,<label>(28)</label></formula><formula xml:id="formula_28">v s i =v i{1,2,3,5,6,8} , c s f i =c f i{1,2,4}<label>(29)</label></formula><p>and build the matrices:</p><formula xml:id="formula_29">G s⊤ = G s 1 ⊤ · · · G s F ⊤ ⊤ , V s = v s 1 · · · v s N ,<label>(30)</label></formula><formula xml:id="formula_30">C s =    c s 11 · · · c s 1N . . . . . . . . . c s F 1 · · · c s F N    ,<label>(31)</label></formula><p>where C s ∈ R 3F ×N , G s ∈ R 3F ×6 and V s ∈ R 6×N . The three matrices are linked by the bilinear relation:</p><formula xml:id="formula_31">C s = G s V s .<label>(32)</label></formula><p>At this point, instead of performing an SVD, we can exploit the camera parameters p mn found by the rank 3 solution in Eq. (23), to recover the matrix G s by simple variable assignments, exploiting the structure in Eq. <ref type="bibr" target="#b10">(11)</ref>. Next, we can estimate the shape and size parameters independently for each quadric, multiplying the pseudo inverse of G s by each column of C s :</p><formula xml:id="formula_32">V s = G s+ C s (33)</formula><p>where G s+ is the pseudo inverse of G s . Finally, we recombine the shape and size parameters contained in V s with the translation parameters in matrix V l in Eq. (23), recovering the correct ellipsoids.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Solution with both points and objects</head><p>Interestingly, it is possible to include both point matches and objects in the same factorization framework. This might be convenient when the number of objects is not enough or to make more accurate the estimation with additional information from reliable 2D tracks.</p><p>To this end, P points can be included in this framework by expressing them as P additional degenerate quadrics or conics. In particular, we associate to each point an arbitrary quadric (and a set of conics in images) whose center is equal to the point coordinates, and then we evaluate the limit for the size of quadric and conic going to zero. In detail, the P additional quadrics and conics in function of a size parameter h are defined as:</p><formula xml:id="formula_33">C f,N +p (h) = T c f,N +p H cC f,N +p H c⊤ T c⊤ f,N +p (34) Q N +p (h) = T q N +p H qQ N +p H q⊤ T q⊤ N +p<label>(35)</label></formula><p>for p = 1, . . . P , with:</p><formula xml:id="formula_34">H c =   h 0 0 0 h 0 0 0 1   , H q =     h 0 0 0 0 h 0 0 0 0 h 0 0 0 0 1     .<label>(36)</label></formula><p>Notice that the point location information is given by the translation matrices T c f,N +p and T q N +p . The degenerate conics and quadrics that correspond to a point can be written as:</p><formula xml:id="formula_35">C f,N +p = lim h→0 C f,N +p (h) Q N +p = lim h→0 Q N +p (h) (37)</formula><p>Notice that in the corresponding vectorized quadrics and conics the shape terms c mn and q mn are multiplied by h and consequently vanish, leaving just the translation terms. At this point the same approach described in Section 4.1 can be followed, simply adding to the number of objects N the number of points N + P . Differently, once the camera parameters, together with 3D points and ellipsoids centers have been found, the matrix related to ellipsoids shape will have the same dimension of C s in Eq. (32), i.e. 3F × N since the additional P columns related to the points contain just zeros and can be removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>The proposed method has been tested on a synthetic scenario and a real dataset. In every experiment, the accuracy of the estimated 3D object position and pose was measured by the volume overlap O 3D given by the intersection between ground truth (GT) and estimated (ES) ellipsoids respectively:</p><formula xml:id="formula_36">O 3D = 1 N N i=1 Q i ∩Q i Q i ∪Q i ,<label>(38)</label></formula><p>where Q i andQ i denote the volume of GT and ES ellipsoids respectively. This metric measures the success of the algorithm in recovering the 3D position and occupancy of an object. Moreover, we also evaluated the orientation error by using the measure θ err , which is the angle in radians between the main axes of GT and ES ellipsoids. We tested the proposed algorithm performance in two conditions: using ellipses from bounding boxes only (ELL) and using ellipses plus a set of additional points (ELL + P ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Synthetic setup</head><p>We generated a synthetic 3D setup with a variable number of ellipsoids, randomly placed inside a cube of side 20 units. The length of the largest ellipsoid axis L ranges from 3 to 12 units, according to a uniform PDF. The lengths of the other two axes are equal to γL with γ ∈ [0.3, 1]. Finally, axes orientation was fixed randomly. Optionally, we added a variable number of 3D points randomly generating their positions. A set of 20 camera views were generated and the camera trajectory was computed so that azimuth and elevation angles span the range [0 • , 60 • ] and [0 • , 70 • ] respectively. Given the orthographic camera matrix P f of each camera frame, GT ellipses and GT 2D points were calculated from the exact projections of the ellipsoids and 3D points.</p><p>Synthetic tests were aimed at validating the robustness of the proposed method against common inaccuracies affecting object detectors, such as coarse estimation of the object center, tightness of the bounding box with respect to the object size and variations over the object pose. Thus, each ellipse was corrupted by three errors, namely translation error (TE), rotation error (RE) and size error (SE). To impose such errors, the ellipses centers coordinates t c 1 , t c 2 , the axes length l 1 , l 2 and the orientation α of the first axis were perturbed as follow <ref type="bibr" target="#b3">4</ref> :</p><formula xml:id="formula_37">t c j = t c j +lν t j ,α = α+ν α ,l j = l j 1 + ν l ,<label>(39)</label></formula><p>where ν t j , ν α and ν l are random variables with uniform PDF and mean value equal to zero, andl = (l 1 + l 2 )/2. Translation errors were also imposed to 3D points, with a magnitude calculated according to Eq. (39), assuming a random ellipsoid associated to each point. In order to highlight the specific impact of each error, they were applied separately. Error magnitudes were set tuning the boundary values of the uniform PDFs of ν t j , ν α and ν l . In detail, for each kind of error, we considered 10 different values of ν t j , ν a and ν l , with uniform spacing, and we applied the resulting error realizations to the ellipses reprojections related to all the ellipsoid. We run 100 trials for each setup, described by the number of objects and error on ellipses.</p><p>In <ref type="figure" target="#fig_0">Fig. 2</ref>, O 3D and θ err are displayed versus RE and SE. Reconstruction is perfect for zero errors, with O 3D = 1, θ err = 0 and smoothly worsening as the error increases, reaching a minimum O 3D = 0.5 for RE = 45 • or SE = = 0.5. The pose error θ err reaches a maximum value of about 50 • for RE = 45 • , and 40 • for SE = 0.5. Overall, results appear to be quite robust to SE and RE. This fact is particularly important since such errors are likely to happen very frequently whenever ellipses are fitted to BBs. Even if the detector is accurate, the bounding box quantises the object alignment at steps of 90</p><p>• , yielding a maximum RE of 45</p><p>• . This tends to overestimate the object area, thus affecting SE, whenever the object is not aligned to the bounding box axes.</p><p>Notice that the performance does not vary with the number of ellipsoids present in the scene. Though this may seem counterintuitive, it follows from the fact that RE and SE do not affect the estimation of camera parameters, the latter being based on translation terms only, as can be seen from Eq. (23). Once camera parameters are recovered, the ellipsoid shape and size is estimated separately for each object (check Eq. (33)), so making the overall performance simply the average of the performance for each single object. The above reasoning is not valid for TE, as can be seen in <ref type="figure" target="#fig_1">Fig. 3</ref>. Both O 3D and θ e rr are dependent on the number of objects in the scene, showing a notable increase in performance passing from 4 to 7 objects and a further slight increase with 10 objects.</p><p>Adding points to the setup improves in general the results and allows to overcome the minimal requirement of 3 objects. In <ref type="figure" target="#fig_2">Fig. 4</ref> we report the results versus TE for 2, 3 and 4 objects with 2 and 5 additional points. In general, what matters for the performance versus TE is the sum of numbers of objects and points. In particular the performance grows strongly starting from 4 points/objects and tends to saturate above about 10 points/objects. Differently the performance versus RE and SE are not reported, since they are independent from the number of points and very similar to the case without objects <ref type="figure" target="#fig_0">(Fig. 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Real setup: KINECT dataset</head><p>We tested the proposed algorithm on the KINECT dataset <ref type="bibr" target="#b1">[2]</ref>. The dataset is composed of five sequences, each one showing a different office desk, with about 10 − 15 objects, from a variable number of frames (but always less than a hundred). Bounding boxes associated to each objects are also provided. The dataset is very challenging as the angle spanned by the camera views is quite narrow. Moreover bounding boxes are quite unprecise in terms of position and aspect ratio. We selected a subset of about 8 − 25 frames for each sequence, associating an ellipse to each BB at each frame. We also extracted a set of points tracks and run the proposed algorithm on ELL and ELL + P setups. In <ref type="figure">Fig.  5</ref> we show the results for Seq. 2, 3 and 4 (ELL). Reprojected ellipses match very well the position, shape and   pose of all the objects in all the frames, as exemplified by the three image frames in <ref type="figure">Fig. 5</ref>. More importantly, the object's relative displacement along the z direction, visible in the upper views of 3D reconstructions, is correctly estimated as well as the objects size. Moreover, for the majority of objects, the aspect ratio and pose is also qualita- <ref type="figure">Figure 5</ref>. Results for the KINECT dataset for ELL setup on Sequences 2 (first column), 3 (second column) and 4 (third column.) First row: a frame from the sequence with BBs (yellow), ellipses from BBs (red) and reprojected ellipses (green) . Second row: upper views of the ES ellipsoids. <ref type="figure">Figure 6</ref>. Results for the KINECT dataset for ELL + P setup on Sequence 3. Left: a frame from the sequence with BBs (yellow), ellipses from BBs (red), points (red), reprojected ellipses (green) and points (blue). Right: upper views of the ES ellipsoids and 3D points. tively correct. Some exceptions like the mugs 2, 3 in Seq. 2 and 3, 4, 5 in Sequence 4 are due to their asymmetric shape for which an ellipsoid represent an intrinsically coarse approximation. Sequence 3 was also tested in the ELL + P setup, adding about 25 point tracks. The result reported in <ref type="figure">Fig. 6</ref> is structurally very similar to the corresponding ELL case for the objects, though ellipsoids are more stretched along the z direction. Also the 3D structure of the points is correctly recovered and it is coherent with the objects dis-placement. For example, points belonging to object 8 are very close to the corresponding ellipsoid, while points from the PC monitor and from the books on the shelf are located at the correct depth with respect to all the objects. These results witness the capability of the method to solve a generalized SfM problem, embedding in a single framework both quadrics and points. Finally, to better understand the goodness of the objects 3D estimation, <ref type="figure" target="#fig_3">Fig. 7</ref> shows the ellipsoid position being coherent with the point cloud: The different objects are lying onto the table and with a correct depth. Some inaccuracies are present for lateral objects due to coarse depth estimates and the possible discrepancy between the perspective model of the Kinect camera and the orthographic one assumed in our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>A generalized SfM method has been proposed that is able to recover, in closed-form, camera poses and objects positions in 3D space, taking as input just a set of bounding boxes from an object detector in a collection of image frames. The devised method, exploiting the relationship between quadrics and conics in dual space, is able to recover also a coarse estimation of objects size, shape and orientation in space. Finally, 2D points can be easily included in the framework as degenerate conics, so overcoming the constraints on the minimal number of objects required. The method has been tested on both synthetic and real data, demonstrating its robustness against possible object detector inaccuracies, and proving to be effective in real challenging conditions. Further research on this topic will include solution refinement methods based on non-linear cost functions able to solve in one step for all the unknowns. Moreover, given the new ideas introduced in this work, we will deal with the more general and complex case of perspective SfM using dual matrix factorization with conics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Results for the synthetic tests without additional points versus RE and SE errors. First row: 3D overlap; second row: pose mismatch; first column: RE; second column: SE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Results for the synthetic tests with 4, 7 and 10 objects without additional points, versus TE. Left: 3D overlap; right: pose mismatch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Results for the synthetic tests versus RE for 2, 3 and 4 objects with 2 or 5 additional points. First row: 3D overlap; second row: pose mismatch; first column 2 points; second column: 5 points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 .</head><label>7</label><figDesc>3D estimated ellipsoids of Sequence 2 aligned to the KINECT point cloud.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We omit for simplicity the object and frame indexes.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bundle adjustment in the large</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV 2010</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic structure from motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2011</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2025" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Photometric stereo with general, unknown lighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="239" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Factorization-based segmentation of motions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Workshop on</title>
		<meeting>the IEEE Workshop on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1991" />
			<biblScope unit="page" from="179" to="186" />
		</imprint>
	</monogr>
	<note>Visual Motion</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Recovering non-rigid 3d shape from image streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Biermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2000</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2000" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A multi-body factorization method for motion analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV 1995</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="1071" to="1076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Quadric reconstruction from dual-space geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV 1998</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="25" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Building rome on a cloudless day</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fite-Georgel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gallup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raguram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Jen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Clipp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV 2010</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Multiple view geometry in computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Vec and vech operators for matrices, with some uses in jacobians and multivariate statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Searle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Canadian Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="81" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Linear fitting with missing data: Applications to structure-from-motion and to characterizing intensity images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 1997</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="206" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Affine structure and motion from points, lines and conics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heyden</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="163" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Factorization without factorization: complete recipe</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kanatani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sugaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mem. Fac. Eng. Okayama Univ</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1&amp;2</biblScope>
			<biblScope unit="page" from="61" to="72" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Line reconstruction from many perspective images by factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matinec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2003</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page">497</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A factorization method for affine structure from line correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 1996</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="803" to="808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The projective reconstruction of points, lines, quadrics, plane conics and degenerate quadrics using uncalibrated cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bayro-Corrochano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="693" to="706" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Principal component analysis with missing data and its application to polyhedral object modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Reddy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="854" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Hierarchical structure-and-motion recovery from uncalibrated images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Toldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gherardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farenzena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fusiello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page" from="127" to="143" />
		</imprint>
		<respStmt>
			<orgName>CVIU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Shape and motion from image streams under orthography: a factorization method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">1992</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Articulated structure from motion by factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tresadern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2005</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1110" to="1115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Factorization methods for projective structure and motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 1996</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="845" to="851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A general framework for motion segmentation: Independent, articulated, rigid, non-rigid, degenerate and non-degenerate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV 2006</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="94" to="106" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
