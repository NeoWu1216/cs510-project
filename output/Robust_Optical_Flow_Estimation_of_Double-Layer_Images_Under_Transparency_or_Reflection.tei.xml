<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust Optical Flow Estimation of Double-Layer Images under Transparency or Reflection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaolong</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ANU &amp; ACRV</orgName>
								<orgName type="institution" key="instit1">BIT &amp; ANU</orgName>
								<orgName type="institution" key="instit2">Yale-NUS College</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongdong</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ANU &amp; ACRV</orgName>
								<orgName type="institution" key="instit1">BIT &amp; ANU</orgName>
								<orgName type="institution" key="instit2">Yale-NUS College</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>CECS</roleName><forename type="first">Yuchao</forename><surname>Dai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ANU &amp; ACRV</orgName>
								<orgName type="institution" key="instit1">BIT &amp; ANU</orgName>
								<orgName type="institution" key="instit2">Yale-NUS College</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robby</forename><forename type="middle">T</forename><surname>Anu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ANU &amp; ACRV</orgName>
								<orgName type="institution" key="instit1">BIT &amp; ANU</orgName>
								<orgName type="institution" key="instit2">Yale-NUS College</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ANU &amp; ACRV</orgName>
								<orgName type="institution" key="instit1">BIT &amp; ANU</orgName>
								<orgName type="institution" key="instit2">Yale-NUS College</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Robust Optical Flow Estimation of Double-Layer Images under Transparency or Reflection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper deals with a challenging, frequently encountered, yet not properly investigated problem in two-frame optical flow estimation. That is, the input frames are compounds of two imaging layers -one desired background layer of the scene, and one distracting, possibly moving layer due to transparency or reflection. In this situation, the conventional brightness constancy constraint -the cornerstone of most existing optical flow methods -will no longer be valid. In this paper, we propose a robust solution to this problem. The proposed method performs both optical flow estimation, and image layer separation. It exploits a generalized double-layer brightness consistency constraint connecting these two tasks, and utilizes the priors for both of them. Experiments on both synthetic data and real images have confirmed the efficacy of the proposed method. To the best of our knowledge, this is the first attempt towards handling generic optical flow fields of two-frame images containing transparency or reflection.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Most optical flow methods assume that there is only one imaging layer on the observed image with the brightness of scene objects, and use the brightness constancy constraint (BCC) to estimate the optical flow for scene objects. This single imaging layer assumption, however, can be often violated in real-world situations, especially in cases involving transparency or reflection. Transparencies and reflections are frequently met in imaging process, e.g., when one is looking at street scene from inside a car through a stained windscreen, or seeing through a thin layer of rain, looking into a window with semi-reflections on the window surface etc. The BCC will generally not hold for the resultant double-layer images, even in ideal noise-free cases.</p><p>In all the above examples, the observed image I can be modeled as a superposition of two constituting layers, denoted as I = L 1 ⊕ L 2 , where ⊕ denotes some suitable layer combination operator. Without loss of generality, we call L 1 the background scene layer, which corresponds to the image of the desired scene that we intend to capture, and L 2 the foreground distracting layer, which corresponds to the semi-transparent media (e.g. a glass window with dirt or reflections on it) or the semi-reflected image.</p><p>The main goal of this paper is to robustly estimate the optical flow field of the scene objects (i.e. the background layer), which is of concern for vision systems. We consider two general cases: the foreground distracting layer is stationary, or dynamically changing.</p><p>Let I and I ′ be two time-consecutive frames of a scene containing the aforementioned two layers. In the presence of a dynamic foreground layer, there are two legitimate optical flow fields -one for the foreground layer and one for the background layer. Denote the two flow fields generated by the movements of the two layers as U and V respectively. The relationships among the observed images, the image layers and the optical flow fields can be given as</p><formula xml:id="formula_0">I = L 1 ⊕ L 2   U   V I ′ = L ′ 1 ⊕ L ′ 2</formula><p>When V ≡ 0 and L 2 ≡ L ′ 2 , i.e. the foreground layer is static, our task is to estimate a single flow field U for background layer, and also estimate the layers L 1 , L ′ 1 , L 2 . Otherwise when a dynamic foreground layer exists, we will estimate two flow fields U, V as well as the layers L 1 , L ′ 1 , L 2 , L ′ 2 . As we explicitly perform image layer separation (i.e. estimating L 1 , L ′ 1 , L 2 , L ′ 2 ), an appealing byproduct of our method is the restoration of the clear scene images.</p><p>For either of the two cases with a static or dynamic foreground layer, this is a highly ill-posed problem, especially considering optical flow estimation and image layer separation problems per se are known to be ill-posed. From only two input images, our task is to recover one or two optical fields, as well as the two unknown layers.</p><p>Little work has been reported in the literature concerning this double-layer image optical flow estimation problem, with only a few exceptions in the early days of computer vision research, e.g. <ref type="bibr" target="#b27">[28]</ref> <ref type="bibr" target="#b28">[29]</ref>[18] <ref type="bibr" target="#b10">[11]</ref>. These works however often used over-simplified assumption and restrictive motion field models, such as assuming a constant flow field over time or over space (e.g. globally translating). Bergen et al. <ref type="bibr" target="#b2">[3]</ref> proposed a "three-frame algorithm" to recover two constituting flow fields, assuming the flow field is constant over at least three frames. In contrast, this paper removes these restrictive assumptions, and proposes a two-frame algorithm for robustly recovering the flow field(s). Our method works for generic motions, and is thus applicable to a much wider range of practical situations for robust optical flow estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Related Works</head><p>This paper is concerned with optical flow estimation in double-layer images where both layers can possibly be moving. Despite that the phenomena of such multiple imaging layers and motions are frequently encountered in reality, few papers in the literature have been devoted to this topic. This is in a sharp contrast to the existence of vast amount of papers on the classic optical flow problems (an analysis of recent practices of optical flow can be found in <ref type="bibr" target="#b30">[31]</ref>).</p><p>One of the first work for multiple optical flow computation is possibly due to Shiwaza et al. <ref type="bibr" target="#b27">[28]</ref> <ref type="bibr" target="#b28">[29]</ref>. By assuming the two underlying flow fields to be constant (e.g. pure translating), they derived a generalized brightness constancy constraint for the multi-motion case. However, this constant motion assumption is restrictive, not applicable for general flow fields with complex motions. Nevertheless, their method, being one of the first, has inspired a number of variants and extensions <ref type="bibr" target="#b23">[24]</ref>[1] <ref type="bibr" target="#b24">[25]</ref> <ref type="bibr" target="#b35">[36]</ref>. Some variants operate in the Fourier domain, e.g. <ref type="bibr" target="#b16">[17]</ref>[18] <ref type="bibr" target="#b10">[11]</ref>.</p><p>The flow estimation problem for two-layer images in this paper should not be confused with those works concerning "motion-layer segmentation", albeit the two do share some similarity and the boundary between them can sometimes be fuzzy. For example, Wang and Adelson <ref type="bibr" target="#b37">[38]</ref> proposed to segment the image layers based on a pre-computed optical flow field. Irani et al. <ref type="bibr" target="#b14">[15]</ref> used temporal integration to track occluding or transparent moving objects with parametric motion. Black and others <ref type="bibr" target="#b3">[4]</ref> <ref type="bibr" target="#b15">[16]</ref>[32] <ref type="bibr" target="#b41">[42]</ref> proposed a number of algorithms for multiple parametric motion estimation and segmentation. Yang and Li <ref type="bibr" target="#b43">[44]</ref> fit a flow filed with piecewise parametric models. Weiss <ref type="bibr" target="#b38">[39]</ref> presented a nonparametric motion estimation and segmentation method to handle generic smooth motions, thus this method is more related to ours. However, the method of Weiss and most other aforementioned methods primarily focused on image and motion segmentation, while we decompose the whole image into two composite brightness layers, and compute one generic flow field on each layer.</p><p>The proposed method involves solving two tasks simultaneously: optical flow field estimation, and reflection/transparent layer separation. For the second task, many researches have been published previously. For example, Levin et al. <ref type="bibr" target="#b19">[20]</ref> <ref type="bibr" target="#b18">[19]</ref> proposed methods for separating an image into two transparent layers using local statistics priors of natural images. Single image solutions are also investigated in <ref type="bibr" target="#b21">[22]</ref> and <ref type="bibr" target="#b45">[46]</ref>. To utilize multiple frames, layer separation methods have been proposed based on aligning the frames with one layer <ref type="bibr" target="#b40">[41]</ref>[21] <ref type="bibr" target="#b13">[14]</ref> or multiple layers <ref type="bibr" target="#b32">[33]</ref> <ref type="bibr" target="#b12">[13]</ref>. Sarel and Irani <ref type="bibr" target="#b25">[26]</ref> presented an information theory based approach for separating transparent layers by minimizing the correlation between the layers. Chen et al. <ref type="bibr" target="#b9">[10]</ref> gave a gradient domain approach for moving layer separation which is also based on information theory. Schechner et al. <ref type="bibr" target="#b26">[27]</ref> developed a method for layer separation using image focus as a cue. By using independent component analysis, Farid and Adelson <ref type="bibr" target="#b11">[12]</ref> proposed a layer separation method which works on multiple observations under different mixing weights. Techniques for image layer separation were also developed in the field of intrinsic image/video extraction <ref type="bibr" target="#b34">[35]</ref>[40] <ref type="bibr" target="#b44">[45]</ref>.</p><p>In the context of stereo matching with transparency, Szeliski and Golland <ref type="bibr" target="#b33">[34]</ref> simultaneously recovered disparities, true colors, and opacity of visible surface elements. Tsin et al. <ref type="bibr" target="#b36">[37]</ref> estimated both depth and colors of the component layers. Li et al. <ref type="bibr" target="#b22">[23]</ref> proposed a simultaneous video defogging and stereo matching algorithm.</p><p>The recent work of Xue et al. <ref type="bibr" target="#b42">[43]</ref> has a very similar formulation compared to ours. However, the goal and motivation of obstruction-free photography from a video sequence in <ref type="bibr" target="#b42">[43]</ref> are different from ours. The underlying assumptions on the flow fields, the employed flow solvers and the initialization techniques are dissimilar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Problem Setup</head><p>For ease of presentation, in formulating the problem (Sec. 2 and Sec. 3) and presenting the optimization (Sec. 4), we will focus on the dynamic foreground case (i.e. doublelayer flow estimation). The static foreground case (i.e. single-layer flow estimation) is simpler and can be derived accordingly. Note that, the static foreground case, though relatively simpler, is also of interest and very challenging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Linear Additive Imaging Model</head><p>In previous discussion, we simply used I = L 1 ⊕ L 2 to denote the layer superposition operation, but did not give its exact form. To make the idea of this paper more concrete, we opt for the linear additive model + as a concrete example for ⊕, i.e.,</p><formula xml:id="formula_1">I = L 1 + L 2 .</formula><p>The linear additive model itself, while simple, has been used successfully in the past in solving many vision problems involving transparency and reflection (e.g., in shadow removal <ref type="bibr" target="#b45">[46]</ref>, image matting <ref type="bibr" target="#b33">[34]</ref> and reflection separation <ref type="bibr" target="#b21">[22]</ref>). Moreover, by applying logarithm operation, a multiplicative superposition model can also be converted to an additive one.</p><p>Taking two frames of observations, I and I ′ , at two consecutive time steps t and t + 1, we have</p><formula xml:id="formula_2">I(X) = L 1 (X) + L 2 (X),<label>(1)</label></formula><formula xml:id="formula_3">I ′ (X) = L ′ 1 (X) + L ′ 2 (X),<label>(2)</label></formula><p>where X is a matrix indexing all pixel coordinates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Double Layer Brightness Constancy</head><p>In the presence of transparencies or reflections, it is important to note that the conventional BCC condition cannot be applied directly to the observed images. Below, we will derive a generalized BCC condition which is applicable to the double-layer case.</p><p>The basic assumption that we will base our method on is: any component layer of the observed image must satisfy the brightness constancy condition individually. This is a realistic and mild assumption which is applicable to a wide range of transparency and reflection phenomena encountered in natural images. Cases that violate this basic assumption are deemed beyond the scope of this current paper.</p><p>Suppose, during two small time steps, layer L 1 changed to L ′ 1 according to a motion field of U, and layer L 2 changed to L ′ 2 according to a different motion field V. Based on the assumption that the brightness of the objects in each individual layer is constant, we have</p><formula xml:id="formula_4">L 1 (X) = L ′ 1 (X + U), (3) L 2 (X) = L ′ 2 (X + V).<label>(4)</label></formula><p>Together with the imaging model in <ref type="formula" target="#formula_2">(1)</ref> and <ref type="formula" target="#formula_3">(2)</ref>, we call the above constraints the generalized double-layer BCC condition for an input double-layer image pair (I, I ′ ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">The Double Layer Optical Flow Problem</head><p>Given the above linear additive imaging model as well as the generalized BCC conditions, we aim to recover both</p><formula xml:id="formula_5">L 1 , L ′ 1 , L 2 , L ′ 2 and U, V.</formula><p>To make this severely ill-posed problem trackable, we adopt the energy minimization framework, and base it on the generalized BCC conditions as well as priors for optical flows and image layers. The energy function reads as</p><formula xml:id="formula_6">E = E B + λ L E L + λ F E F ,<label>(5)</label></formula><p>where E B corresponds to the double-layer BCC condition, E L and E F are the regularization terms (or prior terms) for the latent image layers, and the unknown optical flow fields, respectively. The λs are trade-off parameters.</p><p>In energy <ref type="formula" target="#formula_6">(5)</ref>,</p><formula xml:id="formula_7">we use E B = E B (L 1 , L ′ 1 , L 2 , L ′ 2 , U, V)</formula><p>to represent the BCC condition in the following way 1 :</p><formula xml:id="formula_8">E B = L 1 (X) − L ′ 1 (X + U) + L 2 (X) − L ′ 2 (X + V) .<label>(6)</label></formula><p>We use · to denote the ℓ 1 -norm in this paper unless otherwise specified. We choose to use ℓ 1 -norm as the cost function mainly for its robustness <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b46">47]</ref> and its convenience in optimization. The two regularization terms E L and E F will be detailed in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Regularization</head><p>Using prior information as regularization is a common practice for solving ill-posed problems. In this paper, the task is to separate the input frames into latent layers, and to recover the associated flow fields.</p><p>Priors are generally task-dependent. By enforcing different priors to latent layers and to optical flow fields, the algorithm can be adapted to solving different tasks. For example, if one knows the two latent layers are images of natural scenes, then the layers can be assumed to have sparse gradients (i.e., satisfying the well-known natural image priors). Moreover, for general optical flow fields, one can assume they are piecewise constant or piecewise smooth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Natural Image Prior: Sparse Gradient</head><p>The research in natural image statistics shows that images of typical real-world scenes obey sparse spatial gradient distributions <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b18">19]</ref>. The distribution of a natural image L can often be modeled as a generalized Laplace distribution (a.k.a., generalized Gaussian distribution), i.e.,</p><formula xml:id="formula_9">P (L) = x∈X exp(−|∂ x L(x)| p − |∂ y L(x)| p ),<label>(7)</label></formula><p>where the power p is a parameter usually within [0.0, 1.0]. A convenient choice is p = 1, with which the energy is reduced to the ℓ 1 -norm of image spatial gradients. For ease exposition, we will let p = 1 in this paper, though bear in mind that using other values of p is possible and may be advantageous in particular applications. Taking the negative logarithm, the prior in <ref type="formula" target="#formula_9">(7)</ref> can be represented in the energy minimization form, i.e.</p><formula xml:id="formula_10">∇L(X) → min,<label>(8)</label></formula><p>where ∇ = (∂ x , ∂ y ) ⊤ . Therefore, the latent layer regular-</p><formula xml:id="formula_11">ization term E L = E L (L 1 , L ′ 1 , L 2 , L ′ 2 )</formula><p>can be written as</p><formula xml:id="formula_12">E L = ∇L 1 (X) + ∇L ′ 1 (X) + ∇L 2 (X) + ∇L ′ 2 (X) .<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Optical Flow Priors: Spatial Smoothness</head><p>Early methods for solving multi-layer optical flow problem often made restrictive assumption about the unknown flow fields. For example, <ref type="bibr" target="#b2">[3]</ref> proposed a three-frame algorithm for recovering two component motion fields by assuming that the motion fields are constant over time, and <ref type="bibr" target="#b27">[28]</ref> was built upon a local constant motion assumption to derive its basic equation. In this paper, these restrictions are removed and the proposed method can handle more general and more complex motion fields.</p><p>We use a general assumption on flow field, namely, the optical flows are generally piecewise constant or piecewise smooth. To capture this prior, we adopt the total variation (TV) model <ref type="bibr" target="#b46">[47]</ref> or total generalized variation (TGV) model <ref type="bibr" target="#b4">[5]</ref>. Specifically, a flow field U will be regularized by the following energy:</p><formula xml:id="formula_13">U TGV k → min,<label>(10)</label></formula><p>where U TGV k . = TGV k (U x ) + TGV k (U y ), and TGV k ( · ) denotes the k-th order TGV measure for horizontal and vertical flow components U x and U y .</p><p>In general, the k-th order TGV favors solutions that are piecewise composed of (k −1)-th order polynomials: with k = 1, TGV 1 reduces to the TV model which favors piecewise constant fields; with k = 2, TGV 2 favors piecewise affine fields. We will only consider TV and TGV 2 in this paper, and the resultant prior regularization term E F = E F (U, V) for the flow fields can be written as</p><formula xml:id="formula_14">E F (U, V) = U TGV k + V TGV k .<label>(11)</label></formula><p>where k = 1 (i.e. TV) or 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Energy Minimization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">The Overall Objective Function</head><p>By stacking all the constraints over both latent layers and flow fields, we reach an energy minimization problem as</p><formula xml:id="formula_15">min E(L 1 , L ′ 1 , L 2 , L ′ 2 , U, V) = E B + λ L E L + λ F E F = ( L 1 (X)−L ′ 1 (X+U) + L 2 (X)−L ′ 2 (X+V) ) + λ L ( ∇L 1 + ∇L ′ 1 + ∇L 2 + ∇L ′ 2 ) + λ F ( U TGV k + V TGV k ) ,<label>(12)</label></formula><formula xml:id="formula_16">subject to I = L 1 + L 2 , I ′ = L ′ 1 + L ′ 2 ,<label>(13)</label></formula><formula xml:id="formula_17">0 ≤ L 2 ≤ min(I, c), 0 ≤ L ′ 2 ≤ min(I ′ , c).<label>(14)</label></formula><p>where the X's in the gradient terms of (9) are omitted for brevity.</p><p>Note that, to distinguish background and foreground layers, we introduce in <ref type="bibr" target="#b13">(14)</ref> the element-wise bound constraints on the layers. We assume the foreground layer containing transparency or reflection has weaker signal, and use a small constant scalar c (e.g. c = 0.25 for brightness values in the range of [0,1]) as its brightness upper bound. This can be understood as an additional bound prior for layer separation. Also note that, putting aside <ref type="bibr" target="#b13">(14)</ref>, there is a global shift ambiguity for the layer values: adding an arbitrary scalar s ∈ R to L 1 , L ′ 1 then −s to L 2 , L ′ 2 dose not change the energy in <ref type="bibr" target="#b11">(12)</ref>, nor dose it affect <ref type="bibr" target="#b12">(13)</ref>. This is because all the terms in (12) depend on value difference rather than absolute value. Nevertheless, both the lower and upper bounds in <ref type="bibr" target="#b13">(14)</ref> help constrain the absolute values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Alternated Minimization</head><p>To solve the above energy minimization problem, we first substitute the additive model constraints in <ref type="bibr" target="#b12">(13)</ref> as hard constraints to eliminate L 1 and L ′ 1 in <ref type="bibr" target="#b11">(12)</ref>. Consequently, the energy function is now defined only on latent layers L 2 , L ′ 2 and optical flows U, V. Then, examining the energy form in <ref type="formula" target="#formula_2">(12)</ref>, we notice that: i) the prior terms for optical flow field, i.e. E F , is independent of the prior term for latent layers E L ; and ii) the BCC energy term E B is the only term that links the flow estimation with latent layer separation. Based on these observations, we solve the minimization problem via block coordinate descent in an alternating fashion.</p><p>Specifically, starting from a proper initialization, our algorithm alternately solves the following two sub-problems:</p><p>• (Layer Separation): Given current flow field estimates {U, V}, solve for image layers {L 2 , L ′ 2 } via the following minimization:</p><formula xml:id="formula_18">min L2,L ′ 2 (E B (L 2 , L ′ 2 ) + λ L E L (L 2 , L ′ 2 )) .<label>(15)</label></formula><p>• (Flow Computation): Given current image layers {L 2 , L ′ 2 }, estimate {U, V} by solving the following two-layer optical flow problem:</p><formula xml:id="formula_19">min U,V (E B (U, V) + λ F E F (U, V)) .<label>(16)</label></formula><p>More details are given below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Update the image layers</head><p>Given current optical flow estimates U and V, the latent image layers L 2 , L ′ 2 can be updated by solving the following optimization problem:</p><formula xml:id="formula_20">min L2,L ′ 2 (I−L 2 )(X)−(I ′ −L ′ 2 )(X+U) + L 2 (X)−L ′ 2 (X+V) +λ L ( ∇(I−L 2 ) + ∇(I ′ −L ′ 2 ) + ∇L 2 + ∇L ′ 2 ) subject to 0 ≤ L 2 ≤ min(I, c), 0 ≤ L ′ 2 ≤ min(I ′ , c),<label>(17)</label></formula><p>This is a convex optimization problem defined on L 2 and L ′ 2 , and the cost function can be arranged into min</p><formula xml:id="formula_21">l A · l − b , subject to lb i ≤ l i ≤ ub i , ∀i<label>(18)</label></formula><p>where A and b encode all the ℓ 1 constraints on latent layers, which are extremely sparse (only a few elements in each row are non-zero). l is a column vector containing elements in L 2 and L ′ 2 . lb i and ub i are constant bounds from <ref type="bibr" target="#b13">(14)</ref>. The constraints are linear function of the latent layers L 2 and L ′ 2 , thus this problem can be solved as a linear programming using off-the-self solvers.</p><p>Nevertheless, to utilize the sparse structure in the problem and speed up the implementation, we solve the problem by using a tailored version of Iteratively Reweighted Least Squares (IRLS) <ref type="bibr" target="#b8">[9]</ref>. With IRLS, one can also adapt the formulation to different priors readily, e.g., replacing ℓ 1 -norm with ℓ p -norm (0 &lt; p &lt; 1). Details of our IRLS variant can be found in the Supplementary Material.</p><p>Use of color images. The above formulations can be easily extended to color RGB images. With color images, the double-layer BCC term E B and layer regularization term E L will be evaluated at R-G-B channels separately. The flow fields U and V are shared by all three channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Update the flow fields U and V</head><p>Given current layer estimates L 2 , L ′ 2 , and L 1 = I − L 2 , L ′ 1 = I ′ − L ′ 2 , the next step is to update the associated two flow fields U and V. This is done by solving the following optimization problem:</p><formula xml:id="formula_22">min U,V L 1 (X) − L ′ 1 (X + U) + L 2 (X) − L ′ 2 (X + V) + λ F ( U TGV k + V TGV k ) .<label>(19)</label></formula><p>The computations for these two flow fields are in fact separable. This can be easily seen from the above optimization, as the cost function can be expressed as the sum of two terms, each of which can be solved in isolation, i.e., given</p><formula xml:id="formula_23">{L 1 , L ′ 1 , L 2 , L ′ 2 }, solve min U L 1 (X) − L ′ 1 (X + U) + λ F U TGV k ,<label>(20)</label></formula><formula xml:id="formula_24">min V L 2 (X) − L ′ 2 (X + V) + λ F V TGV k .<label>(21)</label></formula><p>To solve the above optical flow problems, we use quadratic relaxation and introduce an auxiliary flow field to decouple the BCC term and regularization term, similar to <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>To solve the resulting TV-L 2 (a.k.a. the ROF model) and TGV 2 -L 2 problem, we apply the primal-dual method of <ref type="bibr" target="#b7">[8]</ref> which is GPU-friendly. Details of our algorithm and implementation can be found in the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Results</head><p>In this section, we validate the proposed model and framework, and evaluate the performance of our method. We report the experimental results on both synthetic data and real images (e.g. Middlebury <ref type="bibr" target="#b1">[2]</ref> and Sintel <ref type="bibr" target="#b6">[7]</ref> flow datasets, and the reflection dataset in <ref type="bibr" target="#b20">[21]</ref>).</p><p>Initialization. Being an alternated method, the proposed algorithm requires an initialization to start the alternation. One can start from either an initial optical flow estimation or from an initial layer separation. The latter one is used in our experiments, and the initialization details will be given later in the experiments.</p><p>Parameters. In the following experiments, the weights of the priors, i.e. λ L , λ F , are roughly tuned according to the results. Both TV and TGV 2 flow regularizers worked well, consistently improving the accuracy upon initialization. Due to space limitation, in the following we report the results using TV (i.e. k = 1). The results using TGV 2 (i.e. k = 2) can be found in the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Static Foreground Cases</head><p>We start from the simpler case where only background layer L 1 is dynamically changing by an unknown motion field U, while the foreground layer is static (i.e. L 2 ≡ L ′ 2 and V ≡ 0). The task is to estimate flow field U and component layers L 1 , L ′ 1 , L 2 . Again, we would like to emphasize that, even though we call it the "simpler case", to jointly estimate an accurate flow field and recover latent layers remains a challenging task. To the best of our knowledge,   there was no previous method that recovers both a complex dense flow field under transparency/reflection, and separate the two constituting layers. In the following tests, a rather conservative strategy is used to initialize the proposed method: we initiate the static foreground image L 2 to be all zeros. Consequently, in the beginning of the optimization we compute an initial optical flow field naively based on the two input images.</p><formula xml:id="formula_25">(a) Input I (b) Output L 1 (c) Output L ′ 1 (d) Output L 2 (e) Output U (epe 0.29) (f) Naive U (epe 1.01) (g) Input I ′ (h) GT L 1 (i) GT L ′ 1 (j) GT L 2 (k) GT U (l) Oracle U (</formula><formula xml:id="formula_26">(a) Input I (b) Output L 1 (c) Output L 2 (d) Output U (epe 0.30) (e) Naive U (epe 0.61) (f) Input I (g) Output L 1 (h) Output L 2 (i) Output U (epe 0.21) (j) Naive U (epe 0.33)</formula><p>Seeing through rain is a practical situation where measures should be taken to avoid the rain ruining vision systems. In the first test, we first synthesized a scene by superimposing a static rain image over the pair of Dimetrodon in the Middlebury dataset. Gray images were used. As illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>, within about 25 iterations, the optical flow estimation error has been decreased from about 1.0 pixels to about 0.3 pixels. This demonstrates the advantage of our formulation for robust optical flow estimation. The qualitative results are demonstrated in <ref type="figure" target="#fig_1">Fig. 2</ref>.</p><p>Additionally, we overlay the rain image with two color image sequences from the Sintel dataset. We evenly sampled 10 images from the "alley 1", "sleeping 1" , and "sleeping 2" sequences respectively, and <ref type="table" target="#tab_0">Table 1</ref> shows that the proposed method has clearly reduced the mean EPE of initial flows. Two typical results are shown in <ref type="figure" target="#fig_2">Fig. 3</ref>.</p><p>To further test the performance of our method, we synthesized another pair by superimposing the Lena image with the Grove image in the Middlebury dataset. The results are demonstrated in <ref type="figure">Fig. 4</ref>. Again, we obtained a much better optical flow compared to the initial naive optical flow estimate. As for the layer separation results, the portrait of Lena can be hardly seen in the restored grove images.</p><p>In <ref type="figure">Fig. 5</ref> we show the image gradient statistics of the three foreground images used in the above experiments. The experimental results have shown that the proposed method works well on these images with the sparse gradient prior. Whenever available, other strong statistical priors can be incorporated into the optimization framework to further improve the performance. </p><formula xml:id="formula_27">(a) Input I (b) Output L 1 (c) Output L ′ 1 (d) Output L 2 (e) Output U (epe 0.88) (f) Naive U (epe 1.45) (g) Input I ′ (h) GT L 1 (i) GT L ′ 1 (j) GT L 2 (k) GT U (l) Oracle U (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Dynamic Foreground Cases</head><p>In this section, we test the proposed method in the dynamic foreground cases, where the task is that given two frames of input images I and I ′ , recover four component layers L 1 , L ′ 1 , L 2 , L ′ 2 , and two dense motion fields U, V. In the problem of reflection removal, both the background scene and the reflection can be dynamic, which can give rise to such a situation.</p><p>We use two pairs of dynamic reflection scenes from <ref type="bibr" target="#b20">[21]</ref> to test the proposed method on the double-layer optical flow problem. In previous single-flow experiments, we initialize the method with foreground layers being all zero. However, this simple strategy did not work for the double-flow case. No reasonably good flow field could be obtained with this strategy for the background or reflection layer, especially for the reflection layer as its signal is weak. Indeed, the fact that the background layer is much more prominent has been took advantage of by some layer separation methods <ref type="bibr" target="#b20">[21]</ref> <ref type="bibr" target="#b13">[14]</ref> which align the input images with respect to the background layer. To obtain proper initialization, we first ran method of <ref type="bibr" target="#b20">[21]</ref> for initial layer separations 2 , then computed initial optical flows on them.</p><p>The initial and final results are presented in <ref type="figure">Fig. 6</ref>. Vi- sually inspected, the final optical flow fields are smoother and more consistent (see e.g. the results on the back wall in the first example, and results on the floor in the second example). As no ground truth optical flow is available, we use image warping error to quantitatively evaluate the estimated flows. The warping error for a pixel x in L 1 or L 2 is L 1 (x+U(x))−L ′ 1 (x) 2 or L 2 (x+V(x))−L ′ 2 (x) 2 , respectively. We compute the mean warping errors for all pixels on L 1 and L 2 . As shown in <ref type="table" target="#tab_1">Table 2</ref>, our method has significantly reduced the warping error upon the initializations. <ref type="figure">Figure 6</ref> shows the improvements of the reflection removal results upon the initial estimates.</p><p>Discussion. The dynamic foreground case with doublelayer flow estimation is generally much harder than the single-flow case. This is not only because the former has more unknown variables to be solved for, but also due to the difficulties in obtaining a good initialization. Nevertheless, our experiments show that the proposed method consistently improved the reasonable initializations given to it, for both the single-flow and double-flow cases.</p><p>Limitation. The proposed method is better suited for scenarios where the correlation between latent layers and their flow fields are relatively small. It will fail if both the two layers are textureless (as infinite numbers of possible motions exist satisfying the BCC constraints), or they undergo a same motion (thus the original BCC holds and only a single motion field can be extracted).</p><formula xml:id="formula_28">Input I Initial L 1 Final L 1 Initial L 2 Final L 2 Initial U Final U Input I ′ Initial L ′ 1 Final L ′ 1 Initial L ′ 2 Final L ′ 2 Initial V Final V Close-up of initial L 1 Close-up of final L 1 Close-up of initial L ′ 1 Close-up of final L ′ 1 Input I Initial L 1 Final L 1 Initial L 2 Final L 2 Initial U Final U Input I ′ Initial L ′ 1 Final L ′ 1 Initial L ′ 2 Final L ′ 2 Initial V Final V</formula><p>Close-up of initial L 1 Close-up of final L 1 Close-up of initial L ′ 1 Close-up of final L ′ 1 <ref type="figure">Figure 6</ref>: Experimental results on real reflection images. The initial layer separations are estimated by running method of <ref type="bibr" target="#b20">[21]</ref> on the two input images. Visually inspected, the final optical flow fields are smoother and more consistent (see e.g. the results on the back wall in the first example, and results on the floor in the second example). The corresponding warping errors are presented in <ref type="table" target="#tab_1">Table 2</ref>. The close-up images in the third rows show the improvements of the reflection removal results upon the initial estimates. (Best viewed on screen)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Future Work</head><p>This paper has defined the problem of robust optical flow estimation in the presence of possibly moving transparent or reflective layers. To our knowledge, the problem goes beyond the scope of conventional optical flow methods and was not properly investigated before.</p><p>We have presented a generalized double-layer brightness constancy condition as well as an optimization framework to solve this problem. The double-layer brightness constancy condition couples the flow fields and the brightness layers. Encouraging experimental results of optical flow estimation and layer separation on challenging data have been obtained, even though we are using simple priors for them. We hope that this paper can inspire future works to further address this challenging ill-posed problem.</p><p>Our current framework is based on a generative model, which is applied uniformly to both the foreground and background layers. In future, we plan to leverage discriminative models to exploit the differences between the two layers for better layer separation. We also would like to explore some other optical flow priors. One possible strategy is to apply piecewise parametric motion model <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b43">44]</ref>, which provides stronger constraints than general smoothness regularizers such as a TV, and is recently demonstrated to have advanced performances <ref type="bibr" target="#b43">[44]</ref>. Some other issues such as occlusion handling could also be considered.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Convergence of the proposed method. Top: optical flow estimation error (EPE) w.r.t. iterations. Bottom: energy and layer estimation errors w.r.t. iterations. The layer error is evaluated as 1 − N CC(GT L 2 , estimated L 2 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Performance evaluation of the proposed method on a single flow case, where a rain image is superimposed on the Dimetrodon image pair. The estimated flow (e) is significantly better than the initialization (f), a naive optical flow estimate without layer separation. The error evolution curve is shown in Fig. 1. Oracle flow (l) is computed with clean background images (i.e. with ground-truth layer separations). (Best viewed on screen)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Typical results of our method on single-flow cases, where the rain drop image is superimposed on images from the Sintel dataset. For clarity, we only show here the first frame I and its layer separation result. (Best viewed on screen)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Performance evaluation of the proposed method on a single flow case, where the Lena image is superimposed on the Grove image pair. The estimated flow (e) is significantly better than the initialization (f), a naive optical flow estimate without layer separation. Oracle flow (l) is computed with ground-truth L 2 . (Best viewed on screen) Gradient statistics of three used images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Mean flow EPE for the two Sintel image sequences 
superimposed with the static rain image. Oracle flows are 
computed with clean background images. 

Sequence 
Naive flow Our flow Oracle 
"alley1" 
0.49 
0.35 
0.22 
"sleeping1" 
0.80 
0.33 
0.12 
"sleeping2" 
0.26 
0.21 
0.07 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Mean image warping errors (in gray levels) from the double-flow estimation results.</figDesc><table>Image pair Initial results Our final results 
#1 
6.27 
2.55 
#2 
3.86 
1.49 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For brevity, hereafter we use a short-hand notation for functions defined on all pixel coordinates X: a function f (X) should be understood as x∈X f (x), unless otherwise specified.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Method of<ref type="bibr" target="#b20">[21]</ref> takes multiple images as input, with one of them being the reference on which the reflection is to be removed. We apply this method on two images, and run it twice with each image as reference.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Joint motion estimation and layer segmentation in transparent image sequences: application to noise reduction in X-ray image sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Auvray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bouthemy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liénard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Advances in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A database and evaluation methodology for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A threeframe algorithm for estimating two-component image motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Bergen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Burt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hingorani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="886" to="896" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The robust estimation of multiple motions: Parametric and piecewise-smooth flow fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Anandan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding (CVIU)</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="104" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Total generalized variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bredies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kunisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="492" to="526" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">High accuracy optical flow estimation based on a theory for warping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bruhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A naturalistic open source movie for optical flow evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="611" to="625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A first-order primal-dual algorithm for convex problems with applications to imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision (JMIV)</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="145" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Iteratively reweighted algorithms for compressive sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chartrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3869" to="3872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Gradient domain layer separation under independent motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="694" to="701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Nulling&apos; filters and the separation of transparent motions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Simonecelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="738" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Separating reflections and lighting using independent components analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Farid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="262" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Blind separation of superimposed moving images using image statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="19" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Robust separation of reflection from multiple images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2195" to="2202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Computing occluding and transparent motions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rousso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="16" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Skin and bones: Multi-layer, locally affine, optical flow and regularization with transparency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Jepson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="307" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multiple motions from instantaneous frequency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Langley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Atherton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="846" to="849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On transparent motion computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Langley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Atherton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="247" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">User assisted separation of reflections from a single image using a sparsity prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1647" to="1654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning to perceive transparency from the statistics of natural scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zomet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1247" to="1254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploiting reflection change for automatic reflection removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2432" to="2439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Single image layer separation using relative smoothness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2752" to="2759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Simultaneous video defogging and stereo reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-F</forename><surname>Cheong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4988" to="4997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Optical flow constraint equation extended to transparency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pingault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pellerin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Signal Processing Conference</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multi-valued motion fields estimation for transparent sequences with a variational approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramirez-Manzanares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rivera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kornprobst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lauze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INRIA Technical Report</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Separating transparent layers through layer information exchange</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sarel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Separation of transparent layers using focus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Schechner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kiryati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="39" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Simultaneous multiple optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shizawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mase</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="274" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unified computational theory for motion transparency and motion boundaries based on eigenenergy analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shizawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Maze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="289" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Large displacement optical flow computation without warping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Steinbrücker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1609" to="1614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A quantitative analysis of current practices in optical flow estimation and the principles behind them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="137" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Layered image motion with explicit occlusions, temporal consistency, and depth ordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Sudderth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<biblScope unit="page" from="2226" to="2234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Layer extraction from multiple images containing reflections and transparency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Anandan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="246" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Stereo matching with transparency and matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Golland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="517" to="524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Recovering intrinsic images from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Tappen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1459" to="1472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multiple motion estimation and segmentation in transparency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Toro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Medina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="2087" to="2090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Stereo matching with linear superposition of layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="290" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Representing moving images with layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing (TIP)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="625" to="638" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Smoothness in layers: Motion segmentation using nonparametric mixture estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recogniton (CVPR)</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="520" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deriving intrinsic images from image sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="68" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Bayesian estimation of layers from multiple images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wexler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="487" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Modeling blurred video with layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="236" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A computational approach for obstruction-free photography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">79</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Dense, accurate optical flow estimation with piecewise parametric model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1019" to="1027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Intrinsic video and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Garces</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gutierrez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">80</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Extracting smooth and transparent layers from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-K</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-K</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A duality based approach for realtime TV-L1 optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Symposium of the German Association for Pattern Recognition (DAGM)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
