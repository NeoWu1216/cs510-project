<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Field Model for Repairing 3D Shapes *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duc</forename><forename type="middle">Thanh</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technology</orgName>
								<orgName type="institution">Deakin University</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binh-Son</forename><surname>Hua</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Khoi</forename><surname>Tran</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quang-Hieu</forename><surname>Pham</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai-Kit</forename><surname>Yeung</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Field Model for Repairing 3D Shapes *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper proposes a field model for repairing 3D shapes constructed from multi-view RGB data. Specifically, we represent a 3D shape in a Markov random field (MRF) in which the geometric information is encoded by random binary variables and the appearance information is retrieved from a set of RGB images captured at multiple viewpoints. The local priors in the MRF model capture the local structures of object shapes and are learnt from 3D shape templates using a convolutional deep belief network. Repairing a 3D shape is formulated as the maximum a posteriori (MAP) estimation in the corresponding MRF. Variational mean field approximation technique is adopted for the MAP estimation. The proposed method was evaluated on both artificial data and real data obtained from reconstruction of practical scenes. Experimental results have shown the robustness and efficiency of the proposed method in repairing noisy and incomplete 3D shapes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Suppose we are given a set of RGB/RGB-D images of an object captured at multiple viewpoints. The object in the real world (i.e. 3D space) is then re-constructed using some 3D reconstruction algorithm. Ideally, if an object can be observed in RGB/RGB-D images, it can be well reconstructed. However, in reality we have found that the reconstruction often fails even if the RGB/RGB-D data is complete. This is because the matching of the RGB data in structure-frommotion based reconstruction methods (e.g. <ref type="bibr" target="#b13">[14]</ref>) could not be done accurately, specially for objects of uniform colours. For reconstruction methods using depth (e.g. <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b3">4]</ref>), the missing of depth could also cause the incompleteness. We illustrate several cases of this situation in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>Recent advances of 3D acquisition devices and 3D scene reconstruction research <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b3">4]</ref> have enabled large-scale acquisition of 3D scene data and this has raised a demand on 3D data analysis. However, it often happens that the 3D data cannot be obtained at high quality (as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>), even by recent reconstruction methods, e.g. <ref type="bibr" target="#b3">[4]</ref>. Specifically, the 3D surfaces are missing and/or broken and this phenomenon causes difficulties for many sequential tasks such as 3D object detection and recognition <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b35">36]</ref>, shape analysis <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b18">19]</ref>, and scene understanding <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b11">12]</ref>. Repairing missing and broken surfaces thus plays a critical role and deserves in-depth study. In this paper, we focus on repairing incomplete 3D shapes. This problem can be also referred to as shape completion. We assume objects are not occluded, i.e. they can be fully observed in RGB/RGB-D images. However, this assumption does not mean that objects can be completely reconstructed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Related Work</head><p>Existing shape completion approaches make use of geometric information represented at either low-level or highlevel. Low-level geometry describes local structures, e.g. local smoothness, and can be used to fill small holes on broken surfaces. For example, Curless and Levoy <ref type="bibr" target="#b4">[5]</ref> proposed to extract surfaces by examining the boundary of unseen and empty voxels. However, this method requires additional range images to carve away redundant surfaces. In <ref type="bibr" target="#b6">[7]</ref>, Davis et al. filled gaps and holes on broken surfaces by performing a convolution on the signed distance values. This process was repeated until a new implicit surface could be defined at the gaps. In <ref type="bibr" target="#b15">[16]</ref>, a broken object was represented in an octree grid on which inner and outer grid points were determined. The broken object was then constructed by contouring the grid points. In <ref type="bibr" target="#b28">[29]</ref>, holes on a broken object were filled by local patches (on the same object) best suiting to be pasted at the holes. This method implicitly assumed there were local structures similar to the missing parts at holes. In <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr">Kazhdan et al.</ref> proposed to interpolate surfaces by fitting surfaces with gradients that could be transformed into a continuous vector field in 3D. This method was then extended in <ref type="bibr" target="#b17">[18]</ref> in which constraints at the location of 3D points were incorporated in construction of surfaces. In general, methods using low-level geometric features solely rely on the smoothness constraint, they could potentially resolve small gaps but dare not able to recover large missing parts.</p><p>High-level geometric information can be represented via 3D object models. The object models can be predefined using CAD model databases, e.g. <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b30">31]</ref>. Alternatively, the object models can be constructed based on 2D image segmentation, e.g. <ref type="bibr" target="#b26">[27]</ref>, or 2D object detection. For example, in <ref type="bibr" target="#b5">[6]</ref>, image-based object detection method <ref type="bibr" target="#b7">[8]</ref> was used to detect the 2D image of an object model, the 3D model was then computed and the pose was estimated. The model was then incorporated into the SLAM system. Recently, Wu et al. <ref type="bibr" target="#b35">[36]</ref> proposed to learn the shape model via a convolutional deep belief network. The network was trained on a huge training set of 3D CAD models and then used to recognise and complete broken shapes. Although object-based knowledge could show more advantages compared with low-level geometry information, existing methods of this approach use only 3D models to recover incomplete shapes. This manner holds two limitations. First, the shape repaired using this approach is formed by the predefined/trained 3D models and thus may not represent the real data. Second, RGB data contains rich and useful information (i.e. multi-view data) but is not exploited in shape completion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Contributions</head><p>To overcome the above issues, we propose a robust and efficient shape repairing method integrating both geometry and multi-view appearance information. In particular, the contributions of the paper include,</p><p>• We propose a Markov Random Field (MRF) model for representing 3D shapes. The pairwise priors in the MRF model capture local geometrical structures of the shape and can be learnt using a convolutional deep belief network. The likelihoods are constructed from the multi-view RGB data which is used to verify the consistency of 3D points in various viewpoints.</p><p>• We propose a new formulation of shape repairing via maximum a posteriori (MAP) estimation in the MRF model and an efficient inference method for MAP estimation using variational mean field approximation. • We benchmark a new 3D object dataset including objects present in different levels of incompleteness. Compared with existing datasets, e.g. 3D warehouse, SUN database <ref type="bibr" target="#b36">[37]</ref>, our dataset is more enriched. It includes the 3D models, 2D images captured at various viewpoints, and the 2D-3D correspondences. We will release the dataset to the public as an effort to advance the future research.</p><p>The remainder of the paper is organised as follows. Section 2 presents the MRF model and formulates the problem of shape completion. The variational method used for approximation of the MAP estimation is then presented in Section 3. Experimental results and comparisons are reported in section 4. Section 5 concludes the paper with remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Problem Formulation</head><p>Let S be a 3D shape reconstructed from a sequence of images captured at multiple viewpoints. The shape S can be broken (due to missing data) and/or rough (due to the alignment error of the 3D reconstruction method). We represent the geometric information of the shape S in a 3D voxel grid (see <ref type="figure" target="#fig_1">Fig. 2</ref>).</p><p>Let G(V, E) denote an MRF in which V is the set of voxels in the grid and and E is the set of edges connecting the voxels. Each voxel v i ∈ V is associated with a label l i ∈ {0, 1}, l i = 1 if v i is a voxel of S and l i = 0, otherwise. Similarly to the lattice structure often used in MRFs for 2D image segmentation <ref type="bibr" target="#b1">[2]</ref>, for each v i , we consider a set of its 4-connected voxels in the voxel grid; there are 6 neighbours of each voxel (i.e. 4-connected voxels of v i in a 3 × 3 × 3 cube centred at v i ). The label node l i of v i is then connected to the label nodes of the 4-connected voxels of v i . ration L is object-specific and modelled via the probability p(L) (also called prior). As conventionally defined in binary MRFs, p(L) can be expressed in the form of Gibbs distribution as</p><formula xml:id="formula_0">p(L) = 1 Z (vi,vj )∈E ψ i,j (l i , l j ) vi∈V ψ i (l i )<label>(1)</label></formula><p>where ψ i,j and ψ i are respectively the potentials functions and Z is a normalisation factor (partition function).</p><p>In <ref type="bibr" target="#b34">[35]</ref>, the prior p(L) was used to model a single object class (e.g. pedestrian). However, a single prior is weak to model multiple object classes. In our problem, we construct a multi-model prior p(L m ) representing different object types m (e.g. furniture objects). Motivated by the robustness of deep structures in multi-class object recognition <ref type="bibr" target="#b10">[11]</ref>, the convolutional deep belief network (CDBN) proposed in <ref type="bibr" target="#b35">[36]</ref> is adopted to construct the shape prior p(L m ) in our MRF. The CDBN is enriched by learning from a large set of 3D computer graphics CAD models and thus able to cover many possible object classes. In particular, the reconstructed shape S is fed through the pre-trained CDBN to retrieve a set M of matching models. Note that the set M may have more than one model since S is not complete and/or may not exactly match with a unique model. For example, the missing parts of a shape S may be due to the misalignment between image frames used to construct S and those missing parts may be replaced by different parts from different models due to the variation of S. However, each retrieved model m ∈ M is a complete shape in which unobserved voxels are predicted by the CDBN trained on various 3D CAD models. <ref type="figure" target="#fig_2">Fig. 3</ref> shows several results of the CDBN applied on the broken table presented in <ref type="figure" target="#fig_1">Fig. 2</ref>.</p><p>To make the models m adaptive to small variations of the true shape, we extend the 2D Distance Transform in <ref type="bibr" target="#b8">[9]</ref> to the 3D domain and apply it on the models m. <ref type="figure" target="#fig_3">Fig. 4</ref> shows two 2D slices across the 3D Distance Transform computed on a result of the CDBN in <ref type="figure" target="#fig_2">Fig. 3</ref>. By using the Distance Transform, the prior p(L m ) is not restricted to the models m but allows an extent of m. This idea is similar to the 2D shape band proposed in <ref type="bibr" target="#b0">[1]</ref>. In particular, we define,</p><formula xml:id="formula_1">ψ m,i,j (l i , l j ) ∝ exp αf (D m (i), D m (j))l i l j (2)</formula><p>where α &gt; 0 is a user-defined parameter, D m (i) is the value of the Distance Transform of the model m at voxel v i , and f (D m (i), D m (j)) is some activation function representing the co-occurrence of l i and l j . A low value of D m (i) indicates that v i is close to m and vice versa. <ref type="formula">(2)</ref> in the principle that locations close to the model m should have higher value of ψ m,i,j (l i , l j ) than ones far from m. Indeed, if v i and v j are truly empty voxels, D m (i) and D m (j) would have high value and</p><formula xml:id="formula_2">The activation function f (D m (i), D m (j)) is defined as, f (D m (i), D m (j)) = −1 1 + e − √ D 2 m (i)+D 2 m (j) + ǫ (3) where 0.5 &lt; ǫ &lt; 1. The function f (D m (i), D m (j)) is used to regulate the pairwise prior ψ m,i,j (l i , l j ) in</formula><formula xml:id="formula_3">−1 1+e − √ D 2 m (i)+D 2 m (j) → −1. Thus, f (D m (i), D m (j)) &lt; 0, i.e. ψ m,i,j (1, 1) &lt; 1 = ψ m,i,j (0, 0)</formula><p>. In other words, ψ m,i,j (l i , l j ) would attain high value when l i and l j are considered as empty voxels. Note that when <ref type="formula">(3)</ref> is a variant of the Mahalanobis distance in which the covariance matrix is diagonal and the standard deviation is set to 1.</p><formula xml:id="formula_4">l i = l j = 1, D 2 m (i) + D 2 m (j) in</formula><p>In contrast, if v i and v j are close to m (or even if they are the voxels of m), D m (i) and D m (j) would tend to 0 and f (D m (i), D m (j)) would become &gt; 0, i.e. ψ m,i,j (1, 1) &gt; 1 = ψ m,i,j (0, 0). In other words, the prior in this case is in favour of considering v i and v j as foreground voxels.</p><p>In a similar way, we define the potential ψ m,i in (1) through an activation function g(D m (i)) as follows,</p><formula xml:id="formula_5">ψ m,i (l i ) ∝ exp βg(D m (i))l i<label>(4)</label></formula><p>where β &gt; 0 and</p><formula xml:id="formula_6">g(D m (i)) = −1 1 + e −Dm(i) + ǫ<label>(5)</label></formula><p>As in conventional MRFs, the likelihood functions p(v i |l i ) can be computed based on the observation data which is the RGB images in our case. Specifically, the likelihoods p(v i |l i ) are defined based on the consistency of the image appearance observed at different viewpoints as follows. Let I i = {I 1 , I 2 , ...} be the set of images on which v i can be observed. Assume that the images in I i are ordered in time and the difference in the camera's tilt of two adjacent images I j and I j+1 is about an angle θ. Such sets I i can be determined given the temporal sequence of input frames and the camera pose estimated during the reconstruction.  Let x i,j denote the corresponding pixel of v i on an image I j ∈ I i . A local image region R(x i,j ) centred at x i,j on I j is then determined. On R(x i,j ), we extract a histogram of oriented gradients (HOG) <ref type="bibr" target="#b2">[3]</ref>, denoted as h R(xi,j ) . The HOG captures the local appearance of the region R(x i,j ). It is expected that if v i is a foreground voxel, then the HOGs extracted at regions R(x i,j ) and R(x i,j+1 ) on adjacent frames I j and I j+1 should be consistent. However, to achieve this, adjacent frames I j and I j+1 need to be sampled so that they are not very far yet not too close to each other. This is because, when I j and I j+1 are too far from each other, a foreground voxel would even have quite different HOGs on those frames. On the other hand, if I j and I j+1 are too close, an empty voxel even would have very similar HOGs on those frames. In our experiment, we use an angle θ to sample images I j . The likelihood p(v i |l i ) is computed as,</p><formula xml:id="formula_7">p(v i |l i ) ∝ exp −γ |I i | − 1 |Ii|−1 j=1 d(h R(xi,j ) , h R(xi,j+1) )<label>(6)</label></formula><p>where γ &gt; 0 and d(h R(xi,j ) , h t R(xi,j+1) ) is the χ 2 -distance between two HOGs h R(xi,j ) and h R(xi,j+1) . Note that p(v i |l i ) does not depend on m. <ref type="figure" target="#fig_4">Fig. 5</ref> illustrates the computation of the likelihoods using multi-view RGB data.</p><p>Given the likelihoods p(v i |l i ) and prior p(L m ) defined for each model m, the problem of repairing the shape S is to find the optimal L * such that</p><formula xml:id="formula_8">L * = arg max Lm∈{0,1} |V | max m∈M p(L m |V ) ∝ arg max Lm∈{0,1} |V | max m∈M p(V |L)p(L m ) = arg max Lm∈{0,1} |V | max m∈M vi∈V p(v i |l i ) p(L m )<label>(7)</label></formula><p>where p(V |L m ) is replaced by p(V |L) since p(v i |l i ) does not depend on m, and, similarly to conventional MRFs, it is assumed that p(V |L) = vi∈V p(v i |l i ).</p><p>The problem defined in <ref type="formula" target="#formula_8">(7)</ref> is to find the best model m ∈ M that is used as the prior to maximise the posteriori p(L m |V ) (i.e. the MAP inference). Since the MRF model can have cycles, the inference in (7) cannot be solved by using exact inference methods (e.g. <ref type="bibr" target="#b20">[21]</ref>). In addition, a brute-force inference would be intractable due to exponential complexity. To overcome this issue, variational approach is adopted in the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Variational Mean Field</head><p>Variational methods have shown their power as a robust approximation approach applied successfully in various computer vision tasks, e.g. human detection <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref>, object tracking <ref type="bibr" target="#b21">[22]</ref>, template matching <ref type="bibr" target="#b22">[23]</ref>. In the context of graphical models, e.g. MRF <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b32">33]</ref>, the core idea of the variational approach is to approximate the posteriori </p><p>where H(Q(L)) is the entropy of Q(L), E Q(L) {·} is the expectation with respect to Q(L).</p><p>Since KL is non-negative, J(Q) is bounded by log p(V ) and thus maximising J(Q) is equivalent to retrieving both the desired marginal (i.e. p(V )) and the posteriori Q * (L). Indeed, if Q * = p(L|V ), J(Q * ) will reach the maximum. In this paper, we represent Q in the form of full factorisation (e.g. dropping edges in a Boltzmann graph) as,</p><formula xml:id="formula_10">Q(L) = |V | i=1 Q i (l i )<label>(9)</label></formula><p>where Q i (l i ) is the variational distribution of l i .</p><p>As defined in <ref type="formula">(2)</ref> and <ref type="formula" target="#formula_5">(4)</ref>, ψ m,i,j (l i , l j ) and ψ m,i (l i ) are expressed in the form of a Boltzmann distribution. Thus, we can write,</p><formula xml:id="formula_11">Q i (l i ) = µ li i (1 − µ i ) (1−li)<label>(10)</label></formula><p>where µ i , i ∈ {1, ..., |V |} are computed via mean field equations <ref type="bibr" target="#b14">[15]</ref> as follows,</p><formula xml:id="formula_12">µ i = p(v i |l i = 1)k i p(v i |l i = 0) + p(v i |l i = 1)k i<label>(11)</label></formula><p>where p(v i |l i ) is defined in <ref type="formula" target="#formula_7">(6)</ref> and</p><formula xml:id="formula_13">k i = exp vj ∈N (vi) αf (D m (i), D m (j))µ j + βg(D m (i))<label>(12)</label></formula><p>where N (v i ) is the set of neighbouring voxels of v i . As shown in <ref type="formula" target="#formula_0">(11)</ref> and <ref type="formula" target="#formula_0">(12)</ref>, µ i is updated locally based on the neighbouring nodes in N (v i ) and the update is performed iteratively to increase J(Q) which is finally computed as,</p><formula xml:id="formula_14">J(Q) = i H(Q i ) + i,j αf (D m (i), D m (j))µ i µ j + i βg(D m (i))µ i + i (1 − µ i ) log p(v i |l i = 0) + i µ i log p(v i |l i = 1) − log Z<label>(13)</label></formula><p>where H(Q i ) is the entropy of the individual variational distribution Q i and H(Q) = i H(Q i ) due to the full factorisation of Q. The estimation of J(Q), as shown in <ref type="formula" target="#formula_0">(13)</ref>, requires the computation of Z, which again takes an exponential complexity. However, the optimisation of J(Q) can be done without involving Z by using an alternative objective function J(Q) = J(Q) + log Z. Once the optimal variational distribution Q * has been obtained, it can be used to approximate p(L|V ). In particular, since Q is fully factorised, we can approximate</p><formula xml:id="formula_15">p(L * |V ) ≈ |V | i=1 Q i (l * i )<label>(14)</label></formula><p>where l * i = arg max li Q i (l i ). Applying <ref type="bibr" target="#b13">(14)</ref> on the models m, the optimal configurations L * m with respect to m can be determined. The final configuration L * in <ref type="formula" target="#formula_8">(7)</ref> is then selected as L * m which achieves the maximum of p(L * m |V ) over all models m.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation Details</head><p>We adopted the CDBN in <ref type="bibr" target="#b35">[36]</ref> for learning and extracting the shape models m ∈ M as follows. The CDBN represents a shape in a 24 × 24 × 24 volume with 3 voxel-pad for every dimension (resulting in a 30 × 30 × 30 grid). The CDBN sequentially consists of three convolutional layers, one fully connected layer and one final layer (with 4000 hidden units as a combination of Bernoulli variables). In the network, each convolution filter is connected to all features returned by the previous layer. The CDBN was trained on the ModelNet dataset <ref type="bibr" target="#b35">[36]</ref> including 3D CAD models from various sources such as 3D warehouse, SUN database <ref type="bibr" target="#b36">[37]</ref>, etc. Training the CDBN was conducted in a layer-wise fashion and refined using a fine-tuning method. Readers are referred to <ref type="bibr" target="#b35">[36]</ref> for the details of the network architecture and training procedure.</p><p>Given the well-trained CDBN, a test shape is fed into the network. Voxels that belong to the object surface are set to 1 (i.e. observed voxels in the CDBN), those which are empty are set to −1 (i.e. unknown voxels in the CDBN). The CDBN then results in a set of labels using Gibbs sampling; labels 1 for foreground voxels and 0 for free space voxels. Note that the labelling is performed using only the geometric information learnt from the 3D CAD models while the appearance information from the RGB data is not taken into account. We initialise the sampling with 9 different random configurations of labels and obtain 9 labelling results. Those results are considered as the shape models (i.e. |M| = 9). <ref type="figure" target="#fig_2">Fig. 3</ref> shows some results of the CDBN applied on the table in <ref type="figure" target="#fig_1">Fig. 2</ref>. Note that the results may not capture the true shape of the table since only geometric information is used.</p><p>The 3D Distance Transforms are then applied on the results of the CDBN to compute the potentials ψ m,i,j (l i , l j ) and ψ m,i . In our implementation, we set α = 10 and ǫ = 0.7 in (2), β = 30 in (4). To compute the likelihoods p(v i |l i ) in (6), we sample the RGB frames so that the angle between two consecutive frames is about 30 • (with a deviation of 5 • ). In addition, the HOGs are extracted on image regions of size 33 × 33 in relative to a 640 × 480 frame captured at about 1.2 metres from the object. This information is computed from the camera pose information. Each image region is divided uniformly into 4 sub-regions on which the HOGs are extracted. Those HOGs are then concatenated. Similarly to <ref type="bibr" target="#b2">[3]</ref>, we quantise the oriented gradients into 9 bins and compute the HOGs (of 9 bins) for 4 sub-regions to form a 36-dimensional HOG for an image region. We set γ = 10 in (6). We have experimented those parameters with various values and found that the performance was not sensitive to the changes while these settings gave good performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chair</head><p>Monitor Sofa Table <ref type="figure">Figure 6</ref>. Some samples of our dataset: Complete 3D reconstructed model (left) and RGB images captured at different viewpoints.</p><p>For the variational mean field method, we set the maximum number of iterations to 100. However, we have observed that in our practice that the mean field approximation method could complete the inference in less then 10 iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation</head><p>To evaluate the recovery ability of our proposed method, we benchmark a new 3D object dataset including 77 complete objects. Those objects are captured and reconstructed from indoor scenes. Each object is associated with a set of RGB images used to reconstruct the object. Camera poses are computed and the correspondences between 3D points and 2D pixels are also established. <ref type="figure">Fig. 6</ref> shows some examples of complete objects in our collected dataset.</p><p>Each complete object is then degraded by randomly removing the 3D points. The removal is performed at 9 different levels varying from 10% to 90% of the original 3D points. In total, there are 77 × 9 = 693 objects created. In addition to the synthetic data, we also collect 10 incomplete objects reconstructed from realistic data. <ref type="figure" target="#fig_6">Fig. 7</ref> illustrates several samples of our dataset.</p><p>To measure the performance of shape completion, Sung et al. <ref type="bibr" target="#b30">[31]</ref> proposed two metrics: accuracy vs completeness. The accuracy measures the percentage that completed points can be matched with ground-truth points while the completeness measures the percentage that ground-truth points (after removed to create the synthetic data) can be recovered. In <ref type="bibr" target="#b30">[31]</ref>, a match is confirmed by thresholding the distances between completed points and ground-truth points. In this paper, we use the inaccuracy vs incompleteness as shape completion measures. However, instead of thresholding the distances, we directly use them in calculating the inaccuracy and incompleteness. In particular, the inaccuracy is the average of the distances from completed points to nearest ground-truth points. Similarly, the incompleteness is the average of the distances from groundtruth points to completed points. In contrast to the accuracy and completeness, the inaccuracy and incompleteness favour small distances. In other words, the smaller the inaccuracy/incompleteness is, the better the shape completion is. To efficiently compute the distances, the 3D Distance Transform is used. <ref type="figure" target="#fig_7">Fig. 8</ref> shows the performance of our proposed method under varying levels of shape incompleteness. In this experiment, complete shapes are used as the ground truth while degraded shapes are considered as the inputs. As shown in <ref type="figure" target="#fig_7">Fig. 8</ref>, both the inaccuracy and incompleteness increase accordingly to the levels of shape degradation. However, while the inaccuracy gradually changes, the incompleteness shows a significant increase. <ref type="figure" target="#fig_8">Fig. 9</ref> illustrates several completion results of our method.</p><p>For the current implementation, we experiment our method for 30×30×30-voxel objects. However, the method is adaptive to any resolutions specified by 3D shape models. We could also apply tensor voting techniques, e.g. <ref type="bibr" target="#b33">[34]</ref>, to interpolate normals in higher resolutions. We consider this Synthetic data. The most left column represents complete shapes (ground-truth).</p><p>Realistic data  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison</head><p>In addition to evaluation, we also compare our method with other existing methods. In particular, we evaluate the ShapeNets <ref type="bibr" target="#b35">[36]</ref>, a recent shape completion method using high-level geometric information learnt from CAD models. For methods using low-level geometric information, we evaluate the Screened Poisson Surface Reconstruction (SPSR) <ref type="bibr" target="#b17">[18]</ref> 1 (which is shown to perform better than its original work in <ref type="bibr" target="#b16">[17]</ref>) and the PolyMender <ref type="bibr" target="#b15">[16]</ref> 2 . Since the <ref type="bibr" target="#b0">1</ref> The SPRS is available in MeshLab and its implementation can be found at http://www.cs.jhu.edu/˜misha/Code/ PoissonRecon/Version8.0/ 2 Binary code is available at http://www.cse.wustl.edu/ taoju/code/polymender.htm work in <ref type="bibr" target="#b17">[18]</ref> makes use of gradients, in addition to the geometric information of 3D points, the normals of 3D points were also computed and buffered for use during degrading 3D objects in our dataset.</p><p>For comparison, we use the sum of both the inaccuracy and incompleteness as a single metric. Note that the ShapeNets just results in a set of 9 different shapes for a given incomplete shape. Thus, we apply our method to identify the best matching shape amongst the 9 shapes generated by the ShapeNets. The matching shape is then used for comparison. For the SPSR and PolyMender methods, completed results are voxelised to 30 × 30 × 30. We report the comparison between our method and other existing methods in <ref type="figure" target="#fig_0">Fig. 10</ref>. As shown in the experiments, our method achieves the best performance. Compared with the ShapeNets purely using geometric information, our method shows the potential of multi-view RGB data in dealing with incompleteness. The proposed method also significantly outperforms the SPSR and PolyMender methods which use only low-level geometric information. This shows the benefits of the 3D shape prior in shape repairing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Computational Analysis</head><p>We measure the complexity of the proposed method via the processing time and the number of iterations of the variational inference. Our experiments on an Intel(R) Core(TM) i7 2.10GHz CPU computer with 8.00 GB memory have shown that an incomplete shape could be repaired in about 0.03 seconds and 8.89 iterations. We have also found that both the processing time and number of iterations slightly changed under different levels of shape incomplete-  ness. In fact, those quantities depend on the result of the shape models generated by the ShapeNets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper proposes a method for repairing 3D shapes using both the geometry and multi-view RGB data. The 3D shape is modelled in an MRF in which the priors between hidden nodes are obtained from shape models learnt using a convolutional deep belief network. The consistency of the RGB images of the 3D shape at multiple viewpoints is exploited in the data likelihoods. The problem of repairing an incomplete shape is formulated as the maximum a pos-teriori (MAP) estimation in the MRF model. Variational mean field method is used to approximation the MAP estimation. We benchmark a new 3D object dataset for evaluation of the method. Experimental results on the new dataset have shown the robustness and efficiency of the proposed method. Repairing shapes in higher resolutions would be our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Examples of incomplete shapes after reconstruction using<ref type="bibr" target="#b3">[4]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Proposed MRF model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Fig. 2illustrate the proposed MRF model.Let L = {l i } ∈ {0, 1} |V | be a set of labels. The configu-Results of the CDBN applied on the broken table presented inFig. 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>2D slices across the 3D Distance Transform computed on a result of the CDBN inFig. 3. Darker values represent small distance and vice versa.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Illustration of likelihood computation for a foreground voxel (left) and free space voxel (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>=</head><label></label><figDesc>p(L|V ) by a variational distribution Q via maximising an objective function J(Q) defined as, J(Q) = log p(V ) − KL(Q(L)||p(L|V )) H(Q(L)) + E Q(L) {log p(L, V )}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Some examples of incomplete 3D shapes in our dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Performance of our method under various levels of shape degradation. extension as our future work.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>Some completion results of our proposed method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 .</head><label>10</label><figDesc>Comparison between our method and existing methods.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgement</head><p>Sai-Kit Yeung is supported by Singapore MOE Academic Research Fund MOE2013-T2-1-159 and SUTD-MIT International Design Center Grant IDG31300106. We acknowledge the support of the SUTD Digital Manufacturing and Design (DManD) Centre which is supported by the Singapore National Research Foundation (NRF). This research is also supported by the National Research Foundation, Prime Minister's Office, Singapore under its IDM Futures Funding Initiative.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Shape band: A deformable object detection approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1335" to="1342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised image segmentation using Markov random field models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J W</forename><surname>Rayner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="587" to="602" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Robust reconstruction of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5556" to="5565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A volumetric method for building complex models from range images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="303" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dense reconstruction using 3d object shape priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dame</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">A</forename><surname>Prisacariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1288" to="1295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Filling holes in complex surfaces using volumetric diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Marschner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on 3D Data Processing Visualization and Transmission</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="428" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Object detection with discriminatively trained part based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Distance transforms of sampled functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
		<respStmt>
			<orgName>Cornell Computing and Information Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Surface reconstruction using local shape priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pauly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Symposium on Geometry Processing</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Joint 3D scene reconstruction and class segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Angst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="97" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Tutorial on variational approximation methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
		<respStmt>
			<orgName>MIT Artificial Intelligence Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-view reconstruction preserving weakly-supported surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jancosek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3121" to="3128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An introduction to variational methods for graphical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="183" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Robust repair of polygonal models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="888" to="895" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Poisson surface reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bolitho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Geometry Processing</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="61" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Screened poisson surface reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Shape2pose: Human-centric shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<idno>120:1-120:12</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning part-based templates from large collections of 3d shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Diverdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<idno>70:1- 70:12</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Factor graphs and the sum-product algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Kschischang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Loelinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Info. Theory</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="498" to="519" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Mean field approach for tracking similar objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Medrano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Herrero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Orrite</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="907" to="920" />
		</imprint>
		<respStmt>
			<orgName>CVIU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A novel chamfer template matching method using variational mean field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2425" to="2432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Inter-occlusion reasoning for human detection based on variational mean field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ogunbona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="51" to="61" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An mrf-poselets model for detecting highly articulated humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1967" to="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Example-based 3d scan completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pauly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Giesen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Geometry Processing</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="23" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Simultaneous monocular 2d segmentation, 3d pose recovery and 3d reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">A</forename><surname>Prisacariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="593" to="606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Moving volume kinectfusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Context-based surface completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alexa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="878" to="887" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sliding shapes for 3D object detection in depth images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="634" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Data-driven structural priors for shape completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Angst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mesh based semantic modelling for indoor and outdoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P C</forename><surname>Valentin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Warrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shahrokni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2067" to="2074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Graphical models, exponential families, and variational inference. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A closed-form solution to tensor voting: theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1482" to="1495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">A field model for human detection and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="753" to="765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">SUN database: Large-scale scene recognition from abbey to zoo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Ehinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3485" to="3492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">SUN3D: A database of big spaces reconstructed using sfm and object labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1625" to="1632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Dense scene reconstruction with points of interest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="112" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Simultaneous localization and calibration: Self-calibration of consumer depth cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="454" to="460" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
