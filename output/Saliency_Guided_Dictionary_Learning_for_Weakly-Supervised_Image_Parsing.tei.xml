<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Saliency Guided Dictionary Learning for Weakly-Supervised Image Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baisheng</forename><surname>Lai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information Science &amp; Electronic Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<region>Zhejiang</region>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Gong</surname></persName>
							<email>gongxj@zju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information Science &amp; Electronic Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<region>Zhejiang</region>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Saliency Guided Dictionary Learning for Weakly-Supervised Image Parsing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose a novel method to perform weakly-supervised image parsing based on the dictionary learning framework. To deal with the challenges caused by the label ambiguities, we design a saliency guided weight assignment scheme to boost the discriminative dictionary learning. More specifically, with a collection of tagged images, the proposed method first conducts saliency detection and automatically infers the confidence for each semantic class to be foreground or background. These clues are then incorporated to learn the dictionaries, the weights, as well as the sparse representation coefficients in the meanwhile. Once obtained the coefficients of a superpixel, we use a sparse representation classifier to determine its semantic label. The approach is validated on the MSRC21, PAS-CAL VOC07, and VOC12 datasets. Experimental results demonstrate the encouraging performance of our approach in comparison with some state-of-the-arts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image parsing is a fundamental but challenging problem that aims to predict a semantic label for each pixel in the image. In contrast to conventional fully supervised techniques <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b18">19]</ref>, in recent years, it has been attracting more and more research interest to infer labels from weak supervision, for which expensive pixel-level annotated training samples are not required. So far, various forms of weak supervision, such as image-level tags <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref>, bounding boxes <ref type="bibr" target="#b35">[36]</ref>, and points <ref type="bibr" target="#b22">[23]</ref>, have been taken into account. Considering that image-level tags are the cheapest <ref type="bibr" target="#b22">[23]</ref> and most convenient to obtain, in this paper, we use them to supervise image parsing. This paper formulates our task within the dictionary learning and sparse representation (SR) framework. Previous SR-based works <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref> mainly focus on sparse constraints while using raw image patches for representa- * The corresponding author. tion. In light of the outstanding performance that dictionary learning methods have exhibited in many other applications, we attempt to incorporate this technique to boost parsing performance. However, most discriminative dictionary learning methods <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b9">10]</ref> work in a fully supervised manner. It is a challenge to extend them to weakly supervised data because of the label ambiguities. That is, when image-level tags are given, we only know whether an object is present or not within the image, but without location information. Therefore, we are not able to obtain pixelor superpixel-level training instances to learn dictionary for each semantic class. In order to accomplish the task, we make the following contributions:</p><p>• For weakly supervised discriminative dictionary learning, we design an adaptive scheme to dynamically adjust the weights that a superpixel contributes to each semantic class. For instance, given an image labeled with 'grass' and 'cow', a superpixel within it is not equally important for the learning of 'grass' and 'cow' dictionaries. Instead, the weights are adaptively learned according to some constraints.</p><p>• We introduce a saliency prior to guide the learning of the weights. Intuitively, a saliency map provides us with certain information about foreground and background, which helps to reduce the label ambiguities.</p><p>To make use of saliency, we propose an automatic way to evaluate the confidence for a semantic class to be foreground or background according to the cooccurrence of tags. A linear programming constraint is further formulated for the saliency guided weight assignment. Moreover, the procedure of saliency detection <ref type="bibr" target="#b40">[41]</ref> often considers both local and global contexts within an image. Thus, incorporating the saliency prior implicitly introduces global information into our model.</p><p>• We also incorporate a smoothness prior into our model. This constraint encourages label consistency by enforcing superpixels that are similar in appearance to  <ref type="bibr" target="#b11">[12]</ref> Noisy Image tags Spatial-LTM <ref type="bibr" target="#b2">[3]</ref> Image-level Tags Conditional Random Field MIM <ref type="bibr" target="#b27">[28]</ref> Geometric context dataset GMIM <ref type="bibr" target="#b28">[29]</ref> Zhang et al. <ref type="bibr" target="#b39">[40]</ref> Deep Learning MIL-ILP-seg <ref type="bibr" target="#b21">[22]</ref> ImageNet FCN <ref type="bibr" target="#b18">[19]</ref> DCNN-EM-Adapt <ref type="bibr" target="#b19">[20]</ref> STC <ref type="bibr" target="#b30">[31]</ref> ImageNet + Flickr Russakovsky et al. <ref type="bibr" target="#b22">[23]</ref> Boxes + <ref type="table">Tags</ref>  Xu et al. <ref type="bibr" target="#b34">[35]</ref> Sparse Representation</p><p>BiLayer <ref type="bibr" target="#b14">[15]</ref> BiLayer+Continuity <ref type="bibr" target="#b15">[16]</ref> LAS <ref type="bibr" target="#b16">[17]</ref> Internet image search WSDC <ref type="bibr" target="#b17">[18]</ref> have the same representation coefficients. The incorporation of the smoothness prior benefits both dictionary learning and sparse representation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Image parsing is also named semantic segmentation in many literatures. In this paper, following the way defined in <ref type="bibr" target="#b32">[33]</ref>, we use weakly supervised image parsing to refer those researches that propagate labels from images to pixels. It means that image-level tags (ILT) are available for all images. While most semantic segmentation deal with test images that have no ILT. We hereby briefly introduce fully and weakly supervised semantic segmentation first, and then present parsing works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Fully Supervised Semantic Segmentation</head><p>In these works, pixel-level annotation is available for training. Therefore, traditional fully supervised methods often train parametric <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b10">11]</ref> or non-parametric <ref type="bibr" target="#b12">[13]</ref> classifiers to segment pixels into different semantic categories, and meanwhile Conditional Random Field (CRF) frameworks are commonly employed to ensure label consistency between neighboring pixels. A major problem these methods suffer is that they perform poorly in rare classes if the training set contains unbalanced number of samples.</p><p>Recently, deep learning techniques have been applied to semantic segmentation. Researchers <ref type="bibr" target="#b8">[9]</ref> usually take a network trained in ImageNet <ref type="bibr" target="#b3">[4]</ref> as an initialization and finetune it in semantic segmentation data sets. Due to the use of extra data set and the power of deep structure, these methods demonstrate extremely outstanding performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Weakly Supervised Semantic Segmentation</head><p>Existing works take image-level tags, bounding boxes, or other forms of annotations for weak supervision. They often separate training data from test sets. Different techniques such as latent topic models <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b39">40]</ref>, multiple instance learning <ref type="bibr" target="#b26">[27]</ref>, conditional random fields <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>, as well as deep learning <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b18">19]</ref>, have been applied to training data to learn models for predicting pixel-or superpixellevel labels. When testing a new image, they either adopt an image-level annotator <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b34">35]</ref> to predict the image's tags first, or directly use the trained model to infer labels for superpixels. Due to the lack of ground truth tags in the test set, their performance is limited. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Weakly Supervised Image Parsing</head><p>As mentioned above, methods in this category assume that tags are available for all images. Their spirit is to propagate labels from image-level to pixel-level. Thus, various graph-based label propagation techniques <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34]</ref> have been developed, which construct graphs or hypergraphs over superpixels regarding to k-NN or other criteria. Vertices' labels are propagated concerning superpixel consistency, incongruity and the weak supervision information. Another research line is using sparse representation techniques <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref>. Liu et al. <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref> proposed a bi-layer sparse model, in which each superpixel is sparsely reconstructed via the atomic superppixels selected from very few images. Labels are then propagated from images to the associated superpixels. Other SR-based methods are variant mainly on model construction and label propagation scheme. In contrast to existing SR methods, our work focus on dictionary learning and prior incorporation. <ref type="table" target="#tab_0">Table 1</ref> lists most typical or state-of-the-art methods, whose formulation framework and supervision form are provided. It needs to mention that the distinction between two weakly supervised categories are ignored in some methods. Moreover, the name of each method is taken from their own papers if available, otherwise the authors are listed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem Formulation</head><p>Assume we are given an image collection I = {I 1 , · · · , I i , · · · , I N }. Each image is tagged with a label set Y i , which is a subset of the full semantic labels Y = {1, · · · , N l }. We first segment each image into n i number of superpixels via SLIC <ref type="bibr" target="#b0">[1]</ref> and extract their feature descriptors. All superpixels are then represented by A ∈ R d×Ns , where d is the feature dimension and N s = N i n i is the total number of superpixels. Meanwhile, we detect a saliency map <ref type="bibr" target="#b40">[41]</ref> for each image to guide the learning of our</p><formula xml:id="formula_0">dictionary D = [D 1 , ..., D l , ..., D N l ] ∈ R d×N d , in which D l = [D l1</formula><p>, · · · , D lM ] denotes the dictionary atoms associated with the l-th semantic class, M is the number of atoms for a class, and N d = M · N l . All superpixels are sparsely represented by the dictionary, and the corresponding coefficient matrix is denoted by X ∈ R N d ×Ns . Once we obtain the coefficient matrix, the semantic label of each superpixel is determined by the Sparse Representation Classifier (SR-C) <ref type="bibr" target="#b31">[32]</ref>. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the overview of our algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Weighted Dictionary Learning</head><p>Given all superpixels, the basic dictionary learning problem is formulated as arg min</p><formula xml:id="formula_1">X,D 1 2 A − DX 2 F + λ 1 X 1 ,<label>(1)</label></formula><p>where λ 1 is a parameter for balancing the two terms. In order to take the image-level tags into account, we convert the formulation into the following form arg min</p><formula xml:id="formula_2">X,D 1 2 Ns p=1 A p − Ddiag(V p )X p 2 2 + λ 1 X 1 ,<label>(2)</label></formula><p>in which A p denotes the p-th superpixel; X p is its representation coefficient; diag() transforms a vector into a diagonal matrix; and V p ∈ R N d is a vector indicating whether a dictionary atom is used for representing the superpixel. Thus, it is defined as</p><formula xml:id="formula_3">V p [i] = 1, L(D i ) ∈ Y I(Ap) 0, otherwise .<label>(3)</label></formula><p>Here, V p [i] indicates the i-th element; L(D i ) gets the class of the dictionary atom D i ; I(A p ) denotes the image to which the superpixel A p belong; and Y I(Ap) is the associated label set. The above formulation confines that a superpixel only impacts on the learning of the dictionary atoms which associate with its image-level tags. No matter which labels are tagged, the superpixel contributes to each labeled class equally. However, it is not desirable. For instance, if an image is labeled with 'grass' and 'cow', we wish a superpixel on 'cow' should play a more important role in learning the 'cow' dictionary than 'grass'. To this end, we introduce a dynamic weight vector W p ∈ R N d to replace V p . That is arg min</p><formula xml:id="formula_4">X,D,W 1 2 Ns p=1 Ap − Ddiag(Wp)Xp 2 2 + λ1 X 1 s.t.</formula><p>Wp ≥ 0, Πp(Wp) = 0, Πp(Wp) = 1, p = 1, 2, ..., Ns,</p><p>in which W p is assigned the same as V p except that its nonzero entries are unknown variables summed up to be 1. Here, Π p ( ) is an operator to extract the zero part of a vector; Π p ( ) gets the nonzero entries; and W = [W 1 , · · · , W p , · · · , W Ns ].</p><p>The model defined in <ref type="formula" target="#formula_5">(4)</ref> provides a way to adjust the weights dynamically. It makes possible to assign a higher weight for a superpixel to its 'real' class if more information is included, and thus a more discriminative dictionary can be expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Dictionary Clustering</head><p>Before introducing how to adjust the weights, we first explore the structure of dictionary atoms. We expect that the dictionary atoms associated with the same label should be similar to each other. Thus, the spectral clustering technique <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b17">18]</ref> is employed.</p><p>We define an affinity matrix U D ∈ R N d ×N d as follows to indicate whether two atoms belong to a same class or not.</p><formula xml:id="formula_6">U D (i, j) = 1, L(D i ) = L(D j ) 0, otherwise<label>(5)</label></formula><p>Then, dictionary clustering aims to minimize the term</p><formula xml:id="formula_7">tr(DL D D T ),<label>(6)</label></formula><p>in which tr() represents the trace of a matrix, L D is the Laplace matrix computed by</p><formula xml:id="formula_8">L D = I − B −1/2 U D B −1/2 , and B is a diagonal matrix defined as B ii = N d j=1 U D (i, j).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Saliency Prior</head><p>In this subsection, we introduce how a saliency prior is integrated to guide weight assignment. The use of saliency is motivated by an observation that salient regions in an image are often roughly aligned with foreground objects, as shown in <ref type="figure" target="#fig_2">Figure 2</ref>. This property helps to reduce the ambiguities of superpixel labeling. For instance, in the simplest cases where an image is tagged only with two classes, such as 'cow' and 'grass' in <ref type="figure" target="#fig_2">Figure 2</ref>, we can assign salient regions to be the foreground class 'cow' and the remaining to be the background 'grass' with high confidence. When an image contains multiple classes like 'tree', 'grass', 'sky', 'building', the saliency map at least helps to distinguish between foreground and background classes.</p><p>However, a problem still remains: how to tell if a semantic class is foreground or background. Instead of manually determining it, we propose an automatic way to solve this problem. Let us denote P (L j |L i ) as the probability that label L j occurs in an image conditioned on the occurrence of label L i . This probability can be estimated from a given data set. If P (L j |L i ) &gt; P (L i |L j ), then label L i is more likely to be foreground than L j . The conclusion is based on a phenomenon that a foreground label often presents along with a certain background, while a background label may occur with different foreground objects. For example, 'cow' commonly occurs with 'grass', but 'grass' may occur with 'sheep', 'building', and other classes as well. In this case, we get P (grass|cow) &gt; P (cow|grass) and conclude that 'cow' is more likely to be foreground than 'grass'.</p><p>Thus, we define a foreground-background score to measure the confidence for a label L i to be foreground or background in an image I k . It is</p><formula xml:id="formula_9">f bs(L i , I k ) = − 1 2 + 1 1+exp(−g(Li,I k )) , L i ∈ Y k 0, otherwise (7) where g(L i , I k ) = 1 |Y k | Lj ∈Y k Lj =Li P (L j |L i ) − P (L i |L j ),<label>(8)</label></formula><p>and |Y k | is the cardinality. The range of the score is [−0.5, 0.5], in which a positive value indicates a high confidence to be foreground and a negative value implies background. Now, we design a guidance vector G p ∈ R N d that is The designed guidance vector is used for guiding weight assignment. We propose to minimize arg min</p><formula xml:id="formula_10">Gp[i] =    −f</formula><formula xml:id="formula_11">Wp G T p W p s.t. W p ≥ 0, Π p (W p ) = 0, Π p (W p ).<label>(10)</label></formula><p>It is a linear programming problem that aims to assign large weights to the dictionary atoms associated with the labels having high foreground scores if a superpixel is salient. If a superpixel is on the image boundary, it is treated as background so that large weights are expected for background dictionary atoms. Meanwhile, the superpixels that are neither salient nor on boundary are assigned with equal weights for all tagged labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Smoothness Prior</head><p>The smoothness prior refers that two neighboring superpixels tend to have the same labels if they are similar in appearance and saliency. In the sparse representation framework, we are not able to enforce this constraint directly on the labels as in MRF <ref type="bibr" target="#b27">[28]</ref>. Instead, we confine such superpixels to have the same representation coefficients.</p><p>Let U X ∈ R Ns×Ns denote a weighted affinity matrix. It is defined as follows: <ref type="bibr">)</ref> in which N (A j ) is the neighboring superpixel set of A j . Then, the smoothness constraint is formulated by minimizing tr(XL X X T ),</p><formula xml:id="formula_12">UX(i, j) =    exp(− Ai − Aj 2 2 − S(Ai) − S(Aj) 2 2 ), Ai ∈ N (Aj) 0, otherwise<label>(11</label></formula><p>where L X is the Laplace matrix defined analogously to L D .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">The Proposed Formulation</head><p>In summary, we get the entire model as follows:</p><p>arg min </p><p>where λ 1 , · · · , λ 4 are parameters for balancing the terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Optimization</head><p>Before optimization, we first initialize the dictionary D and the weight matrix W as follows. Based on the definition in Eq.(9), we know that a small G p [i] value indicates a high confidence for superpixel A p belonging to the L(D i ) class. Therefore, for each class we collect the superpixels of the smallest guidance values and use k-means to cluster them. The obtained centroids are taken as the initial dictionary atoms of the corresponding semantic class. For W, we simply assign normalized equal values for all non-zero entries.</p><p>With above initializations, we then employ an alternating scheme to solve X, D, and W iteratively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Update X</head><p>The superscript t denotes the t-th iteration. At the (t+1)th iteration, we fix D t and W t to solve X t+1 . Thus, the problem in Eq. (13) is turned into the following form:</p><formula xml:id="formula_15">X t+1 = arg min X 1 2 Ns p=1 A p − D t diag(W t p )X p 2 2 + λ 1 X 1 + λ 4 2 tr(XL X X T ).<label>(14)</label></formula><p>It consists of one L 1 term and two quadratic terms. Although the first two terms are separable in column-wise, the trace term is only separable in rows. Therefore this problem can not be solved in column-wise. We thus apply a general method, FISTA <ref type="bibr" target="#b1">[2]</ref>, to solve the whole matrix X. It first computes a gradient step on the terms except the sparse one and then applies a soft-thresholding step on X to get the sparse results, so it is applicable to our model. In addition, FISTA is also efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Update D</head><p>When fixing X t+1 and W t , we update D via solving</p><formula xml:id="formula_16">D t+1 = arg min D Ns p=1 A p − Ddiag(W t p )X t+1 p 2 2 + λ 2 tr(DL D D T ).<label>(15)</label></formula><p>This is a quadratic problem so that we apply L-BFGS <ref type="bibr" target="#b23">[24]</ref> to solve it efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Update W</head><p>We finally fix X t+1 and D t+1 to optimize W. Note that A p − D t+1 diag(W p )X t+1 p 2 2 can be rewritten as</p><formula xml:id="formula_17">A p − (D t+1 • X t+1 p )W p 2 2 , where D • X p = [D 1 X p1 , D 2 X p2 , ...]</formula><p>. Therefore W can be solved column-wisely as below.</p><formula xml:id="formula_18">W t+1 p = arg min Wp 1 2 Ap − (D t+1 • X t+1 p )Wp 2 2 + λ3G T p Wp s.t. Wp ≥ 0, Πp(Wp) = 0, Πp(Wp) = 1,<label>(16)</label></formula><p>This is a standard quadratic programming problem that can be solved via an interior-point-convex algorithm <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Segmentation</head><p>Once we obtain the final coefficient matrix X, the semantic label of each superpixel is determined by the Sparse Representation Classifier (SRC) <ref type="bibr" target="#b31">[32]</ref>. It chooses the label via minimizing the representation residual, i.e. arg min</p><formula xml:id="formula_19">l A p − Ddiag(W p )δ l (X p ) 2 2 .<label>(17)</label></formula><p>Here, δ l (X p ) sets the coefficients that are not associated with the class l to be zero while preserves others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In this section, we conduct a series of experiments to validate and analyze the performance of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Setup</head><p>The experiments are performed on three extensively used datasets: MSRC21 <ref type="bibr" target="#b25">[26]</ref>, PASCAL VOC07, and VOC12 <ref type="bibr" target="#b5">[6]</ref>. Throughout all experiments, we empirically set the involved parameters as follows: λ 1 = 10 −3 , λ 2 = 5 × 10 −1 , λ 3 = 10 −1 , and λ 4 = 10 −2 in Problem (13); T s = 50 and c = 10 −1 in Eq. <ref type="bibr" target="#b8">(9)</ref>. Moreover, the number of dictionary atoms for each class is set to be 30. The number of iterations for updating X, W and D is 5, which is enough for getting converged in almost all images.</p><p>On each dataset, we compare our results to the available results reported in some typical or state-of-the-art methods. Two criteria are used for comparison, which are, respectively, the average per-class accuracy (mAcc) and the average intersection-over-union score (mIOU) <ref type="bibr" target="#b4">[5]</ref>. The former criterion measures the percentage of correctly labeled pixels for each class then averaged over all classes. It is commonly used for previous works to evaluate the performance on MSRC21 and VOC07. The mIOU is a standard measure for segmentation evaluation in PASCAL VOC12 challenges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Experiments on MSRC</head><p>The MSRC21 dataset contains 591 images, accompanied by ground-truth segmentations of 21 classes. The scenarios range from simple objects to complicated road scenes. The average number of tagged labels is about 3.</p><p>We first investigate the performance of our saliency guided weight assignment scheme. <ref type="figure">Figure 3</ref> illustrates a typical example, in which the superpixels coming from each class and their weights contributed to all dictionary atoms are presented. In this image, the foreground-background score (fbs) of 'tree', 'building', 'sky', and 'grass' are 0.0277, 0.0035, 0.0018, and −0.0329 respectively. According to Formulation <ref type="bibr" target="#b9">(10)</ref> we know that if a superpixel is salient then its weights are assigned to the class with the largest fbs, like 'tree' in this case, and a boundary superpixel assigns its weights to the class with the smallest fbs, such as 'grass'. With the balance of the representation term, as defined in <ref type="bibr" target="#b15">(16)</ref>, the weights of 'sky' and 'building' superpixels are correctly assigned. Taking the 'building' superpixel as an example, although there are non-zero weights assigned to dictionary atoms of the other classes, the weights of 'building' dictionary atoms are dominant. Moreover, due to the sparse constraint on X, the weights are also learned sparsely. <ref type="figure">Figure 3</ref>. An illustration of superpixels and their weights learned for each label. In the right figures, the x-axis represents the indexes of dictionary atoms. The atoms belonging to 'building', 'grass', 'tree', and 'sky' are marked in red, green, orange, and blue respectively.</p><p>Then, we justify the effectiveness of each prior in our proposed model. We take the full formulation in <ref type="bibr" target="#b12">(13)</ref>, which is named the Saliency Guided Dictionary Learning (SGDL) model, as a reference, and leave the smoothness prior and the saliency prior out step by step. The model without the smoothness prior is referred to as SGDL-Sm and the one without both priors is denoted by SGDL-Sm-Sal. Experiments are conducted on MSRC21 for the three models and compared. <ref type="figure" target="#fig_4">Figure 4</ref> presents some typical examples, from which we gain the following observations: 1) Without the guidance of saliency, the learned dictionary might be wrong even for simple objects, which results in totally wrong labeling results such as shown in the 'sheep' image.</p><p>2) The use of the smoothness prior greatly improves label consistency.</p><p>3) The full model obtains encouraging results in most cases. However, as shown in the last row, if the saliency order of regions do not match the estimated foreground-background scores, we may get wrong labeling results. Quantitative results listed in <ref type="table" target="#tab_2">Table 2</ref> show that S-GDL greatly improves mAcc and mIOU in comparison with SGDL-Sm and SGDL-Sm-Sal.</p><p>We also compare our models to the classical or state-ofthe-art techniques summarized in <ref type="table" target="#tab_0">Table 1</ref>    <ref type="bibr" target="#b13">[14]</ref> 70    <ref type="table">Methods  bkgd  plane  bike  bird  boat  bottle  bus  car  cat  chair  cow  table  dog  horse  motor  person  plant  sheep  sofa  train  tv  mAcc</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experiments on VOC</head><p>We further validate the proposed method on the more challenging PASCAL VOC07 and VOC12 datasets <ref type="bibr" target="#b4">[5]</ref>. The reason of choosing these two datasets is that most previous works have reported experimental results on VOC07 and the recent deep learning approaches are mainly performed on VOC12. VOC07 contains 632 segmented images of 21 labels. VOC12 has the same number of classes but more images. Its training, validation and test sets have 1464, 1449, and 1456 images respectively. We conduct our experiments on the training and validation sets, i.e. 2913 images in total, for evaluation because the ground truth segmentation of the test set is not available. <ref type="table" target="#tab_0">Table 1</ref> presents the quantitative results of our full model, together with comparisons to the classical and state-of-theart methods. It shows that our approach outperforms the others to a great extent, even for k-NN SG+HG <ref type="bibr" target="#b33">[34]</ref> that is comparable to ours on MSRC21.</p><p>The results on VOC12 are also provided in <ref type="table">Table 4</ref>. Among all the methods summarized in <ref type="table" target="#tab_0">Table 1</ref>, only these powerful deep learning techniques published their results on this dataset. Therefore, although these techniques do not use the ground-truth tags and evaluate their results on the val set, we still include their results, only for the purpose of reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we have presented a Saliency Guided Dictionary Learning (SGDL) method to conduct weaklysupervised image parsing. The spectral dictionary clustering, the saliency prior, and the smoothness prior are integrated into our model to learning dictionaries, weights, and sparse representations at the same time. Extensive experiments on three challenging datasets have validated the effectiveness of our approach. Future work will focus on placing a group sparse constraint on the weights so that each superpixel only contributes to less semantic classes. We believe it will improve the performance of our approach further. Moreover, in the current model, some errors in saliency detection are unavoidably propagated to dictionary learning. How to reduce error propagation is also another direction we will take. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Acknowledge</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>The overview of the proposed approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>bs(L(Di), I(Ap)) · S(Ap), S(Ap) &gt; Ts f bs(L(Di), I(Ap)), B(Ap) = 1 −c, otherwise (9) in which S(A p ) is the average saliency value of superpixel A p ; B(A p ) indicates if the superpixel is on the image boundary or not; T s is a threshold; L(D i ) and I(A p ) are defined in Eq.(3); and c is a constant experimentally determined.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Typical examples on MSRC21.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(XLX X T ) s.t.Wp ≥ 0, Πp(Wp) = 0, Πp(Wp) = 1, p = 1, 2, ..., Ns,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Performance comparison of our models on MSRC21. SGDL refers to the entire model, SGDL-Sm is the model leaving the smoothness prior out, and SGDL-Sm-Sal is the one without both prior terms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>92 49 10 10 83 36 82 62 20 52 98 88 48 98 70 75 95 76 43 23 61 -LAS [17] ---------------------67 -BiLayer+Cont[16] ---------------------70 -WSDC [18] ---------------------71k-NN SG+HG[34] 71 89 60 64 57 93 90 76 90 85 95 99 95 83 99 99 66 99 99 34 25</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>This work was supported by State High-Tech Development Plan (863 Program) of China (No. 2014AA09A510), and the Fundamental Research Funds for the Central Universities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 .</head><label>1</label><figDesc>A comparison of related works.</figDesc><table>Supervision Framework 
Method 
Annotation Form 
Using Extra Dataset 

Full 
Conditional Random Field 

TextonBoost [26] 

Pixel-level Annotation 

TextonForest [25] 
HCRF [11] 
NLT [13] 
Deep Learning 
C+ref [9] 
ImageNet 

Weak 

Topic Model 
Li et al. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 .</head><label>2</label><figDesc>Performance comparison on MSRC21.</figDesc><table>Methods 
bldg 
grass 
tree 
cow 
sheep 
sky 
plane 
water 
face 
car 
bike 
flower 
sign 
bird 
book 
chair 
road 
cat 
dog 
body 
boat 
mAcc 
mIOU 

Fully-supervised 
TextonBoost[26] 
62 98 86 58 50 83 60 53 74 63 75 63 35 19 92 15 86 54 19 62 7 58 
HCRF[11] 
80 96 86 74 87 99 74 87 86 87 82 97 95 30 86 31 95 51 69 66 9 75 
Weakly-supervised 
MIM [28] 
12 83 70 81 93 84 91 55 97 87 92 82 69 51 61 59 66 53 44 9 58 67 -
Weakly-supervised + Ground Truth Tags 
WSG</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2</head><label>2</label><figDesc>lists quantitative comparisons. Note that both fully supervised methods and weakly-supervised but without tags methods split the dataset into training and test parts. Their results are evaluated on the test set. While for methods in the category of 'weakly-supervised + Ground Truth Tags', results are on the entire dataset. From the results we see that the proposed approach outperforms both traditional fully supervised techniques and state-of-the-art weakly supervised methods.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 .</head><label>3</label><figDesc>Experimental results on VOC07.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head></head><label></label><figDesc>mIOU Table 4. Experimental results on VOC12 val set.</figDesc><table>Fully-supervised 
TextonForest[25] 
22 77 45 45 19 14 45 48 29 26 20 59 45 54 63 37 40 42 10 68 72 42 -
Weakly-supervised 
Zhang et al. [40] 
75 47 36 65 15 35 82 43 62 27 47 36 41 73 50 36 46 32 13 42 33 45 -
Weakly-supervised + Ground Truth Tags 
WSG[14] 
65 28 20 62 28 46 41 39 60 25 68 25 35 17 35 56 36 46 17 31 20 38 -
BiLayer[15] 
82 24 25 40 25 32 35 27 45 16 49 24 32 13 25 56 28 17 16 33 18 32 -
k-NN SG+HG[34] 41 77 48 87 50 56 48 44 60 27 76 18 38 25 31 52 38 59 31 51 34 47 -
SGDL 
79 65 56 75 67 27 58 56 69 25 54 33 65 67 69 28 45 60 23 67 48 54 31 

Methods 
bkgd 
plane 
bike 
bird 
boat 
bottle 
bus 
car 
cat 
chair 
cow 
table 
dog 
horse 
motor 
person 
plant 
sheep 
sofa 
train 
tv 
mAcc 
mIOU 

Weakly-supervised 
MIL-FCN [19] 
----------------------26 
CCNN[21] 
66 24 18 23 19 36 47 47 47 16 36 22 43 34 45 40 30 33 22 39 36 -35 
MIL-ILP[22] 
73 25 18 23 22 29 40 45 47 12 40 12 45 40 36 35 21 42 17 35 30 -33 
MIL-ILP-seg[22] 
80 50 22 41 35 41 46 52 61 13 51 12 57 53 45 43 31 55 22 39 37 -42 
STC[31] 
85 68 20 61 43 45 68 64 65 15 52 23 58 55 58 61 41 57 23 57 31 -50 
Weakly-supervised + Ground Truth Tags 
SGDL 
68 37 19 32 21 24 49 35 44 13 38 22 45 38 42 29 23 40 23 48 26 60 34 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Slic superpixels compared to state-of-the-art superpixel methods. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Susstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2274" to="2282" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A fast iterative shrinkagethresholding algorithm for linear inverse problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM journal on imaging sciences</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="183" to="202" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spatially coherent latent topic model for concurrent segmentation and classification of objects and scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
	<note>CVPR 2009. IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The pascal visual object classes challenge: A retrospective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="136" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning hierarchical features for scene labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Najman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1915" to="1929" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Preprocessing for quadratic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Programming, Series B</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="95" to="132" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simultaneous detection and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Label consistent k-svd: learning a discriminative dictionary for recognition. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2651" to="2664" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Associative hierarchical crfs for object class image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ladicky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Towards total scene understanding: Classification, annotation and segmentation in an automatic framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2036" to="2043" />
		</imprint>
	</monogr>
	<note>CVPR 2009. IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Nonparametric scene parsing: Label transfer via dense scene alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1972" to="1979" />
		</imprint>
	</monogr>
	<note>CVPR 2009. IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Weakly supervised graph propagation towards collective image parsing. Multimedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="361" to="373" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Label to region by bi-layer sparsity priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM international conference on Multimedia</title>
		<meeting>the 17th ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Label-to-region with continuity-biased bi-layer sparsity priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">50</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Nonparametric label-to-region by search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3320" to="3327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Weakly-supervised dual clustering for image semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2075" to="2082" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Weakly-and semi-supervised learning of a deep convolutional network for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Constrained convolutional neural networks for weakly supervised segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1796" to="1804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">From image-level to pixellevel labeling with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1713" to="1721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">What&apos;s the point: Semantic segmentation with point supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Bearman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>In arXiv</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">minfunc: unconstrained differentiable multivariate optimization in matlab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<ptr target="http://www.di.ens.fr/mschmidt/Software/minFunc.html" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Semantic texton forests for image categorization and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer vision and pattern recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>CVPR 2008. IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Textonboost for image understanding: Multi-class object recognition and segmentation by jointly modeling texture, layout, and context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="23" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Towards weakly supervised semantic segmentation by means of multiple instance and multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vezhnevets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3249" to="3256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Weakly supervised semantic segmentation with a multi-image model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vezhnevets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2011 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="643" to="650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Weakly supervised structured output learning for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vezhnevets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="845" to="852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Von</forename><surname>Luxburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Stc: A simple to complex framework for weaklysupervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semantic graph construction for weakly-supervised image parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Eighth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Weakly-supervised image parsing via constructing semantic graphs and hypergraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Multimedia</title>
		<meeting>the ACM International Conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="277" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Tell me what you see and i will show you where it is</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3190" to="3197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning to segment under various forms of weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fisher discrimination dictionary learning for sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2011 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="543" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Probabilistic graphlet cut: Exploiting spatial structure cue for weakly supervised image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1908" to="1915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Discriminative k-svd for dictionary learning in face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2691" to="2698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Weakly supervised semantic segmentation for social images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2718" to="2726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Saliency optimization from robust background detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
