<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Longitudinal Face Modeling via Temporal Deep Restricted Boltzmann Machines</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><forename type="middle">Nhan</forename><surname>Duong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Software Engineering</orgName>
								<orgName type="institution">Concordia University</orgName>
								<address>
									<settlement>Montréal</settlement>
									<region>Québec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khoa</forename><surname>Luu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">CyLab Biometrics Center</orgName>
								<orgName type="department" key="dep2">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kha</forename><forename type="middle">Gia</forename><surname>Quach</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Software Engineering</orgName>
								<orgName type="institution">Concordia University</orgName>
								<address>
									<settlement>Montréal</settlement>
									<region>Québec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tien</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
							<email>bui@encs.concordia.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Software Engineering</orgName>
								<orgName type="institution">Concordia University</orgName>
								<address>
									<settlement>Montréal</settlement>
									<region>Québec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Longitudinal Face Modeling via Temporal Deep Restricted Boltzmann Machines</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modeling the face aging process is a challenging task due to large and non-linear variations present in different stages of face development. This paper presents a deep model approach for face age progression that can efficiently capture the non-linear aging process and automatically synthesize a series of age-progressed faces in various age ranges. In this approach, we first decompose the longterm age progress into a sequence of short-term changes and model it as a face sequence. The Temporal Deep Restricted Boltzmann Machines based age progression model together with the prototype faces are then constructed to learn the aging transformation between faces in the sequence. In addition, to enhance the wrinkles of faces in the later age ranges, the wrinkle models are further constructed using Restricted Boltzmann Machines to capture their variations in different facial regions. The geometry constraints are also taken into account in the last step for more consistent age-progressed results. The proposed approach is evaluated using various face aging databases, i.e. FG-NET, Cross-Age Celebrity Dataset (CACD) and MORPH, and our collected large-scale aging database named AginG Faces in the Wild (AGFW). In addition, when ground-truth age is not available for input image, our proposed system is able to automatically estimate the age of the input face before aging process is employed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Face age progression presents the capability to predict future faces of an individual in input photos. In most cases, there is only one photo of that individual and we have to predict the future faces, i.e. age progression, or construct the former faces, i.e. age regression or deaging, of that subject <ref type="bibr" target="#b1">[2]</ref>. Face aging can find its origins from missing children when police require age progressed pictures. This problem <ref type="bibr">Figure 1</ref>. Examples of age progression using our proposed approach. Each subject has three images: the input image (left), the synthesized age-progressed face (middle), and the ground truth (right). Our system also can predict the ages of input faces in case these ground-truths are not available.</p><p>is also applicable in cases of wanted fugitives where face age progression is also required. The predominant approach to aging pictures involves the use of forensic artists <ref type="bibr" target="#b31">[32]</ref>. Although forensic artists are trained in the anatomy and geometry of faces, they still can suffer from psycho-cognitive bias that may affect their interpretation of the source face data. In addition, an age-progressed image can differ significantly from one forensic artist to the next. Manual age progression usually takes lots of time and requires the work of numerous professional forensic artists. Therefore, automatic and computerized age-progression systems are important. Their applications range from very sensitive national security problems to tobacco or alcohol stores/bars to control the patron's age and cosmetic studies against aging.</p><p>Synthesizing plausible faces of individuals at different stages in their life is an extremely challenging task, even for human, due to several reasons. Firstly, human face aging is <ref type="bibr">Figure 2</ref>. Processing steps of our proposed method to synthesize the face at ages of 60s given a face at age of <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref> a complicated process since people usually age in different ways. It is non-deterministic and greatly depends on intrinsic factors, i.e. gender, ethnicity and heredity. Moreover, extrinsic factors, i.e. environment, living styles and smoking, have also created various effects to the facial changes and resulted in large aging variations even between people in the same age group. Secondly, facial shapes and textures dramatically change over the long periods. Thirdly, it is very hard to collect a longitudinal face age database that is generative enough to learn an aging model. Currently existing aging databases in the research community are small or unbalanced among genders, ethnicities and age groups. In addition, they are usually mixed with other variations, e.g. expressions and illuminations.</p><p>Automatic face age progression has attracted huge interest from the computer vision community in recent years. There are numerous efforts to model the longitudinal aging process presented in computer vision literature <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b11">12]</ref>. In most conventional methods, linear models, e.g. Active Appearance Models (AAMs) and 3D Morphable Model, are usually adopted to interpret the geometry and appearance of the faces before the aging rules are learned. However, the face aging variations are not only large but also non-linear. It apparently violates the assumption of linear models. Therefore, these age-progression methods meet a lot of difficulties and limitations to interpret these non-linear aging variations.</p><p>Recently, Temporal Restricted Boltzmann Machines (TRBM) <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b33">34]</ref> have gained attention significantly as one of the probabilistic models to accurately model complex time-series structure while keeping the inference tractable. As an extension of Restricted Boltzmann Machines (RBM), the structure of TRBM consists of further directed connections from previous states of visible and hidden units. By this way, the short history of their activations can act as "memory" and is able to contribute to the inference step of visible units. In this structure, multiple factors are learned and interacted to efficiently explain the temporal data. Therefore, TRBM provides the ability to extract more complicated and nonlinear structures in time series data.</p><p>This work presents a novel deep model based approach to face age progression. Instead of synthesizing faces directly from long periods, the long-term aging process is considered as a set of short-term changes and presented us-ing a sequence of faces. The TRBM based model is then constructed to capture the aging transformation between consecutive faces in the sequence. In addition, to enforce the model on the capabilities of aging variations, a set of reference faces that are mainly different in age conditions is generated and incorporated into the model. Then, a set of RBMs based wrinkle models is developed to enhance the wrinkle details in these aging faces. Finally, the facial geometric information of each age group is extracted and adopted to adjust the face shapes. <ref type="figure">Figure 2</ref> illustrates the main processing steps of our proposed system. The novelties of our approach are :</p><p>• The face structure and specific aging features presented in each age group are modeled using RBM. Compared to other linear models, the use of RBMs can help to better interpret the non-linear variations and produce faces with more aging details. In addition, the high-level features extracted from hidden layer can be transferred between RBMs of different age groups for reconstructing a reference face sequence that can benefit the learning process.</p><p>• Together with the reference sequence, the proposed TRBM based model provides an efficient way to capture the aging transformation between faces in different age groups. Similar to RBM, TRBM is more advanced in interpreting the complex and non-linear aging process.</p><p>• Far apart from previous approaches where wrinkles are cloned from an average face or the closest faces of each age group, we propose a machine learning based approach to learn these aging rules, i.e. construct a set of RBMs based wrinkle models for every age group. In this way, the method is able to learn their distributions and generate synthetic wrinkles by sampling from these distributions. As a result, our model is more flexible in producing more wrinkle types.</p><p>• The geometric differences between face shapes in every age group are also taken into account in our system.</p><p>• A large-scale dataset named AginG Faces in the Wild (AGFW) is collected for analysing the aging effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Generally, previous age progression approaches can be divided into two groups, i.e. the anthropology approach and example-based approach.</p><p>In the first group, the main idea is to simulate the biological structure and aging process of facial features such as muscles and facial skins based on theories from anthropometric studies <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>. Inspiring from the 'revise' cardioidal strain transformation, Ramanathan et al. <ref type="bibr" target="#b22">[23]</ref> proposed a physiological craniofacial growth model for age progression. Ramanathan et al. <ref type="bibr" target="#b23">[24]</ref> later introduced an aging model that incorporates both shape and texture variation models. To simulate the geometry changes, the shape transformation models are designed to capture the aging variations of three facial muscles. For the texture model, an image gradient based transformation function is adopted to characterize the facial wrinkles and skin artifacts.</p><p>In the second group, a straightforward idea is to use the age prototypes <ref type="bibr" target="#b25">[26]</ref> defined by the average faces of people in the same age group. Then the age-progressed faces can be produced by adding the differences between the prototypes of the target and the query age groups to the input face. In recent work of Kemelmacher-Shlizerman et al. <ref type="bibr" target="#b11">[12]</ref>, the authors extended this idea with a large-scale collection of images for age prototypes construction. Then illumination normalization and subspace alignment technique are proposed to better handle images with various lighting conditions. Another direction is to represent a face as a set of parameters and learning aging functions from the relationships between these facial parameters and age label. Lanitis et al. <ref type="bibr" target="#b13">[14]</ref> proposed to use AAMs parameters and introduced several aging functions to model both generic and specific aging processes. Pattersons et al. <ref type="bibr" target="#b20">[21]</ref> also used AAMs and aging function in their system. However, they put more efforts on simulating the adult aging stage. The genetic facial features of siblings and parents were also incorporated to age progression in <ref type="bibr" target="#b17">[18]</ref>.</p><p>Geng et al. <ref type="bibr" target="#b7">[8]</ref> proposed an AGing pattErn Subspace (AGES) approach for both age estimation and age synthesis. Tsai et al. <ref type="bibr" target="#b32">[33]</ref> then extended the AGES with the guidance faces corresponding to the subject's characteristics for more stable results. Suo et al. <ref type="bibr" target="#b28">[29]</ref> proposed to decompose a face into smaller components (i.e. eyes, mouth, etc.) and learning the aging process for each component. A threelayer And-Or graph is adopted for face representation. Then the changes in face aging are modeled by a Markov chain on parse graphs. Similarly, in <ref type="bibr" target="#b27">[28]</ref>, Suo et al. further employed this decomposition strategy in temporal aspects where longterm evolution of the graphical representation is learned by connecting sequences of short-term patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Proposed Age Progression Approach</head><p>Our proposed age progression system (as shown in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data Collection</head><p>In order to train the model and to analyze the aging effects, a large-scale dataset named AginG Faces in the Wild (AGFW) 1 is first collected. Moreover, to ensure the consistency of the collected data, the tag names and the agerelated information of these images are also considered. The resulting dataset consists of 18,685 images with the age ranging from 10 to 64 years. It is then decomposed into 11 age groups with the age span of 5 years. On average, each age group consists of 1700 images of different people in the same age group. The Productive Aging Laboratory (PAL) Face database <ref type="bibr" target="#b18">[19]</ref> is also included in our collected dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Preprocessing</head><p>Face Alignment: In order to align all face images in the dataset, a reference shape is extracted from a selected subset of 2,000 face images in the passport style photos, i.e. frontal faces without expressions. All face images in the AGFW dataset are then warped to the texture domain corresponding to this reference shape. The warping step aims to remove the effects of shape variations during the texture modeling step. Finally, we obtain the dense correspondence between all faces in the training data. The DLIB tool <ref type="bibr" target="#b12">[13]</ref> is employed to extract 68 landmarks for each face and the Procrustes Analysis is used to align these face images.</p><p>Expression Normalization: The expressions in the images of each age group are further normalized using the Collection Flow technique <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Reference Sequence Generation</head><p>This section presents how to generate the set of reference faces that are mainly different in age conditions.</p><p>Baseline: A straightforward approach to construct the reference sequence is to order the mean faces of all age groups chronologically. The advantage of using mean faces is that several variations such as identity, occlusion can be removed. However, due to the averaging property, the aging variation is also smoothed out in the mean faces. Therefore, mean faces usually look younger than those from their own age groups. Moreover, it is noted that the lighting presented in the mean faces could be remarkably different from that of the input face. <ref type="figure">Figure 4</ref>(A) shows the unmatched tones between the sequence of mean faces and the input faces.</p><p>Our Improvement using RBMs: Given an input face I at a particular age, instead of using the set of mean faces in all age groups as the reference sequence, a set of RBMs is constructed to model faces in different age groups. The high-level features are then transferred among RBMs to generate the reference faces for I.</p><p>In particular, for each age group k, all images collected at that age group are used to construct an RBM to model the distributions of texture features presented in this age group. Since the texture data is real-valued, the Gaussian-Bernoulli RBM (GRBM) is employed. Once RBMs of all age groups are constructed, given an input face image, its high-level features are first extracted using the RBM of the corresponding age group. These features are then transferred to the hidden layers of other RBMs to reconstruct the faces of other age groups. Gibbs sampling technique is used for this reconstruction stage.</p><p>There are several advantages of using RBMs in this step. Firstly, RBMs can help to model faces in more details comparing to mean faces. Secondly, since each RBM is built for a particular age group, it has the ability to generalize the faces with specific aging features. Therefore, transferring the high-level features between RBMs can generate new faces that consist of both original subject and new aging features. Thirdly, the lighting has implicitly corrected during the reconstruction process. <ref type="figure">Figure 4(A)</ref> illustrates the sequence of mean faces and the RBMs reconstructions by transferring features in six age groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Modeling the Aging Transformation via TRBM</head><p>In order to learn the aging transformation between faces in the sequence, we employ a TRBM with Gaussian visible units. As illustrated in <ref type="figure" target="#fig_0">Figure 3</ref>(A), the model consists of two sets of visible units (i.e. v t , v t−1 ) encoding the texture of current face at age group t and previous face at age group t − 1; and a set of binary hidden units h t that are latent variables. In addition, the faces in reference sequence, s &lt;=t = {s t , s t−1 }, at age group t and t − 1 are also incorporated by the connections to both hidden and visible units.</p><p>The energy of the joint configuration {v t , h t } is formulated as follows. </p><formula xml:id="formula_0">E(v t , h t |v t−1 , s &lt;=t ; θ) = i (v t i − b t i ) 2 2σ 2 i − j h t j a t j − i,j v t i σi Wijh t j (1) where θ = {W, A, B, P, Q, σ 2 , b t , a t }</formula><p>where l is the index of reference faces in sequence s &lt;=t . The probability of v t assigned by the model is given by</p><formula xml:id="formula_2">p(v t |v t−1 , s &lt;=t ; θ) = h t p(v t , h t |v t−1 , s &lt;=t ; θ) = 1 Z h t e −E(v t ,h t |v t−1 ,s &lt;=t ;θ)<label>(4)</label></formula><p>where Z is the partition function. The probability of a sequence with T faces given the first face and the reference sequence s 1:T is defined as Eqn. <ref type="formula" target="#formula_3">(5)</ref>.</p><formula xml:id="formula_3">p(v 2:T |v 1 , s 1:T ; θ) = T t=2 p(vt|v t−1 , s &lt;=t ; θ)<label>(5)</label></formula><p>The conditional distributions over v t and h t are given as</p><formula xml:id="formula_4">p(h t j = 1|v t , v t−1 , s &lt;=t ) = σ i Wij v t i σi + a t j v t i |h t , v t−1 , s &lt;=t ∼ N σi j Wijh t j + b t i , σ 2 i<label>(6)</label></formula><p>Model Properties: With this structure, two types of information can be learned from the model: <ref type="figure">Figure 4</ref>. A comparison between (A) two approaches to generate reference sequences and (B) synthesized aging faces using these two reference sequences. Faces in the red box: the sequence of mean faces in several age groups. Faces in the green box: reference faces generated by transferring features among RBMs of these age groups. Given input images in the age range of 10-14, our system automatically synthesizes a sequence of age-progressed images in various age ranges respectively.</p><p>1. The temporal information presented in the relationship between previous face v t−1 and the current face v t .</p><p>2. The aging information provided by the reference sequence. This type of information acts as guidance information enforcing the model to learn the aging differences rather than other variations. Moreover, in order to transfer the information between faces, both linear and nonlinear interactions are employed in this model. In particular, v t−1 and v t are connected via two pathways: (1) the linear and direct connections using weight matrix B; and (2) the nonlinear connections through the latent variables h t with the weight matrices A and W. Similar to the relationship between v t and s &lt;=t , the direct (with weight matrix P) and indirect (with weights Q and W) connections allow both linear and nonlinear interactions. Notice that except the undirected connections between hidden units h t and visible units v t , all connections are directed. Model Learning: The learning process is to find the model parameters that maximize the log-likelihood:</p><formula xml:id="formula_5">θ * = arg max θ T t=2 log p(vt|v t−1 , s &lt;=t ; θ)<label>(7)</label></formula><p>The optimal parameter values can then be obtained via a gradient descent procedure given by <ref type="bibr" target="#b7">(8)</ref> where E data [·] and E model [·] are the expectations with respect to data distribution and distribution estimated by the TRBM model. The Contrastive Divergence technique <ref type="bibr" target="#b8">[9]</ref> is used for the learning process.</p><formula xml:id="formula_6">∂ ∂θ E log p(vt|v t−1 , s &lt;=t ; θ) = T t=2 Edata ∂E ∂θ −Emodel ∂E ∂θ</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">RBM based Wrinkle Modeling</head><p>Since facial muscles play an important role on the changes of wrinkle appearance during aging process, we make use of the anatomical evidence for wrinkles enhancement. In particular, inspiring from the analysis on the behaviors of facial muscles <ref type="bibr" target="#b23">[24]</ref>, we select the muscles that are more relevant to wrinkle appearance and use their physical positions to extract the wrinkle subregions from the face image. Three chosen subregions are shown in <ref type="figure" target="#fig_3">Figure 5</ref>. A set of RBMs is then employed to learn the distributions of wrinkle appearance for every age group.</p><p>Once RBMs for all subregions and age groups are learned, the wrinkles are enhanced via a two-step process: (1) Generating the wrinkles through a Gibbs sampling process with the learned distributions; and (2) Wrinkle rendering by blending the generated wrinkles with the synthesized faces obtained from the TRBM based texture progression step. The Poisson blending technique <ref type="bibr" target="#b21">[22]</ref> is used for seamless fusion results. <ref type="figure" target="#fig_4">Figure 6</ref> shows the wrinkles enhancement results in three wrinkle regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Shape Adjustment</head><p>To further take into account the changes of shape during aging process, for each age group, we compute the average face shape using the same pipeline as in Section 3.2 with the AGFW dataset. Then the synthesized faces obtained from the previous step are warped to the corresponding face shapes for the final age-progressed result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head><p>In this section, we evaluate the efficiency and flexibility of our proposed system in both age progression and regres- sion applications. We next demonstrate the generality and robustness of our model with "in the wild" data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Databases</head><p>For the training phase, we use two databases: the AGFW dataset collected as presented in section 3.1 and a subset of the Cross-Age Celebrity Dataset (CACD) <ref type="bibr" target="#b5">[6]</ref>. Then two public face aging databases: FG-NET <ref type="bibr" target="#b0">[1]</ref> and MORPH <ref type="bibr" target="#b24">[25]</ref> are employed for evaluation.</p><p>Cross-Age Celebrity Dataset (CACD) provides a largescale dataset with 163446 images and the age ranging from 14 to 62. This dataset is collected from the Internet using keywords formed by the names of 2000 celebrities and the year (i.e. from 2004 to 2013). The annotations for this database are limited with 16 landmarks.</p><p>FG-NET contains 1002 face images of 82 subjects with the age ranging from 0 to 69. In addition, each facial image is annotated with 68 landmark points.</p><p>MORPH provides a large-scale dataset with two albums of passport style images. The MORPH-I includes 1690 images from 515 subjects and the age ranges from 15 to 68. The MORPH-II contains 55134 photos of 13000 subjects. In our experiments, MORPH-I is used for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Age Progression</head><p>In order to train the RBMs for reference sequence generation, the AGFW dataset is decomposed into 11 age groups with the age span of 5 (i.e. age <ref type="bibr">10-14, 15-19, .</ref>.., 60-64). On average, each age group consists of 1700 images. These images are then used for constructing the set of RBMs as represented in Section 3.3. For training the TRBM based age progression component, we select a subset of 572 celebrities from the CACD dataset and also classify their images into 11 age groups with the age span of 5. Then for each person, one image per age group is randomly selected. This process results in a training data with 572 sequences. Since  All training images are then aligned and normalized as presented in section 3.2. The size of the normalized image is set to 95 × 95 pixels based on the reference shape generated in the alignment step. The TRBM based age progression model is then employed to learn the aging transformation between faces. After all components are trained, we run our system on every face over 10 years old of FG-NET and MORPH databases. <ref type="figure" target="#fig_5">Figure 7</ref> illustrates the age-progressed faces reconstructed by our model. Notice that both FG-NET and MORPH databases are not part of our training data.</p><p>Our age-progressed sequences are also compared with the recent age progression work, Illumination-Aware Age Progression (IAAP) <ref type="bibr" target="#b11">[12]</ref> against FG-NET database in <ref type="figure">Fig-Figure 8</ref>. Comparisons between our appproach and other age progression approaches: IAAP <ref type="bibr" target="#b11">[12]</ref>, EAP <ref type="bibr" target="#b26">[27]</ref> and CG <ref type="bibr" target="#b22">[23]</ref>. <ref type="figure">Figure 9</ref>. Comparisons between our approach and IAAP <ref type="bibr" target="#b11">[12]</ref>. For each case, the input face image (1st column) is aligned and normalized to frontal face (2nd column). From the 3rd to the 7th column: the progressed images corresponding to several age groups using our approach (the row above) and IAAP (the row below). ure 9. From these sequences, one can see that IAAP approach synthesizes very similar faces among different age groups. Moreover, since the texture difference between average faces is used as the main source for aging process, the synthesized faces usually look younger than those from their own age groups. Meanwhile, more nonlinear aging features in each age group are still kept in the reconstructed results of our approach. In addition, one can easily see that our age-progressed sequences are able to better reflect the face changes during the aging process (i.e. the appearance of beard in the middle stages and wrinkle in the later stages). For further evaluations, we compare our proposed model with other approaches including IAAP; Exemplar based Age Progression (EAP) <ref type="bibr" target="#b26">[27]</ref> and Craniofacial Growth (CG) model <ref type="bibr" target="#b22">[23]</ref> in <ref type="figure">Figure 8</ref>. The ground truth images are also provided for comparisons. It should be noted that since our model is trained using the collected data with ages ranging from 10 to 64, in cases where the IAAP uses input images at ages less than 5, we choose images of the same individuals with age close to 10 as input for our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Age Progression "in the Wild"</head><p>In order to validate the robustness of our model, in this experiment, we focus on input images that include different variations such as poses, expressions, illuminations. Blurry images are also considered. <ref type="figure" target="#fig_6">Figure 10</ref> illustrates ageprogressed images that are automatically reconstructed by our model. From these results, one can see that although other non-linear variations also present in the input images, <ref type="figure">Figure 11</ref>. Age regression results. For each case, the input image (1st row) is normalized to frontal face (2nd row). From the 3rd row to 5th row: the age-regressed images generated by our model (left) and the ground truth images with the corresponding ages (right).</p><p>remarkable results can still be achieved by our model in terms of fine aging details without any quality reduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Age Regression</head><p>We next emphasize the flexibility of our proposed model by evaluating its capability to generate the younger faces of an individual given his/her current appearance. The results of this application can be easily obtained using our model by simply keeping the same training process as in previous experiments except the training sequences are reversed. The faces at younger ages are represented in <ref type="figure">Figure 11</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Automatic Age Estimation</head><p>One challenge of the face data "in the wild" comes from the age labels of the input images. In most cases, this information is incorrect or unavailable. Thus, it causes lots of difficulties for age progression process in later stage. Far apart from previous age progression systems, the effectiveness and scalability of our proposed model is further increased by integrating an age estimation system to the proposed framework. In this way, given a face image, our system can do age progression without any further information.</p><p>Besides some other previous age estimation approaches <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17]</ref>, in this work, we re-implement the method in <ref type="bibr" target="#b15">[16]</ref> which is among the state-of-the-art age estimators reported in <ref type="bibr" target="#b19">[20]</ref>. Moreover, this approach is modified with three-group classification in the first step (youths, adults, and elders) before constructing three Support Vector Regression (SVR) based aging functions. In order to train this age estimator, we randomly select 802 images from FG-NET and 1000 images from MORPH as the training data. The remaining images of these two databases are used for testing. The Mean Absolute Errors (MAEs) achieved are 5.86 years for FG-NET and 4.84 years for MORPH. By in- corporating this age estimator to our age-progression framework, the need for age label is alleviated and, therefore, making the whole framework fully automatic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Age Accuracy of Age-progressed Results</head><p>This section illustrates the accuracy of our synthesized results in term of age perceived. In other words, this experiment aims at assessing whether the age-progressed faces are perceived to be at the target ages. In this evaluation, the trained age estimation system in the previous experiment is adopted to compare the accuracies on the ground-truth and age-progressed faces. From the testing set of FG-NET database, we select all images above 10 years old and consider them as the ground truth images. This forms the set A consisting of 135 images. Each photo of an individual in set A is then progressed to the later ages where the ground truth faces are available. This process results in the set B of 194 age-progressed images. In order to compare with IAAP method, we apply this process using IAAP and obtain the set B'. For a large scale evaluation, we further generate a test set using MORPH database. Let the test set of MORPH as in section 4.5 be set C. For each individual in the testing data, we synthesize four aged images accross three decades. This gives us 1421 images that compose set D. The MAEs of the age estimation system on these test sets are listed in <ref type="table" target="#tab_0">Table 1</ref>. These results show that the age estimation accuracies of our age-progressed images are comparable to those of ground truth images. Therefore, our proposed model is able to generate the age-progressed faces at the target ages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper has developed a novel deep model based approach for face age progression that can operate "in the wild". With the deep structured models for both face representation and aging transformation modeling, the proposed model can efficiently capture the non-linear aging changes as well as robustly handle other variations such as pose, expressions, and illuminations. The aging rules in terms of wrinkle appearance and geometric constraints are also taken into account for more consistent progression results. Experimental results in both age progression and age regression applications have shown the efficiency, generality and flexibility of our proposed model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>The proposed age progression approach: (A) Temporal Restricted Boltzmann Machines for learning aging transformation in a single node; (B) The proposed system using multiple nodes; wrinkle enhancement and shape adjustment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 3(B)) consists of five main steps: (1) Preprocessing, (2) Reference sequence generation; (3) Texture age progression; (4) Wrinkles enhancement; and (5) Shape adjustment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>are the model parameters. In particular, {W, A, B, P, Q} are the weights of connections as illustrated in Figure 3(A); {σ 2 , b t , a t } are the variance, bias of the visible units and bias of the hidden units, respectively. Notice that the form of this energy function is very similar to the original form of an RBM. However, the bias terms are redefined as:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Wrinkle Model Construction Steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Wrinkle Enhancement. From top to bottom: the synthesized images from the previous step, the results after enhancing eye; eye and cheek; eye, cheek and mouth regions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Age progression results. Given an input image in age range 10-19, the system automatically reconstructs age-progressed images in various age ranges. the images are collected from 2004 to 2013, the longest sequence consists of only three images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 .</head><label>10</label><figDesc>Age progression "in the wild" with other variations in the input images such as poses, illuminations, expressions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 .</head><label>1</label><figDesc>The MAEs (years) of Age Estimation System on Ground Truth and Age-progressed Results</figDesc><table>Inputs 
Dataset MAEs 
Ground Truth faces (set A) 
FGNET 
5.89 
Synthesized faces (set B) 
FGNET 
5.96 
IAAP 's synthesized faces (set B') FGNET 
6.29 
Ground Truth faces (set C) 
MORPH 
4.84 
Synthesized faces (set D) 
MORPH 
5.17 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">This dataset will be published online for later research uses.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fg-Net Aging Database</surname></persName>
		</author>
		<ptr target="http://www.fgnet.rsunit.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A review of the literature on the aging adult skull and face: Implications for forensic science research and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ricanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. Journal of Forensic Science</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A simple method for modeling wrinkles on human skin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kuratate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nishita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 10th Pacific Conference on</title>
		<meeting>10th Pacific Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="166" to="175" />
		</imprint>
	</monogr>
	<note>Computer Graphics and Applications</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Aging of orbicularis muscle in virtual human faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Justo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization, 2003. IV 2003. Proceedings. Seventh International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="164" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Simulation of skin aging and wrinkles with cosmetics insight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Boissieux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Thalmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kalra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cross-age reference coding for age-invariant face recognition and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Beyond principal components: Deep boltzmann machines for face modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">N</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Quach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4786" to="4794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Automatic age estimation based on facial aging patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smith-Miles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2234" to="2240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Investigating age invariant face recognition based on periocular biometrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Juefei-Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biometrics (IJCB), 2011 International Joint Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Collection flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1792" to="1799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Illumination-aware age progression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suwajanakorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3334" to="3341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dlib-ml: A machine learning toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1755" to="1758" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Toward automatic simulation of aging effects on face images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lanitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="442" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Kernel spectral regression of perceived age from hybrid facial features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Face &amp; Gesture Recognition and Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>2011 IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Age estimation using active appearance models and support vector machine regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ricanek</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BTAS&apos;09</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Contourlet appearance model for facial age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biometrics (IJCB), 2011 International Joint Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatic childface age-progression based on heritability factors of familial faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Ricanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BIdS</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A lifespan database of adult facial stimuli</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minear</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="630" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Face recognition vendor test (frvt) -performance of automated age estimation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Ngan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Grother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIST Interagency Report</title>
		<imprint>
			<biblScope unit="volume">7995</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Automatic representation of adult aging in facial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ricanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Boone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IASTED Intl Conf. Visualization, Imaging, and Image Processing</title>
		<meeting>IASTED Intl Conf. Visualization, Imaging, and Image essing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="171" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Poisson image editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gangnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="313" to="318" />
			<date type="published" when="2003" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Modeling age progression in young faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="387" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Modeling shape and textural variations in aging faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FG&apos;08</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Morph: A longitudinal image database of normal adult age-progression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ricanek</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tesafaye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FGR 2006</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="341" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Manipulating facial appearance through shape and color</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rowland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Perrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="70" to="76" />
			<date type="published" when="1995" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Exemplar-based age progression prediction in children faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-W</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><forename type="middle">M</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISM</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="123" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A concatenational graph evolution aging model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2083" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A compositional and dynamic model for face aging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="385" to="401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning multilevel distributed representations for high-dimensional sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="548" to="555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Modeling human motion using binary latent variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1345" to="1352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Forensic Art and Illustration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Human face aging with guided prediction and detail synthesis. Multimedia tools and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-K</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I.-C</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="801" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Facial expression transfer with input-output temporal restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1629" to="1637" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
