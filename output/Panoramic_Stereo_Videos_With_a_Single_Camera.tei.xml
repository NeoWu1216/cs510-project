<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Panoramic Stereo Videos with a Single Camera</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajat</forename><surname>Aggarwal</surname></persName>
							<email>rajat.aggarwal@research</email>
							<affiliation key="aff0">
								<orgName type="department">Kohli Center on Intelligent Systems</orgName>
								<orgName type="institution">International Institute of Information Technology-Hyderabad</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrisha</forename><surname>Vohra</surname></persName>
							<email>amrisha.vohra@research</email>
							<affiliation key="aff0">
								<orgName type="department">Kohli Center on Intelligent Systems</orgName>
								<orgName type="institution">International Institute of Information Technology-Hyderabad</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><forename type="middle">M</forename><surname>Namboodiri</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Kohli Center on Intelligent Systems</orgName>
								<orgName type="institution">International Institute of Information Technology-Hyderabad</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Panoramic Stereo Videos with a Single Camera</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a practical solution for generating 360 • stereo panoramic videos using a single camera. Current approaches either use a moving camera that captures multiple images of a scene, which are then stitched together to form the final panorama, or use multiple cameras that are synchronized. A moving camera limits the solution to static scenes, while multi-camera solutions require dedicated calibrated setups. Our approach improves upon the existing solutions in two significant ways: It solves the problem using a single camera, thus minimizing the calibration problem and providing us the ability to convert any digital camera into a panoramic stereo capture device. It captures all the light rays required for stereo panoramas in a single frame using a compact custom designed mirror, thus making the design practical to manufacture and easier to use. We analyze several properties of the design as well as present panoramic stereo and depth estimation results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The ability to capture and transmit high quality omnidirectional stereo videos enables several applications such as virtual tourism, remote navigation, and immersive entertainment. However, accurate omnidirectional stereo requires the capture of a four-dimensional light-field. Peleg et al. <ref type="bibr" target="#b15">[17]</ref> showed that if we assume the two eyes are restricted to move along a horizontal circle (panoramic stereo), one can create independent 2D panoramic images for each eye that closely reproduces the stereo views for a human. This result theoretically enabled the capture of omnidirectional stereo videos. However, practical systems for capturing stereo panoramic videos are just emerging <ref type="bibr" target="#b0">[1]</ref>.</p><p>In recent years, display devices for stereo panoramas have become ubiquitous with virtual reality (VR) headsets that uses smart phone displays such as Google Cardboard and Samsung GearVR c . Stereo panoramic videos allows * Equal Contribution one to stand at any location in the world and look around as if they were present in the real environment. However, the capture of stereo panoramas currently requires a camera that moves along a circle or a complex synchronized multicamera setup. We aim to develop a simple solution that can capture 360 • stereo panorama using an existing digital camera, thus making the creation process of immersive VR content accessible to a much larger population. The primary challenge here is to capture all the light rays corresponding two sets of cameras (left and right eye views) arranged along the same circle to a single sensor without causing blind spots or occlusions in the optical system. We show for the first time that such an optical system is possible and practical using a set of custom designed reflective surfaces that we refer to as the Coffee Filter Mirror (See <ref type="figure" target="#fig_0">Fig. 1</ref>). We derive the surface equations of the mirror petals and discuss the optimization of its parameters for maximizing the visual quality of the captured images.</p><p>As mentioned before, most of the existing approaches in-volve either multiple cameras to capture various perspective directions <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b3">5]</ref>, or a single camera that rotates along a horizontal circle to acquire the images <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b18">20]</ref>. The problem with moving or multiple cameras is that it makes the calibration and camera positioning difficult thus making the system bulky and delicate to use. They also give rise to visible artifacts like motion parallax, visible seams, synchronization errors and mis-alignments <ref type="bibr" target="#b11">[13]</ref>. Moving cameras also limit their use to static scenes and require extensive post processing to get the left and right panoramas. In comparison, our approach has the following advantages:</p><p>1. Simplicity of Data Acquisition: In the multi-camera systems like Google Jump <ref type="bibr" target="#b0">[1]</ref> or the system proposed by Amini et al. <ref type="bibr" target="#b3">[5]</ref>, all the cameras need to be synchronized using an electronic system to ensure that the images are captured at the same time. The use of a single camera eliminates the need for synchronization and reduces the size of the device making it easy to be used and handled. Data is acquired in the form of a regular image or video and may be stored in standard formats. 2. Ease of Calibration and Post Processing: Our approach solves the problem without any moving parts, thus simplifying the calibration process. As we explain later, simple binary patterns can be used to calibrate the relative configuration of the camera and the mirror. This also simplifies the post-acquisition dewarping process to obtain the left and right panoramas. The whole process of data acquisition and post processing can easily be done on a smartphone, making it a panoramic stereo video capture and display device. 3. Adaptability to Various Applications: Our custom designed mirror can be easily used as an attachment to any consumer camera to convert it into a stereo panoramic capture device. The size of the mirror can be adapted according to the application and the field of view can be controlled. 4. Complete omni-directionality: Our design can be extended using a concave lens to capture mono images of the top or bottom region. We can thus generate a complete 360 • x 270 • view of the world captured using a simple set up.</p><p>We describe in detail the design of the proposed catadioptric omni-stereo system. We also show that our system works efficiently for acquiring both 3D images and videos and for both static and dynamic scenes. We discuss the optimization of the design parameters and present the reconstructed stereo panoramas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Last two decades have seen significant advances towards achieving omnistereo imaging. The first set of approaches generates a pair of panoramic images with a vertical offset. While such a geometry results in simple epipolar lines leading to fast disparity estimates, they are not suitable for human stereo perception as our brain expects a horizontal disparity. Gluckman et al. <ref type="bibr" target="#b10">[12]</ref> proposed the use of two omnidirectional cameras, each consisting of a parabolic mirror, telecentric optics and a conventional camera, that were aligned vertically along the same axis. Kawanishi et al. <ref type="bibr" target="#b13">[15]</ref> proposed a more complex setup that replaces each omnidirectional camera in the above device with 6 cameras and a hexagonal mirror. While this increases the resolution of the omnidirectional images, the disparity remains vertical as before. Lin et al. <ref type="bibr" target="#b14">[16]</ref> created omnidirectional stereo using two cameras and a conical mirror, which limits the vertical FOV. Yi and Ahuja <ref type="bibr" target="#b21">[23]</ref> improved on the above designs by capturing stereo omnidirectional panoramas with a single camera. Their system uses a mirror-lens combination to create two light paths that reflect off different positions in the mirror forming a stereo pair with a vertical disparity.</p><p>Acquiring a horizontal disparity panoramic stereo requires one to record a 3D light-field that is the equivalent of all cameras with centers along a horizontal circle. Peleg et al. <ref type="bibr" target="#b15">[17]</ref> showed that this may be compressed to two 360 • panoramas, one for each eye, without affecting the visual perception. They proposed the use of a single camera that rotates in a circular trajectory to acquire the 3D lightfield. Strips of images are then extracted from left and right ends of the frames that are stitched to create the right and left eye panoramas respectively. While this method works quite efficiently for static scenes, it is affected by artifacts like visible seams and vertical parallax for moving objects or uneven camera motions. These errors cause major misperceptions when viewed in 3D as explained by Held and Banks <ref type="bibr" target="#b11">[13]</ref>. Couture et al. <ref type="bibr" target="#b6">[8,</ref><ref type="bibr" target="#b7">9]</ref> proposed the use of a rotating stereo camera pair and stitching complete frames instead of small strips, which can generate panoramic stereo video textures. Use of rotating cameras limits the system to small repetitive motion and suffers from the perception artifacts like visible seams and vertical parallax.</p><p>Richardt et al. <ref type="bibr" target="#b18">[20]</ref> proposed a flow based blending approach that helps reducing these visual artifacts and works well for images captured using hand held cameras. However, the use of SFM makes this approach computationally expensive when applied to high resolution images.</p><p>Peleg et al. <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b17">19]</ref> also explored creating panoramic images using a perspective camera and a spiral mirror. They could capture the 360 • panorama using three such setups, each acquiring 132 • . They also proposed the use of a fresnel lens cylinder around an omnidirectional camera for each eye. Both systems were complex and hard to manufacture and use because of its large size and delicate structure.</p><p>To reduce visual artifacts and capture dynamic scenes, synchronized multi-camera setups were recently proposed. Couture and Roy <ref type="bibr" target="#b4">[6]</ref> have proposed a setup which uses 6 cameras with fisheye lenses. Large occlusions are visible in the produced omnistereo panoramas due to the huge curvature of the lenses. Also to reduce depth distortions, the number of cameras needs to be increased, which in turn makes the system bulkier. Tanaka and Tachi <ref type="bibr" target="#b20">[22]</ref> also proposed a method to capture omnistereo video sequences. Their rotating optics system consisted of prism sheets, circular or linear polarizing films, and a hyperboloidal mirror. The latest and most effective solution is a simple extension of the idea by Peleg et al. <ref type="bibr" target="#b15">[17]</ref>, where the rotating camera is replaced by 16 static cameras along a circle. This virtual reality camera was introduced at the Google I/O conference, called 'Google Jump' <ref type="bibr" target="#b0">[1]</ref>. All the cameras are synchronized to take frame-aligned videos, which are then stitched to form a complete 360 • video. Although several systems have been proposed in the past most of them either suffer from limited FOV, or are limited by their size, calibration and alignment issues and cost of manufacturing. Our goal is to reduce this to a simple catadioptric system using a custom designed mirror and a single camera. We also provide a theoretical foundation of the design choices and demonstrate results for both static and dynamic scenes. <ref type="table">Table 1</ref> shows the more detailed comparison of our device with other omnistereo devices/approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Design Overview</head><p>3D information can be extracted from two images taken by two cameras horizontally displaced by a baseline. For a complete 360 • view, the two cameras, analogous to the two eyes, can move around the center of a circle called viewing circle, as shown in <ref type="figure" target="#fig_1">Fig. 2a</ref>. The diameter of the viewing circle is equal to the baseline. For each viewpoint, the set of tangential rays in the clockwise direction account for the left eye views, and the set of tangential rays in the anticlockwise direction account for the right eye views. To accurately capture stereo information, the camera should be able to capture all the rays tangential to the viewing circle. For this purpose, we propose a special mirror design for omnistereo viewing, called coffee filter mirror, owing to the similarity in shape. Using the image captured by this mirror we generate panoramas for left and right eye views with appropriate disparity. The disparity in these images is used to perceive depth when seen in 3D using a VR headset such as Google cardboard <ref type="bibr" target="#b1">[2]</ref>.</p><p>Consider the arrangement of two flat mirrors P 1 P 2 and P 2 P 3 as shown in <ref type="figure" target="#fig_2">Fig. 3b</ref>, P B is the tangent to the viewing circle V and represents the direction of the rays that are required to be collected for the right eye view. Using a mirror P 1 P 2 , normal to the rays falling in the direction P B , the incident rays can be reflected to the camera placed at the center of the design. P 1 P 2 provides a horizontal field of view to the eye and is analogous to the strip width in the image-based approaches as mentioned in <ref type="bibr" target="#b15">[17]</ref>. Each such mirror is referred to as a face. Multiple faces, when arranged in the configuration shown in <ref type="figure" target="#fig_1">Fig. 2b</ref>, captures all the tangential rays required for constructing the panorama for a single eye. These faces are arranged at equal angular separation such that P i (even i) lies on the circle C max and P j (odd j) lies on the circle C min . Rays that are falling in the direction of P B correspond to the view of the world as seen from the right eye, as shown in <ref type="figure" target="#fig_2">Fig. 3b</ref>. Our design is motivated from the idea to capture both eyes' views in a single device for omnistereo imaging. Between two consecutive faces that are catering to same eye view, we introduce a similar face that captures a second eye view.We combine the two arrangements of <ref type="figure" target="#fig_1">Fig. 2b</ref> in a single design, as shown in <ref type="figure" target="#fig_2">Fig. 3b</ref>, such that rays for both eyes' views are reflected to a single camera. The combination of one left and one right face is referred to as a petal in rest of the paper. Different number of petals can be used depending upon the application requirements. <ref type="figure" target="#fig_2">Fig. 3a</ref> shows a general horizontal cross-section of the proposed device to explain the structure and the nomenclature that would be used further in the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Design Details</head><p>In order to provide a better 3D experience to the user, it is important that the horizontal FOV of each face of the mirror is sufficient enough to avoid any stitching artifacts and mis-alignments. Also, vertical FOV should cover the appropriate height of the world and the resolution must be uniform across all the regions of the captured scene. In this section, we explain how these factors affect our choice of design parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Horizontal Field of View</head><p>Horizontal field of view refers to the amount of the scene captured by a face in the horizontal direction. In our design, this is directly dependent on the number of petals, say n.</p><p>To cover the complete 360 • view, each face should cover at-least 2π n FOV. As shown in <ref type="figure" target="#fig_3">Fig. 4a</ref>, face P 1 P 2 , which is a flat mirror, views only the region parallel to its length. The best arrangement of the next face for the same eye view, P 3 P 4 would be such that the FOV of the two mirrors cover consecutive areas of the scene. However, this is only possible if the mirrors are arranged linearly. FOVs can not intersect at any point if flat mirrors are arranged in a circular manner, as shown in <ref type="figure" target="#fig_3">Fig. 4a</ref>. Hence, certain areas of the world will be left unseen by the camera and will be missing from the captured images. Field of view of each face is increased by opting for a horizontal curvature for the face as shown in <ref type="figure" target="#fig_3">Fig. 4b</ref>. Center of each curved face lies on the tangent to the viewing circle. Increasing the curvature of the faces, increases the overlap between the FOVs of two consecutive same eye view's faces. This overlap is advantageous while de-warping the captured image into the panoramas, as it resolves the problem of missing regions. However, the increase in curvature also increases the inter-reflections between the neighboring faces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Inter reflections</head><p>Due to the curvature in the faces in the proposed design, the FOV of the adjacent faces aligned at an obtuse angle β, overlap. As shown in <ref type="figure">Fig. 5</ref>, a ray originating from the camera that strikes the face P 2 P 3 , may get reflected multiple times because of the FOV overlap between faces P 2 P 3 and P 3 P 4 . These inter-reflections will cause mis-captured information at the camera sensor,thus decreasing the resolution of the final de-warped panoramas. Hence, an optimal amount of overlap is kept such that inter-reflections are kept to a minimum, while also solving the problem of missing regions as explained in Section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Vertical Field of View</head><p>In the past, several catadioptric systems using various combinations of flat and curved mirrors have been used to increase the amount of the scene captured by the camera in the vertical direction. For better quality and perception Interreflections P 2 FOV 2 <ref type="figure">Figure 5</ref>: Inter-reflections cause wrong world points to be captured due to FOV overlap between each pair of left and right eye view mirrors of the de-warped images, it is important that the resolution is uniform both horizontally and vertically. In a flat mirror, vertical FOV is equal to the height of the mirror and hence the resolution remains constant.Our proposed design is such that at each horizontal cross section the faces can be confined within a circle. The radii of these circles increase from 0 to R max . As we need uniform resolution, we see that a parabolic curvature in the vertical direction is more desirable as compared to a hyperbola or straight line(see <ref type="figure">Fig. 6</ref>) <ref type="bibr" target="#b0">1</ref> . There have been several approaches proposed to attain uniform resolution on some planes or uniform angular resolutions <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b12">14]</ref>. However, there work focuses mainly on creating sensors with uniform resolution along the radial line, whereas our mirror is designed to capture stereoscopic views. Therefore, to simplify the set up and the dewarping process, at present, We seek optimality in terms of the size, complexity, and minimizing inter-reflections. Creating a device that can optimally capture stereoscopic views with uniform radial resolution is an aspect that needs to be explored in future.  <ref type="figure">Figure 6</ref>: Uniformity of vertical resolution in terms of differential angle of the incident rays along the radial length for a cone, parabola and hyperbola.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">The Mirror Surface</head><p>We now derive the equation of the mirror surface. Multiple factors can be varied to make the device adaptive to specific applications. We derive the expressions for only one petal AP B as shown in the <ref type="figure" target="#fig_6">Fig. 7a</ref>. and the same expressions hold for all n petals rotated by 2π/n. Circular surfaces AP and P B are used to capture the right and left eye view respectively. Let us consider the angle between the chords of these two faces as β. Each petal subtends an angle θ at the center, where θ = 2π n . Hence, we get n views each for left and right eye. The design of the mirror is symmetrical, and all the petals are of same size and dimensions. The distance between the two extreme points of a mirror surface i.e AP as shown in <ref type="figure" target="#fig_6">Fig. 7a</ref> is referred as petal length, denoted by l. Each petal, say P i , where i = 1 to n is bounded by a circle C max with radius R max , and inside by a circle C min with radius R min . V is the viewing circle with radius equal to b. From <ref type="figure" target="#fig_6">Fig. 7a</ref>, OA = R min and OP = R max . From △OAP and △OBP , by sine rule we get the relations as, l</p><formula xml:id="formula_0">sin( θ 2 ) = Rmax sin(π− (θ+β) 2 ) = Rmin sin( β 2 )</formula><p>Note that ∠AP O = ∠BP O = β 2 and ∠AOP = ∠P OB = θ 2 , because each face is symmetrical and oriented at equal separation. ∴ ∠OAP = π − θ 2 − β 2 . LD is the perpendicular bisector of the chord AP and is tangent to the viewing circle V . OD = b is the radius of the viewing circle. In △OCD and △CLP , we get LP = CP cos( β 2 ), implies CP = LP sec( β 2 ) = l 2 sec( β 2 ). In △P LC, ∠LCP = π 2 − β 2 . ∠OCD = ∠LCP , being vertically opposite angles. Hence, ∠COD = π 2 − ∠OCD = β 2 . Also, OC + CP = R max , which gives, OC = R max − l 2 sec( β 2 ) In △OCD, OD OC = cos β 2 , which gives OC = b sec( β 2 ). Using this we get, R max − l 2 sec( β 2 ) = b sec( β 2 ) and R max = (b + l 2 ) sec( β 2 ). Combining all these, we get:</p><formula xml:id="formula_1">R max = 2b sin( θ+β 2 ) sin( θ+2β 2 ) (1) R min = R max sin( β 2 ) sin( θ+β 2 ) (2) l = R max sin( θ 2 ) sin( θ+β 2 )</formula><p>(3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Optimizing the design parameters</head><p>In our proposed design, disparity and mirror size can be altered depending upon the application requirement. Size of the mirror is proportional to R max . In order to have a compact mirror design that generates human perceivable stereo panoramas, the design parameters need to be optimized. The minimum value of the outer radius of the coffee filter mirror i.e. R max is dependent upon β. At petal angle, β opt = π−θ 2 , R max is minimum, and hence we get the minimum size of the device.</p><p>In <ref type="figure" target="#fig_6">Fig. 7a</ref>, Let ∠P BE be α, the angle between two petals. In △OBP , ∠OP B = β 2 , ∠P OB = θ 2 and ∠OBP = π − θ+β 2 . Therefore, ∠P BF = π −(π − θ+β 2 ) = θ+β 2 . ∠P BE = 2∠P BF , which means α = θ + β. Consider <ref type="figure" target="#fig_6">Fig. 7b</ref> where O ′ is the center of curvature of the face P B. P O ′ and O ′ B are the radii of curvature i.e r c and ∠P O ′ B = 2γ is the angle subtended by each face at the center of curvature. In △P O ′ B, ∠A = π − (θ + β), which implies, γ = π 2 − ∠A = (θ + β) − π 2 . In order to have small mirror size, γ opt = (θ + β opt ) − π 2 . Therefore, the optimal horizontal angular field of view γ opt = θ 2 and is independent of the obtuse angle ∠P BE between nearby faces.</p><p>O ′ C is the perpendicular bisector of P B, CB = l 2 . In △O ′ CB, l 2 rc = sin γ. Radius of curvature r c can be optimized by using the optimal value of γ. Therefore, r c = l 2 sin θ 2 , is the optimal radius of curvature. It is to be noted that these centers of curvature lie on a circle.</p><p>To avoid wastage of pixels due to inter-reflections, as explained in Section 4.2, it is important to collect the maximum scene information in the captured image. Each face covers 2θ n angular FOV, thus a total of n such faces for each view covers complete 2π FOV. For no missing regions, FOVs of two faces for the same eye views should be covering consecutive areas of the scene. This is achieved by aligning one face in the direction of O ′ P and the next face for the same eye view, in the direction BE. Hence the obtuse angle between the two faces P B and BE is π+θ 2 . The amount of inter-reflections depends upon the angle between two consecutive petals, α, which depends upon the sampling angle of the mirror 2π n . Ideally, the amount of interreflections reduces down to zero, when the FOV of two consecutive faces do not intersect at all. However, this way, some of the scene regions will be left uncovered in the FOV of some faces and hence not imaged at all. In order to account for these inter-reflections, we introduce a small angle δ such that the angle of curvature becomes 2γ + δ. This makes sure some overlap is there, so that some redundant information is captured, which can be used while dewarping. However, the value of δ is kept sufficiently low, such that inter-reflections are also reduced to a huge extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Resultant Mirror Surface</head><p>In this section, we obtain the surface equations of the proposed coffee filter mirror in terms of polar coordinates φ and r. As explained earlier, the surface of the coffee filter mirror is such tha each face is paraboloidal vertically and at each horizontal cross section the faces can be confined within a circle. The radii of these circles increase from 0 to R max . Let us consider the central axis of the mirror to be the z axis. Then the surface equation can be written as a function of x and y axis:</p><formula xml:id="formula_2">z = f (x, y) = m φ (x 2 + y 2 ),<label>(4)</label></formula><p>where m φ is the slope of the parabola for a given φ. Let x 2 + y 2 = r 2 , where r is the radial distance in the XY plane and φ is the angle of the radial line, then: z = m φ r 2 (5) Eqn 5 represents the petal surface of our custom designed mirror centered around origin. Consider the uppermost and widest cross section of the mirror at z = z max , such that z max = m φ r 1 2 , m φ = zmax r 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head><p>. Let (x c , y c ) be the center of the circle of curvature of a face of a petal and (x d , y d ) be the point which lie on the curvature, r 2 1 = k 2 r 2 such that x d = kx and y d = ky. r c be the radius of the circle of curvature for a face. Combining this with Eqn 5, we get m φ = zmax k 2 r 2 which implies, z = zmax k 2 . It is to be noted that x 2 c + y 2 c = d 2 c , Calculating distance from center of the curvature and the point on the curvature we have:</p><formula xml:id="formula_3">(x d −x c ) 2 +(y d −y c ) 2 = (kx−x c ) 2 +(ky−y c ) 2 = r 2 c (6) =⇒ k = (xx c + yy c ) + (xx c + yy c ) 2 − r 2 (d 2 c − r 2 c ) r 2 Since, m φ = z max /k 2 r 2 , m φ = z max r (xx c + yy c ) + (xxc + yyc) 2 − r 2 (d 2 c − r 2 c ) 2</formula><p>as m φ = z max /k 2 r 2 . Also, it can be derived from the <ref type="figure" target="#fig_7">Fig. 8</ref>,</p><formula xml:id="formula_4">(x c , y c ) = (x d , y d ) + r c (cos(θ 1 + θ 2 + β 2 + θ 2 ), sin(θ 1 + θ 2 + β 2 + θ 2 )), where θ 2 = tan −1 ( 2rc l )</formula><p>. From this and Eqn 5 we get,</p><formula xml:id="formula_5">z = zmax r 2 (xxc + yyc) + (xxc + yyc) 2 − r 2 (d 2 c − r 2 c ) 2<label>(7)</label></formula><p>Therefore, Eqn 7 gives the equation of the paraboloidal surface of the mirror. Note that the slope m φ at every point is a function of r. Any incident ray I coming from the world point falls on the mirror surface at the point P (r, φ) and is reflected in the directionR = 2(Ĩ ·n(r, φ))n(r, φ) −Ĩ, where n(r, φ) is the direction of normal vector at P . n is the normal vector to the tangent plane containing the tangents in both horizontal and the vertical direction. For a horizontal plane, the direction of normal vector n h at point (r, φ) is given by</p><formula xml:id="formula_6">y c − r sin φ r cos φ − x c 0 T where (x c , y c )</formula><p>are the center of curvature. Similarly, the normal vector n v in vertical direction is obtained by dx dr dy dr dz dr T which is obtained as cos φ sin φ 2m φ r T . Hence, the normal vector to the tangent plane at point (r, φ) is obtained by n =n h ×n v .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Calibration and De-warping</head><p>Images captured by the camera using the coffee filter mirror are of the form as shown in <ref type="figure" target="#fig_0">Fig. 1b</ref>. Captured images varies with the orientation and viewing angle of the camera. However, for stereo vision to be perceivable, camera's viewing axis must be aligned with the central axis of the device. To calibrate our device, we use a generic non-parametric camera calibration method as proposed by Posdamer and Altschuler <ref type="bibr" target="#b16">[18]</ref>. We project structured light binary patterns onto a display surface and project both normal and inverse binary sequence patterns. The obtained calibration images together will be used to compute a mapping from 3D world coordinates to 2D image coordinates which is used for dewarping the captured scene image into left and right eye panoramas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Epipolar Geometry and Stereo</head><p>To find the center of projections of the proposed coffeefilter mirror, we find the trajectory of the viewpoints by finding the intersection of the reflected rays for every pair of adjacent points. Let a point lying on a radial line with single φ j is denoted by p i,φj . Then the reflected rays for each pair of adjacent points p i,φj and p i+1,φj intersect at the c i,φj . The set of all such points form a line as shown in <ref type="figure" target="#fig_0">Fig. 10a</ref>. L φj = {c i,φj }∀i. We take the average of these intersection points c ′ φj , to find the average viewing circle for complete 360 • view. Locus of c ′ φj for φ for a single face is a straight line parallel to central axis of the camera. Let c ′′ k be the average center for a single face. Locus of c ′′ k for all n faces is viewing circle, as shown in <ref type="figure" target="#fig_0">Fig. 10b</ref>. In order to have a mirror with diameter of the viewing circle equal to the baseline of human eye, diameter of the uppermost cross-section must be twice the human baseline. With the change of diameter of the cross-section from top to bottom, both linear and angular disparities change. However, for panorama to be perceivable, linear disparities are more important than the angular disparities. The change in linear disparities are avoided by interpolation during dewarping. The combination of mirrors and a conventional camera behave as a non-central catadioptric camera. For details on such classification, readers are directed to <ref type="bibr" target="#b19">[21]</ref>. Let us consider a point in 3D world defined by (X, Y, Z) which is imaged by a mirror surface at point P (r, φ), then the ray coming from X to P is viewed by some other mirror surface at location P ′ (r ′ , φ ′ ). The set of such points form an epipolar curve for the point P . Each point is then transformed into the corresponding image coordinate using the calibration explained in previous section. Epipolar curve for a point in the left face is found by minimizing the distance between the reflected rays from a point in a left face P to every other point in it's right face P ′ . Thus, for each φ in the mirror surface, we find the r φ which intersects the reflected ray from point P such that,</p><formula xml:id="formula_7">|[PP ′ , I r,φ , I r ′ ,φ ′ ]| |I r,φ × I r ′ ,φ ′ | = 0<label>(8)</label></formula><p>where I r,φ represents the direction of reflected ray from mirror surface. Since, the design behaves as a non-central camera, every point has different epipolar constraints. We calculate stereo disparity between the left and right views by finding the correspondences along these epipolar curves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Results and Discussions</head><p>In order to test our design, we have modeled the coffee filter mirror using POVRay <ref type="bibr" target="#b2">[4]</ref>, a freely available ray tracing software tool that accurately simulates imaging by tracing rays through a given scene. We have used two 3D scene datasets <ref type="bibr" target="#b8">[10,</ref><ref type="bibr">3]</ref> to demonstrate how the proposed mirror is used to create stereo panoramas (red-cyan anaglyph) as shown in <ref type="figure" target="#fig_0">Fig. 1c and Fig. 9</ref>. Our mirror can also be used to capture dynamic scenes and create 3D stereo videos. As shown in the results, the proposed coffee filter mirror is able to capture 103 • FOV in vertical direction and 360 • in the horizontal direction. The image of the simulated scene is captured using the simulated proposed setup and a virtual camera at a resolution of 5000 x 5000 and is dewarped into two left and right panoramas of resolution 512 x 8192. <ref type="figure" target="#fig_0">Fig. 11a</ref> shows a stereo depth map of the POVRay scene 'average office' <ref type="bibr" target="#b8">[10]</ref> computed using the coffee filter mirror. The qualitative comparison of the depth map with the ground truth is shown in <ref type="figure" target="#fig_0">Fig. 11b. Fig. 12a</ref> and <ref type="figure" target="#fig_0">Fig. 12b</ref> shows left and right panoramas respectively created using 12 petals of the initial manufactured prototype of the coffeefilter mirror. Additional results including anaglyph images, videos of dynamic scenes and stereo depth maps may be found at the project website 2 .</p><p>We have created a physical prototype of the proposed mirror ( <ref type="figure" target="#fig_0">Fig. 13(b)</ref>) with 24 petals, capturing 48 different left or right eye views. Each face subtends an angle θ = 15 • at the center of the coffee filter mirror. The total height of the mirror z max is kept as 5 cm and the radius of the hole r min = 2.7cm. We have kept b = 6.5 cm which is equal to the average value for human baseline. This optimal petal angle β opt comes out to be 82.5 • , the optimal values of R max = 9.77 cm, R min = 8.571 cm and l = 1.696 cm. To mitigate the effects of inter-reflections in the adjacent faces, as explained in Section 4.2, we introduced a small angular overlap between two adjacent petals as δ = 2 • . This means each petal captures with a redundancy of 1/15 • , since θ = 15 • . The resulting panoramas are shown in <ref type="figure" target="#fig_0">Fig. 12</ref>. Degradations in quality of images are due to imperfections of the mirror surface that was created by SLA printing. In our design, the horizontal shift in camera centers between faces is very small (≈ 2mm) reducing the blind spot to within 5 cm of the device. The shift decreases along the height of the mirror. To simplify the post-capture setup, we avoided depth computation step at dewarping. This retains a small disparity difference from the top of the image to its bottom. This difference is visible on close inspection and may be corrected with depth estimation. As our goal was human perceivable stereo and the artifacts are imperceivable while using stereo glasses or HMD, we avoided this step. There are radial and vertical shifts in camera cen- ters between faces that causes the artifacts in <ref type="figure">Fig. 9</ref>. However, the ratio of the vertical shift to the horizontal shift is very small and does not create any visible artifacts beyond a depth of d. The value of d turns out to be 70 cm when the rendering cylinder is kept at 200 cm, for images captured at 5000 × 5000 resolution. These could also be corrected like other approaches by depth estimation at the dewarping stage. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusions</head><p>We have proposed a simple practical solution to capturing 360 • stereo panoramas using a single digital camera for immersive human experience. As the resolution of sensors increase, the quality of the panoramas also increase. We derived the optimal parameters of the design and experimental results show that we can avoid most visual artifacts in the panoramas. While designed with human consumption in mind, the stereo pairs could also be used for depth estimation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>(a) 3D printed model of the proposed coffee-filter mirror (b) Image of the proposed mirror placed in a scene (POVRay) (c) Stereoscopic panorama (red-cyan anaglyph) recovered from the image in (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>(a) The scene point P viewed by L and R eyes forming a viewing circle with diameter equal to baseline (b) Arrangement of mirrors for capturing right and left views. Tangential rays are captured by placing a mirror normal to the viewing circle.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>(a) A general horizontal cross-section of the proposed coffee filter mirror.(b) Combination of the two arrangements as shown inFig. 2bto capture both eye views in a single design.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>(a) Flat mirrors have limited FOV, causing blind spots (b) Curved mirrors increase the FOV and the overlap between consecutive faces of an eye.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>1Figure 7 :</head><label>7</label><figDesc>Please see Supplementary Material for more mathematical details Geometry of the petal surface used to obtain optimal design parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Parameters of the mirror petal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :Figure 10 :Figure 11 :</head><label>91011</label><figDesc>Red-Cyan anaglyph panorama obtained by using the proposed set up using POVRay dataset [(a) Lines in black represents the locus of the intersection of consecutive rays for different radial lines lying on a single face (b) Red and blue curves represent the caustic curve for left and right faces respectively. (a) Comparison of reconstructed depth as obtained using the proposed set up with the ground truth depth map.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 12 :</head><label>12</label><figDesc>Left and right panoramas extracted from 12 petals of an initial prototype of the mirror shown in Fig13(b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 13 :</head><label>13</label><figDesc>(a) Mockup of proposed device attached to a consumer cellphone camera (b) Set up created using initial manufactured prototype of coffee filter mirror.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Omnistereo device/approach comparison based on device setup complexity, Type of scenes that the camera can handle, Perceived artifacts in the omnistereo experience and resolution of the omnistereo panoramas.</figDesc><table>Principle 

Camera Name 
Device 
setup 

Type of 
scenes 

Perceived Artifacts 
Image 
Resolution 

Single Camera based 

Omnistereo [17] 
Rotating 
Static 
Mis-alignments, stitching artifacts &amp; 
Vertical parallax 

Medium 

Megastereo [20] 
Rotating 
Static 
No artifacts but extensive run time for 
SFM 

High 

Coffee-filter 
(proposed) 

Fixed 
Dynamic 
No stitching artifacts and horizontal 
disparity errors. Very less vertical 
disparity errors. 

Medium 

Multiple camera 
based, needs 
camera 
synchronization 

Omnistereo, fresnel 
Lens solution[17] 

2 Fixed 
cameras 

Dynamic 
Chromatic aberrations, difficult to 
manufacture and use , Self-occlusions 

Low 

Panoramic Stereo 
Video Textures [8, 9] 

2 Rotating 
Cameras 

Dynamic 
textures 

Visible seams and vertical parallax 
High 

Google Jump [1] 
16 Fixed 
Cameras 

Dynamic 
No stitching artifacts but setup is 
expensive and bulky 

High 

Omnipolar [6] 
6 Fixed 
Cameras 

Dynamic Self occlusions , setup is expensive and 
bulky 

High 

Hexagonal Pyramidal 
Mirrors [15] 

12 Fixed 
cameras 

Dynamic 
Vertical disparity errors 
High 

Table 1: </table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://cvit.iiit.ac.in/research/projects/panoStereo/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Jump</surname></persName>
		</author>
		<ptr target="https://www.google.com/get/cardboard/jump/.1" />
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Cardboard</surname></persName>
		</author>
		<ptr target="https://www.google.com/get/cardboard/.3" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Povray</surname></persName>
		</author>
		<ptr target="http://www.povray.org/.7" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Evaluating a new stereo panorama system based on stereo cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Varshosaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saadatseresht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">in Inventions and New Ideas</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The omnipolar camera: A new approach to stereo immersive capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chapdelaine-Couture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Photography, IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Resolution invariant surfaces for panoramic vision systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Proceedings of the Seventh IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="392" to="397" />
		</imprint>
	</monogr>
	<note>Computer Vision</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Panoramic stereo video textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Couture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Omnistereo video textures without ghosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">C</forename><surname>Couture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3D Vision, International Conference on</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Focus mismatch detection in stereoscopic content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Devernay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pujades</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IS&amp;T/SPIE Electronic Imaging. International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mirror design for an omnidirectional camera with a space variant imager</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gächter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Micusik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop on Omnidirectional Vision Applied to Robotic Orientation and Nondestructive Testing</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="99" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Real-time omnidirectional and panoramic stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gluckman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Thoresz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Image Understanding Workshop</title>
		<meeting>Image Understanding Workshop</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Misperceptions in stereoscopic displays: a vision science perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Banks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th symposium on Applied perception in graphics and visualization</title>
		<meeting>the 5th symposium on Applied perception in graphics and visualization</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Equi-areal catadioptric sensors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Perline</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>IEEE</publisher>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generation of high-resolution stereo panoramic images by omnidirectional imaging sensor using hexagonal pyramidal mirrors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kawanishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yamazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Iwasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Takemura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yokoya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition. Fourteenth International Conference on</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">High resolution catadioptric omnidirectional stereo sensor for robot vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bajcsy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics and Automation. IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Omnistereo: Panoramic stereo imaging. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ben-Ezra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pritch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="279" to="290" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Surface measurement by space-encoded projected beam systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Posdamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Altschuler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer graphics and image processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Optics for omnistereo imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pritch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ben-Ezra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Image Understanding</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="447" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Megastereo: Constructing high-resolution stereo panoramas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Richardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pritch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On calibration, structure from motion and multi-view geometry for generic camera models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramalingam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lodha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Imaging Beyond the Pinhole Camera</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Tornado: Omnistereo video imaging with rotating optics. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tachi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="614" to="625" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An omnidirectional stereo vision system using a single camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition. Eighteenth International Conference on</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
