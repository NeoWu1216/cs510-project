<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Detecting Migrating Birds at Night</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
							<email>jbhuang1@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
							<email>rcaruana@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Farnsworth</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">Cornell Lab of Ornithology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Kelling</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">Cornell Lab of Ornithology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narendra</forename><surname>Ahuja</surname></persName>
							<email>n-ahuja@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Detecting Migrating Birds at Night</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Bird migration is a critical indicator of environmental health, biodiversity, and climate change. Existing techniques for monitoring bird migration are either expensive (e.g., satellite tracking), labor-intensive (e.g., moon watching), indirect and thus less accurate (e.g., weather radar), or intrusive (e.g., attaching geolocators on captured birds). In this paper, we present a vision-based system for detecting migrating birds in flight at night. Our system takes stereo videos of the night sky as inputs, detects multiple flying birds and estimates their orientations, speeds, and altitudes. The main challenge lies in detecting flying birds of unknown trajectories under high noise level due to the low-light environment. We address this problem by incorporating stereo constraints for rejecting physically implausible configurations and gathering evidence from two (or more) views. Specifically, we develop a robust stereo-based 3D line fitting algorithm for geometric verification and a deformable part response accumulation strategy for trajectory verification. We demonstrate the effectiveness of the proposed approach through quantitative evaluation of real videos of birds migrating at night collected with near-infrared cameras.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Bird migration is the regular seasonal, large-scale, often long-distance movement between breeding and wintering grounds. Many species of bird migrate. Migration behavior is a critical indicator for evaluating environmental health <ref type="bibr" target="#b23">[24]</ref>. By identifying important stopover and wintering locations, one can take action to save these key locations to protect endangered species. Scientists use a variety of methods to monitor bird migration, including satellite tracking, weather radar, moon-watching, or attaching geolocators on captured birds. However, these methods are either expensive (e.g., satellite tracking), inaccurate because they are indirect (e.g., weather surveillance radars), laborintensive and error-prone (e.g., moon-watching), or intrusive (e.g., geolocators). Moreover, these techniques only crudely estimate the bulk density of migrating birds aloft. <ref type="bibr">Figure</ref> 2. An example of automatic bird detection in stereo sequences. Our system takes stereo videos of the night sky as inputs, detects migrating birds in flight, and infers their orientation, speed, and altitude in very low SNR.</p><p>We propose to use a vision-based approach as a complementary sensing modality to build a bird migration monitoring system. By setting up stereo cameras facing up to the night sky, we can detect and track migrating birds in flight illuminated from below by light pollution in the recorded videos, as shown in <ref type="figure">Figure 2</ref>. Vision-based solutions offer several advantages over existing techniques. First, we can automatically and accurately count the number of individual birds aloft along with detailed trajectory estimation such as orientation, speed, and altitude. Such unprecedented accuracy in the reconstructed trajectories of individual birds may help re-evaluate migration, locomotion and navigation theories. Second, the estimated statistics could be used to calibrate other sensing modalities such as weather radar. Third, low-cost digital cameras allow us to build large-scale, distributed monitoring systems that cover broad areas.</p><p>There are three main challenges in developing a robust bird detection algorithm from videos. First, as migration usually occurs at night, the recorded videos inevitably contain substantial noise because of the low-light environment -the birds are generally invisible to the naked eye in the sky unless they pass in front of an illuminated object such as the moon. We illustrate this using sample frames from three video sequences in <ref type="figure">Figure 1</ref>. Second, depending on the species, migrating birds fly at altitudes ranging from several hundred feet to two miles. If the lens and camera provide an adequate field of view, the imaged bird may span only 1-2 pixels in a frame. This suggests that motion is the only reliable cue for detecting a bird. Third, efficient algorithms are required for large-scale deployment.</p><p>Several methods have been proposed to detect small ob-  <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b35">36]</ref> the presence of the target is detected either using simple frame differencing, filter responses, or matching against a known template and then tracking over time. Similarly, in ridge detection in three-dimensional volumetric data (e.g., vessel extraction <ref type="bibr" target="#b27">[28]</ref>), the ridge is often detected using a predefined set of oriented filters. The common drawback of these approaches is that the detection is mostly performed locally. These techniques are thus not directly applicable to our problem due to the extremely low SNRs in our case. Recent methods address this issue by designing filter banks to improve detection of faint signals <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref> or by searching a large set of curves <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b31">32]</ref>. However, most of these algorithms, designed specifically for 2D images, are computationally infeasible for 3D image data. In multiobject tracking, several algorithms have been proposed to track objects in 3D using stereoscopy <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b2">3]</ref>.</p><p>In general, the problem of target tracking can be divided into four main categories: 1) Large objects in bright light (e.g., tracking cars, pedestrians, faces in daylight). 2) Small objects in bright light (e.g., meteor streaks in sky surveys, planes with lights at night or in daylight at a great distance, rockets/missiles that are bright in IR). 3) Large objects in dim light (e.g., people detection and tracking at night under surveillance illumination). 4) Small objects in low light (e.g., birds flying over 1 mile high at night illuminated by light pollution). Unfortunately, a direct application of existing techniques does not suffice for our problem (category 4). These techniques often pose tracking and trajectory reconstruction as independent problems of frame-level target localization and cross-frame and cross-view data-association. The target size and SNR in our case are so low that targets cannot be reliably detected in individual frames.</p><p>In this paper, we tackle this problem using a two-stage  robust model fitting approach. In contrast to prior work that aims at local detections in each frame, we aim at detecting using domain knowledge and global reasoning. Our fundamental assumption is that the migrating birds do not significantly change course and speed over short temporal spans (e.g., 5 seconds). We can thus cast the bird detection as finding curved 3D ridges in a spatiotemporal volume. The core detection algorithm consists of two main stages:</p><p>(1) Geometric verification: Given a large collection of noisy local detections, we extend the RANSAC-based 3D line fitting algorithm by explicitly incorporating stereo vision constraints. Specifically, we fit the model to both views jointly, which offers several advantages over a straightforward application of RANSAC independently in each view. First, the sample subset is used to determine the full bird model including altitude, speed, orientation, and position. Second, we can quickly reject a large number of physically implausible model hypotheses by checking the disparity, the temporal alignment, and extreme speed and altitude. Third, our model hypothesis allows us to exploit simultaneously the detected foreground points from both view by compensating the disparity. We set a loose threshold for line fitting so that birds flying at time-varying speed or directions could also be detected. To the best of our knowledge, while RANSAC has been extensively applied to two-view robust correspondence problems (e.g., solving the fundamental matrix, homography), it is less explored in robust model fitting (e.g., fitting 3D lines in volumetric data) by incorporating multi-view inputs and constraints.</p><p>(2) Trajectory verification: In this step, we aim at verifying the presence of the bird using guidance from geometric verification. Given a small set of 3D line hypotheses, we integrate the signals along the direction of the coarse 3D trajectory while accounting for spatial uncertainties due to time-varying speed, direction, and altitude. This is technically realized using the generalized distance transform to efficiently search over all possible spatial deformations. The trajectory verification allows us to integrate all of the local responses along the predicted trajectory, resulting in a more discriminative signal for separating birds from noisy background night sky and ranking hypothesis. This step is critical for handling challenging low-SNR scenarios.</p><p>We make the following contributions in this paper: 1. We address a novel application domain using computer vision algorithms. The vision-based system provides a low-cost, accurate, and new sensing modality for monitoring and studying bird migration. 2. We propose a RANSAC-based 3D line fitting algorithm that explicitly incorporates stereo vision constraints. We demonstrate that such constraints are crucial for robust model fitting in very low SNRs. 3. We account for birds flying with time-varying speeds and directions using deformable part modeling. The trajectory verification step allows us to gather all the local responses along the predicted trajectory, resulting in a discriminative signal for separating birds from the noisy background night sky.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Bird migration monitoring techniques. Scientists use methods such as weather radar <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b18">19]</ref> and acoustic sensors <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b17">18]</ref> to monitor migrating birds <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b12">13]</ref>. Radar networks can provide wide area coverage over 1000's of kilometers, but radar reflectivity data is difficult to interpret and requires careful calibration as the data contain many biological (birds, bats, and insects) and metorological phenomena. Calibration often is based on a traditional method for counting migrating birds: the use of a telescope to count birds as they pass across the full moon. Although moon-watching <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b24">25]</ref> can provide direct visual bird counts, it is labor-intensive, error-prone (e.g., when multiple birds fly across), and only covers a very small portion of the night sky (the moon is about 0.5 deg wide in the sky). In contrast, our vision-based approach can accurately detect birds, infer their orientations, speeds, altitudes, and cover a large portion of the sky -a 5-10 degree FOV covers 250 to 1000× larger area than the moon.</p><p>Small target detection in image sequences. Detecting and tracking small targets in infrared image sequences is a long-standing problem in computer vision with numerous military applications. These methods typically rely on detecting the small targets locally, e.g., using framedifferencing <ref type="bibr" target="#b11">[12]</ref>, max-mean/max-median filter <ref type="bibr" target="#b13">[14]</ref>, tophat transformation <ref type="bibr" target="#b4">[5]</ref>, or directional filters <ref type="bibr" target="#b3">[4]</ref>. Local detections are then linked over time using sequential hypothesis testing or motion models such as Kalman, particle filters, or global optimization approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b34">35]</ref>. As our videos contain a substantial amount of noise, local detections are not reliable (as shown in <ref type="figure" target="#fig_1">Figure 3</ref>). Unlike previous approaches that aim at getting correct local detections, we leverage topdown models with global reasoning for robust detection.</p><p>The work most related to our work is that of Ballerini et al. <ref type="bibr" target="#b6">[7]</ref>, which uses stereo vision to reconstruct 3D positions of individual birds to study the collective behavior of flocks of birds during the day. Our problem differs from theirs because many birds migrate at night. The challenge thus lies in how to detect birds in very low SNRs reliably. We can perform detection only by doing detection and tracking simultaneously so that detection is enabled by additional constraints coming from tracking, and vice versa.</p><p>Ridge detection in three-dimensions. We can view our problem as ridge detection in three-dimensional volumetric data (i.e., spatiotemporal volume). Ridge detection techniques often detect ridges using a pre-defined set of oriented filters at multiple scales. However, the local filters are not optimal for detecting faint signals in low SNR settings. Recent efforts include designing image representation for facilitating faint signal detection <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b16">17]</ref> or detecting faint curved edges in images <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b31">32]</ref>.</p><p>Geometric model fitting. Our work is related to classical parametric shape fitting techniques in computer vision such as RANSAC <ref type="bibr" target="#b20">[21]</ref> and generalized Hough transform <ref type="bibr" target="#b5">[6]</ref>. In our problem context, Hough transform would need to construct a 5-D parameter space, making the memory cost prohibitively high. Our method uses a RANSAC-based algorithm to perform line fitting in 3D point clouds (2D space + 1D time). The novelty lies in that we propose a sample selection approach for generating hypothetical inliers by leveraging the stereo vision constraints.  To account for birds flying at time-varying speed and directions, we interpret the motion compensated local image patch as a "part" of an object and use the generalized distance transform <ref type="bibr" target="#b19">[20]</ref> for handling such spatial uncertainty. We detect the birds by thresholding the final response map. first use classical statistical background modeling to detect foreground candidates (Section 4.3). As shown in <ref type="figure" target="#fig_2">Figure 4</ref>, the substantial number of outliers obscure the hidden curved line. Second, we use a RANSAC-based 3D line fitting algorithm to generate and verify hypotheses (Section 4.4). We propose a sampling strategy that explicitly incorporates stereo vision constraints. Such constraints are powerful because it allows us to reject a large portion of physically implausible configurations, and thereby offers computational efficiency when a large number of random samples are required due to the unusually high outliers ratio. We use a coarse threshold to maintain high recall in detection. Third, we use trajectory verification (Section 4.4) to integrate the faint signals along the predicted trajectory from geometric verification while accounting for spatial uncertainties. Unlike RANSAC-based detection methods that use sparse detection data (i.e., 3D point clouds), we exploit dense information across the spatiotemporal volume. Through gathering local evidence across a long temporal span, we get a clean and discriminative signal that allows us to separate birds from the noisy background with high precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Overview</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Stereo-based Bird Detection</head><p>In this section, we describe the proposed method in detail. We first present the local bird trajectory model by assuming a weak perspective camera model. We then briefly describe pre-processing steps for rectifying videos of the night sky by registering stars, followed by the core detection algorithm: (1) foreground detection, (2) geometry verification, and (3) trajectory verification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Bird trajectory modeling</head><p>To model the coarse bird trajectory in a video, we make the following two assumptions. First, we assume affine camera models because the migrating birds in flight are reasonably far away from the camera (with altitudes ranging from several hundred feet to two miles) compared with the size of a bird. Second, we assume that birds fly at relatively constant speed, orientation, and altitude during a short timeframe (e.g., 5 seconds). Denote the three-dimensional position in space of a bird at time t as P t = [X t ,Y t , Z t ] ⊤ , we can express the imaged position of the bird p t = [x t , y t ] ⊤ as p t = M[P ⊤ t , 1] ⊤ , where M ∈ R 2×4 is the camera projection matrix. Using the constant speed, orientation, and altitute assumptions, we simplify the 3D position P t as P t = P 0 + t[V x ,V y , 0] ⊤ , where P 0 indicates the position at time t = 0, and V x ,V y are the physical speeds in space. We can write down the imaged position</p><formula xml:id="formula_0">p t = p 0 + t[v x , v y ] ⊤ ,</formula><p>where v x , v y are the speed in the image space. We can thus view this idealized bird trajectory as a thin, straight ridge in the spatio-temporal video cube.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Stereo image rectification</head><p>Our system uses stereo vision to determine the altitude of a flying bird from correspondence. To simplify the 2D correspondence search to 1D, we first rectify the images from two views so that all epipolar lines are parallel to the horizontal axis. We follow the standard procedure for stereo image rectification: (1) finding a set of correspondences in the stereo pair of videos, (2) estimate the fundamental matrix <ref type="bibr" target="#b36">[37]</ref>, and (3) compute the rectifying matrices using <ref type="bibr" target="#b29">[30]</ref>.</p><p>For night sky images, we cannot apply the commonly used local interest point and feature descriptor matching approaches to establish correspondences. Fortunately, mother nature provides stars as markers. The two cameras are setup to capture roughly the same patch of the sky, so we exploit the imaged star positions for image registration. For each video, we first apply a moving average filter over the temporal axis to suppress the background noise. We then apply a single-scale 2D Laplacian of the Gaussian (LoG) to locate bright blob structures. After thresholding the LoG filter response and non-maximum suppression, we obtain a set of star positions (i.e., 2D point cloud) for each video.</p><p>With the detected star positions, we use the Iterative Closest Point (ICP) algorithm <ref type="bibr" target="#b9">[10]</ref> with an affine motion model to find the transformation and inlier matches. However, as the stars are infinitely far away from the camera, the correspondences from stars gives rise to a degenerated case in fundamental matrix estimation. To eliminate this degeneracy, we manually label the position of a flying bird in several frames. We only need to do this manual labeling once because we assume the cameras remain fixed through the videos. It is possible to use the proposed automatic flying bird detection to perform self-calibration (e.g., for cases where the stereo camera setup cannot remain fixed over time), but we leave that for future work.</p><p>We show in <ref type="figure" target="#fig_4">Figure 5</ref>(a) the detected starts in two views (Red and Green) the correspondence from ICP in Blue line. <ref type="figure" target="#fig_4">Figure 5</ref>(b) shows the rectified positions for the stars and the manually labeled bird. The stars from two views align accurately (as they are infinitely far) and the labeled birds fall on horizontal lines. Note that the results shown here contain star positions over 20 mins. The purpose of using this "star trail" is to provide additional accuracy for registration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Foreground detection</head><p>In this step, we look for local evidences for detecting flying birds. As imaged flying birds appear brighter than the surrounding background (illuminated from below by light pollution), the imaged bird trajectory can be seen as an intensity ridge in the video sequence. The problem of bird detection could be naturally cast as a ridge detection task in a 3D spatiotemporal video cube. Ridge (and valley) detection have been extensively studied in computer vision and image analysis with typical applications for detecting road in aerial images and for detecting blood vessels in 2D retinal or 3D magnetic resonance images. These methods often rely on designing filters that respond to locally linear intensity features followed by linking processes. However, these methods cannot directly be applied to our problem. As our videos have very low SNR, achieving accurate local detection would require evaluating a large collection of oriented filters with large kernel sizes, and thus would not scale well with large-scale video datasets.</p><p>For efficiency, we rely on top-down knowledge and global reasoning for detecting dim flying birds and resort to a simple statistical background modeling approach for local foreground pixel detection. Specifically, we build a per-pixel Gaussian model and compute the response of a pixel by measuring the intensity deviation from the learned model. We detect foreground pixels by thresholding the local responses. We estimate the parameters of the per-pixel Gaussian model (mean and variance) online using a predefined learning rate. Note that while other more sophisticated background modeling and subtraction techniques are available, we did not observe substantial improvement. <ref type="figure" target="#fig_5">Figure 6</ref> shows the three-dimensional (X-Y-T) scattered plot of the foreground detection on West and East camera on a video with a flock of three birds. <ref type="figure" target="#fig_5">Figure 6</ref>(b) shows the projections of the 3D point cloud onto X-Y, Y-T, and X-T planes, respectively. We could visually spot the three flying birds. The challenge, however, lies in how to handle the high outliers ratio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Geometric verification</head><p>Our coarse bird model (i.e., a straight line in a 3D video cube) consists of 5 parameters, including an initial spatial position in the image plane (2D), constant motion vectors (2D), and disparity from stereo vision (1D). The goal of geometric verification is to fit coarse bird models to the 3D point clouds with a significant portion of outliers from the foreground detection step. The most widely used robust fitting algorithms are (1) Generalized Hough Transform (GHT) and (2) RANSAC. We choose to perform geometric verification using RANSAC because of the demanding memory complexity in GHT for estimating 5D models.</p><p>A straightforward approach would be using RANSACbased 3D line fitting method independently for each video and then solve the disparity by matching fitted lines in two views after the models in each video are found. However, such an approach does not exploit the available physical constraints presented in the stereo videos. For example, the two corresponding 3D lines in the stereo pair should be parallel, having the same y-coordinate at all frames, and with positive disparity values. To incorporate these constraints, we propose a stereo-based 3D line fitting algorithm. Specifically, of the detected foreground points from the stereo pair, we select random subsets of three detected points to estimate the bird model, where two points are drawn from one video, and one point is drawn from the other video. <ref type="figure" target="#fig_2">Figure 4(b)</ref> illustrates the three-point hypothetical inlier. The proposed three-point subset sampling strategy offers several advantages. First, we can fully determine the 5D bird model using the selected three points. Second, we can quickly reject a large collection of model hypotheses that are not physically plausible by checking the disparity and temporal alignment. Third, as we also have disparity in the estimated model, we can simultaneously exploit the detected foreground points from both videos by compensating for the disparity.</p><p>We follow the standard RANSAC algorithm and count the number of inliers (number of foreground points fall inside the 3D tube). We then apply the J-linkage clustering algorithm <ref type="bibr" target="#b33">[34]</ref> to group repeatedly sampled hypothesis. Once we have the grouped model hypothesis, we perform least squares fitting using all the inlier foreground points from both videos to compute a more reliable bird model estimation. We solve this refinement step iteratively. Given an estimated disparity, we can solve the orientation using Singular Value Decomposition. In turn, we fix the orientation and update the disparity using least-square fitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Trajectory verification</head><p>While geometric verification can efficiently detect flying birds by exploiting the stereo vision constraints, we observe a high false positive rate due to inevitable noisy foreground detections. We address this issue by integrating signals along the bird's trajectory. Unlike geometric verification that fit models to sparse foreground candidates, trajectory verification exploits dense information across the entire video cube.</p><p>One way to achieve this is to use the corresponding matched filter that computes the average local response along its trajectory. However, the actual bird trajectory may not be a perfect 3D straight line in the video because the bird may not fly along the same direction or maintain constant speed and altitude. Simply using the estimated coarse bird model to filter the videos is clearly sub-optimal as spatial misalignments lead to blurry accumulated response.</p><p>We address this problem by allowing the bird trajectory to be "deformed" as illustrated in <ref type="figure">Figure 7</ref>. We interpret the bird response at the predict position using the coarse model at a frame as the local response for a "part". The detection of the bird can then be cast as the detection of a deformable part model. Specifically, we evaluate the score of a small <ref type="figure">Figure 7</ref>. Trajectory verification. Given a 3D line model, we gather the spatial patches along the coarse trajectory from T = 1 (when the bird enters the frame) to T = N (when the bird leaves the frame). These local responses are noisy and misalignment due to time-varying speed and directions. We transform the responses to account for spatial uncertainty.</p><p>window (e.g., 15 × 15) as</p><formula xml:id="formula_1">score(x, y) = N t ∑ t=1 max dx,dy R t (x t + dx, y t + dy) − α dx 2 + dy 2 ,</formula><p>where R t is the response map for foreground object, (x t , y t ) is the predicted position at time t using the hypothesized 3D line from the geometric verification step, and α is the weights for allowing different levels of spatial deformation. As we also have the disparity estimation, we aggregate the scores from two views. We use the Generalized Distance Transform <ref type="bibr" target="#b19">[20]</ref> to efficiently search over all possible deformations through time. These transformed responses can then be added together and ranked for verification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Implementation details</head><p>In foreground detection, we classify a pixel as a foreground if its intensity is greater than the mean background intensity by 2.75 standard deviations. In geometric verification, we keep model hypotheses with at least 5 inliers and reject the rest. In trajectory verification, we use 15 × 15 windows and set the spatial deformation parameter α = 0.5. We fix these parameters throughout all experiments.</p><p>We process a video in a mini-batch mode, by dividing a long video sequence into a set of overlapping five-second sequences with a one-second interval. We detect birds in each video clip and cluster these detections in the nearby clips to generate our final results. In a video with frame rate 30 fps, we have in total 150 frames. For processing one </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Evaluation on real videos</head><p>To evaluate the proposed method, we have developed a prototype stereo video system to capture videos of migrating birds at night. In what follows, we present the data collection steps and our results on real videos.</p><p>Data collection We use two low-light near-IR mono industrial VGA cameras to capture the stereo video. We chose the cameras because of their superior low-light sensitivity (10k-100k × more sensitive than consumer video cameras). The cameras have a spatial resolution of 640 × 480 pixels. We use a pair of 50 mm lenses and set the two cameras on tripods facing the sky with a two-meter baseline. We captured hours of stereo video on different nights and selected a 40-minutes long video from Spring migration for testing.</p><p>Quantitative results To evaluate performance, we developed a Graphical User Interface to allow experts to annotate the birds flying across video frames. In total, 86 birds were found in the video. A majority of the birds head North + − 20 degrees. Among the 86 annotated birds, our method detects 74 of them, with two false positives and 12 missed detections. In <ref type="table" target="#tab_1">Table 1</ref>, we show the quantitative performance of our algorithm. When using geometric verification only, we achieve 83.10% in recall. However, precision is very poor, with only 6.08%. Coupled with trajectory verification, precision rises above 95% with 83% recall. The automatic system detects 9 birds missed by the experts.</p><p>We further evaluate the relative contributions from (1) fusing information from two views and (2) using the deformable part model to account for the inevitable spatial uncertainty when using real videos of birds migrating at night. Specifically, we report the precision and recall values using the four variants. One View: use only the video from the West camera. Two Views: use both West and East videos. Without deformation: did not transform the scores in each local image patch. With deformation: use the generalized distance transform to allow spatial uncertainty.</p><p>To make the contribution of each term clear, <ref type="figure" target="#fig_6">Figure 8</ref> shows the precision and recall of these four variants using a version of the system that does no post-processing to reduce 1 https://sites.google.com/site/jbhuang0604 false detections. In cases of integrating signals along the estimated trajectory (from geometric verification) in one view, both the precision and recall improve when we account for the spatial deformation. When using two views without accounting for the spatial deformation, we found that the recall drops significantly. We attribute the performance degradation to the imperfect disparity estimation between the two views. Integrating scores from two views without taking the spatial uncertainty into account, the results suggest that the algorithm may not be able to accumulate the weak signals due to the misalignment, and, therefore, fails to detect dim birds. Overall, the best performance is achieved by taking advantage of the stereo constraint while also allowing for deformation to account for spatial uncertainty.</p><p>Qualitative results In <ref type="figure" target="#fig_7">Figure 9</ref>, we show detection results in a variety of scenarios to demonstrate the effectiveness of the proposed approach. For example, our method can detect birds flying at altitudes ranging from 200 meters to more than 2,500 meters as well as at different directions and speeds. We can also handle multiple birds flying across the video frame. Unlike existing techniques that can only detect the presence of the birds, the direct visual analysis provides detailed measurements about the trajectory of individual birds. We believe such information may provide valuable insights about the behavior of migrating flocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Discussion</head><p>Limitations One potential problem and limitation in evaluating the performance on real videos is that the groundtruth annotations are not available, and the human visual system may not be able to detect very dim, high-flying birds from the video. In the future, we plan to investigate a multi-modal solution (e.g., vision-based, acoustics-based, and weather radar) toward this problem. <ref type="figure" target="#fig_8">Figure 10</ref> shows a few of the limitations of our method. First, as our foreground detection is based on a statistical background mod-  (c) a true negative -the moving blob is an insect. Our system uses the estimated altitude to avoid confusion with high-flying objects (e.g., above 3000 meters) such as satellites or planes and low-flying objects (e.g., under 50 meters) such as insects.</p><p>eling approach, we are not able to handle dynamic background or sudden illumination changes. For example, in <ref type="figure" target="#fig_8">Figure 10</ref>(a), our method falsely detect the moving cloud as a bird. Second, even with the use of stereo-based constraints for rejecting physically implausible detections (e.g., <ref type="figure" target="#fig_8">Figure 10(b)</ref>), our method may sometimes produce false positives due to the substantial noise in the video. One potential solution is to use three or more cameras covering the same patch of the night sky. Our framework could be extended to multi-camera settings to further improve the detection performance. Third, in <ref type="figure" target="#fig_8">Figure 10</ref>(c) we show that our method is robust to other types of flying objects. The altitude estimation provides important cues for separating migrating birds from high-flying objects (satellites or airplanes) and low-flying objects (insects).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>We presented the first stereo-vision-based approach for monitoring migrating birds at night. From a pair of stereo videos, we perform stereo image rectification by detecting and registering stars. The core bird detection algorithm then consists of three main steps. First, we use a statistical background modeling for foreground detection for each video. This produces a noisy three-dimensional point cloud. Second, we propose a novel RANSAC-based 3D line fitting that explicitly takes into account stereo vision constraints. Third, we apply deformable part modeling for handling the spatial uncertainty of birds due to time-varying speed and orientation. Through evaluation on real videos captured from a physical setup, we demonstrate the effectiveness of the proposed method. We believe the new capabilities will make significant impact on computational ecology.</p><p>While our work address a particular application, the approach for detecting and tracking multiple small targets in 3D volumic data with very low SNR using multiple cameras is general and potentially can be applied to many other important problems. In this work, we show how to leverage the underlying physical constraints and domain knowledge to achieve physically plausible detection that otherwise would not be feasible due to the high level of noise.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>The difficulty of detection based on local image patches. (a) 16 cropped local image patch along a manually labeled bird trajectory. (b) 16 cropped random background patches. These patches are virtually indistinguishable by the naked eye.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4</head><label>4</label><figDesc>illustrates the three main steps for detecting migrating birds in flight. Given a pair of stereo videos, we</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Overview of the bird detection algorithm. Our algorithm consists of three main modules: (a) Foreground detection: using statistical background modeling for moving object detection. (b) Geometric verification: RANSAC-based line fitting with stereo vision constraints. The three red boxes indicate the selected hypothetical inliers. This strategy naturally handles disparity estimation and offer computational efficiency by rejecting a large number of physically implausible configurations. (c) Trajectory verification: with the coarse 3D line fitting, we integrate weak signals along the predicted trajectory for both videos to verify if there is a bird.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Stereo image rectification using star registration. (a) Star detection from a video frame, (b) Correspondence, (c) Stereo image rectification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Foreground detection. (a) Sample foreground detection plots. Flying birds in a video appear like curved lines in the spatiotemporal volume. In this scattered plot, there are three curved lines. (b) Projection of foreground detection onto X-Y, X-T, and Y-T planes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Precision and recall of four variants of the proposed trajectory verification approach on real videos.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>Detection results on real videos. Our system can handle diverse scenarios, e.g., single, multiple birds, birds flying parallel with each other, or birds flying at very different altitudes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 .</head><label>10</label><figDesc>Interesting cases: (a): a false positive detection due to a moving cloud. (b) a false positive detection due to noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Figure 1. Detecting migrating birds from noisy image sequences. Each row shows a set of frames from a video sequence. From top to bottom, the sequences shown here have increasing levels of difficulty. Most of the bright spots in the images are stars. Color boxes indicate the birds in the first and the last frame of each sequence. Because of the low SNR and small size of high-flying birds (1-2 pixels), detection is very difficult, and often impossible, when looking at individual frames. It is only by detecting motion in the video stream that the human perceptual system can identify and track most birds. Similarly, the detection algorithm can only detect the more difficult high-flying birds by looking at the full video sequence and by simultaneously using stereo constraints from both cameras. Results are best viewed on a high-resolution display with adequate zoom level.</figDesc><table>jects in image sequences under different problem contexts. 
In Automatic Target Recognition (ATR) </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 .</head><label>1</label><figDesc>Quantitative performance</figDesc><table>Method 
Precision Recall 
Geometric verification only 
6.08% 83.10% 
Geometric and Trajectory verification 97.30% 83.72% 

5 second video clip, our MATLAB implementation takes 7 
seconds on a PC with 1.9GHz and 8 GB memory. The data 
and source code are available on the project website 1 . 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported in part by Office of Naval Research N00014-12-1-0259, and Air Force Office of Scientific Research AF FA8750-13-2-0008, National Science Foundation grant IIS-1125098, and the Leon Levy Foundation. We want to thank Peter Gural, David Samuels, and the CAMS (Cameras for Allsky Meteor Surveillance) Project for their generous help in the initial stages of this project (the 1st images of birds flying at night came from their meteor cameras), and Danil Radchenko and Konstantin Kobylinsky at Sensoray for modifying their frame-grabber drivers for this project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Long-distance migration: evolution and determinants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Alerstam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hedenström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Åkesson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oikos</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="247" to="260" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Detecting faint curved edges in noisy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Alpert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV. 2010</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Greta-a novel global and recursive tracking algorithm in three dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Attanasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cavagna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Castello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Giardina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jelic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Melillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Parisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pellacini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Silvestri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Edge directional 2d lms filter for infrared small target detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-W</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I.-S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Infrared Physics &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="137" to="145" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Analysis of new top-hat transformation and the application for infrared dim small target detection. Pattern Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generalizing the hough transform to detect arbitrary shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="122" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Interaction ruling animal collective behavior depends on topological rather than metric distance: Evidence from a field study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ballerini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1232" to="1237" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Detecting bird sounds in a complex acoustic environment and application to bioacoustic monitoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bardeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kurth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-H</forename><surname>Tauchert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-H</forename><surname>Frommolt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Bird migration: a general survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Berthold</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A method for registration of 3-d shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Besl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mckay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="239" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic target recognition: State of the art survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bhanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Aerospace and Electronic Systems</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="364" to="379" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Detecting small, moving objects in image sequences using sequential hypothesis testing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Blostein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1611" to="1629" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Technology on the move: recent and forthcoming innovations for tracking migratory birds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Bridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Thorup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Bowlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Chilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Diehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Fléron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hartl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Roland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">D</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioScience</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="689" to="698" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Maxmean and max-median filters for detection of small targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Venkateswarlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE&apos;s International Symposium on Optical Science, Engineering, and Instrumentation</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bird migration flight altitudes studied by a network of operational weather radars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Dokter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liechti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Delobbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tabary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Holleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of The Royal Society Interface</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">54</biblScope>
			<biblScope unit="page" from="30" to="43" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Beamlets and multiscale image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multiscale and Multiresolution Methods: Theory and Applications</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">149</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Fast x-ray and beamlet transforms for three-dimensional data. Modern signal processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Strategies for bird conservation: The Partners in Flight planning process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Rosenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
	<note>Acoustic monitoring of nightmigrating birds: a progress report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A characterization of autumn nocturnal migration detected by weather surveillance radars in the northeastern us</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farnsworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Van Doren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Hochachka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sheldon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Winner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Geevarghese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kelling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Applications</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Distance transforms of sampled functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Bolles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="381" to="395" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multiscale edge detection and fiber enhancement using differences of oriented means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Optimally sparse multidimensional representation using shearlets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Labate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM journal on mathematical analysis</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bird migration and the conservation of the global environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Higuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Ornithology</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="14" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A comparison of traffic estimates of nocturnal flying animals using radar, thermal imaging, and acoustic recording</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Horton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">G</forename><surname>Shriver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Buler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Image completion using planar structure guidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Gr</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">129</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Single image super-resolution from transformed self-exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A review of vessel extraction techniques and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kirbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Quek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="81" to="121" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Quantification of nocturnal bird migration by moonwatching: Comparison with radar and infrared observations (cuantificación de la migración nocturna de aves observando la luna: Comparación con observaciones de radar e intrarrojas)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liechti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bruderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Paproth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Field Ornithology</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="457" to="468" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Computing rectifying homographies for stereo vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Loop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Estimating animal population density using passive acoustics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Mellinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Moretti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Tyack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Reviews</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Fast detection of curved edges at low snr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ofir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.06600</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Approximate bayesian inference for reconstructing velocities of migrating birds from weather radar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sheldon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farnsworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Doren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kelling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Robust multiple structures estimation with j-linkage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Toldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fusiello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Global optimization for coupled detection and data association in multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Betke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
		<respStmt>
			<orgName>CVIU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Algorithms for optical weak small targets detection and tracking: review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Neural Networks and Signal Processing</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Determining the epipolar geometry and its uncertainty: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="195" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
