<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Patch-based Convolutional Neural Network for Whole Slide Tissue Image Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Hou</surname></persName>
							<email>lehhou@cs.stonybrook.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Samaras</surname></persName>
							<email>samaras@cs.stonybrook.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahsin</forename><forename type="middle">M</forename><surname>Kurc</surname></persName>
							<email>tahsin.kurc@stonybrook.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Biomedical Informatics</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Oak Ridge National Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Biomedical Informatics</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Applied Mathematics and Statistics</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">E</forename><surname>Davis</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Dept. of Pathology</orgName>
								<orgName type="institution">Stony Brook Hospital</orgName>
								<address>
									<addrLine>6 Cancer Center</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Stony Brook Hospital</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">H</forename><surname>Saltz</surname></persName>
							<email>joel.saltz@stonybrook.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Biomedical Informatics</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Dept. of Pathology</orgName>
								<orgName type="institution">Stony Brook Hospital</orgName>
								<address>
									<addrLine>6 Cancer Center</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Stony Brook Hospital</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Patch-based Convolutional Neural Network for Whole Slide Tissue Image Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Convolutional Neural Networks (CNN) are state-of-theart models for many image classification tasks. However, to recognize cancer subtypes automatically, training a CNN on gigapixel resolution Whole Slide Tissue Images (WSI) is currently computationally impossible. The differentiation of cancer subtypes is based on cellular-level visual features observed on image patch scale. Therefore, we argue that in this situation, training a patch-level classifier on image patches will perform better than or similar to an image-level classifier. The challenge becomes how to intelligently combine patch-level classification results and model the fact that not all patches will be discriminative. We propose to train a decision fusion model to aggregate patch-level predictions given by patch-level CNNs, which to the best of our knowledge has not been shown before. Furthermore, we formulate a novel Expectation-Maximization (EM) based method that automatically locates discriminative patches robustly by utilizing the spatial relationships of patches. We apply our method to the classification of glioma and non-small-cell lung carcinoma cases into subtypes. The classification accuracy of our method is similar to the inter-observer agreement between pathologists. Although it is impossible to train CNNs on WSIs, we experimentally demonstrate using a comparable non-cancer dataset of smaller images that a patch-based CNN can outperform an image-based CNN.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Convolutional Neural Networks (CNNs) are currently the state-of-the-art image classifiers <ref type="bibr" target="#b27">[30,</ref><ref type="bibr" target="#b26">29,</ref><ref type="bibr" target="#b4">7,</ref><ref type="bibr" target="#b20">23]</ref>. However, due to high computational cost, CNNs cannot be applied to very high resolution images, such as gigapixel Whole Slide Tissue Images (WSI). Classification of cancer WSIs into grades and subtypes is critical to the study of disease onset and progression and the development of targeted therapies, because the effects of cancer can be observed in WSIs at the cellular and sub-cellular levels ( <ref type="figure" target="#fig_0">Fig. 1)</ref>. Applying CNN directly for WSI classification has several drawbacks. First, extensive image downsampling is required by which most of the discriminative details could be lost. Second, it is possible that a CNN might only learn from one of the multiple discriminative patterns in an image, resulting in data inefficiency. Discriminative information is encoded in high resolution image patches. Therefore, one solution is to train a CNN on high resolution image patches and predict the label of a WSI based on patch-level predictions. The ground truth labels of individual patches are un-known, as only the image-level ground truth label is given. This complicates the classification problem. Because tumors may have a mixture of structures and texture properties, patch-level labels are not necessarily consistent with the image-level label. More importantly, when aggregating patch-level labels to an image-level label, simple decision fusion methods such as voting and max-pooling are not robust and do not match the decision process followed by pathologists. For example, a mixed subtype of cancer such as oligoastrocytoma, might have distinct regions of other cancer subtypes. Therefore, neither voting nor max-pooling could predict the correct WSI-level label since the patchlevel predictions do not match the WSI-level label. We propose using a patch-level CNN and training a decision fusion model as a two-level model, shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. The first-level (patch-level) model is an Expectation Maximization (EM) based method combined with CNN that outputs patch-level predictions. In particular, we assume that there is a hidden variable associated with each patch extracted from an image that indicates whether the patch is discriminative (i.e. the true hidden label of the patch is the same as the true label of the image). Initially, we consider all patches to be discriminative. We train a CNN model that outputs the cancer type probability of each input patch. We apply spatial smoothing to the resulting probability map and select only patches with higher probability values as discriminative patches. We iterate this process using the new set of discriminative patches in an EM fashion. In the second-level (image-level), histograms of patch-level predictions are input into an image-level multiclass logistic regression or Support Vector Machine (SVM) <ref type="bibr" target="#b7">[10]</ref> model that predicts the image-level labels.</p><p>Pathology image classification and segmentation is an active research field. Most WSI classification methods focus on classifying or extracting features on patches <ref type="bibr" target="#b14">[17,</ref><ref type="bibr" target="#b32">35,</ref><ref type="bibr" target="#b47">50,</ref><ref type="bibr" target="#b53">56,</ref><ref type="bibr" target="#b8">11,</ref><ref type="bibr" target="#b1">4,</ref><ref type="bibr" target="#b45">48,</ref><ref type="bibr" target="#b11">14,</ref><ref type="bibr" target="#b47">50]</ref>. In <ref type="bibr" target="#b47">[50]</ref> a pretrained CNN model extracts features on patches which are then aggregated for WSI classification. As we show here, the heterogeneity of some cancer subtypes cannot be captured by those generic CNN features. Patch-level supervised classifiers can learn the heterogeneity of cancer subtypes, if a lot of patch labels are provided <ref type="bibr" target="#b14">[17,</ref><ref type="bibr" target="#b32">35]</ref>. However, acquiring such labels in large scale is prohibitive, due to the need for specialized annotators. As digitization of tissue samples becomes commonplace, one can envision large scale datasets, that could not be annotated at patch scale. Utilizing unlabeled patches has led to Multiple Instance Learning (MIL) based WSI classification <ref type="bibr" target="#b13">[16,</ref><ref type="bibr" target="#b48">51,</ref><ref type="bibr" target="#b49">52]</ref>.</p><p>In the MIL paradigm <ref type="bibr" target="#b15">[18,</ref><ref type="bibr" target="#b30">33,</ref><ref type="bibr" target="#b2">5]</ref>, unlabeled instances belong to labeled bags of instances. The goal is to predict the label of a new bag and/or the label of each instance. The Standard Multi-Instance (SMI) assumption <ref type="bibr" target="#b15">[18]</ref> states that for a binary classification problem, a bag is positive iff there exists at least one positive instance in the bag. The probability of a bag being positive equals to the maximum positive prediction over all of its instances <ref type="bibr" target="#b3">[6,</ref><ref type="bibr" target="#b51">54,</ref><ref type="bibr" target="#b24">27]</ref>. Combining MIL with Neural Networks (NN) <ref type="bibr" target="#b40">[43,</ref><ref type="bibr" target="#b54">57,</ref><ref type="bibr" target="#b28">31,</ref><ref type="bibr" target="#b10">13]</ref>, the SMI assumption is modeled by max-pooling. Following this formulation, the Back Propagation for Multi-Instance Problems (BP-MIP) <ref type="bibr" target="#b40">[43,</ref><ref type="bibr" target="#b54">57]</ref> performs back propagation along the instance with the maximum response if the bag is positive. This is inefficient because only one instance per bag is trained in one training iteration on the whole bag.</p><p>MIL-based CNNs have been applied to object recognition <ref type="bibr" target="#b35">[38]</ref> and semantic segmentation <ref type="bibr" target="#b37">[40]</ref> in image analysis -the image is the bag and image-windows are the instances <ref type="bibr" target="#b33">[36]</ref>. These methods also follow the SMI assumption. The training error is only propagated through the object-containing window which is also assumed to be the window that has the maximum prediction confidence. This is not robust because one significantly misclassified window might be considered as the object-containing window. Additionally, in WSIs, there might be multiple windows that contain discriminative information. Hence, recent semantic image segmentation approaches <ref type="bibr" target="#b9">[12,</ref><ref type="bibr" target="#b38">41,</ref><ref type="bibr" target="#b36">39]</ref> smooth the output probability (feature) maps of the CNNs.</p><p>To predict the image-level label, max-pooling (SMI) and voting (average-pooling) were applied in <ref type="bibr" target="#b33">[36,</ref><ref type="bibr" target="#b27">30,</ref><ref type="bibr" target="#b14">17]</ref>. However, it has been shown that in many applications, learning decision fusion models can significantly improve performance compared to voting <ref type="bibr" target="#b39">[42,</ref><ref type="bibr" target="#b42">45,</ref><ref type="bibr" target="#b21">24,</ref><ref type="bibr" target="#b44">47,</ref><ref type="bibr" target="#b23">26,</ref><ref type="bibr" target="#b43">46]</ref>. Furthermore, such a learned decision fusion model is based on the Count-based Multiple Instance (CMI) assumption which is the most general MIL assumption <ref type="bibr" target="#b46">[49]</ref>.</p><p>Our main contributions in this paper are: (1) To the best of our knowledge, we are the first to combine patch-level CNNs with supervised decision fusion. Aggregating patchlevel CNN predictions for WSI classification significantly outperforms patch-level CNNs with max-pooling or voting.</p><p>(2) We propose a new EM-based model that identifies discriminative patches in high resolution images automatically for patch-level CNN training, utilizing the spatial relationship between patches.</p><p>(3) Our model achieves multiple state-of-the-art results classifying WSIs to cancer subtypes on the TCGA dataset. Our results are similar or close to inter-observer agreement between pathologists. Larger classification improvements are observed in the harder-toclassify cases. (4) We provide experimental evidence that combining multiple patch-level classifiers might actually be advantageous compared to whole image classification.</p><p>The rest of this paper is organized as follows. Sec. 2 describes the framework of the EM-based MIL algorithm. Sec. 3 discusses the identification of discriminative patches. Sec. 4 explains the image-level model that predicts the image-level label by aggregating patch-level predictions. Sec. 5 shows experimental results. The paper concludes in Sec. 6. App. A lists the cancer subtypes in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">EM-based method with CNN</head><p>An overview of our EM-based method can be found in <ref type="figure" target="#fig_1">Fig. 2</ref>. We model a high resolution image as a bag and patches extracted from it as instances. We have a ground truth label for the whole image but not for the individual patches. We model whether an instance is discriminative or not as a hidden binary variable.</p><p>We denote X = {X 1 , X 2 , . . . , X N } as the dataset containing N bags. Each bag</p><formula xml:id="formula_0">X i = {X i,1 , X i,2 , . . . , X i,Ni } consists of N i instances, where X i,j = x i,j , y i is the j-th</formula><p>instance and its associated label in the i-th bag. Assuming the bags are independent and identically distributed (i.i.d.), the X and the hidden variables H are generated by the following generative model:</p><formula xml:id="formula_1">P (X, H) = N i=1 P (X i,1 , . . . , X i,Ni | H i )P (H i ) , (1)</formula><p>where the hidden variable H = {H 1 , H 2 , . . . , H N }, H i = {H i,1 , H i,2 , . . . , H i,Ni } and H i,j is the hidden variable that indicates whether instance x i,j is discriminative for label y i of bag X i . We further assume that all X i,j depends on H i,j only and are independent with each other given H i,j . Thus</p><formula xml:id="formula_2">P (X, H) = N i=1 Ni j=1 P (X i,j | H i,j )P (H i ) .</formula><p>(2)</p><p>We maximize the data likelihood P (X) using EM.</p><p>1. At the initial E step, we set H i,j = 1 for all i, j. This means that all instances are considered discriminative.</p><p>2. M step: We update the model parameter θ to maximize the data likelihood</p><formula xml:id="formula_3">θ ← arg max θ P (X | H; θ) = arg max θ xi,j ∈D P (x i,j , y i | θ) × xp,q ∈D P (x p,q , y q | θ),<label>(3)</label></formula><p>where D is the discriminative patches set. Assuming a uniform generative model for all non-discriminative instances, the optimization in Eq. 3 simplifies to:</p><formula xml:id="formula_4">arg max θ xi,j ∈D P (x i,j , y i | θ) = arg max θ xi,j ∈D P (y i | x i,j ; θ)P (x i,j | θ).<label>(4)</label></formula><p>Additionally we assume an uniform distribution over x i,j . Thus Eq. 4 describes a discriminative model (in this paper we use a CNN).</p><p>3. E step: We estimate the hidden variables H. In particular, H i,j = 1 if and only if P (H i,j | X) is above a certain threshold. In the case of image classification, given the i-th image, P (H i,j | X) is obtained by applying Gaussian smoothing on P (y i | x i,j ; θ) (Detailed in Sec 3). This smoothing step utilizes the spatial relationship of P (y i | x i,j ; θ) in the image. We then iterate back to the M step till convergence.</p><p>Many MIL algorithms can be interpreted through this formulation. Based on the SMI assumption, the instance with the maximum P (H i,j | X) is the discriminative instance for the positive bag, as in the EM Diverse Density (EM-DD) <ref type="bibr" target="#b52">[55]</ref> and the BP-MIP <ref type="bibr" target="#b40">[43,</ref><ref type="bibr" target="#b54">57]</ref> algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Discriminative patch selection</head><p>Patches x i,j that have P (H i,j | X) larger than a threshold T i,j are considered discriminative and are selected to continue training the CNN. We present in this section the estimation of P (H | X) and the choice of the threshold.</p><p>It is reasonable to assume that P (H i,j | X) is correlated with P (y i | x i,j ; θ), i.e. patches with lower P (y i | x i,j ; θ) tend to have lower probability x i,j to be discriminative. However, a hard-to-classify patch, or a patch close to the decision boundary may have low P (y i | x i,j ; θ) as well. These patches are informative and should not be rejected. Therefore, to obtain a more robust P (H i,j | X), we apply the following two steps: First, we train two CNNs on two different scales in parallel. P (y i | x i,j ; θ) is the averaged prediction of the two CNNs. Second, we simply denoise the probability map P (y i | x i,j ; θ) of each image with a Gaussian kernel to compute P (H i,j | X). This use of spatial relationships yields more robust discriminative patch identification as shown in the experiments in Sec. 5.</p><p>Choosing a thresholding scheme carefully yields significantly better performance than a simpler thresholding scheme <ref type="bibr" target="#b36">[39]</ref>. We obtain the threshold T i,j for P (H i,j | X) as follows: We note S i as the set of P (H i,j | X) values for all x i,j of the i-th image and E c as the set of P (H i,j | X) values for all x i,j of the c-th class. We introduce the imagelevel threshold H i as the P 1 -th percentile of S i and the class-level threshold R i as the P 2 -th percentile of E c , where P 1 and P 2 are predefined. The threshold T i,j is defined as the minimum value between H i and R i . There are two advantages of our method. First, by using the image-level threshold, there are at least 1 − P 1 percent of patches that are considered discriminative for each image. Second, by using the class-level threshold, the thresholds can be easily adapted to classes with different prior probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Image-level decision fusion model</head><p>We combine the patch-level classifiers of Sec. 3 to predict the image-level label. We input all patch-level predictions into a multi-class logistic regression or SVM that outputs the image-level label. This decision level fusion method <ref type="bibr" target="#b25">[28]</ref> is more robust than max-pooling <ref type="bibr" target="#b42">[45]</ref>. Moreover, this method can be thought of as a Count-based Multiple Instance (CMI) learning method with two-level learning <ref type="bibr" target="#b46">[49]</ref> which is a more general MIL assumption <ref type="bibr" target="#b17">[20]</ref> than the Standard Multiple Instance (SMI) assumption.</p><p>There are three reasons for combining multiple instances: First, on difficult datasets, we do not want to assign an image-level prediction simply based on a single patchlevel prediction (as is the case of the SMI assumption <ref type="bibr" target="#b15">[18]</ref>). Second, even though certain patches are not discriminative individually, their joint appearance might be discriminative. For example, a WSI of the "mixed" glioma, Oligoastrocytoma (see App. A) should be recognized when two single glioma subtypes (Oligodendroglioma and Astrocytoma) are jointly present on the slide possibly on non-overlapping regions. Third, because the patch-level model is never perfect and probably biased, an image-level decision fusion model may learn to correct the bias of patch-level decisions.</p><p>Because it is unclear at this time whether strongly discriminative features for cancer subtypes exist at whole slide scale <ref type="bibr" target="#b31">[34]</ref>, we fuse patch-level predictions without the spatial relationship between patches. In particular, the class histogram of the patch-level predictions is the input to a linear multi-class logistic regression model <ref type="bibr" target="#b5">[8]</ref> or an SVM with Radial Basis Function (RBF) kernel <ref type="bibr" target="#b7">[10]</ref>. Because a WSI contains at least hundreds of patches, the class histogram is very robust to miss-classified patches. To generate the histogram, we sum up all of the class probabilities given by the patch-level CNN. Moreover, we concatenate histograms from four CNNs models: CNNs trained at two patch scales for two different numbers of iterations. We found in practice that using multiple histograms is robust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We evaluate our method on two Whole Slide Tissue Images (WSI) classification problems: classification of glioma and Non-Small-Cell Lung Carcinoma (NSCLC) cases into glioma and NSCLC subtypes. Glioma is a type of brain cancer that rises from glial cells. It is the most common malignant brain tumor and the leading cause of cancer-related deaths in people under age 20 <ref type="bibr" target="#b0">[1]</ref>. NSCLC is the most common lung cancer, which is the leading cause of cancerrelated deaths overall [3]. Classifying glioma and NSCLC into their respective subtypes and grades is crucial to the study of disease onset and progression in order to provide targeted therapies. The dataset of WSIs used in the experiments part of the public Cancer Genome Atlas (TCGA) dataset <ref type="bibr">[2]</ref>. It contains detailed clinical information and the Hematoxylin and Eosin (H&amp;E) stained images of various cancers. The typical resolution of a WSI in this dataset is 100K by 50K pixels. In the rest of this section, we first describe the algorithm we tested then show the evaluation results on the glioma and NSCLC classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Patch extraction and segmentation</head><p>To train the CNN model, we extract patches of size 500×500 from WSIs (examples in <ref type="figure" target="#fig_2">Fig. 3</ref>). To capture structures at multiple scales, we extract patches from 20X (0.5 microns per pixel) and 5X (2.0 microns per pixel) objective magnifications. We discard patches with less than 30% tissue sections or have too much blood. We extract around 1000 valid patches per image per scale. In most cases the patches are non-overlapping given WSI resolution.</p><p>To prevent the CNN from overfitting, we perform three kinds of data augmentation in every iteration. We select a random 400×400 sub-patch from each 500×500 patch. We randomly rotate and mirror the sub-patch. We randomly adjust the amount of Hematoxylin and eosin stained on the tissue. This is done by decomposing the RGB color of the tissue into the H&amp;E color space <ref type="bibr" target="#b41">[44]</ref>, followed by multiplying the magnitude of H and E of every pixel by two i.i.d. Gaussian random variables with expectation equal to one. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">CNN architecture</head><p>The architecture of our CNN is shown in Tab. 1. We used the CAFFE tool box <ref type="bibr" target="#b22">[25]</ref> for the CNN implementation. The network was trained on a single NVidia Tesla K40 GPU. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experiment setup</head><p>The WSIs of 80% of the patients are randomly selected to train the model and the remaining 20% to test. Depending on method, training patches are further divided into i) CNN and ii) decision fusion model training sets. We separate the data twice and average the results. Tested algorithms are:</p><p>1. CNN-Vote: CNN followed by voting (averagepooling). We use all patches extracted from a WSI to train the patch-level CNN. There is no second-level model. Instead, the predictions of all patches vote for the final predicted label of a WSI.</p><p>2. CNN-SMI: CNN followed by max-pooling. Same as CNN-Vote except the final predicted label of a WSI equals to the predicted label of the patch with maximum probability over all other patches and classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">CNN-Fea-SVM:</head><p>We apply feature fusion instead of decision level fusion. In particular, we aggregate the outputs of the second fully connected layer of the CNN on all patches by 3-norm pooling <ref type="bibr" target="#b47">[50]</ref>. Then an SVM with RBF kernel predicts the image-level label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EM-CNN-Vote/SMI, EM-CNN-Fea-SVM:</head><p>EM-based method with CNN-Vote, CNN-SMI, CNN-Fea-SVM respectively. We train the patch-level EM-CNN on discriminative patches identified by the E-step. Depending on the dataset, the discriminative threshold P 1 for each image ranges from 0.18 to 0.25; the discriminative threshold P 2 for each class ranges from 0.05 to 0.28 (details in Sec. 3). In each M-step, we train the CNN on all the discriminative patches for 2 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EM-Finetune-CNN-Vote/SMI: Similar to EM-CNN-</head><p>Vote/SMI except that instead of training a CNN from scratch, we fine-tune a pretrained 16-layer CNN model <ref type="bibr" target="#b43">[46]</ref> by training it on discriminative patches.</p><p>6. CNN-LR: CNN followed by logistic regression. Same as CNN-Vote except that we train a second-level multiclass logistic regression to predict the image-level label. One tenth of the patches in each image is held out from the CNN to train the second-level multi-class logistic regression.</p><p>7. CNN-SVM: CNN followed by SVM with RBF kernel instead of logistic regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">EM-CNN-LR/SVM: EM-based method with CNN-LR</head><p>and CNN-SVM respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">EM-CNN-LR w/o spatial smoothing:</head><p>We do not apply Gaussian smoothing to estimate P (H | X). Otherwise similar to EM-CNN-LR. <ref type="bibr" target="#b7">10</ref>. EM-Finetune-CNN-LR/SVM: Similar to EM-CNN-LR/SVM except that instead of training a CNN from scratch, we fine-tune a pretrained 16-layer CNN model <ref type="bibr" target="#b43">[46]</ref> by training it on discriminative patches.</p><p>11. SMI-CNN-SMI: CNN with max-pooling at both discriminative patch identification and image-level prediction steps. For the patch-level CNN training, in each WSI only one patch with the highest confidence is considered discriminative.</p><p>12. NM-LBP: We extract Nuclear Morphological features <ref type="bibr" target="#b12">[15]</ref> and rotation invariant Local Binary Patterns <ref type="bibr" target="#b34">[37]</ref> from all patches. We build a Bag-of-Words (BoW) <ref type="bibr" target="#b16">[19,</ref><ref type="bibr" target="#b50">53]</ref> feature using k-means followed by SVM with RBF kernel <ref type="bibr" target="#b7">[10]</ref>, as a non-CNN baseline.</p><p>13. Pretrained-CNN-Fea-SVM: Similar to CNN-Fea-SVM. But instead of training a CNN, we use a pretrained 16-layer CNN model <ref type="bibr" target="#b43">[46]</ref> to extract features from patches. Then we select the top 500 features according to accuracy on the training set <ref type="bibr" target="#b47">[50]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="14.">Pretrained-CNN-Bow-SVM:</head><p>We build a BoW model using k-means on features extracted by the pretrained CNN, followed by SVM <ref type="bibr" target="#b47">[50]</ref>. The results of our experiments are shown in Tab. 3. The confusion matrix is given in Tab. 4. An experiment showed that the inter-observer agreement of two experienced pathologists on a similar dataset was approximately 70% and that even after reviewing the cases together, they agreed only around 80% of the time <ref type="bibr" target="#b19">[22]</ref>. Therefore, our accuracy of 77% is similar to inter-observer agreement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">WSI of glioma classification</head><p>In the confusion matrix, we note that the classification accuracy between GBM and Low-Grade Glioma (LGG) is 97% (chance was 51.3%). A fully supervised method achieved 85% accuracy using a domain specific algorithm trained on ten manually labeled patches per class <ref type="bibr" target="#b32">[35]</ref>. Our  method is the first to classify five LGG subtypes automatically, a much more challenging classification task than the benchmark GBM vs. LGG classification. We achieve 57.1% LGG-subtype classification accuracy with chance at 36.7%. Most of the confusions are related to oligoastrocytoma (OA) since it is a mixed glioma that is challenging for pathologists to agree on, according to a neuropathology study: "Oligoastrocytomas contain distinct regions of oligodendroglial and astrocytic differentiation... The minimal percentage of each component required for the diagnosis of a mixed glioma has been debated, resulting in poor interobserver reproducibility for this group of neoplasms." <ref type="bibr" target="#b6">[9]</ref>.</p><p>We compare recognition rates for the OA subtype. The  becomes increasingly more significant using our proposed method on the harder-to-classify classes. The discriminative patch (region) segmentation results in <ref type="figure" target="#fig_5">Fig. 4</ref> demonstrate the quality of our EM-based method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">WSI of NSCLC classification</head><p>We use three major subtypes of Non-Small-Cell Lung Carcinoma (NSCLC). Numbers of WSIs and patients in each class are in <ref type="table">Tab</ref> Experimental results are shown in Tab. 6; the confusion matrix is in Tab. 7. When classifying SCC vs. non-SCC, inter-observer agreement between pulmonary pathology experts and between community pathologists measured by Cohen's kappa is κ = 0.64 and κ = 0.41 respectively <ref type="bibr" target="#b18">[21]</ref>. We achieved κ = 0.75. When classifying ADC vs. non-ADC, the inter-observer agreement between experts and between community pathologists are κ = 0.69 and κ = 0.46 respectively <ref type="bibr" target="#b18">[21]</ref>. We achieved κ = 0.60. Therefore, our results appear close to inter-observer agreement.</p><p>The ADC-mix subtype is hard to classify because it contains visual features of multiple NSCLC subtypes. The Pretrained CNN-Fea-SVM method achieves an F-score of 0.412 recognizing ADC-mix cases, whereas our proposed method EM-Finetune-CNN-SVM achieves 0.472. Consistent with the glioma results, our method's performance advantages are more pronounced in the hardest cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.">Rail surface defect severity grade classification</head><p>We evaluate our approach beyond classification of pathology images. A CNN cannot be applied to gigapixel images directly because of computational limitations. Even when the images are small enough for CNNs, our patchbased method compares favorably to an image-based CNN if discriminative information is encoded in image patch scale and dispersed throughout the images.</p><p>We classify the severity grade of rail surface defects. Automatic defect grading can obviate the need for laborious examination and grading of rail surface defects on a regular basis. We used a dataset <ref type="bibr" target="#b29">[32]</ref> of 939 rail surface images with defect severity grades from 0 to 7. Typical image resolution is 1200×500, as in <ref type="figure" target="#fig_6">Fig. 5</ref>.</p><p>To support our claim, we tested two additional methods:</p><p>1. CNN-Image: We apply the CNN on image scale directly. In particular, we train the CNN on 400×400 regions randomly extracted from images in each iteration. At test time, we apply the CNN on five regions (top left, top right, bottom left, bottom right, center) and average the predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Pretrained CNN-ImageFea-SVM:</head><p>We apply a pretrained 16-layer network <ref type="bibr" target="#b43">[46]</ref> to rail surface images to extract features, and train an SVM on these features.</p><p>The CNN used in this experiment has a similar achitecture to the one described in Tab. 1 with smaller and fewer filters. The size of patches in our patch-based methods is 64 by 64. We apply 4-fold cross-validation and show the averaged results in Tab. 8. Our patch-based methods EM-CNN-SVM and EM-CNN-Fea-SVM outperform the conventional image-based method CNN-Image. Moreover, results using CNN features extracted on patches (Pretrained CNN-Fea-SVM) are better than results with CNN features extracted on images (Pretrained-CNN-ImageFea-SVM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>We presented a patch-based Convolutional Neural Network (CNN) model with a supervised decision fusion model that is successful in Whole Slide Tissue Image (WSI) classification. We proposed an Expectation-Maximization (EM) based method that identifies discriminative patches automatically for CNN training. With our algorithm, we can classify subtypes of cancers given WSIs of patients with accuracy similar or close to inter-observer agreements between pathologists. Furthermore, we experimentally demonstrate using a comparable non-cancer dataset of smaller images, that the performance of our patch-based CNN compare favorably to that of an image-based CNN. In the future we will leverage the non-discriminative patches as part of the data likelihood in the EM formulation. We will optimize CNN-training so that it scales up to larger scale pathology datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A gigapixel Whole Slide Tissue Image of a grade IV tumor. Visual features that determine the subtype and grade of a WSI are visible in high resolution. In this case, patches framed in red are discriminative since they show typical visual features of grade IV tumor. Patches framed in blue are non-discriminative since they only contain visual features from lower grade tumors. Discriminative patches are dispersed throughout the image at multiple locations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>An overview of our workflow. Top: A CNN is trained on patches. An EM-based method iteratively eliminates non-discriminative patches. Bottom: An image-level decision fusion model is trained on histograms of patchlevel predictions, to predict the image-level label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Some 20X sample patches of gliomas and Non-Small-Cell Lung Carcinoma (NSCLC) from the TCGA dataset. Two patches in each column belong to the same subtype of cancer. Notice the large intra-class heterogeneity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>:</head><label></label><figDesc>are WSIs of six subtypes of glioma in the TCGA dataset [2]. The numbers of WSIs and patients in each class are shown in Tab. 2. All classes are described in App. The numbers of WSIs and patients in each class from the TCGA dataset. Class descriptions are in App. A.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>F-score of OA recognition is 0.426, 0.482, and 0.544 using PreCNN-Fea-SVM, CNN-LR, and EM-CNN-LR respectively. We thus see that the improvement over other methods Examples of discriminative patch (region) segmentation (best viewed in color</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Sample images of rail surfaces. The grade indicates defect severity. Notice that the defects are in image patch scale and dispersed throughout the image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>The architecture of our CNN used in glioma and NSCLC classification. ReLU+LRN is a sequence of Rectified Linear Units (ReLU) followed by Local Response Normalization (LRN). Similarily, ReLU+Drop is a sequence ofReLU followed by dropout. The dropout probability is 0.5.</figDesc><table>Layer Filter size, stride Output W×H×N 
Input 
-
400 × 400 × 3 
Conv 
10 × 10, 2 
196 × 196 × 80 
ReLU+LRN 
-
196 × 196 × 80 
Max-pool 
6 × 6, 4 
49 × 49 × 80 
Conv 
5 × 5, 1 
45 × 45 × 120 
ReLU+LRN 
-
45 × 45 × 120 
Max-pool 
3 × 3, 2 
22 × 22 × 120 
Conv 
3 × 3, 1 
20 × 20 × 160 
ReLU 
-
20 × 20 × 160 
Conv 
3 × 3, 1 
18 × 18 × 200 
ReLU 
-
18 × 18 × 200 
Max-pool 
3 × 3, 2 
9 × 9 × 200 
FC 
-
320 
ReLu+Drop 
-
320 
FC 
-
320 
ReLu+Drop 
-
320 
FC 
-
Dataset dependent 
Softmax 
-
Dataset dependent 
Table 1: </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Glioma classification results. The proposed EM-CNN-LR method achieved the best result, close to interobserver agreement between pathologists. (Sec. 5.4 ). Confusion matrix of glioma classification. The nature of Oligoastrocytoma causes the most confusions. See Sec. 5.4 for details.</figDesc><table>Predictions 
Ground Truth GBM OD OA DA AA AO 
GBM 
214 
0 
2 
0 
1 
0 
OD 
1 
47 
22 
2 
0 
1 
OA 
1 
18 
40 
8 
3 
1 
DA 
3 
9 
6 
20 
0 
1 
AA 
3 
2 
3 
3 
4 
0 
AO 
2 
2 
3 
0 
0 
1 
Table 4: </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>. 5. All classes are listed in App. A. The numbers of WSIs and patients in each class from the TCGA dataset. Class descriptions are in App. A.</figDesc><table>NSCLCs SCC ADC ADC-mix 
# patients 316 
250 
75 
# WSIs 
347 
291 
80 
Table 5: </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>NSCLC classification results. The proposed EM-CNN-SVM and EM-Finetune-CNN-SVM achieved best results, close to the inter-observer agreement between pathologists. See Sec. 5.5 for details. The confusion matrix of NSCLC classification.</figDesc><table>Methods 
Acc mAP 
CNN-Vote 
0.702 0.838 
CNN-SMI 
0.731 0.852 
CNN-Fea-SVM 
0.637 0.793 
EM-CNN-Vote 
0.714 0.842 
EM-CNN-SMI 
0.731 0.850 
EM-CNN-Fea-SVM 
0.637 0.791 
EM-Finetune-CNN-Vote 
0.773 0.877 
EM-Finetune-CNN-SMI 
0.729 0.853 
CNN-LR 
0.727 0.845 
CNN-SVM 
0.738 0.856 
EM-CNN-LR 
0.743 0.856 
EM-CNN-SVM 
0.759 0.869 
EM-Finetune-CNN-LR 
0.784 0.883 
EM-Finetune-CNN-SVM 
0.798 0.889 
SMI-CNN-SMI 
0.531 0.749 
Pretrained CNN-Fea-SVM 
0.778 0.879 
Pretrained-CNN-Bow-SVM 
0.759 0.871 
Chance 
0.484 0.715 
Table 6: Predictions 
Ground Truth SCC ADC ADC-mix 
SCC 
199 
26 
0 
ADC 
30 
155 
11 
ADC-mix 
2 
25 
17 
Table 7: </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head></head><label></label><figDesc>Rail surface defect severity grade classification results. Our patch-based method EM-CNN-SVM and EM-CNN-Fea-SVM outperform image-based methods CNN-Image and Pretrained CNN-ImageFea-SVM significantly.</figDesc><table>Methods 
Acc mAP 
CNN-Vote 
0.695 0.823 
CNN-SMI 
0.700 0.801 
CNN-Fea-SVM 
0.822 0.903 
EM-CNN-Vote 
0.683 0.817 
EM-CNN-SMI 
0.684 0.799 
EM-CNN-Fea-SVM 
0.830 0.908 
CNN-LR 
0.764 0.867 
CNN-SVM 
0.803 0.886 
EM-CNN-LR 
0.772 0.871 
EM-CNN-SVM 
0.813 0.895 
SMI-CNN-SMI 
0.258 0.461 
Pretrained CNN-Fea-SVM 
0.808 0.894 
CNN-Image 
0.770 0.876 
Pretrained CNN-ImageFea-SVM 
0.778 0.878 
Chance 
0.228 0.438 
Table 8: </table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This work was supported in part by 1U24CA180924-01A1 from the National Cancer Institute, R01LM011119-01 and R01LM009239, and partially supported by NSF IIS-1161876, IIS-1111047, FRA DTFR5315C00011, the Subsample project from DIGITEO Institute, France, and a gift from Adobe Corp. We thank Ke Ma for providing the rail surface dataset. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<ptr target="http://www.abta.org/about-us/news/brain-tumor-statistics/.4" />
	</analytic>
	<monogr>
		<title level="j">Brain tumor statistics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Color graphs for automated cancer diagnosis and grading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Altunbay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cigir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sokmensuer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gunduz-Demir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Biomed Eng</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multiple instance classification: Review, taxonomy and comparative study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Amores</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIJ</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Support vector machines for multiple-instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<title level="m">Representation learning: A review and new perspectives. PAMI</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Diagnosis of malignant glioma: role of neuropathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Brat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Prayson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Ryken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Olson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of neuro-oncology</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Libsvm: a library for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIST</title>
		<imprint>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Stacked predictive sparse decomposition for classification of histology sections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Barner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Spellman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Parvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Semantic image segmentation with deep convolutional nets and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Multi-instance multilabel image classification: A neural approach. Neurocomputing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Cireşan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Giusti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<title level="m">Mitosis detection in breast cancer histology images with deep neural networks. In MICCAI</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Integrated morphologic analysis for the identification and characterization of disease subtypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Gutman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Appin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cholleti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Scarpace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automated gastric cancer diagnosis on h&amp;e-stained sections; ltraining a classifier on a large scale with multiple instance machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cosatto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-F</forename><surname>Laquerre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Malon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Graf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kiyuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marugame</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kamijo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Medical Imaging</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic detection of invasive ductal carcinoma in whole slide images with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cruz-Roa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Basavanhally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gilmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tomaszewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madabhushi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Solving the multiple instance problem with axis-parallel rectangles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Lathrop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lozano-Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIJ</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A bayesian hierarchical model for learning natural scene categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A review of multi-instance learning assumptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foulds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl Eng Rev</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Validation of interobserver agreement in lung cancer assessment: hematoxylin-eosin diagnostic reproducibility for non-small cell lung cancer: the 2004 world health organization classification and therapeutically relevant subsets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Grilley-Olson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F</forename><surname>Qaqish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Socinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Stinchcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Banks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Archives of pathology &amp; laboratory medicine</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Clarifying the diffuse gliomas an update on the morphologic features and markers that discriminate oligodendroglioma from astrocytoma</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Djalilvand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Brat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AJCP</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Improving human action recognition using score distribution and ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hoai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>ACCV. 2014. 3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Caffe</surname></persName>
		</author>
		<title level="m">Convolutional architecture for fast feature embedding. arXiv</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Large-scale video classification with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gaussian processes multiple instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Torre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Data vs. decision fusion in the category theory framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Kokar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Tomasik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weyman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An efficient parallel neural network-based multi-instance learning algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gondra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Supercomput</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Texture classification for rail surface condition evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F Y</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Samaras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Petrucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Magnus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A framework for multipleinstance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lozano-Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Histology for pathologists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Mills</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Lippincott Williams &amp; Wilkins</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Automated discrimination of lower and higher grade gliomas based on histopathological image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">U</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JPI</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Weakly supervised discriminative localization and classification: a joint learning process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Maenpaa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>PAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Weakly supervised object recognition with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oquab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<idno>NIPS. 2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Weakly-and semi-supervised learning of a dcnn for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Fully convolutional multi-class multiple instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Weakly supervised semantic segmentation with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Deep convolutional neural network textual features and multiple kernel learning for utterance-level multimodal sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Multi instance neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ramon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>De Raedt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Quantification of histochemical staining by color deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Ruifrok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Johnston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anal Quant Cytol Histol</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">2d view aggregation for lymph node detection using a shallow hierarchy of linear classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Turkbey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">a decision level fusion method for object recognition using multi-angular imagery. International Archives of the Photogrammetry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mahmoudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Samadzadegan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Reinartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing and Spatial Information Sciences</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Dfdl: Discriminative feature-oriented dictionary learning for histopathological image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A two-level learning method for generalized multi-instance problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Weidmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deep convolutional activation features for large scale brain tumor histopathology image classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">I</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep learning of feature representation with multiple instance learning for medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">I</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Weakly supervised histopathology cancer image segmentation and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Evaluating bag-of-visual-words representations in scene classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Ngo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on multimedia information retrieval</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Multiple instance boosting for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Viola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Em-dd: An improved multiple-instance learning technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Goldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Classification of histology sections via multispectral convolutional sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Barner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Spellman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Parvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Neural networks for multiinstance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIIT</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
