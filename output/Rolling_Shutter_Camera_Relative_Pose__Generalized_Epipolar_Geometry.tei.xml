<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rolling Shutter Camera Relative Pose: Generalized Epipolar Geometry</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchao</forename><surname>Dai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research School of Engineering</orgName>
								<orgName type="institution">Australian National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongdong</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research School of Engineering</orgName>
								<orgName type="institution">Australian National University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">ARC Centre of Excellence for Robotic Vision (ACRV)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Kneip</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research School of Engineering</orgName>
								<orgName type="institution">Australian National University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">ARC Centre of Excellence for Robotic Vision (ACRV)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Rolling Shutter Camera Relative Pose: Generalized Epipolar Geometry</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The vast majority of modern consumer-grade cameras employ a rolling shutter mechanism. In dynamic geometric computer vision applications such as visual SLAM, the so-called rolling shutter effect therefore needs to be properly taken into account. A dedicated relative pose solver appears to be the first problem to solve, as it is of eminent importance to bootstrap any derivation of multi-view geometry. However, despite its significance, it has received inadequate attention to date. This paper presents a detailed investigation of the geometry of the rolling shutter relative pose problem. We introduce the rolling shutter essential matrix, and establish its link to existing models such as the push-broom cameras, summarized in a clean hierarchy of multi-perspective cameras. The generalization of well-established concepts from epipolar geometry is completed by a definition of the Sampson distance in the rolling shutter case. The work is concluded with a careful investigation of the introduced epipolar geometry for rolling shutter cameras on several dedicated benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Rolling-Shutter (RS) CMOS cameras are getting more and more popularly used in real-world computer vision applications due to their low cost and simplicity in design. To use these cameras in 3D geometric computer vision tasks (such as 3D reconstruction, object pose, visual SLAM), the rolling shutter effect (e.g. wobbling) must be carefully accounted for. Simply ignoring this effect and relying on a global-shutter method may lead to erroneous, undesirable and distorted results (e.g. <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b2">3]</ref>).</p><p>Recently, many 3D vision algorithms have been adapted to the rolling shutter case (e.g. absolute Pose <ref type="bibr" target="#b15">[15]</ref> [3] <ref type="bibr" target="#b22">[22]</ref>, Bundle Adjustment <ref type="bibr" target="#b8">[9]</ref>, and stereo rectification <ref type="bibr" target="#b21">[21]</ref>). Quite surprisingly, no previous attempt has been reported on solving the relative pose problem with a RS camera.</p><p>The complexity of this problem stems from the fact that an RS camera does not satisfy the pinhole projection model, hence the conventional epipolar geometry defined by the standard 3 × 3 essential matrix (in the form of x ′ T Ex = 0) is no longer applicable. This is mainly because of the timevarying line-by-line image capturing nature of an RS camera, rendering the imaging process a non-central one.</p><p>In this paper we show that similar epipolar relationships do exist between two rolling-shutter images. Specifically, in contrast to the conventional 3 × 3 essential matrix for the pinhole camera, we derive a 7 × 7 generalized essential matrix for a uniform rolling-shutter camera, and a 5×5 generalized essential matrix for a linear rolling-shutter camera. Under the rolling-shutter epipolar geometry, the "epipolar lines" are no longer straight lines, but become higher-order "epipolar curves" (c.f . <ref type="figure" target="#fig_0">Fig. 1</ref>).</p><p>Armed with these novel generalized rolling-shutter essential matrices, we can easily develop efficient numerical algorithms to solve the relative pose problem. Similar to the 8-point linear algorithm in the perspective case, we derive a 20-point linear algorithm for linear RS cameras, and a Linear rolling shutter      0 0 f13 f14 f15 0 0 f23 f24 f25 f31 f32 f33 f34 f35 f41 f42 f43 f44 f45 f51 f52 f53 f54 f55</p><formula xml:id="formula_0">     (u 2 i , uivi, ui, vi, 1) 21 = 5 2 − 2 2 20-point 11-point R, t, d1, d2</formula><p>Uniform push broom</p><formula xml:id="formula_1">       0 0 f13 f14 f15 f16 0 0 f23 f24 f25 f26 f31 f32 f33 f34 f35 f36 f41 f42 f43 f44 f45 f46 f51 f52 f53 f54 f55 f56 f61 f62 f63 f64 f65 f66        (u 2 i vi, u 2 i , uivi, ui, vi, 1) 32 = 6 2 − 2 2 31-point 17-point R, t, w1, w2, d1, d2</formula><p>Uniform rolling shutter</p><formula xml:id="formula_2">         0 0 f13 f14 f15 f16 f17 0 0</formula><p>f23 f24 f25 f26 f27 f31 f32 f33 f34 f35 f36 f37 f41 f42 f43 f44 f45 f46 f47 f51 f52 f53 f54 f55 f56 f57 f61 f62 f63 f64 f65 f66 f67 f71 f72 f73 f74 f75 f76 f77 Experiments on both synthetic RS datasets and real RS images have validated the proposed theory and algorithms. To the best of our knowledge, this is the first work that provides a unified framework and practical solutions to the rolling shutter relative pose problem. Our 5 × 5 and 7 × 7 RS essential matrices are original; they were not reported before in computer vision literature. We further discover that there also exist practically meaningful 4 × 4 and 6 × 6 generalized essential matrices, corresponding to linear, and uniform push-broom cameras, respectively. Together, this paper provides a unified framework for solving the relative pose problem with rolling-shutter or push-broom cameras under different yet practically relevant conditions. It also provides new geometric insights into the connection between different types of novel camera geometries. <ref type="table" target="#tab_0">Table-1</ref> gives a brief summary of the new results discovered in this paper. Details will be explained in Section-4.</p><formula xml:id="formula_3">         (u 3 i , u 2 i vi, u 2 i ,</formula><p>Related work: The present work discusses a fundamental geometric problem in the context of RS cameras. The most notable, early related work is by Geyer et al. <ref type="bibr" target="#b16">[16]</ref>, who proposed a projection model for RS cameras based on a constant velocity motion model. This fundamental idea of a compact, local expression of camera dynamics has regained interest through Ait-Aider et al. <ref type="bibr" target="#b0">[1]</ref>, who solved the absolute pose problem through iterative minimization, and for the first time described the higher density of the temporal sampling of a rolling shutter mechanism as an advantage rather than a disadvantage. Albl et al. <ref type="bibr" target="#b2">[3]</ref> proposed a twostep procedure in which the pose is first initialized using a global shutter model, and then refined based on a rolling shutter model and a small-rotation approximation. Saurer et al. <ref type="bibr" target="#b22">[22]</ref> solved the problem in a single shot, however under the simplifying assumption that the rotational velocity of the camera is zero. Sunghoon et al. <ref type="bibr" target="#b11">[11]</ref> also employed a linear model, however with the final goal of dense depth estimation from stereo. Grundmann et al. proposed a method to automatic rectify RS distortion from feature correspondences only <ref type="bibr" target="#b4">[5]</ref>. To date, a single-shot, closed-form solution to compute the relative pose for a RS camera remains an open problem, thus underlining the difficulty of the geometry even in the first-order case.</p><p>Rolling shutter cameras can be regarded as general multi-perspective cameras, and are thus closely related to several other camera models. For instance, Gupta and Hartley <ref type="bibr" target="#b5">[6]</ref> introduced the linear push-broom model wheresimilar to rolling shutter cameras-the vertical image coordinate becomes correlated to the time at which the corresponding row is sampled. This notably leads to a quadratic essential polynomial and a related, higher-order essential matrix. We establish the close link to this model and contribute to the classification in <ref type="bibr" target="#b27">[27]</ref> by presenting a novel hierarchy of higher order essential matrices.</p><p>Moving towards iterative non-linear refinement methods permits a more general inclusion of higher-order motion models. Hedborg et al. <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">10]</ref> introduced a bundle adjustment framework for RS cameras by relying on the SLERP model for interpolating rotations. Magarand et al. <ref type="bibr" target="#b15">[15]</ref> introduced an approach for global optimization of pose and dynamics from a single RS image. Oth et al. <ref type="bibr" target="#b17">[17]</ref> proposed to use more general temporal basis functions for parameterizing the trajectory of the camera. Solutions to the RS problem have also been explored for further types of sensors. For instance, Ait-Aider and Berry <ref type="bibr" target="#b1">[2]</ref> and Saurer et al. <ref type="bibr" target="#b21">[21]</ref> had anaylzed the problem in the context of stereo cameras. Recently, Kerl et al. <ref type="bibr" target="#b13">[13]</ref> have started to apply continuous time parametrizations to RGB-D cameras. Ponce studied general concept of various types of cameras including line pencil camera akin to general rolling shutter <ref type="bibr" target="#b20">[20]</ref>.</p><p>The relative pose problem is of eminent importance in structure-from-motion, as it allows to bootstrap the computation in the absence of any information about the structure. To the best of our knowledge, the present work is the first to address it in the context of a rolling shutter camera.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Rolling-Shutter Camera Models</head><p>A critical difference between a RS camera and a pinhole camera is that the former does no longer possess a single center-of-projection in the general case. Instead, in a rolling-shutter image, each of its scanlines generally has a different effective projection center (temporal-dynamic) as well as a different local frame and orientation.</p><p>In an attempt to present this matter from a mathematical perspective, let us start with re-examining the model of a (global shutter) pinhole camera, which can be entirely described by a central projection matrix:</p><formula xml:id="formula_4">P = K[R, t].</formula><p>When an RS camera is in motion during image acquisition, all its scanlines are sequentially exposed at different time steps; hence each scanline possesses a different local frame. Mathematically, we need to assign a unique projection matrix to every scanline in an RS image P ui = K[R ui , t ui ].</p><p>General Rolling Shutter Camera. It is common to assume that the motion of a rolling-shutter camera during image acquisition is smooth. Otherwise an arbitrarily nonsmoothly moving RS camera would create meaningless images suffering from arbitrary fragmentations.</p><p>Therefore, a smoothly moving RS camera is considered as the most general form of rolling-shutter models. It is easy to see that for a general RS image its scanlines' local pose matrices P 0 , P 1 , P 2 , · · · , P N−1 will trace out a smooth trajectory in the SE(3) space. B-splines have been used to model this trajectory in the RS context <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b18">18]</ref> <ref type="bibr" target="#b13">[13]</ref>.</p><p>To ease the derivation, we assume the RS camera is intrinsically calibrated. However, note that many of the results presented in this paper remain extendable to the uncalibrated case as well (by transitioning from the essential matrix to the corresponding fundamental matrix). Also note that the task of intrinsic calibration can be easily done, e.g. by applying any standard camera calibration procedure to still imagery taken by an RS camera.</p><p>Linear Rolling-Shutter Camera. The motion of the camera is a pure translation by a constant linear velocity. The orientations of local scanline frames are constant. In this case, the projection centers of the scanlines lie on a straight line in 3D space. Supposing that constant velocity induces a translation shift of d per image row (expressed in normalized coordinates), we can write down the u i -th projection matrix as</p><formula xml:id="formula_5">P ui = [R 0 , t 0 + u i d].</formula><p>(1)</p><p>We use the top-most scanline's local frame [R 0 , t 0 ] as the reference frame of the RS image.</p><p>Uniform Rolling-Shutter Camera. The uniform rollingshutter camera is another popular RS model, which is more general than the linear RS model. The camera is performing a uniform rotation at a constant angular velocity, in addition to a uniform linear translation at constant linear velocity. All the centers of projection form a helix spiral trajectory. We use d ∈ R 3 to denote the constant linear velocity and w ∈ R 3 for the constant angular velocity (expressing angular displacement per row). Let w be parametrized in the angle-axis representation (i.e. w = ω[n]). The u i -th scanline's local projection matrix is</p><formula xml:id="formula_6">P ui = [R ui , t ui ], where R ui = (I + sin(u i ω)[n] × + (1 − cos(u i ω)) [n] 2 × )R 0 , t ui =t 0 + u i d.<label>(2)</label></formula><p>One may further assume that the inter-scanline rotation during image acquisition is very small. This is a reasonable assumption, as the acquisition time for a single image is very short, often in the order of 10s milliseconds, and the motion of an RS camera is typically small. Under the small-rotation approximation, we have</p><formula xml:id="formula_7">R ui =(I + u i ω[n] × )R 0 , t ui =t 0 + u i d.<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Rolling Shutter Relative Pose Problem</head><p>The RS Relative Pose problem consists of finding the relative camera displacement between two RS views, given image feature correspondences.</p><p>It is well known that for the perspective case the epipolar geometry plays a central role in relative pose estimation, translated into a simple 3-by-3 matrix called the essential (or fundamental) matrix. Specifically, given a set of correspondences between two views,</p><formula xml:id="formula_8">x i = [u i , v i , 1] T ↔ x ′ i = [u ′ i , v ′ i , 1] T ,</formula><p>we have the standard essential matrix constraint: x ′T i Ex i = 0. From a sufficient number of correspondences one can solve for E. Decomposing E according to E = [t] × R leads to the relative pose (i.e. R and t).</p><p>For a rolling-shutter camera, unfortunately, such a global 3-by-3 essential matrix does not exist. This is primarily because an RS camera is not a central projection camera; every scanline has its own distinct local pose. As a result, every pair of feature correspondences may give rise to a different "essential matrix". Formally, for</p><formula xml:id="formula_9">x i ↔ x ′ i , we have x ′T i E ui,u ′ i x i = 0.<label>(4)</label></formula><p>Note that E is dependent of the scanlines u i and u ′ i . In other words, there does not exist a single global 3 × 3 essential matrix for a pair of RS images. <ref type="figure" target="#fig_1">Figure-2</ref> shows that despite the fact that different scanlines possess different centers of projection, for a pair of feature correspondences the co-planarity relationship still holds, because the two feature points in image planes correspond to the same 3D point in space. As such, the concept of two-view epipolar relationship should still exist. Our next task is to derive such a generalized epipolar relation. Given two scanlines u i , u j and the corresponding camera</p><formula xml:id="formula_10">poses P ui = [R ui , t ui ] and P uj = [R uj , t uj ], we have E uiuj = [t uj − R uj R T ui t ui ] × R uj R T ui .<label>(5)</label></formula><p>Rolling Shutter Relative Pose. Note, given a pair of feature correspondences x i ↔ x ′ i , one can establish the following RS epipolar equation:</p><formula xml:id="formula_11">x ′T i E uiu ′ i x i = 0.</formula><p>Given sufficient pairs of correspondences; each pair contributes to one equation over the unknown parameters; our goal is to solve for the relative pose between the two RS images.</p><p>We set the first camera's pose at [I, 0], and the second camera at [R, t]. We denote the two cameras' inter-scanline rotational (angular) velocities as w 1 , and w 2 , and their linear translation velocities as d 1 and d 2 . Taking a uniform RS camera as an example, the task of finding the relative pose is to find the unknowns {R, t, w 1 , w 2 , d 1 , d 2 }. In total there are 2 × 12 − 6 − 1 = 17 non-trivial variables (excluding the gauge freedom of the first camera, and a global scale). Collecting at least 17 equations in general configuration, it is possible to solve this system of (generally nonlinear) equations over the 17 unknown parameters. In this paper, we will show how to derive linear N-point algorithms for rolling shutter cameras, as an analogy to the linear 8-point algorithm for the case of a pinhole camera.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Rolling-Shutter Essential Matrices</head><p>In this section, we will generalize the conventional 3 × 3 essential matrix for perspective cameras to 4×4, 5×5, 6×6, and 7 × 7 matrices for different types of Rolling-Shutter (RS) and Push-Broom (PB) cameras. The reason for including push-broom cameras will be made clear soon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">A 5 × 5 essential matrix for linear RS cameras</head><p>For a linear rolling shutter camera, since the interscanline motion is a pure translation, there are four parameter vectors to be estimated, namely{R, t, d 1 , d 2 }. The total degree of freedom of the unknowns is 3+3+3+3−1 = 11. (the last '-1' accounts for a global scale).</p><p>The epipolarity defined between the u i -th scanline of the first RS frame and the u ′ i -th scanline of the second RS frame</p><formula xml:id="formula_12">is represented as E uiu ′ i = [t uiu ′ i ] × R uiu ′ i , where the trans- lation t uiu ′ i = t + u ′ i d 2 − u i Rd 1 . This translates into   u ′ i v ′ i 1   T [t + u ′ i d 2 − u i Rd 1 ] × R   u i v i 1   = 0.<label>(6)</label></formula><p>Expanding this scanline epipolar equation, one can obtain the following 5 × 5 matrix form:</p><formula xml:id="formula_13">       u ′ 2 i u ′ i v ′ i u ′ i v ′ i 1        T      0 0 f 13 f 14 f 15 0 0 f 23 f 24 f 25 f 31 f 32 f 33 f 34 f 35 f 41 f 42 f 43 f 44 f 45 f 51 f 52 f 53 f 54 f 55           u 2 i u i v i u i v i 1      = 0,<label>(7)</label></formula><p>where the entries of the 5×5 matrix F = [f i,j ] are functions of the 11 unknown parameters {R, t, d 1 , d 2 }. In total, there are 21 homogeneous variables, thus a linear 20-point solver must exist to solve for this hyperbolic essential matrix.</p><p>By redefining d 1 ← Rd 1 , we easily obtain</p><formula xml:id="formula_14">E uiu ′ i = ([t] × + u ′ i [d 2 ] × − u i [d 1 ] × ) R.<label>(8)</label></formula><p>Denoting</p><formula xml:id="formula_15">E 0 = [t] × R, E 1 = [d 1 ] × R and E 2 = [d 2 ] × R, we have: [u ′ i , v ′ i , 1](E 0 + u ′ i E 2 − u i E 1 )[u i , v i , 1] T = 0. (9)</formula><p>The 5 × 5 matrix F is defined in the following way </p><formula xml:id="formula_16">F =      0 0 E 1,</formula><formula xml:id="formula_17">     ,<label>(10)</label></formula><p>where a = E 0,11 + E 1,13 + E 2,31 , b = E 0,21 + E 1,23 , c = E 0,31 + E 1,33 . Hyperbolic epipolar curves. Note that the "epipolar lines" for a linear RS camera are hyperbolic curves. It is easy to verify that the generalized essential matrix for linear rolling shutter camera is full rank and the epipole lies in infinity.</p><p>Difference with axial camera The linear rolling shutter camera give rise to an axis where every back-projection ray intersects. However, the temporal-dynamic nature of linear rolling shutter camera distinguishes itself from the axial camera <ref type="bibr" target="#b26">[26]</ref>, where the internal displacement (linear velocity) is unknown and to estimate. Even though our linear RS essential matrix shares the same size as axial camera essential matrix <ref type="bibr" target="#b25">[25]</ref>, the detailed structure is different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">A 7×7 essential matrix for uniform RS cameras</head><p>Consider a uniform RS camera undergoing a rotation at constant angular velocity w and a translation at constant linear velocity d. We assume the angular velocity is very small. By using the small-rotation approximation,we have the u i -th scanline's local pose as</p><formula xml:id="formula_18">P ui = [(I + u i [w] × )R 0 , t 0 + u i d].<label>(11)</label></formula><p>Given a pair of two corresponding uniform RS camera frames, we then have</p><formula xml:id="formula_19">[u ′ i , v ′ i , 1][t+u ′ i d2 −uiR u i u ′ i d1]×R u i u ′ i [ui, vi, 1] T = 0,<label>(12)</label></formula><p>Expanding this equation with the aid of the small rotation approximation results in</p><formula xml:id="formula_20">R ui,u ′ i = (I + u ′ i [w 2 ] × )R 0 (I − u i [w 1 ] × ),<label>(13)</label></formula><p>and we finally obtain:</p><formula xml:id="formula_21">u ′ 3 i , u ′ 2 i v ′ i , u ′ 2 i , u ′ i v ′ i , u ′ i , v ′ i , 1 F u 3 i , u 2 i v i , u 2 i , u i v i , u i , v i , 1 T = 0,<label>(14)</label></formula><p>where</p><formula xml:id="formula_22">F =          0 0 f 13 f 14 f 15 f 16 f 17 0 0 f 23 f 24 f 25 f 26 f 27 f 31 f 32 f 33 f 34 f 35 f 36 f 37 f 41 f 42 f 43 f 44 f 45 f 46 f 47 f 51 f 52 f 53 f 54 f 55 f 56 f 57 f 61 f 62 f 63 f 64 f 65 f 66 f 67 f 71 f 72 f 73 f 74 f 75 f 76 f 77          .</formula><p>This gives a 7 × 7 RS essential matrix F, whose elements are functions of the 18 unknowns (i.e. {R, t, w 1 , w 2 , d 1 , d 2 }). Also note the induced epipolar curves are cubic. In total there are 45 homogeneous variables, thus a 44-point linear algorithm exists to solve for this hyperbolic essential matrix. The generalized essential matrix for uniform rolling shutter camera is full rank and the epipole lies in infinity.</p><p>If w 1 = w 2 = 0, the equation will reduce to Eq.-(9). This exactly reduces to the linear rolling shutter case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">A 4 × 4 essential matrix for linear PB cameras</head><p>Researchers have previously noticed the similarity between a spacetime sweeping camera (such as RS) and a push-broom camera <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b23">23]</ref>. Here, we further illustrate this similarity, via our high-order essential matrix. Specifically, the above 5 × 5 and 7 × 7 RS essential matrices have inspired us to explore further. Do 4 × 4 or 6 × 6 generalized essential matrices also exist? Following a similar approach, we quickly find out that: these two generalized essential matrices do exist and they each corresponds to a special type of push-broom camera.</p><p>For linear push-broom (PB) cameras (as defined in <ref type="bibr" target="#b5">[6]</ref>), there exists a 4 × 4 essential matrix:</p><formula xml:id="formula_23">F =     0 0 f 13 f 14 0 0 f 23 f 24 f 31 f 32 f 33 f 34 f 41 f 42 f 43 f 44     .<label>(15)</label></formula><p>The resulting linear push-broom epipolar equation reads as</p><formula xml:id="formula_24">(u ′ 1 v ′ 1 , u ′ 1 , v ′ 1 , 1)F(u1v1, u1, v1, 1) T = 0.<label>(16)</label></formula><p>We must point out that this 4 × 4 linear PB essential matrix result is not new; paper <ref type="bibr" target="#b5">[6]</ref> already reported it though via a different approach. This however precisely confirms that our method provides a unified framework for handling different types of novel, higher-order epipolar geometries, including a PB camera.</p><p>Difference with X-slit camera The linear PB camera give rise to two oblique slits setting, where one slit is the line of center of projection and the other slit corresponds to the viewing direction. However, the slit corresponds to the moving camera projection center is unknown and to estimate. Although the linear PB essential matrix shares the same size as the X-Slit camera essential matrix <ref type="bibr" target="#b25">[25]</ref>, the detailed structure is different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">A 6×6 essential matrix for uniform PB cameras</head><p>Similarly, for the uniform PB camera where the view plane of the camera is undergoing a uniform rotation besides its linear sweeping, we can easily derive a 6 × 6 uniform PB essential matrix as:</p><formula xml:id="formula_25">         u ′ 2 i v ′ i u ′ 2 i u ′ i v ′ i u ′ i v ′ i 1          T        0 0 f 13 f 14 f 15 f 16 0 0 f 23 f 24 f 25 f 26 f 31 f 32 f 33 f 34 f 35 f 36 f 41 f 42 f 43 f 44 f 45 f 46 f 51 f 52 f 53 f 54 f 55 f 56 f 61 f 62 f 63 f 64 f 65 f 66               u 2 i v i u 2 i u i v i u i v i 1        = 0.<label>(17)</label></formula><p>There are 32 variables in this PB essential matrix (6 × 6 minus the top-left 2 × 2 corner), suggesting that a 31-point linear algorithm can be used to estimate F. Note also that the resulting (generalized) epipolar curves are cubic.</p><p>RS camera VS PB camera: Both RS camera and PB camera have a scanline dependent pose, i.e., temporaldynamic center of projection. For PB cameras, the scanline direction is fixed relative to the local coordinate while the scanline direction changes relative to the local coordinate for RS cameras. This creates the main difference between PB cameras and RS cameras and the extras freedom explains the increased order of polynomials in expressing the generalized epipolar geometry (4 VS 6 and 5 VS 7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Linear N-point algorithms for RS cameras</head><p>Summary of the Above Results. The above results are summarized in <ref type="table" target="#tab_0">Table-1</ref>. We also include the number of points needed to solve linearly for the respective generalized essential matrices. Next, let us use as an example the linear RS camera to derive a linear 20-point algorithm for solving the uniform RS essential matrix. The linear solutions for other types of cameras in the table can be similarly derived, hence are omitted here. Interested readers will find more information in our supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">A linear 20-point algorithm for RS cameras</head><p>For solving the linear RS relative pose problem, we first solve for the 5 × 5 RS essential matrix F ∈ R 5×5 . Then from its 21 non-zero elements, we recover the three atomic essential matrices E 0 , E 1 and E 2 . Finally, the relative pose (R, t) and velocities d 1 , d 2 can be simply extracted by decomposing E 0 , E 1 and E 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Solving the 5 × 5 linear RS essential matrix</head><p>The linear RS essential matrix F contains only 21 nontrivial homogeneous variables, hence its degree of freedom is 20. Collecting 20 correspondences, one can solve for the 5 × 5 matrix F linearly by SVD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Recovering atomic essential matrices</head><p>Once the 5 × 5 matrix F is found, our next goal is to recover the individual atomic essential matrices E 0 , E 1 and E 2 . Eq.-(10) provides 21 linear equations on the three essential matrices. As the three essential matrices consist of 27 elements, we need six extra constraints to solve for E 0 , E 1 and E 2 . To this end, we resort to the inherent constraints on standard 3×3 essential matrices, e.g. det(E) = 0 and 2EE T E − Tr(EE T )E = 0, since E 0 , E 1 and E 2 are standard 3 × 3 essential matrices.</p><p>A quadratic solution. Examining the relationship between the linear RS essential matrix and the atomic essential matrices, we find that the right bottom 2 × 2 corner of E 0 matrix can be directly read out; the first and second columns of E 1 can also be read out; the first and second rows of E 2 are also available from the RS essential matrix F.</p><p>Taking E 1 as an example, we now illustrate how to complete its missing column from two recovered columns. Once we have solved F, we can directly read out the first two columns of E 1 , i.e. E 1 =</p><formula xml:id="formula_26">  E 11 1 E 12 1 * E 21 1 E 22 1 * E 31 1 E 32 1 *   .</formula><p>In order to recover the last missing column, we use both of its rank-2 constraint and cubic constraints. First, by using the rank-2 constraint we express the third column as a linear combination of the first two columns,</p><formula xml:id="formula_27">i.e. E 13 E 23 E 33 = λ 1 E 11 E 21 E 31 + λ 2 E 12 E 22 E 32</formula><p>. The remaining nonlinear constraints on a 3 × 3 essential matrix provide 9 equations over λ 1 and λ 2 , among which we need to choose two in order to solve for λ 1 and λ 2 . For simplicity, we only choose two quadratic ones, namely a 11 λ 2 1 + a 12 λ 1 λ 2 + a 13 λ 2 2 + a 14 = 0 a 21 λ 2 1 + a 22 λ 1 λ 2 + a 23 λ 2 2 + a 24 = 0 .</p><p>These quadratic equations can be solved efficiently by using any off-theshelf solver. Following a similar procedure, we can also solve for E 2 , and subsequently solve for E 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Recovering relative pose and velocities</head><p>Given the three essential matrices E 0 = [t] × R, E 1 = [d 1 ] × R, and E 2 = [d 2 ] × R, we decompose them into relative transformations (R, t) and velocities d 1 , d 2 <ref type="bibr" target="#b7">[8]</ref>.</p><p>Other linear N-point algorithms can be similarly derived. In solving the linear RS essential matrix F, we apply normalization to the image coordinates and the lifted coordi-</p><formula xml:id="formula_28">nates (u 2 i , u i v i , u i , v i , 1)</formula><p>in the way as in <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Nonlinear Solvers w/ Sampson Error</head><p>Based on the above generalized essential matrices, we can now also devise nonlinear solvers. Instead of minimizing an algebraic error, we minimize the geometrically more meaningful (generalized) Sampson error metric. For example, in the case of a uniform RS camera, the Sampson error is the first-order approximation of the distance between a (generalized) feature vector</p><formula xml:id="formula_29">x i = [u 3 i , u 2 i v i , u 2 i , u i v i , u i , v i , 1]</formula><p>T and its corresponding RS epipolar curve, i.e.,</p><formula xml:id="formula_30">e Sampson = n i=1 (x ′ T i Fxi) 2 7 j=1 ((Fxi) 2 j +(F T x ′ i ) 2 j )</formula><p>. We envisage three scenarios where such nonlinear solvers can prove useful: a) Use it as a 'gold-standard' nonlinear refinement procedure. b) Use it as a general solver which directly searches the variables. c) Use it as a minimal-case solver together with RANSAC.</p><p>The last case is particularly relevant as RANSAC favors smaller sample sizes. For example, for the case of uniform RS camera our linear algorithm asks for 44 points; in contrast, a minimal-case solver only requires 17 points, as there are in total 18 degrees of freedom in [R, t, w 1 , w 2 , d 1 , d 2 ].</p><p>To solve the above Sampson error minimization problem, we parametrize the rotation with its angle-axis representation, then we use the standard unconstrained optimization solver 'fminunc' in Matlab.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Experimental evaluation</head><p>We evaluated the linear and uniform RS relative pose methods on both synthetic and real image datasets. When ground-truth data is available, error metrics for rotation and translation estimates are defined as e R = acos((trace( RR T GT ) − 1)/2), and e T = acos( t T t GT /( t t GT )).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Simulation Experiments</head><p>Generating geometrically consistent simulation measurements for a dynamic RS camera is a challenge in itself. First, a relative pose (R, t) is randomly defined between the image pair. The focal length is set to 640 while the image resolution is defined to be 640 × 480. Second, given translation velocities d 1 and d 2 , and angular velocities w 1 , w 2 , the camera pose for each row can be determined. The correspondences are then simulated such that they are not too far from what a real world image feature tracker would return. Each generation is finalized by a cheirality check to guarantee the corresponding 3D point lies in front of both cameras. All experiments are repeated 200 times to obtain statistically relevant conclusions.</p><p>Evaluation of the linear methods. Here we first test our 20-point algorithm for linear RS relative pose. We use the angle between vectorized ground truth and estimated essential matrices as a performance indicator. <ref type="figure" target="#fig_2">Fig. 3</ref> illustrates the essential matrix estimation error with respect to increasing noise. The figure is using a double logarithmic scale. For the 44-point algorithm, a similar curve could also be obtained. We observe that the linear methods are very sensitive to noise. To deal with real world noise, in the following experiments, we used the nonlinear optimization method. Accuracy versus noise level. To evaluate the performance in the presence of noise, we added random Gaussian noise to the correspondences. As we worked mainly on the normalized image coordinates, noise was added immediately on the normalized image plane (i.e., unit image plane). Statistical results are illustrated in <ref type="figure" target="#fig_4">Fig. 4</ref>, demonstrating that our linear RS camera model always achieves better performance than the global shutter camera model, while both rotation and translation errors increase with increasing noise level.  Accuracy versus focal-length. The observability of the RS effect depends on several factors, namely, focal length, depth of the 3D points and the ratio between linear and angular velocities. Here we investigate the performance of relative pose estimation with respect to the focal length. For a constant Gaussian noise level of 2 × 10 −3 , we decrease the camera focal length from 640 to 80. Experimental results of rotation and translation estimation are illustrated in <ref type="figure" target="#fig_5">Fig.5</ref>. With a decreasing focal length, the RS effect becomes increasingly well observable, leading to a decrease of the motion estimation error. However, the pose estimation error does not necessarily decrease monotonically. Accuracy versus RS velocity. Finally, we analyzed the effect of varying dynamics on the RS effect and the accuracy of the RS relative pose algorithm. We decreased the scale of the translation velocity from 10 −2 to 10 −4 . The results are illustrated in <ref type="figure" target="#fig_6">Fig. 6</ref>. With an increasing velocity, our linear RS model achieves an obvious improvement in pose estimation, which suggests that the RS effect is more observable under large linear and angular motion. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Tests on synthetic RS images</head><p>To evaluate the performance of our RS relative pose solvers, we further used the simulated RS image datasets from <ref type="bibr" target="#b3">[4]</ref>. This dataset includes six image sequences generated by 'Autodesk's Maya', where each sequence consists of 12 RS distorted frames. Ground truth camera poses were provided for each row of the image frame.</p><p>As pure rotation is always a degenerate case for epipolar geometry, we used only the last sequence "house trans rot1 B40" in our experiment, where the camera experiences both translational and angular displacements. To establish correspondences between the image frames, we used the standard KLT tracker (A sample result is shown in <ref type="figure">Fig. 7(a)</ref>). Both global shutter camera model and uniform RS model were used to estimate the camera motion. In <ref type="figure">Fig. 7(b)</ref>, we compare the accuracy of the resulting rotation estimation for the global shutter model and our uniform rolling shutter solution. Our method achieves a significant improvement on most of the image frames. shows how the inclusion of a RS model and the extended Sampson distance take those distortions into account, and produce a reprojection error that distributes much more uniformly across the entire image plane. (c) illustrates a histogram of reprojection errors for both cases, thus demonstrating a general reduction of the error through the used of the proposed rolling shutter essential matrix.</p><p>We tested our algorithm on pairs of images taken from a publicly available RS images dataset (http://www.cvl.isy.liu.se/research/datasets/rsba-dataset/). The pairs are chosen such that the median frame-to-frame disparity of the extracted feature correspondences remains below 100 pixels. The images have a resolution of 1280×720, and are captured by an iPhone 4 camera. The focal length of the camera is 1485.2, and the principal point is simply defined as the center of the image. We apply a Harris corner extractor and 31×31 image patches to extract the interest points, and match them using a simple brute-force approach. We apply Ransac to the resulting correspondences, and refine the final model over all inliers. In each iteration, we first apply a global shutter relative pose solver to identify all inliers and initialize the relative pose, and then use Sampson error minimization in order to optimize the result. We use standard Sampson error minimization (i.e. based on a global shutter model) as a baseline implementation, and our adapted Sampson error for RS cameras as the improved alternative.</p><p>An example result with 2287 input correspondences is shown in <ref type="figure">Figure 8</ref>. As can be clearly observed, the RS model allows for a more complete description of the geometry, and leads to a significant reduction in the (approximate) reprojection error after the final optimization step. Moreover, it is interesting to see that the global shutter model achieves a relatively small error for a sub-part of the image only, while the RS model is able to explain the distortion in other regions and achieves a small error in almost the entire image. A similar difference in performance can be observed for any pair of images with sufficient dynamics, thus underlining the importance of taking the RS effect into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>We have derived novel generalized essential matrices of size 4 × 4, 5 × 5, 6 × 6, and 7 × 7 for linear PB, linear RS, uniform PB, and uniform RS cameras, respectively. We also developed effective linear N-point algorithms and nonlinear Sampson error minimizers for solving these generalized essential matrices. The entire work represents a unified and elegant framework for solving the Relative Pose problem with new types of cameras, including the practically relevant and previously unsolved case of a RS camera. It is our hope that the presented theoretical contribution to the field of epipolar geometry will serve as a solid foundation for further extensions to novel and practically relevant types of cameras. This, for instance, includes light-field cameras <ref type="bibr" target="#b12">[12]</ref>, general linear cameras <ref type="bibr" target="#b27">[27]</ref>, and generalized camera models <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b25">25]</ref>. The theory promises a more general applicability to spatio-temporally scanning sensors, such as satellite imagery and sweeping Laser scanners.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Example epipolar curves for the camera models discussed in this paper. Groups of epipolar curves of identical color originate from points on the same row in another image. For linear rolling shutter (a) and linear push broom cameras (c), the epipolar curves are conic. The epipolar curves for uniform rolling shutter (b) and uniform push broom cameras (d) are cubic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>This figure shows that different scanlines in a RS image have different effective optical centers. For any pair of feature correspondences (indicated by red 'x's in the picture), a co-planarity relationship however still holds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Evaluation on increasing Gaussian noise for linear 20point algorithm. Noise is added to the normalized coordinates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Performance evaluation with increasing Gaussian noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Evaluation on decreasing focal length with noise of 2 × 10 −3 standard deviation on the unit image plane.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Evaluation over decreasing translation velocity with noise 5 × 10 −3 standard deviation on the unit image plane.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .Figure 8 .</head><label>78</label><figDesc>Synthetic image experiments on the sequence "house trans rot1 B40", performance comparison between global shutter model and our uniform rolling shutter solver. Comparisons of the Sampson errors for a pair of images taken from a RS video dataset. (a) shows the final result of Sampson error minimization based on a global shutter model. The error distribution has a structure in the image plane, indicating regions for which the RS distortion is not properly taken into account. (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 .</head><label>1</label><figDesc>A hierarchy of generalized essential matrices for different types of rolling-shutter and push-broom cameras.</figDesc><table>Camera Model 
Essential Matrix 
Monomials 
Degree-of-freedom Linear Algorithm Non-linear Algorithm 
Motion Parameters 

Perspective camera 

 

 

f11 f12 f13 
f21 f22 f23 
f31 f32 f33 

 

 
(ui, vi, 1) 
3 2 = 9 
8-point 
5-point 
R, t 

Linear push broom 

 

 
 
 

0 
0 
f13 f14 
0 
0 
f23 f24 
f31 f32 f33 f34 
f41 f42 f43 f44 

 

 
 
 

(uivi, ui, vi, 1) 
12 = 4 2 − 2 2 
11-point 
11-point 
R, t, d1, d2 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Simultaneous object pose and velocity computation using a single view from a rolling shutter camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ait-Aider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Andreff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lavest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Martinet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="56" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Structure and kinematics triangulation with a rolling shutter stereo rig</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ait-Aider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Berry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2009-09" />
			<biblScope unit="page" from="1835" to="1840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">R6p -rolling shutter absolute camera pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Albl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kukelova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Rectifying rolling shutter video from hand-held devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-E</forename><surname>Forssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ringaby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2010-06" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Calibration-free rolling shutter removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grundmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kwatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Essa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCP</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Linear pushbroom cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="1997-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">In defense of the eight-point algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="580" to="593" />
			<date type="published" when="1997-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Multiple View Geometry in Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">I</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="page">521540518</biblScope>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rolling shutter bundle adjustment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hedborg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-E</forename><surname>Forssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ringaby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf</title>
		<meeting>IEEE Conf</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Comp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Patt. Recogn</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1434" to="1441" />
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Structure and motion estimation from rolling shutter video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hedborg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ringaby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-E</forename><surname>Forssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision Workshops</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="17" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">High quality structure from small motion for rolling shutter cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Im</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-G</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis<address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On linear structure from motion for light field cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Johannsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sulc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goldluecke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dense continuoustime tracking and mapping with rolling shutter RGB-D cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kerl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stueckler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis<address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A linear approach to motion estimation using generalized camera models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Global optimization of object pose and motion from a single rolling shutter image with automatic 2d-3d matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Magerand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bartoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ait-Aider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pizarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="456" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Geometric models of rolling-shutter cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meingast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Geyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OMNIVIS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Rolling shutter camera calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Oth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Furgale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kneip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Siegwart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="1360" to="1367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A splinebased trajectory representation for sensor fusion and rolling shutter cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Patron-Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lovegrove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sibley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="208" to="219" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using many cameras as one</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pless</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2003-06" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="587" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">What is a camera?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="1526" to="1533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Rolling shutter stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Saurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Koser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Bouguet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="465" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A minimal solution to the rolling shutter pose estimation problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Saurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On the spacetime geometry of galilean cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gritai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Spline fusion: A continuous-time representation for visual-inertial fusion with application to rolling shutter cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Steven Lovegrove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alonso</forename><surname>Patron-Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Brit. Mach. Vis. Conf</title>
		<meeting>Brit. Mach. Vis. Conf</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multi-view geometry for general camera models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sturm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2005-06" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="206" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Towards a minimal solution for the relative pose between axial cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vasconcelos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barreto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Brit. Mach. Vis. Conf</title>
		<meeting>Brit. Mach. Vis. Conf</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">General linear cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcmillan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<editor>T. Pajdla and J. Matas</editor>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<biblScope unit="volume">3022</biblScope>
			<biblScope unit="page" from="14" to="27" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
