<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A nonlinear regression technique for manifold valued data with applications to Medical Image Analysis *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monami</forename><surname>Banerjee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of CISE</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<postCode>32611</postCode>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudrasis</forename><surname>Chakraborty</surname></persName>
							<email>rudrasis@cise.ufl.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CISE</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<postCode>32611</postCode>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Ofori</surname></persName>
							<email>eofori@ufl.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Applied Physiology and Kinesiology</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<postCode>32611</postCode>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Okun</surname></persName>
							<email>3okun@neurology.ufl.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Neurology</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<postCode>32611</postCode>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">E</forename><surname>Vaillancourt</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Applied Physiology and Kinesiology</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<postCode>32611</postCode>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baba</forename><forename type="middle">C</forename><surname>Vemuri</surname></persName>
							<email>vemuri@cise.ufl.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CISE</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<postCode>32611</postCode>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A nonlinear regression technique for manifold valued data with applications to Medical Image Analysis *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regression is an essential tool in Statistical analysis of data with many applications in Computer Vision, Machine</head><p>Learning, Medical Imaging and various disciplines of Science and Engineering. Linear and nonlinear regression in a vector space setting has been well studied in literature. However, generalizations to manifold-valued data are only recently gaining popularity. With the exception of a few, most existing methods of regression for manifold valued data are limited to geodesic regression which is a generalization of the linear regression in vector-spaces. In this paper, we present a novel nonlinear kernel-based regression method that is applicable to manifold valued data. Our method is applicable to cases when the independent and dependent variables in the regression model are both manifold-valued or one is manifold-valued and the other is vector or scalar valued. Further, unlike most methods, our method does not require any imposed ordering on the manifold-valued data. The performance of our model is tested on a large number of real data sets acquired from Alzhiemers and movement disorder (Parkinsons and Essential Tremor) patients. We present an extensive set of results along with statistical validation and comparisons.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>An essential task in any regression-based analysis involves finding the relation between two sets of variables, i.e., the independent and the dependent variables. So, given a training data set {x i , y i } of independent and dependent * This research was funded in part by the NSF grant IIS-1525431 and NIH grant NS066340 to BCV. variables our goal is to regress between these two sets of variables, i.e., find a function f : x → y s.t. y i = f (x i ). If both of these variables are vector valued and if there is a linear relationship between them, i.e., y i = ax i + b for some a, b, any linear least square estimator can be used to find this relationship. However, in most real applications, this relationship is rather nonlinear and thus, one resorts to the use of either nonlinear least-squares or tools such as support vector regression <ref type="bibr" target="#b0">[1]</ref>.</p><p>Often, one or the other or both the variables lie on a Riemannian manifold which lacks global vector space structure. This lack of vector space structure means that any linear combination of points on the manifold does not lie on that manifold. For example, in general, a linear combination of points on a hypersphere do not lie on that hypersphere. Moreover, in a vector space the linear relation between {x i , y i } can be expressed as a straight line, y i = ax i + b, but on a general Riemannian manifold with non-zero sectional curvature, straight lines correspond to geodesic curves. Hence, even for the linear relation, one can not use the linear least squares method on a general Riemannian manifold. Instead, a sophisticated technique is needed even to find a linear relationship for manifold valued data. This poses a restriction on the direct use of well known vector-space based linear/non-linear least-squares type techniques on the manifold. Hence, finding a relationship between manifold valued variables poses a formidable challenge. One may be tempted to use an embedding of the manifold valued variables in the Euclidean space (using the Whitney Embedding <ref type="bibr" target="#b1">[2]</ref>) and apply the linear/non-linear regression scheme in the Euclidean settings. But, note that often embedding results in a poor estimation of the underlying relationship. Moreover, the data dimension after the embedding becomes larger. For example, using the strong Whitney embedding, one can embed any n-dimensional manifold in a 2n-dimensional Euclidean space, i.e., R 2n . These problems motivated the research community to seek a regression technique applicable to manifold valued data sets. Now, we will briefly present some earlier work in this context.</p><p>The most commonly used regression on Riemannian manifolds is the geodesic regression, where, some notion of ordering is imposed on the manifold-valued data <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref>. In <ref type="bibr" target="#b3">[4]</ref>, Fletcher et al. proposed a geodesic regression technique from real-valued to manifold-valued data. Hong et al. <ref type="bibr" target="#b7">[8]</ref> proposed a shooting spline based regression technique on the Grassmannian. In <ref type="bibr" target="#b8">[9]</ref>, Hinkle et al. proposed a polynomial regression method on Riemannian manifolds in a variational framework. The minimization in their problem requires the solution to a system of covariant differential equations. In <ref type="bibr" target="#b9">[10]</ref>, authors estimate the correlation between shape and age using manifold regression. Recently, a variational spline regression for the manifold of diffeomorphisms was presented in a large deformation diffeomorphic mapping (LDDMM) setting <ref type="bibr" target="#b10">[11]</ref>. In <ref type="bibr" target="#b11">[12]</ref>, authors formulate the manifold regression problem in a regularized risk minimization setting. In <ref type="bibr" target="#b12">[13]</ref>, Skwerer proposed a regression scheme in phylogenetic tree spaces (negatively curved spaces). Most of these methods however are applicable to cases where the independent variable in the regression problem is scalar valued. Recently, a multivariate general linear model (MGLM) to regress from realvalued vectors to manifold-valued data was proposed in <ref type="bibr" target="#b6">[7]</ref>. Further, in <ref type="bibr" target="#b13">[14]</ref>, Kim et al. generalized the well known Canonical Correlation Analysis (CCA) to Riemannian manifolds. Both these methods use geodesic regression on the manifold, which is the equivalent of the linear regression in vector-spaces. To the best of our knowledge, there is no nonlinear regression method between manifold valued independent and dependent variables or even from manifold to vector valued data.</p><p>Recently in <ref type="bibr" target="#b14">[15]</ref>, authors proposed a non-linear regression technique where, either of the independent or the dependent variables are manifold-valued. Unlike existing methods, this method does not require an ordering of the manifold-valued data. Motivated by their work, in this paper, we propose a novel regression scheme in a more complex setting where both of the variables (independent and dependent) are manifold-valued (lie on the same or different Riemannian manifold(s)). Such problems are commonly encountered in Medical Image Analysis. For e.g., given diffusion tensor images (DTIs) derived from diffusion magnetic resonance data sets, to assess changes caused by pathologies, one needs to warp the given DTI to an atlas DTI. The information in the warp can be captured using the Cauchy deformation tensors that are symmetric and positive definite. This gives another tensor field (one deformation tensor at each voxel). Finding the relation between the lo-cal water molecule diffusion in the tissue and the changes with respect to a reference template (atlas), provides a way to characterize the population. Several other applications include finding relationship between diffusion and conductance tensor fields in Cardiac imaging etc.</p><p>The rest of the paper is organized as follows. In section 2, we briefly present some relevant concepts of Riemannian geometry and notations for subsequent use. In section 3, we propose our manifold to manifold regression technique. We report experimental results of our regression method in section 4. In section 5, we extend our regression method to a new robust regression technique on manifold valued data and present experimental results on synthetic data. Finally, in section 6, we draw the conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Mathematical Preliminaries</head><p>In this section, we present some basic definitions of terms from Riemannian Geometry that will be used throughout the paper. For further details on these concepts, we refer the readers to <ref type="bibr" target="#b15">[16]</ref>. Let M be a topological space. There ∃! a torsion-free connection on T M which respects g. This connection is called the Levi-Civita connection. In the rest of the paper, we use (M, g) to denote a Riemannian manifold equipped with a Levi-Civita connection ∇.</p><p>A vector field along a smooth map γ is a map Y :</p><formula xml:id="formula_0">I → T M such that Y (t) ∈ T γ(t) M. We say that Y is paral- lel along γ if ∇ γ ′ (t) Y ≡ 0. Let Y 0 ∈ T γ(t0) M, where t 0 ∈ I. Then, ∃! parallel vector field Y along γ, such that Y (t 0 ) = Y 0 . Y (t) is called the parallel transport of Y (t 0 ) along γ. A geodesic is a curve γ : I → M such that ∇ γ ′ γ ′ = 0. For v ∈ T M, ∃! geodesic γ v : I → M with γ ′ v = v. If 1 ∈ I, i.e., γ v (1)</formula><p>is defined, then we can define Exp(v) = γ v (1). So, we can define Exp :</p><formula xml:id="formula_1">{v ∈ T M|γ v (1) is defined} → M.</formula><p>The geodesic distance function on a connected manifold M determined by g is ρ = ρ g : M × M → R by ρ(p, q) = inf{L(γ)|γ ∈ Ω p,q }, where Ω p,q = {γ : [0, 1] → M piecewise smooth, γ(0) = p, γ(1) = q. L(γ) = 1 0 γ ′ (t) dt. It's easy to show that ρ g is a metric and M is a metric space. It can be shown that, ∀p ∈ M, ∃ open neighborhood W of p, ǫ &gt; 0, such that ∀q ∈ W , Exp q ↾ Bǫ(0)⊂TqM is a diffeomorphism onto an open neighborhood U q with q ∈ U q and W ⊂ U q . Exp q is called Riemannian Exponential map. On U q , Exp −1 q is defined and is called Riemannian inverse Exponential map (denoted by Log). A Riemannian manifold is called geodesically complete (or complete) if domain(Exp) = T M. For a complete manifold, there exists a minimal geodesic between any two points on the manifold.</p><p>Without going into the definition and details of sectional curvature, for the rest of this paper, we will assume that the data points lie inside a geodesic ball of convexity radius &lt; ρ where ρ = 1 2 min(conv(M), π √ ∆ ) <ref type="bibr" target="#b16">[17]</ref> where conv(M) is the convexity radius of M and ∆ is the upper bound on the sectional curvature. This assumption is needed to ensure that the Riemannian ℓ p center of mass exists and is unique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem Formulation and Algorithm</head><p>Let (M, g M ) and (N , g N ) be complete Riemannian manifolds <ref type="bibr" target="#b15">[16]</ref> with g M and g N being the Riemannian metrics on the Riemannian manifolds M and N , respectively.</p><formula xml:id="formula_2">Given {x i , y i } N i=1 ⊂ M × N , our goal is to find a function f : M → N s.t., y i = f (x i ), ∀i. Let, d M : M × M → R be the distance function on M, i.e., d M (x i , x j ) = g M xi (Log xi x j , Log xi x j ),</formula><p>where Log is the Riemannian inverse Exponential map (Note that the completeness assumption of manifold ensures that Log map is defined on the entire manifold, but for a manifold which is not geodesically complete, within a geodesic ball of appropriate radius (mentioned in Section 2), the Log map is well defined). Let d N be the distance function on N induced by the Riemannian metric g N . Now, we can estimate f by minimizing the following objective function,</p><formula xml:id="formula_3">E = 1 N N i=1 d N (y i ,ŷ i ) 2 , whereŷ i is the predicted y i de- fined by, y i =f (x i ) = arg min µ∈N k j=1 K(x i , t j ) k l=1 K(x i , t l ) d N (c j , µ) 2 (1) where, {c j } k j=1 ⊂ N and {t j } k j=1 ⊂ M</formula><p>are the representatives on N and M respectively. K : M × M → R is the kernel function (not necessarily positive-definite). Thus,ŷ is approximated as a weighted Fréchet mean (FM) <ref type="bibr" target="#b17">[18]</ref> of {c j } k j=1 . We use {t j } k j=1 as the cluster representatives (of the given manifold-valued data) and estimate {c j } k j=1 using the steepest descent on the objective function. The direction of the gradient of E with respect to c j is given by,</p><formula xml:id="formula_4">D cj E = − 2 N N i=1 Logŷ i y i D cjŷi .<label>(2)</label></formula><p>Where, c j andŷ i both are on N , hence, we will use chart maps <ref type="bibr" target="#b15">[16]</ref> </p><formula xml:id="formula_5">to compute D cjŷi . Let {U α , Φ α } α∈I be the chart map of N . Without loss of generality, assume c j ∈ U α1 andŷ i ∈ U α2 where, (U α1 , Φ α1 ) and (U α2 , Φ α2 )</formula><p>are the corresponding charts. Note that, by definition, chart maps are diffeomorphisms. Given a fixed x i , from Eq. 1, let us define a function F :</p><formula xml:id="formula_6">N k → N byŷ i = F {c j } k j=1 . Now, we can define D cjŷi as D cjŷi := Dc j F, where,c j = Φ α1 (c j ) and F = Φ α2 • F • Φ −1 α1 : R n → R n , with n = dim(N ). Hence, Dc j F is the Jacobian of F.</formula><p>Note that, D cj E ∈ T cj N , thus, in order to make the RHS of Eq. 2 to be in T cj N , we use parallel transport of Logŷ i y i fromŷ i to c j . For a general Riemannian manifold N , as parallel transport is not easy to compute, we can approximate this parallel transport, Λ cj Logŷ i y i by, Λ cj Logŷ i y i ≈ Log cj y i − Log cjŷi . Moreover, for a general Riemannian manifold, as the weighted FM is not in closed form for more than two samples, F is not in closed form, hence, computation of the Jacobian is not feasible. But, recently, an efficient recursive FM estimator was proposed for several Riemannian manifolds including the manifold of symmetric positive definite matrices, SP D(m) <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>, hypersphere, S m <ref type="bibr" target="#b20">[21]</ref> and the Grassmannian, Gr(p, m) <ref type="bibr" target="#b21">[22]</ref>. We use this recursive FM estimator to compute F (and the Jabcobian) in closed form for these aforementioned manifolds. But, for other Riemannian manifolds, we approximate Eq. 1 (in the spirit of <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref></p><formula xml:id="formula_7">) byŷ i ≈ Exp p k j=1 K(t j , x i ) Log p c j ,</formula><p>where, p ∈ N and Exp is the Riemannian Exponential map. For the sake of completeness, we will briefly present the recursive FM estimator formulation here (as given in <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>. Let X 1 , X 2 , · · · , X k be independent samples drawn from a probability distribution P (X ) on a complete manifold N with a set of associated weights {w j } k j=1 such that j w j = 1. Then, we define the weighted Fréchet mean estimator M k by the following recursion:</p><formula xml:id="formula_8">M 1 = X 1 (3) M l+1 = Γ X l+1 M l w l+1 /( l+1 i=1 w i )<label>(4)</label></formula><p>where, Γ X l+1 M l : [0, 1] → N is the shortest geodesic between M l and X l+1 , i.e., Γ</p><formula xml:id="formula_9">X l+1 M l (0) = M l , Γ X l+1 M l (1) = X l+1 .</formula><p>Note that, this formulation can be easily extended to any complete Riemannian manifold (or within a geodesic ball of specific radius of any Riemannian manifold) where a closed form expression of the Riemannian Exponential and Inverse Exponential map exist. But, in order to be a valid FM estimator, one needs to show its consistency which is proved in <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref> for SP D(m), S m and Gr(p, m) respectively. Hence, for Riemannian manifolds other than the aforementioned three, we will use the approximation discussed above. Now, we sketch our manifold regression algorithm for a general Riemannian manifold below.  </p><formula xml:id="formula_10">Input: {x i } N i=1 ⊂ M, {y i } N i=1 ⊂ N , k, b, η, ǫ &gt; 0 Output: {t j } k j=1 ⊂ M, {c j } k j=1 ⊂ N 1 Compute {t j } k j=1 as k cluster centers of {x i } N i=1 ; 2 Compute K N ×k matrix, where K i,j = K(x i , t j ); 3 Initialize {c j } k j=1 as, c j = arg min µ∈N {l|x l ∈k j } w l,j d N (y l , µ), where k j is the j th cluster, and w l,j = K l,j/ {l|x l ∈k j } K l,j ; 4 Compute W N ×k matrix, where W i,j = K i,j/ k l=1 K i,l ; 5 Compute the objective function E = 1 N i d N (y i ,ŷ i ) 2 , using the predictionsŷ i 's in Eq. (1), and c j values in line (3) above; 6 E old ← E, and flag ← 1; 7 while flag = 1 do 8 Compute Dc j E, ∀j = 1, · · · , k, using Eq. (2); 9 c new j ← Exp c j (−η Dc j E); 10 Recompute {ŷ i } N i=1 and E, using {c new j } k j=1 ; 11 if Dc j E &lt; ǫ, ∀j = 1, · · · ,</formula><formula xml:id="formula_11">Input: x ∈ M, {t j } k j=1 ⊂ M, {c j } k j=1 ⊂ N Output:ŷ ∈ N 1 Compute {w j } k j=1 as w j = K(x,t j ) / k l=1 K(x,t l ); 2ŷ = arg min µ∈N k j=1 w j d N (c j , µ); Special Case: SP D(m) → S n regression</formula><p>Here, we present the derivation of our regression formulation where, M = SP D(m) and N = S n . We will use the GL-invariant Riemannian metric on SP D(m), the induced distance is given by d M (x, t) = Tr((Log(x −1 t)) 2 ), where Log and Tr are the matrix logarithm and matrix trace operators respectively, and x, t ∈ SP D(m). On S n , we chose the arc length metric, and the distance d N (y, c) = arccos(y t c), where y, c ∈ S n . Now, using Eq. 1,ŷ i is a weighted FM of {c j }, where the j th weight, w j = K(x i , t j ). In this work, we chose, K(x i , t j ) = exp(−b d M (x i , t j ) 2 /2σ 2 ), b and σ being the kernel parameters. Using the inductive FM estimator presented in <ref type="bibr" target="#b20">[21]</ref>, D cjŷi is computed as follows.ŷ i = M k , i.e., the k th intrinsic mean estimator, hence</p><formula xml:id="formula_12">D cjŷi = D M k−1 M k D M k−2 M k−1 · · · D Mj M j+1 D cj M j , where D M l−1 M l = (1 − s l ) sin((1 − s l ) θ l )/ sin(θ l ) I n+1 ,</formula><p>and D c l M l = s l sin(s l θ l )/ sin(θ l ) I n+1 . Here, s l = w l /( l p=1 w p ), θ l = arccos(c t l M l−1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head><p>In this section, we evaluate the performance of our proposed nonlinear regression technique via several experiments on real datasets. In all of these experiments, we have used the kernel parameter σ 2 as the data variance. In order to measure the accuracy of the regression, we use the R 2 statistical measure on Riemannian manifolds, described in <ref type="bibr" target="#b3">[4]</ref>. The R 2 statistic on a Riemannian manifold captures the fraction of the data variance that can not be explained by the regression model. Let the unexplained variance be defined as</p><formula xml:id="formula_13">N i=1 d N (y i ,ŷ i ) 2 . Then, the R 2 statistic is given by R 2 = 1 − unexplained variance datavariance ∈ [0, 1].</formula><p>The value of the R 2 statistic lies in the interval [0, 1], and a large value indicates a better regression performance. We vary the b value from 1 to 100 in increments of 1 and select the b value using a cross-validation scheme. In order to measure the statistical significance of our results, we perform the following statistical analysis. We executed 100 independent runs with varying b-value and fit a normal distribution to the 100 R 2 statistic values. Let this random variable be denoted by X . Now, we fit a normal distribution to the R 2 statistic from the 100 independent runs with varying b value and a random permutation of the independent variables. Let this random variable be denoted by Y. The null hypothesis is set to, H 0 : mean of X = mean of Y. We reject the null hypothesis with a significance level of 0.01 (this p-value is denoted as p 1 in the rest of this section).</p><p>In the second analysis setting, we consider the b value (denoted by b M ) which yields the largest R 2 statistic (denoted by r 2 M ). Now, for b = b M , we execute 100 independent runs by randomly permuting the independent variables and fit a student's t-distribution to these R 2 values. Let this random variable be denoted by Z. The null hypothesis is then set to, H 0 : r 2 M comes from the distribution of Z. As before, we reject the null hypothesis with a 0.01 significance level (this p-value is denoted as p 2 in the rest of this section). Moreover as in <ref type="bibr" target="#b3">[4]</ref>, we performed the following test. For b M , we execute 100 independent runs by randomly permuting the independent variables and compute the R 2 statistics. Let this 100 R 2 statistics be denoted by Z. Then, we report what fraction of Z is larger than r 2 M (denoted by the f -value). Note that, the f -value is in the range [0, 1], with smaller values being preferred. The f -value is a measure used to see if there is a relationship between the independent and the dependent sets of variables. We now provide the detailed experimental results on two real datasets.</p><p>OASIS data <ref type="bibr" target="#b23">[24]</ref>: We used the OASIS data <ref type="bibr" target="#b23">[24]</ref> to perform several regression tasks. This data consists of 36 T1 magnetic resonance (MR) brain scans of subjects with varying ages in the range of 18 to 96, including early stage AD patients.</p><p>We construct two different data representations as follows. (i) First, we segmented the Corpus Callosum (CC) from these MR brain scans. Then, we take points on the 3D boundary of the CC and map it to S 24575 using the Schrödinger distance transform (SDT) <ref type="bibr" target="#b24">[25]</ref>. (ii) We used a set of landmark points on the boundary of CC and map each of these point sets into the Kendall's shape space (CP n ) <ref type="bibr" target="#b25">[26]</ref>, which is a complex projective space. In this experiment, n = 249. First, we seek to model the relationship between CP n and the SDT representation of CC shapes. The regression results are given in <ref type="table" target="#tab_1">Table 1 and Table 2</ref>. Since this relationship is fairly complex, we can say that the R 2 statistic values are very good even for a small number of control points (k). We vary k over ⌈N/4⌉, ⌈N/3⌉, and ⌈N/2⌉, i.e., we took k to be 9, 12 and 18 respectively. Note that, if k = N , then the model will memorize the data rather than learn from the data. Hence, a very large k is not a good choice. Also note that, the R 2 statistic values for CP n to SDT regression are better than the vice-versa case. This is justified because, SDT does not contain enough information to recover the shape while one can recover the shape (up to an rigid transformation) from CP n representation. Thus, given a point on S n , representing an SDT, finding it's corresponding point in the CP n representation correctly, is a much harder problem. This justifies the comparatively smaller R 2 statistics in <ref type="table" target="#tab_2">Table 2</ref>. Moreover, as evident, since the shape of the CC varies a lot with age, it would be useful to find a regression model from these two representations of CC shapes to age. The regression results from CP n and SDT to age are given in Tables 3 4 respectively. From these two tables, one can see that SDT is a better representative of CC shapes than CP n for the task of finding a relationship between shape and age. The usefulness of SDT features in finding the relationship between age and CC shapes were also noted in <ref type="bibr" target="#b14">[15]</ref>, where the authors regressed CC shapes from age information. Moreover, Kendall's shape space representation is a canonical representation of shapes. Hence, the usefulness of regression between SDT and CP n is evident. As mentioned before, to the best of our knowledge there does not exist any manifold to manifold (or even manifold to real) regression technique in the literature, so we could not compare the performance of our method with any previous work in this context.</p><p>We have given the performance of our regressor for CC</p><formula xml:id="formula_14">k b M r 2 M p 1 p 2 f -val 9</formula><p>63 0.479 &lt; 0.01 &lt; 0.01 0 12 59 0.752 &lt; 0.01 &lt; 0.01 0 18 98 0.754 &lt; 0.01 &lt; 0.01 0      From each of these images, we identify the region of interest (ROI) (40 voxels in size) containing the Substantia Nigra, a neuroanatomical structure known to be affected most by PD and ET. Then, from the HARDI data within the ROI we compute the ensemble average propagator (EAP), a local probability density function that fully captures the local diffusional characteristics of the tissue. The EAP density function is extracted using methods described in <ref type="bibr" target="#b26">[27]</ref> and represented by a Gaussian mixture model, with fixed eigen values for their covariance matrices. This is done to facilitate the representation of multiple neuronal fiber bundles in a voxel and since the fibers are tubular in structure, the eigen values are assumed to satisfy λ 1 &gt; λ 2 = λ 3 . Thus the degrees of freedom are controlled by the eigen vector orientations. We choose 321 directions for tessellation of the sphere (of directions), using an icosadodecahedron as in <ref type="bibr" target="#b26">[27]</ref>. Thus, the EAP field now has a discrete representation of 40 voxels, with each voxel containing a probability vector of size 321.</p><p>In morphometric analysis, it is common to use the Cauchy deformation tensor (CDT) field to capture changes in a patient scan with respect to a reference template/ atlas. Thus, in order to capture changes in a patient HARDI scan with respect to the control atlas, we first nonrigidly register each EAP-field estimated from the HARDI data to the EAP atlas and obtain the CDT at each voxel in the ROI, given by √ JJ T , where, J is the Jacobian of the non-rigid transformation <ref type="bibr" target="#b27">[28]</ref>. The CDT is a symmetric positive definite matrix (SPD) of dimension 3 × 3 in this case. Hence, for each patient we extract a CDT field of dimension 3×3×40.</p><p>In this experiment, we seek to find the relationship between structural information in the form of CDT and clinical measures such as the MDS-UPDRS (Movement Disorder Society's Unified Parkinson's Disease Rating Scale) <ref type="bibr" target="#b28">[29]</ref>. The MDS-UPDRS score is widely used to follow the longitudinal course of PD. These scores are obtained via interviews and clinical observations by an expert. In this experiment, available to us are the MDS-UPDRS scores of 58 subjects in the population under consideration, including 21 controls, 13 ET, and 24 PD patients. This score is a nonnegative integer, with smaller values indicating normality of the patient.</p><p>For these 58 patients, we first find a relationship between the EAP field and the MDS-UPDRS score by regressing the EAP against the MDS-UPDRS. We did the similar experiment as before. We vary k to be ⌈N/4⌉, ⌈N/3⌉, and ⌈N/2⌉. The results are given in <ref type="table" target="#tab_5">Table 5</ref>. From the results, it is evident that even for small number of control points, i.e., k = 15, the R 2 statistic is quite high (very high) and the statistical significance of our result can be ensured by examining the two p-values. Like before the f -value denotes the number of times the regression result on a random permutation of independent variables is better than the reported R 2 statistic. And the small f -values, i.e., 0 signify that there is indeed a relationship between the two sets of variables. So, by examining the combination of these statistical measures reported, one can see that the regression result is good not because there is over fitting but because, there exists a relationship (inferred from f -value) which is captured well (inferred from R 2 statistics and p-values) by our method.</p><p>Finally, we present an experiment to find a relation between the two distinct structural representations derived from the HARDI data, namely, the EAP field and Cauchy deformation tensor field. The former captures the local diffusional characteristics of the tissue being imaged and the latter captures the changes between the imaged sample and the control atlas. We first regress the Cauchy deformation tensor field to EAP field and the regression result is given     Now, we present the regression from EAP field to Cauchy deformation tensor field. The results for this regression are reported in <ref type="table" target="#tab_7">Table 7</ref>. From a statistical accuracy view point, these results are analogous to the earlier case of mapping between the Cauchy deformation tensor field to the EAP field regression. This is justified given that both Cauchy and EAP tensor fields are equally good representatives of HARDI data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head><p>Our   <ref type="bibr" target="#b13">[14]</ref>. CCA can be applied to find the relation between two manifold valued data, X and Y , on the same Riemannian manifold. Since for none of our data sets, independent and dependent variables are on the same manifold, we present a comparison for two synthetic data sets. The first data is on SP D(3), here we first draw 1000 samples in R 6 from Normal distribution with 0 mean and small variance. Then we create a 3 × 3 symmetric matrix from each of these vectors. Each of these symmetric matrices lie on the tangent space anchored at I 3 (the 3 × 3 identity matrix). As SP D(n) is geodesically complete, we use Exp map to map each tangent vector to a point on SP D(3). Now, for each A ∈ SP D(3), obtain B ∈ SP D(3) using RAR T , where R is a randomly generated matrix in SO <ref type="formula">(3)</ref>. Note that, all the eigenvalues of A and B are same. Now, we do regression and CCA between {A} and {B}. For the second data, we randomly generate 1000 points on S 9 and scale and translate these points and project them back on S 9 . Then, we applied CCA and regression to these two sets of variables. But, as cross-correlation (CC) and R 2 statistic are different metrics, the rationale between comparing the two is as follows. Note that, R 2 statistic can be thought as a square of the CC between {Y } and {Ŷ }. Moreover, for only one independent variable regression, it is also the square of the CC between {X} and {Y }. Hence, there is a relation (though not explicit for the manifold valued cases) between these two measures. Moreover, a high absolute CC value and an R 2 statistic value close to 1 imply there is a strong relation between these two sets of variables. Hence, though they are different metrics, it is still meaningful to compare and contrast them. The comparison results are presented in <ref type="table" target="#tab_8">Table 8</ref>. From this table,it is evident that for both the synthetic data sets, our regression method yields a comparatively better performance than CCA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Robust formulation for manifold value regression</head><p>In this section, we show how to extend the nonlinear regression formulation presented earlier to cope with outliers in the data. This leads to a new and robust formulation for the regression of manifold valued data. Let (M, g M ) and (N , g N ) be complete Riemannian manifolds. Given</p><formula xml:id="formula_15">{x i , y i } N i=1 ⊂ M × N ,</formula><p>our goal is to find a function f : M → N s.t., y i = f (x i ), ∀i. But, in this section, we assume that {y i } are corrupted with outliers. It is well known, that an ℓ 1 norm based formulation is much more robust to outliers than the one based on the ℓ 2 norm. Hence, instead of using the weighted Fréchet mean (FM) of {c j } k j=1 as in Eq. 1, we use the weighted Fréchet median (FMd). For X 1 , X 2 , · · · , X k ∈ N , with associated weights {w j } with w j = 1, the weighted FMd,M is defined as follows:</p><formula xml:id="formula_16">M = arg min µ∈N k j=1 w j d N (µ, X j )<label>(5)</label></formula><p>Using this formulation, we reformulate Eq. 1 as follows:</p><formula xml:id="formula_17">y i =f (x i ) = arg min µ∈N k j=1 K(x i , t j ) k l=1 K(x i , t l ) d N (c j , µ) (6)</formula><p>As in the case of the FM, the FMd also has no closed form expression. Hence, we use the incremental FMd computation formulation in spirit of the work in <ref type="bibr" target="#b29">[30]</ref>. Note that in <ref type="bibr" target="#b29">[30]</ref>, the formulation involves a stochastic gradient descent for finding the ℓ p FM, while our formulation is deterministic, i.e., the next data point is fixed and not selected at random within the neighborhood. The incremental FMd formulation is given below. Assuming the above hypothesis holds, we define the incremental FMd estimator,M k as follows:</p><formula xml:id="formula_18">M 1 = X 1 (7) M l+1 = ExpM l w l+1 ( l+1 i=1 w i v l )<label>(8)</label></formula><p>where v l = LogM l (X l+1 )/d N (M l , X l+1 ). Though this method is deterministic in contrast to <ref type="bibr" target="#b29">[30]</ref>, one might prove the consistency ofM k to the true FMd in a similar way as in <ref type="bibr" target="#b29">[30]</ref>. Notice that, the formulation in Eq. 7 requires only the Riemannian Exponential and the inverse Exponential maps, respectively. For example, on S n ,M l+1 is:</p><formula xml:id="formula_19">M l+1 = cos(s l+1 )M l + sin(s l+1 ) X l+1 −M l cos(θ l ) sin(θ l ) ,<label>(9)</label></formula><p>where, θ l = arccos(M t l X l+1 ). In the next section, we discuss some experimental results on a synthetic data with outliers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Results of Robust Regression</head><p>In this section, we give some preliminary regression results of our Fréchet median (FMd) based regressor to show its effectiveness on synthetic data corrupted with outliers. We compare the performance with our earlier formulation, i.e., using the incremental FM estimator. In our future work,  <ref type="table">Table 9</ref>: SP D(3) to S 2 regression with outliers we will apply this method to real datasets. First, we generated 1000 i.i.d. samples on SP D(3) from a Log-Normal distribution <ref type="bibr" target="#b30">[31]</ref> with a variance of 0.25 and an expectation of I 3 (the identity matrix). Then, for each of these matrices, we compute the principal eigen vector which lies on S 2 . Then, we added random noise only to a fraction of the dependent variables in order to create outliers, and perform a regression from SP D(3) to S 2 . The values of this fraction are varied during the experiments and given in the <ref type="table">Table  9</ref>. The R 2 statistic results using both the FM (Eq. 6) and the FMd (Eq. 1) formulations are reported in <ref type="table">Table 9</ref>. We use N − 1 cluster representatives, where N is the number of sample points, and perform leave-one-out analysis. We varied b from 1 to 20 in unit increments. From the results, when there are no outliers, our FM formulation gives a better R 2 statistic, whereas with increasing outliers, the intrinsic FMd yields a far better performance. Moreover, for more than 15% outliers, the R 2 statistic for regression based on the FM formulation is negative. The negative value denotes that the regressor performed worse than the most trivial choice, which is FM of {y i } for any given x value. This result depicts the robustness of our regressor with the ℓ 1 norm and justifies its choice over the FM in this situation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we presented a novel nonlinear kernelbased regression technique for manifold-valued data sets. Our method is applicable to a variety of situations inclusive of regression between the manifold valued independent and dependent variables. We presented an extensive set of experiments on MR and diffusion MR scans from Alzheimers and movement disorder patients respectively. Further, we validated our results using the R 2 -statistic and permutation tests. As an extension to our regression model, we presented a way to make the regression robust to outliers and showed its performance on synthetic data. Our future efforts will be focused on further developing and experimenting with the robust model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>A chart of dimension n ≥ 0 on M is a pair (U, φ), U ⊂ M open, and φ : U → R n is a diffeomorphism onto an open subset of R n . An atlas on M is a collection of charts, U = {U α , φ α } α∈A such that each pair of charts is C ∞ compatible and {U α } is an open cover of M. A (smooth) manifold is a pair (M, M), where M is a topological manifold and M is an atlas on M. For simplicity, we will use M to denote a smooth manifold. Let p ∈ M. Then, define S p = {γ : I → M , I open, 0 ∈ I, γ(0) = p}. Define an equivalence relation ∼ p on S p as γ 1 ∼ p γ 2 iff γ ′ 1 (0) = γ ′ 2 (0). Then, the tangent space of M at p, denoted by T p M is the set S p / ∼, T p M ≃ R n , where n = dim(M). The tangent bundle of M is defined as a set by T M = ∪ p∈M T p M. The Riemannian metric on M is a field g of smoothly varying inner products on the tangent spaces. A Riemannian manifold, (M, g) is a manifold equipped with a Riemannian metric g. A connection on T M is a map ∇ : Γ(T M) × Γ(T M) → Γ(T M) which is F−linear in the first argument and Leibnitzian in the second argument.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>4 :</head><label>4</label><figDesc>OASIS: CP n to age (R + ) regression shapes inFigure 1. The top row contains six sample shapes and the bottom two rows have the corresponding regressed shapes with varying number of control points. We also present the number of control points and R 2 statistics for these reconstructions. The value of b used here is 109. These results provide an evidence of the good performance of our proposed regression method.Movement Disorder data: This dataset consists of High Angular Resolution Diffusion Image (HARDI) scans from, (i) healthy controls, (ii) patients with essential tremor (ET) and (iii) Parkinson's disease (PD) patients. This data pool contains HARDI scans from 25 controls, 15 ET and 26 PD patients. These HARDI data were acquired using a singleshot spin echo EPI sequence, with repetition time = 7748 ms, echo time = 86 ms, flip angle = 90 • , field of view = 224 × 224 mm, voxel size = 2 mm isotropic with no gap between slices (n = 60), number of diffusion gradient (monopolar) directions = 64, diffusion gradient timing DELTA/ delta = 42.4/10 ms, b-values: 0, 1000 s/ mm2, fat suppression was performed using SPIR, in-plane, SENSE factor = 2. The dimension of each image is 112 × 112 × 60.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Reconstruction of Corpus Callosum shapes. The top row depicts the original shapes and the bottom two rows depict the regressed shapes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>k then ← c j , E ← E old , and η ← 0.9 η; Nonlinear Regression of Manifold Valued Data, Testing Stage.</figDesc><table>12 

flag ← 0; 

13 

end 

14 

if E &lt; E old then 

15 

c j ← c new 
j , and E old ← E; 

16 

else 

17 

c new 

j 

18 

end 

19 end 

Algorithm 2: </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 :</head><label>1</label><figDesc>OASIS: CP n to SDT regression</figDesc><table>k 
b M 
r 2 

M 

p 1 
p 2 
f -val 
9 
77 0.348 &lt; 0.01 &lt; 0.01 
0 
12 62 0.626 &lt; 0.01 &lt; 0.01 
0 
18 109 0.631 &lt; 0.01 &lt; 0.01 
0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 :</head><label>2</label><figDesc>OASIS: SDT to CP n regression</figDesc><table>k 
b M 
r 2 

M 

p 1 
p 2 
f -val 
9 
100 0.888 &lt; 0.01 &lt; 0.01 
0 
12 93 0.988 &lt; 0.01 &lt; 0.01 
0 
18 62 0.987 &lt; 0.01 &lt; 0.01 
0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 :</head><label>3</label><figDesc>OASIS: SDT to age (R + ) regression</figDesc><table>k 
b M 
r 2 

M 

p 1 
p 2 
f -val 
9 
80 0.474 &lt; 0.01 &lt; 0.01 
0 
12 90 0.737 &lt; 0.01 &lt; 0.01 
0 
18 56 0.719 &lt; 0.01 &lt; 0.01 
0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Movement</figDesc><table>Disorder: EAP to MDS-UPDRS (N ∪ 
{0}) regression 

in Table 6. Note that, here we have taken all the subjects, 
i.e., sample size is 67. Analogous to the previous exper-
iments we vary k and b. Though the results reported are 
statistically significant, the R 2 statistics are not very high. 
The possible reasons behind this comparatively small R 2 
statistics are two-fold. (i) The dimensionality of either of 
the independent or dependent variable is very large. More-
over they lie on different Riemannian manifolds, which are 
far more "complex" compared to a vector space. (ii) The 
relationship between Cauchy deformation tensor and EAP 
is highly nonlinear and complex, and the number of sam-
ple points, i.e., 67 is far less compared to the dimension 
of either of the independent or dependent variable. Hence, 
in this example with a complex relationship, the relatively 
small R 2 statistic values are justified. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc>Movement</figDesc><table>Disorder: Cauchy tensor field to EAP 
field regression 

k 
b M 
r 2 

M 

p 1 
p 2 
f -val 
17 15 0.331 &lt; 0.01 &lt; 0.01 
0 
23 10 0.407 &lt; 0.01 &lt; 0.01 
0 
34 10 0.573 &lt; 0.01 &lt; 0.01 
0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 7 :</head><label>7</label><figDesc>Movement Disorder: EAP field to Cauchy tensor field regression</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 8 :</head><label>8</label><figDesc>Comparative results with CCA</figDesc><table>Comparison with CCA [14]: We now compare our man-
ifold regression technique with Cross Correlation Analysis 
for manifold-valued data by Kim et al. </table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Support vector regression machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harris</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Chris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="155" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Embeddings and immersions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masahisa</forename><surname>Adachi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiki</forename><surname>Hudson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>American Mathematical Soc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A gradient-descent method for curve fitting on Riemannian manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chafik</forename><surname>Samir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P-A</forename><surname>Absil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of Comput. Mathematics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="49" to="73" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Geodesic regression and the theory of least squares on Riemannian manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P Thomas</forename><surname>Fletcher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note>International journal of computer vision</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Time-warped geodesic regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Geodesic regression on orientation distribution functions with its application to an aging study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvina</forename><surname>Goh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="416" to="426" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">MGLM on Riemannian manifolds with applications to statistical analysis of diffusion weighted images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hyunwoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><forename type="middle">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bendlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Geodesic regression on the Grassmannian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kwitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="632" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Polynomial regression on Riemannian manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Hinkle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasanna</forename><surname>Muralidharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Population shape regression from random design data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fletcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Splines for diffeomorphic image regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Niethammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="121" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Non-parametric regression between manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Steinke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1561" to="1568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Tree Oriented Data Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skwerer</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1409.5501" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Canonical Correlation analysis on Riemannian Manifolds and its Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hyunwoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagesh</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adluru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Nonlinear regression on riemannian manifolds and its applications to neuro-image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monami</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudrasis</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Ofori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vaillancourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention-MICCAI 2015</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Manfredo Perdigao do Carmo Valero, Riemannian geometry</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Riemannian L p center of mass: Existence, uniqueness, and convexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bijan</forename><surname>Afsari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the American Mathematical Society</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="655" to="673" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Leséléments aléatoires de nature quelconque dans un espace distancié</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><surname>Fréchet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1948" />
			<biblScope unit="page" from="215" to="310" />
		</imprint>
	</monogr>
	<note>Annales de l&apos;institut Henri Poincaré</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Recursive Karcher expectation estimators and geometric law of large numbers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Cheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>AISTATS</publisher>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Probability measures on metric spaces of nonpositive curvature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Sturm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Heat Kernels and Analysis on Manifolds, Graphs, and Metric Spaces</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An efficient recursive estimator of the fréchet mean on a hypersphere with applications to medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hesamoddin</forename><surname>Salehian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudrasis</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Ofori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vaillancourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MICCAI sponsored workshop MFCA</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Recursive fréchet mean computation on Grassmannian and its applications to computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudrasis</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vemuri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On a nonlinear generalization of sparse coding and dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1480" to="1488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">OASIS: crosssectional mri data in young, middle aged, nondemented, and demented older adults</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tracy</forename><forename type="middle">H</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of cognitive neuroscience</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1498" to="1507" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Riemannian framework for matching point clouds represented by the Schrodinger distance transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3756" to="3761" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A survey of the statistical theory of shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Science</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="87" to="99" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-fiber reconstruction from diffusion mri using mixture of wisharts and sparse deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Processing in Medical Imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="384" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Non-rigid registration of high angular resolution diffusion images represented by gaussian mixture fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vemuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">H</forename><surname>Carney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mareci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer-Assisted Intervention-MICCAI</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="190" to="197" />
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Systematic evaluation of rating scales for impairment and disability in parkinson&apos;s disease</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Ramaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Marinus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><forename type="middle">Margarethe</forename><surname>Stiggelbout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bob</forename><surname>Johannes Van Hilten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Movement Disorders</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="867" to="876" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Stochastic gradient descent on riemannian manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvere</forename><surname>Bonnabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2217" to="2229" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Automatic Control</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Random ellipsoids and false discovery rates: Statistics for diffusion tensor imaging data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armin</forename><surname>Schwartzman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
