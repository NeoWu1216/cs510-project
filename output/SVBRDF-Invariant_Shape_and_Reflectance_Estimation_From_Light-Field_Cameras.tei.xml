<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SVBRDF-Invariant Shape and Reflectance Estimation from Light-Field Cameras</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Chun</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC Berkeley</orgName>
								<orgName type="institution" key="instit2">NEC Labs</orgName>
								<address>
									<settlement>Berkeley, San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC Berkeley</orgName>
								<orgName type="institution" key="instit2">NEC Labs</orgName>
								<address>
									<settlement>Berkeley, San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
							<email>efros@eecs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC Berkeley</orgName>
								<orgName type="institution" key="instit2">NEC Labs</orgName>
								<address>
									<settlement>Berkeley, San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Ramamoorthi</surname></persName>
							<email>ravir@cs.ucsd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC Berkeley</orgName>
								<orgName type="institution" key="instit2">NEC Labs</orgName>
								<address>
									<settlement>Berkeley, San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SVBRDF-Invariant Shape and Reflectance Estimation from Light-Field Cameras</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Light-field cameras have recently emerged as a powerful tool for one-shot passive 3D shape capture. However, obtaining the shape of glossy objects like metals, plastics or ceramics remains challenging, since standard Lambertian cues like photo-consistency cannot be easily applied. In this paper, we derive a spatially-varying (SV)BRDF-invariant theory for recovering 3D shape and reflectance from lightfield cameras. Our key theoretical insight is a novel analysis of diffuse plus single-lobe SVBRDFs under a light-field setup. We show that, although direct shape recovery is not possible, an equation relating depths and normals can still be derived. Using this equation, we then propose using a polynomial (quadratic) shape prior to resolve the shape ambiguity. Once shape is estimated, we also recover the reflectance. We present extensive synthetic data on the entire MERL BRDF dataset, as well as a number of real examples to validate the theory, where we simultaneously recover shape and BRDFs from a single image taken with a Lytro Illum camera.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Light-fields implicitly capture the 3D geometry and reflectance properties of a scene, but until recently, they have been primarily used in rendering <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b15">17]</ref>. In recent years, light-field cameras have become popular (e.g. Lytro [1] and Raytrix <ref type="bibr" target="#b20">[22]</ref>), and their use for shape recovery in a single shot has been demonstrated. However, most current depth estimation methods support only Lambertian scenes, making them unreliable for glossy surfaces.</p><p>In this paper, we present a depth and reflectance estimation algorithm that explicitly models spatially varying BRDFs (SVBRDFs) from light-field cameras <ref type="figure">(Fig. 1)</ref>. Since the problem is under-constrained, we assume a known distant light source. We think of a light-field camera as a multi-camera array (of virtual viewpoints), and follow the shape estimation framework using camera motion proposed by Chandraker <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b4">6,</ref><ref type="bibr" target="#b5">7]</ref>. We then show that in the case of light-fields, shape cannot be directly recovered using <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b4">6,</ref><ref type="bibr" target="#b5">7]</ref> (Sec. 3). However, in many instances where the BRDF depends on only the half-angle, we derive an SVBRDF-invariant equation relating depths and normals (Sec. 4).</p><p>(a) Light-field input (b) Our depth (c) PLC <ref type="bibr" target="#b24">[26]</ref> (d) SDC <ref type="bibr" target="#b23">[25]</ref> (e) PSSM <ref type="bibr" target="#b11">[13]</ref> (f) Lytro Illum <ref type="figure">Figure 1</ref>: Comparison of depth estimation results of different algorithms. We texture map the input image onto the depth results, so we can clearly see where each method fails. It can be seen that our method correctly handles the glossy surface, while other methods generate visible artifacts, especially around the most specular parts.</p><p>After this equation is derived, we recover the shape by applying a locally polynomial shape prior (Sec. 5.1). To ease the optimization, we require the normal at one seed pixel to be specified. Then, we solve for the BRDF derivatives and integrate them to recover the reflectance (Sec. 5.2). Finally, we demonstrate extensive real-world examples of shape and reflectance estimation using commercial lightfield cameras (Figs. 1, 7, and 8). Our main contributions are:</p><p>1) A generalization of optical flow to the non-Lambertian case in light-field cameras (Secs. 3 and 4).</p><p>2) A depth estimation algorithm for light-field cameras that handles diffuse plus specular 1-lobe BRDFs (Sec. 5.1).</p><p>3) A reflectance estimation approach that recovers BRDFs for up to 2-lobes once shape is given (Sec. 5.2).</p><p>4) An extensive synthetic evaluation on the entire MERL BRDF dataset <ref type="bibr" target="#b16">[18]</ref> (Sec. 6, Figs. 5 and 6). 5) A practical realization of our algorithm on images taken with the Lytro Illum camera (Sec. 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Depth from Light-Field Cameras: Many depth estimation methods for light-field cameras have been proposed. However, most of them rely on the Lambertian assumption and work poorly on glossy surfaces <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b11">13,</ref><ref type="bibr" target="#b13">15,</ref><ref type="bibr" target="#b23">25,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b29">31]</ref>. Recently, there are some works that try to deal with specularity. Tao et al. <ref type="bibr" target="#b25">[27]</ref> proposed a clustering method that eliminates specular pixels when enforcing photo consistency. However, they attempt a binary classification of pixels into either Lambertian or specular, which cannot handle general glossy surfaces. A follow-up work <ref type="bibr" target="#b24">[26]</ref> adopts the dichromatic model and combines point and line consistency to deal with Lambertian and specular surfaces respectively. However, the dichromatic model fails to hold for materials like metals <ref type="bibr" target="#b26">[28]</ref>. Therefore, their method fails if the BRDFs in different views do not lie on a line as in the dichromatic model, which is discussed in Sec. 4.1. Moreover, line consistency is not robust if neighboring pixels have a similar color. In contrast, our model can work on general 1-lobe BRDFs, and can also recover reflectance in addition to shape (Sec. 5.2), which has not been achieved by previous light-field shape acquisition approaches.</p><p>Differential Motion Theory: Our theoretical contributions are most closely related to the differential theory proposed by Chandraker <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b4">6,</ref><ref type="bibr" target="#b5">7]</ref>. He constructs a mathematical model to recover depth and reflectance using differential camera motion or object motion. Our work has three major differences. First, in contrast to the differential motions he uses, which contain both translations and rotations, we only have translations in light-field cameras. While this changes the form of equations obtainable through differential motions, we show that a BRDF-invariant equation of similar form as in <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b4">6,</ref><ref type="bibr" target="#b5">7]</ref> can still be obtained for halfangle BRDFs (Sec. 4). Second, the work by Chandraker then assumes a constant viewing direction (i.e., (0, 0, −1) ⊤ ) for all pixels to solve for depth directly. In contrast, for our purely translational light-field setup, we must account for viewpoint variations. This is necessary because if the view directions do not differ between cameras, it inherently implies photo-consistency in the Lambertian case. As we show, accounting for viewpoint changes results in the infeasibility to directly obtain depth, and we try to solve the BRDF-invariant equation by applying a polynomial shape prior instead (Sec. 5.1). Finally, to obtain depth directly Chandraker also assumes a homogeneous BRDF. Since we are solving the BRDF-invariant equation instead of computing depth directly, this change also enables us to deal with spatially-varying BRDFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BRDF Estimation:</head><p>BRDF estimation has been studied for many years and different models have been proposed <ref type="bibr" target="#b17">[19]</ref>. Parametric models <ref type="bibr" target="#b18">[20]</ref> can achieve good accuracy by modeling the BRDF as a statistical distribution on the unit sphere. Non-parametric <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b22">24]</ref> and data-driven methods <ref type="bibr" target="#b16">[18]</ref> are also popular, but rely on complex estimation or require a large amount of data. Semi-parametric approaches <ref type="bibr" target="#b6">[8,</ref><ref type="bibr" target="#b14">16]</ref> have also been proposed.</p><p>For joint shape and BRDF estimation, the closest to our work is <ref type="bibr" target="#b3">[5]</ref> described above. Alldrin et al. <ref type="bibr" target="#b0">[2]</ref> proposed an alternating approach to recover both shape and BRDF under light source motion. The work by Oxholm and Nishino <ref type="bibr" target="#b19">[21]</ref> also uses an alternating optimization over shape and re-flectance under natural illumination. None of these methods tries to recover shape or reflectance using camera motions, and the techniques are not intended for light-field cameras.</p><p>Shape from Shading: Shape from shading has a long history. Since it is a very under-constrained problem, most work assumes a known light source to increase feasibility <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b31">33]</ref>. The method by Johnson and Adelson <ref type="bibr" target="#b12">[14]</ref> can estimate shape under natural illumination, but requires a known reflectance map, which is hard to obtain. Barron and Malik <ref type="bibr" target="#b1">[3,</ref><ref type="bibr" target="#b2">4]</ref> described a framework to recover shape, illumination, reflectance, and shading from an image, but many constraints are needed for both geometry and illumination. Since shape from shading is usually prone to noise, recent methods <ref type="bibr" target="#b9">[11,</ref><ref type="bibr" target="#b30">32]</ref> assumed that the shape is locally polynomial for a small patch, and thus increased robustness. We adopt this strategy in our final optimization procedure. However, note that our case is harder, since most shape from shading methods are limited to Lambertian surfaces. In the Lambertian case, if both the pixel value and the light source are given, the normal must be lying on a cone around the light direction. In our case, since the BRDF is an unknown function, we do not have this condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Differential Stereo</head><p>Since light-field cameras can be considered as a multicamera array corresponding to the set of virtual viewpoints, we first consider a simple two-camera case in Sec. 3.1. The idea is then extended to a multi-camera array in Sec. 3.2. Finally, the BRDF invariant equation is derived in Sec. 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Two-camera System</head><p>Consider a camera in the 3D spatial coordinates, where the origin is the principal point of its image plane. The camera is centered at p = (0, 0, −f ) ⊤ , where f is the focal length of the camera. Let β ≡ 1/f . Then for a perspective camera, a 3D point x = (x, y, z) ⊤ is imaged at pixel u = (u, v) ⊤ , where</p><formula xml:id="formula_0">u = x 1 + βz , v = y 1 + βz .<label>(1)</label></formula><p>Let s be the known distant light source direction. Given a 3D point x, let n be its corresponding normal, and v be its (unnormalized) viewing direction from the camera center, v = p − x. Then the image intensity at pixel u for the camera at position p is</p><formula xml:id="formula_1">I(u, p) = ρ(x, n, s, v)<label>(2)</label></formula><p>where ρ is the BRDF function, and the cosine falloff term is absorbed into ρ. Note that unlike most previous work, ρ can be a general spatially-varying BRDF. Practical solutions will require a general diffuse plus 1-lobe specular form (Sec. 4), but the BRDF can still be spatially-varying. Now suppose there is another camera centered at p + τ , where τ = (τ x , τ y , 0) ⊤ . Also suppose a point at pixel u in the first camera image has moved to pixel u + δu in the second camera image. Since the viewpoint has changed, the brightness constancy constraint in traditional optical flow no longer holds. Instead, since the view direction has changed by a small amount τ and none of x, n, s has changed, the intensities of these two pixels can be related by a first-order approximation</p><formula xml:id="formula_2">I(u + δu, p + τ ) ∼ = I(u, p) + (∇vρ) ⊤ τ (3)</formula><p>We can also model the intensity of the second image by,</p><formula xml:id="formula_3">I(u + δu, p + τ ) ∼ = I(u, p) + (∇uI) ⊤ δu + (∇pI) ⊤ τ<label>(4)</label></formula><p>Note that (∇ p I) ⊤ τ is just the difference between the image intensities of the two cameras,</p><formula xml:id="formula_4">I 2 − I 1 . Let ∆I = I 2 − I 1 .</formula><p>Combining <ref type="formula" target="#formula_31">(3)</ref> and <ref type="formula" target="#formula_3">(4)</ref> then gives</p><formula xml:id="formula_5">(∇uI) ⊤ δu + ∆I = (∇vρ) ⊤ τ<label>(5)</label></formula><p>Finally, since the second camera has moved by τ , all objects in the scene can be considered as equivalently moved by δx = −τ while assuming the camera is fixed. Using (1), we can write</p><formula xml:id="formula_6">δu = δx 1 + βz = −τ 1 + βz<label>(6)</label></formula><p>Substituting this term for δu in <ref type="formula" target="#formula_5">(5)</ref> yields</p><formula xml:id="formula_7">(∇uI) ⊤ −τ 1 + βz + ∆I = (∇vρ) ⊤ τ<label>(7)</label></formula><p>Let I u , I v be the spatial derivatives of image I 1 . Then multiplying the vector form out in <ref type="formula" target="#formula_7">(7)</ref> gives ∆I = (∇vρ)xτx + (∇vρ)yτy + Iu τx 1 + βz + Iv τy 1 + βz <ref type="bibr" target="#b6">(8)</ref> where (·) x and (·) y mean the xand y-components of (·), respectively. An intuition for the above equation is given in <ref type="figure" target="#fig_1">Fig. 2</ref>. Consider the 1D case where two cameras are separated by distance τ x . The 2D case can be derived similarly. First, an object is imaged at pixel u on camera 1 and u ′ on camera 2. The difference of the two images at pixel u, ∆I(u) = I 2 (u) − I 1 (u) in <ref type="figure" target="#fig_1">Fig. 2a</ref>, will be the difference caused by the view change (from I 1 (u) to I 2 (u ′ ) in <ref type="figure" target="#fig_1">Fig. 2b</ref>), plus the difference caused by the spatial change (from I 2 (u ′ ) to I 2 (u) in <ref type="figure" target="#fig_1">Fig. 2c</ref>). The view change is modeled by (∇ v ρ) x · τ x , which is how the BRDF varies with viewpoint multiplied by the view change amount. The spatial change is modeled by I u · τ x /(1 + βz), which is the image derivative multiplied by the change in image coordinates. Summing these two terms gives (8) <ref type="figure" target="#fig_1">(Fig. 2d)</ref>.</p><p>Compared with the work by Chandraker <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b4">6,</ref><ref type="bibr" target="#b5">7]</ref>, we note that since different system setups are considered, the parameterization of the total intensity change in (3) is different. We believe this parameterization is more intuitive, since it allows the above physical interpretation of the various terms in the total intensity change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multi-camera System</head><p>We now move on to consider the case of a light-field camera, which can be modeled by a multi-camera array. For a multi-camera array with m + 1 cameras, we can form m camera pairs using the central camera and each of the other cameras. Let the translations of each pair be τ 1 , τ 2 , ..., τ m and the corresponding image differences be  ∆I 1 , ∆I 2 , ..., ∆I m . Each pair will then have a stereo relation equation as in <ref type="bibr" target="#b6">(8)</ref>. We can stack all the equations and form a linear system as</p><formula xml:id="formula_8">           Iuτ 1 x + Ivτ 1 y τ 1 x τ 1 y ... Iuτ m x + Ivτ m y τ m x τ m y                       1 1 + βz (∇vρ)x (∇vρ)y            =            ∆I 1 ... ∆I m            . (9)</formula><p>Let B be the first matrix in <ref type="bibr" target="#b7">(9)</ref>. If B is full rank, given at least three pairs of cameras (four cameras in total), we would be able to solve for depth by a traditional least squares approach. Unfortunately, it can easily be seen that B is rank deficient, since the first column is a linear combination of the other two columns. This should not be surprising, since we only have two degrees of freedom for translations in two directions, so the matrix is at most rank two. Adding more cameras does not add more degrees of freedom. 1 However, adding more cameras does increase the robustness of the system, as shown later in <ref type="figure" target="#fig_2">Fig. 3a</ref>. Finally, although directly solving for depth is not achievable, we can still obtain a relation between depth and normals for a specific form of the BRDF, which we derive next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">BRDF-Invariant Derivation</head><p>We first briefly discuss the BRDF model we adopt (Sec. 4.1), and then show how we can derive a BRDF invariant equation relating depth and normals (Sec. 4.2). A comparison between our work and the work by Chandraker <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b4">6,</ref><ref type="bibr" target="#b5">7]</ref> is given in Sec. 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">BRDF model</head><p>It is commonly assumed that a BRDF contains a sum of "lobes" (certain preferred directions). Thus, the BRDF can be represented as a sum of univariate functions <ref type="bibr" target="#b6">[8]</ref>:</p><formula xml:id="formula_9">ρ(x, n, s, v) = K i=1 f x,i (n ⊤α i ) · (n ⊤ŝ )<label>(10)</label></formula><p>wheren is the normalized normal,α i are some directions, f x,i are some functions at position x, and K is the number of lobes. For the rest of the paper, when we useŵ to represent a vector w, it means it is the normalized form of w. The model we adopted is similar to the Blinn-Phong BRDF; for each of the RGB channels, the BRDF is 1-lobe that depends on the half-angle directionĥ = (ŝ+v)/ ŝ+v , plus a diffuse term which is independent of viewpoint,</p><formula xml:id="formula_10">ρ c (x, n, s, v) = ρ c d (x, n, s)+ρ c s (x,n ⊤ĥ ) ·(n ⊤ŝ ), c = r, g, b<label>(11)</label></formula><p>For the work by Tao et al. <ref type="bibr" target="#b24">[26]</ref>, it is assumed that the BRDFs of different views will lie on a line not passing the origin in the RGB space. Taking a look at, e.g., the BRDFs in <ref type="figure">Fig. 5</ref>, we can see that the BRDFs do not necessarily lie on a line, and passing the origin is possible for the materials whose diffuse components are not significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">BRDF invariant</head><p>To derive the invariant, we first derive two expressions for ∇ v ρ, one using depth z and the other using normals n. Combining these two expressions gives an equation which contains only z and n as unknowns and is invariant to the BRDF. We then show how to solve it for shape.</p><p>a. Expression using depth Continuing from (9), let γ γ γ = B + (∆I), where B + is the Moore-Penrose pseudoinverse of B. Then (9) has an infinite number of solutions,</p><formula xml:id="formula_11">   1 1 + βz (∇ v ρ) x (∇ v ρ) y    = γ γ γ + λ   1 −I u −I v  <label>(12)</label></formula><p>with λ ∈ R. From the first row λ can be expressed as</p><formula xml:id="formula_12">λ = 1 1 + βz − γ 1<label>(13)</label></formula><p>Thus, we can express (∇ v ρ) y /(∇ v ρ) x , which can be seen as the direction of the BRDF gradient, as a function of z,</p><formula xml:id="formula_13">(∇ v ρ) y (∇ v ρ) x = γ 3 − λI v γ 2 − λI u = γ 3 − ( 1 1+βz − γ 1 )I v γ 2 − ( 1 1+βz − γ 1 )I u<label>(14)</label></formula><p>b. Expression using normals Next, using the BRDF model in <ref type="bibr" target="#b9">(11)</ref>, in Appendix A we show that</p><formula xml:id="formula_14">∇ v ρ = ρ ′ sn ⊤ H ŝ +v (1 + βz) u 2 + v 2 + f 2<label>(15)</label></formula><p>where ρ ′ s = ∂ρ s /∂(n ⊤ĥ ) is an unknown function, and H ≡</p><formula xml:id="formula_15">(I −ĥĥ ⊤ )(I −vv ⊤ ) is a known 3 × 3 matrix.</formula><p>Since ρ ′ s is unknown, we cannot express ∇ v ρ as a function of n and z only. However, if we take the ratio between the y-component and the x-component of ∇ v ρ corresponding to the direction of the gradient, all unknowns except n will disappear,</p><formula xml:id="formula_16">(∇ v ρ) y (∇ v ρ) x = (n ⊤ H) y (n ⊤ H) x = n x H 12 + n y H 22 − H 32 n x H 11 + n y H 21 − H 31<label>(16)</label></formula><p>c. Combining expressions Equating the right-hand sides of <ref type="formula" target="#formula_0">(16)</ref> and <ref type="formula" target="#formula_0">(14)</ref> for the direction of the gradient ∇ v ρ then gives</p><formula xml:id="formula_17">γ 3 − ( 1 1+βz − γ 1 )I v γ 2 − ( 1 1+βz − γ 1 )I u = n x H 12 + n y H 22 − H 32 n x H 11 + n y H 21 − H 31<label>(17)</label></formula><p>which is an equation of z and n only, since γ γ γ is known and H is known if s is known. Note that the spatially-varying BRDF dependent terms have been eliminated, and it is only possible for a single-lobe BRDF. Expanding (17) leads to solving a quasi-linear partial differential equation (PDE)</p><p>(κ 1 + κ 2 z)n x + (κ 3 + κ 4 z)n y + (κ 5 + κ 6 z) = 0 <ref type="bibr" target="#b16">(18)</ref> where κ 1 to κ 6 are constants specified in Appendix A. We call this the BRDF invariant relating depths and normals. Note that, in the case that ∇ v ρ is zero, γ 2 and γ 3 will be zero for most solvers (e.g., mldivide in Matlab). Using the formulas for κ in Appendix A, (18) just reduces to (γ 1 − 1) + (βγ 1 )z = 0, and z can be directly solved. This corresponds to the Lambertian case; the equation just stands for the photo-consistency, where the left hand side can be thought of as the intensity difference between different views. In the specular case, the same point in different views does not have the same intensity anymore; they differ by (∇ v ρ) ⊤ τ (3), which can be written as a function of n. That is where the first two normal terms in (18) come from.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion</head><p>Compared to the work of Chandraker <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b4">6,</ref><ref type="bibr" target="#b5">7]</ref>, we note that a similar BRDF invariant equation is derived. However, our derivation is in the light field setup and lends better physical intuition <ref type="figure" target="#fig_1">(Fig. 2)</ref>. Moreover, our resolution of the shape ambiguity is distinct and offers several advantages. To be specific, the work of Chandraker assumes a constant viewing direction over the image, which can generate one more equation when solving the linear system (9), so directly recovering depth is possible. However, we cannot adopt it under the light-field setup. Instead, we directly solve the PDE, using a polynomial shape prior introduced next (Sec. 5.1). Furthermore, a homogeneous BRDF is also assumed in <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b4">6,</ref><ref type="bibr" target="#b5">7</ref>] to obtain depth directly. Our solution, on the other hand, is capable of dealing with spatially-varying BRDFs since we solve the PDE instead, as shown in the following section. Finally, while <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b4">6,</ref><ref type="bibr" target="#b5">7]</ref> are very sensitive to noise, we achieve robustness through multiple virtual viewpoints provided by the light field <ref type="figure" target="#fig_2">(Fig. 3a)</ref> and the polynomial regularization, as shown in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Shape and Reflectance Estimation</head><p>Given the BRDF invariant equation derived in Sec. 4, we utilize it to solve for shape (Sec. 5.1) and reflectance (Sec. 5.2) in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Shape estimation</head><p>As shown in Appendix A, solving (18) mathematically requires initial conditions, so directly solving for depth is not possible. Several possible solutions can be used to address this problem. We adopt a polynomial regularization, similar to the approach proposed in <ref type="bibr" target="#b9">[11,</ref><ref type="bibr" target="#b30">32]</ref>. The basic idea is to represent z and n x ,n y as some shape parameters, so solving <ref type="bibr" target="#b16">(18)</ref> can be reduced to solving a system of quadratic equations in these parameters. Specifically, for an r × r image patch, we assume the depth can be represented by a quadratic function of the pixel coordinates u and v, z(u, v) = a 1 u 2 + a 2 v 2 + a 3 uv + a 4 u + a 5 v + a 6 (19)</p><p>where a 1 , a 2 , ..., a 6 are unknown parameters. We now want to express normals using these parameters as well. However, to compute n x = ∂z/∂x, we need to know the x-distance between the 3D points imaged on those two pixels, which is not given. Therefore, we cannot directly compute n x and n y . Instead, we first compute the normals in the image coordinate,</p><formula xml:id="formula_18">nu(u, v) = ∂z ∂u = 2a1u + a3v + a4 nv(u, v) = ∂z ∂v = 2a2v + a3u + a5<label>(20)</label></formula><p>In Appendix B we show that normals in the world coordinate n x are related to normals in the image coordinate n u by</p><formula xml:id="formula_19">nx = ∂z ∂x = nu 1 + β(3z − 2a6 − a4u − a5v)<label>(21)</label></formula><p>and n y is computed similarly. Thus, <ref type="bibr" target="#b16">(18)</ref> can be rewritten as (κ1 + κ2z)nu + (κ3 + κ4z)nv</p><formula xml:id="formula_20">+ (κ5 + κ6z) 1 + β(3z − 2a6 − a4u − a5v) = 0<label>(22)</label></formula><p>Plugging <ref type="formula" target="#formula_0">(19)</ref>- <ref type="bibr" target="#b18">(20)</ref> into <ref type="bibr" target="#b20">(22)</ref> results in r 2 quadratic equations in a 1 , ..., a 6 , one for each pixel in the patch,</p><formula xml:id="formula_21">a ⊤ 1 Mi a 1 = 0 i = 1, 2, ..., r 2<label>(23)</label></formula><p>where a = a 1 a 2 a 3 a 4 a 5 a 6 ⊤ and M i is a 7 × 7 matrix.We then apply standard Levenberg-Marquardt method to solve for the parameters. To avoid ambiguity we require the normal at one seed pixel to be specified; in practice we specify the nearest point and assume its normal is the −z direction. The shape parameters for other pixels in the image are then estimated accordingly. For spatial coherence we enforce neighboring pixels to have similar depths and normals. Our final optimization thus consists of a data term D that ensures the image patch satisfies the PDE, and a smoothness term S that ensures neighboring normals and depths (a 4 to a 6 ) are similar,</p><formula xml:id="formula_22">a = arg min a i D 2 i + η j S 2 j<label>(24)</label></formula><p>where D i is computed by the left hand side of (23), and</p><formula xml:id="formula_23">Sj = aj − a 0 j j = 4, 5, 6<label>(25)</label></formula><p>where a 0 j is the average a j of its 4-neighbors that have already been computed, and η is the weight, which is 10 3 in our experiment.</p><p>Finally, note that although theoretically, three cameras are enough to solve for depth, in practice more cameras will increase the robustness against noise, as shown in <ref type="figure" target="#fig_2">Fig. 3a</ref>. Indeed, the multiple views provided by light-field cameras are essential to obtaining high-quality results. More cameras, along with the polynomial regularizer introduced above, helps to increase the system robustness compared to previous work <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b4">6,</ref><ref type="bibr" target="#b5">7]</ref>. Next, in <ref type="figure" target="#fig_2">Fig. 3b</ref>, we further test the effect of different camera baselines. We vary the baseline from 10 −3 to 1 cm, and report their depth errors on a synthetic sphere. As can be seen, our method achieves best performance when the baseline is between 0.01 cm to 0.5 cm. When the baseline is too small, there is little difference between adjacent images; when the baseline is too large, the differential motion assumption fails. Note that the effective baseline for Lytro Illum changes with focal length and focus distance, and is in the order of 0.01 to 0.1 cm, so our method is well suited to the practical range of its baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Reflectance estimation</head><p>After the shape is recovered, reflectance can also be recovered, similar to <ref type="bibr" target="#b3">[5]</ref>. First, (∇ v ρ) x and (∇ v ρ) y can be obtained using <ref type="bibr" target="#b10">(12)</ref>. Then <ref type="bibr" target="#b13">(15)</ref> can be used to recover ρ ′ s . Specifically, let k ≡ ŝ +v (1 + βz) u 2 + v 2 + f 2 , then</p><formula xml:id="formula_24">ρ ′ s = k(∇ v ρ) x /(n ⊤ H) x = k(∇ v ρ) y /(n ⊤ H) y<label>(26)</label></formula><p>In practice we just take the average of the two expressions to obtain ρ ′ s . A final integration overn ⊤ĥ then suffices to generate ρ s . Finally, subtracting ρ s from the original image gives the diffuse component <ref type="bibr" target="#b9">(11)</ref>. Note that although we assumed a 1-lobe BRDF to obtain the depth information, if shape is already known, then ρ can actually be 2-lobe since two equations are given by the xand y-component of (15). Specifically, from (15) we have</p><formula xml:id="formula_25">(∇ v ρ) x = ρ ′ s,1 m x + ρ ′ s,2 q x (∇ v ρ) y = ρ ′ s,1 m y + ρ ′ s,2 q y<label>(27)</label></formula><p>where ρ ′ s,1 , ρ ′ s,2 are (unknown) derivatives of the two BRDF lobes, and other variables are constants. Since we have two unknowns and two equations, we can solve for the BRDFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>We validate our algorithm using extensive synthetic scenes as well as real-world scenes. We compare our results with two methods by Tao et al., one using point and line consistency to deal with specularity (PLC) <ref type="bibr" target="#b24">[26]</ref> and one that handles diffuse only but includes the shading cue (SDC) <ref type="bibr" target="#b23">[25]</ref>. We also compare with the phase-shift method by Jeon et al. (PSSM) <ref type="bibr" target="#b11">[13]</ref> and results by Lytro Illum. Since the pixel clustering method by Tao et al. <ref type="bibr" target="#b25">[27]</ref> has been superseded by <ref type="bibr" target="#b24">[26]</ref>, we only include the comparison with <ref type="bibr" target="#b24">[26]</ref> here.</p><p>Synthetic scenes For synthetic scenes, we use a 7 × 7 camera array of 30 mm focal length. We test on a sphere of radius 10 cm positioned at 30 cm away from the cameras. <ref type="figure">Figure 5</ref> shows example results on materials in the MERL BRDF dataset <ref type="bibr" target="#b16">[18]</ref> on the sphere. Note that spheres are not a polynomial shape (z = r 2 − x 2 − y 2 ). We provide a summarized figure showing depth errors on different material types in <ref type="figure" target="#fig_3">Fig. 4</ref>. It can be seen that our method achieves good results on most material types except fabric, which does not follow the half-angle assumption. However, for all the material types, we still outperform the other state-ofthe-art methods. For PLC <ref type="bibr" target="#b24">[26]</ref>, although it tries to handle glossy surfaces, the line consistency they adopted is not able to handle general BRDFs. For SDC <ref type="bibr" target="#b23">[25]</ref> and PSSM <ref type="bibr" target="#b11">[13]</ref>, they are designed for Lambertian scenes and perform poorly on glossy objects. Finally, to evaluate our reflectance reconstruction we compute the ground truth BRDF curves by averaging BRDFs for all given half-angles. It can be seen that our curves look very similar to the ground truth BRDFs.</p><p>Next, we test our method on a sphere with a spatiallyvarying BRDF, where we linearly blend two materials (alum bronze and green metal) from left to right <ref type="figure" target="#fig_4">(Fig. 6)</ref>. In addition to recovering depth, we also compute the BRDFs for each column in the image, and show results for two sample columns and a relighting example, where we accurately produce results similar to the ground truth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Real-world results</head><p>We show results taken with the Lytro Illum in Figs. 1, 7 and 8. In <ref type="figure">Fig. 7</ref> we show reconstructed shapes and BRDFs of objects with homogeneous BRDFs. For objects that are symmetric, we obtain the ground truth by surface of revolution using the outline curve in the image, and compute the RMSE for each method. It can be seen that our method realistically reconstructs the shape, and achieves the lowest RMSE when ground truth is available. The recovered BRDFs also seem qualitatively correct, e.g., for the bowling pin its BRDF has a very sharp specularity. In <ref type="figure">Figs. 1 and 8</ref> we show results of objects with spatially-varying BRDFs. Again, it can be seen that other methods have artifacts or produce distorted shapes around the specular regions, while our method realistically reproduces the shape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>In this paper, we propose a novel BRDF-invariant shape and reflectance estimation method for glossy surfaces from light-field cameras. By utilizing the differential motion theory, we show that direct shape recovery is not possible for general BRDFs. However, for a 1-lobe BRDF that depends only on half-angle, we derive an SVBRDF-invariant equation relating depth and normals. Using a locally polynomial prior on the surface, shape can be estimated using this equation. Reflectance is then also recovered using our framework. Experiments validate our algorithm on most material types in the MERL dataset, as well as real-world data taken with the Lytro Illum. Spatially-varying BRDFs can also be handled by our method, while this is not possible using <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b4">6,</ref><ref type="bibr" target="#b5">7]</ref>. Finally, since we showed that there is actually inherent ambiguity in light-fields for unknown shape and general multi-lobe reflectance, future work includes deriving its ambiguity-space, i.e., what is the precise set of shapes and reflectances that generates the same light-field.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Derivation of ∇vρ</head><p>Suppose ρ = (ρ d (x, n, s) + ρs(x,n ⊤ĥ )) · (n ⊤ŝ ), wheren ⊤ŝ is the cosine falloff term. Sincen ⊤ŝ is independent of v, it just carries over the entire derivation and will be omitted in what follows. By the chain rule we have ∇vρ = ∂ρs ∂(n ⊤ĥ )</p><formula xml:id="formula_26">∂(n ⊤ĥ ) ∂v = ρ ′ s ∂(n ⊤ĥ ) ∂v = ρ ′ s ∂(n ⊤ĥ ) ∂ĥ ∂ĥ ∂v = ρ ′ sn ⊤ ∂ĥ ∂v = ρ ′ sn ⊤ ∂ĥ ∂h ∂h ∂v ∂v ∂v<label>(28)</label></formula><p>Recall that for a vector w, ∂ŵ/∂w = (I −ŵŵ ⊤ )/ w . Then</p><formula xml:id="formula_27">∂ĥ ∂h = I −ĥĥ ⊤ ŝ +v , ∂v ∂v = I −vv ⊤ v<label>(29)</label></formula><p>And</p><formula xml:id="formula_28">∂h ∂v = ∂(ŝ+v) ∂v = I<label>(30)</label></formula><p>So <ref type="formula" target="#formula_1">(28)</ref> can be simplified as</p><formula xml:id="formula_29">∇vρ = ρ ′ sn ⊤ I −ĥĥ ⊤ ŝ +v · I · I −vv ⊤ v<label>(31)</label></formula><p>Let H ≡ (I −ĥĥ ⊤ )(I −vv ⊤ ), and note that v = (0, 0, −f ) ⊤ − (x, y, z) ⊤ = x 2 + y 2 + (z + f ) 2</p><formula xml:id="formula_30">= (1 + βz) u 2 + v 2 + f 2<label>(32)</label></formula><p>then <ref type="formula" target="#formula_0">(31)</ref> becomes (d) Our BRDF (e) PLC <ref type="bibr" target="#b24">[26]</ref> (f) SDC <ref type="bibr" target="#b23">[25]</ref> (g) PSSM <ref type="bibr" target="#b11">[13]</ref> (h) Lytro Illum <ref type="figure">Figure 7</ref>: Shape and reflectance estimation results on real data with homogeneous BRDFs. The intensities of the input images are adjusted for better contrast. It can be seen that our method realistically reconstructs the shapes, and also achieves the lowest RMSE when ground truth is available. The recovered BRDFs also look qualitatively correct, e.g., the bowling pin has a very sharp specularity.</p><formula xml:id="formula_31">∇vρ = ρ ′ sn ⊤ H ŝ +v v = ρ ′ sn ⊤ H ŝ +v (1 + βz) u 2 + v 2 + f 2<label>(</label></formula><p>RMSE=0.0004 RMSE=0.0055 RMSE=0.0076 RMSE=0.0022 RMSE=0.0032 (a) Input image (b) Our depth (c) PLC <ref type="bibr" target="#b24">[26]</ref> (d) SDC <ref type="bibr" target="#b23">[25]</ref> (e) PSSM <ref type="bibr" target="#b11">[13]</ref> (f) Lytro Illum <ref type="figure">Figure 8</ref>: Shape estimation results on real data with spatially-varying BRDFs. It can be seen that our method realistically reconstructs the shapes, while other methods generate artifacts around the specular regions.</p><p>which is the equation we used in <ref type="bibr" target="#b13">(15)</ref>. The following procedure is described in the main text. Finally, after expanding <ref type="formula" target="#formula_0">(17)</ref> </p><p>where c1, c2, c3 are constants, and require some initial condition to be uniquely identified. Note that κ's are different for each pixel, which makes the problem even harder. Therefore, directly obtaining shape is not possible, and we refer to a polynomial shape prior, as introduced in the main text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Derivation of nx</head><p>Since u = x/(1 + βz) by (1), we can multiply both sides in <ref type="bibr" target="#b17">(19)</ref> by (1 + βz) 2 and get z(1 + βz) 2 = a 1 x 2 + a 2 y 2 + a 3 xy + a 4 x(1 + βz) + a 5 y(1 + βz) + a 6 (1 + βz) 2</p><p>Taking derivatives of both sides and after some rearrangement, we can write the normal nx as, ∂z ∂x = 2a 1 x + a 3 y + a 4 (1 + βz) (1 + βz) 2 + 2βz(1 + βz) − a 4 βx − a 5 βy − 2βa 6 (1 + βz) = 2a 1 u + a 3 v + a 4 1 + 3βz − a 4 βu − a 5 βv − 2βa 6 = nu 1 + 3βz − a 4 βu − a 5 βv − 2βa <ref type="bibr" target="#b4">6</ref> (37)</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Optical flow for glossy surfaces. (a) The difference between two images at the same pixel position, is (b) the view change plus (c) the spatial change. (d) Summing these two changes gives the overall change.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>(a) Depth error vs. number of cameras (virtual viewpoints) used. We add Gaussian noise of variance 10 −4 on a synthetic sphere and test the performance when different numbers of cameras are used. As the number of cameras increases, the system becomes more robust. (b) Depth error vs. camera baseline. Our method performs the best when the baseline is between 0.01 cm to about 0.5 cm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Depth errors on different material types. Our method achieves good results on all materials except fabric. For all material types, we outperform the other methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Shape and reflectance estimation results on a spatially-varying example in the MERL dataset. (a) Two materials, alum bronze and green metal, are blended linearly from left to right. We reconstruct (b) the depth and (c)(d) the BRDFs for each column, where two examples are shown at the red and green points specified in (a). Finally, we show a relighting example in (e). The error percentage compared to (f) the ground truth is 3.20%. Acknowledgement This work was funded in part by a Berkeley Fellowship, ONR grant N00014152013, Draper Lab, a Google Research Award, Intel Research grant, and support by Nokia, Samsung and Sony to the UC San Diego Center for Visual Computing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>, the κ's in<ref type="bibr" target="#b16">(18)</ref> areκ 1 = (γ 2 + γ 1 Iu − Iu)H 12 − (γ 3 + γ 1 Iv − Iv)H 11 κ 2 = β(γ 2 + γ 1 Iu)H 12 − β(γ 3 + γ 1 Iv)H 11 κ 3 = (γ 2 + γ 1 Iu − Iu)H 22 − (γ 3 + γ 1 Iv − Iv)H 21 κ 4 = β(γ 2 + γ 1 Iu)H 22 − β(γ 3 + γ 1 Iv)H 21 κ 5 = −(γ 2 + γ 1 Iu − Iu)H 32 + (γ 3 + γ 1 Iv − Iv)H 31 κ 6 = −β(γ 2 + γ 1 Iu)H 32 + β(γ 3 + γ 1 Iv)H 31 (34)The mathematical solution to the PDE (18) is a parametric curve defined by z(s) = −κ 5 /κ 6 + c 1 e −κ 6 s x(s) = κ 1 s + κ 2 − (c 1 /κ 6 )e −κ 6 s − (κ 5 /κ 6 )s + c 2 y(s) = κ 3 s + κ 4 − (c 1 /κ 6 )e −κ 6 s − (κ 5 /κ 6 )s + c 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Figure 5: Shape and reflectance estimation results on example materials in the MERL dataset. For shape estimation, the upper-left shows the recovered depth, while the lower-right shows the error percentage (hotter color means larger error). For reflectance estimation, we show the recovered BRDF compared to ground truth curves.(d) BRDF at green point (e) Our relit image (f) GT relit image</figDesc><table>violet acrylic 

n T h 

0.85 
0.9 
0.95 
1 

BRDF 

0 

0.05 

0.1 

0.15 

0.2 

0.25 

0.3 

Recovered r 
Recovered g 
Recovered b 
True r 
True g 
True b 

gold metal 

n 
T h 

0.9 
0.92 
0.94 
0.96 
0.98 
1 

BRDF 

0 

0.1 

0.2 

0.3 

0.4 

0.5 

Recovered r 
Recovered g 
Recovered b 
True r 
True g 
True b 

red phenolic 

(a) Input image 
(b) Our depth 

n T h 

0.95 
0.96 
0.97 
0.98 
0.99 
1 

BRDF 

0 

0.05 

0.1 

0.15 

0.2 

0.25 

0.3 

Recovered r 
Recovered g 
Recovered b 
True r 
True g 
True b 

(c) Our BRDF 
(d) PLC [26] 
(e) SDC [25] 
(f) PSSM [13] 

(a) Input image 
(b) Our depth 

0.8 
0.82 
0.84 
0.86 
0.88 
0.9 
0.92 
0.94 
0.96 
0.005 

0.01 

0.015 

0.02 

0.025 

0.03 

0.035 

n 

T 

h 

BRDF 

Recovered r 
Recovered g 
Recovered b 
True r 
True g 
True b 

(c) BRDF at red point 

0.8 
0.85 
0.9 
0.95 
0 

0.01 

0.02 

0.03 

0.04 

0.05 

0.06 

0.07 

0.08 

0.09 

n T h 

BRDF 

Recovered r 
Recovered g 
Recovered b 
True r 
True g 
True b 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>RMSE=0.0188 RMSE=0.0267 RMSE=0.0166 RMSE=0.0407</figDesc><table>33) 
RMSE=0.0132 

n T h 

0.8 
0.85 
0.9 
0.95 
1 

BRDF 

0.02 

0.04 

0.06 

0.08 

0.1 

0.12 

0.14 

0.16 

0.18 

0.2 

Recovered r 
Recovered g 
Recovered b 

RMSE=0.0160 

n T h 

0.4 
0.5 
0.6 
0.7 
0.8 
0.9 
1 

BRDF 

0 

0.1 

0.2 

0.3 

0.4 

0.5 

0.6 

0.7 

0.8 

0.9 

Recovered r 
Recovered g 
Recovered b 

RMSE=0.0209 RMSE=0.0331 RMSE=0.0312 RMSE=0.0528 

(a) Input (b) Ground truth (c) Our depth 

n T h 

0.94 
0.95 
0.96 
0.97 
0.98 
0.99 
1 

BRDF 

0.12 

0.13 

0.14 

0.15 

0.16 

0.17 

0.18 

0.19 

0.2 

0.21 

Recovered r 
Recovered g 
Recovered b 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that, adding translations in the z direction does not help either, since moving the camera along the viewing direction of a pixel does not change its pixel intensity (v/ v does not change), so ∇vρ · v = 0. Thus, (∇vρ)z is just a linear combination of (∇vρ)x and (∇vρ)y, and adding it does not introduce any new degree of freedom.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Photometric stereo with non-parametric and spatially-varying reflectance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Alldrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zickler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Color constancy, intrinsic images, and shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Shape, albedo, and illumination from a single image of an unknown object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On shape and material recovery from motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">What camera motion reveals about shape with unknown BRDF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The information available to a moving observer on shape with unknown</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">isotropic BRDFs. IEEE Transactions on Pattern Analysis Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">What an image reveals about material reflectance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Light field stereo matching using bilateral statistics of surface cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Numerical methods for shape-from-shading: A new survey with benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Durou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Falcone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sagona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="43" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Polynomial shape from shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Jepson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The lumigraph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gortler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grzeszczuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Siggraph</title>
		<meeting>Siggraph</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Accurate depth map estimation from a lenslet light field camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-G</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Shape estimation in natural illumination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Scene reconstruction from high spatio-angular resolution light fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pritch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">73</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Inverse shade trees for non-parametric material representation and editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ben-Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Decoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Matusik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="735" to="745" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Light field rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Siggraph</title>
		<meeting>Siggraph</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A datadriven reflectance model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Matusik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcmillan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Experimental analysis of BRDF models. Rendering Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ngan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Matusik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Directional statistics-based reflectance model for isotropic bidirectional reflectance distribution functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nishino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lombardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Optical Society of America A</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="18" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Shape and reflectance from natural illumination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Oxholm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nishino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Single lens 3D-camera with extended depth-of-field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Perwass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wietzke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IS&amp;T/SPIE Electronic Imaging</title>
		<meeting>IS&amp;T/SPIE Electronic Imaging</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Passive reflectometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Romeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Vasilyev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zickler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Blind reflectometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Romeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zickler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Depth from shading, defocus, and correspondence using light-field angular coherence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Depth estimation and specular removal for glossy surfaces using point and line consistency with lightfield cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Depth estimation for glossy surfaces with light-field cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision Workshops</title>
		<meeting>the European Conference on Computer Vision Workshops</meeting>
		<imprint>
			<publisher>ECCVW</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Surface identification using the dichromatic reflection model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tominaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="658" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Occlusionaware depth estimation using light-field cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Depth estimation with occlusion modeling using light-field cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Globally consistent depth labeling of 4D light fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goldluecke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">From shading to local shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gortler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zickler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Shape-fromshading: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-S</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Cryer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="690" to="706" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
