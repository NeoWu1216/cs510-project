<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ordinal Regression with Multiple Output CNN for Age Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenxing</forename><surname>Niu</surname></persName>
							<email>zhenxingniu@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Xidian University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xidian University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Wang</surname></persName>
							<email>lewang@mail.xjtu.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Jiaotong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinbo</forename><surname>Gao</surname></persName>
							<email>xinbogao@mail.xidian.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Xidian University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Hua</surname></persName>
							<email>ganghua@gmail.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Ordinal Regression with Multiple Output CNN for Age Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To address the non-stationary property of aging patterns, age estimation can be cast as an ordinal regression problem. However, the processes of extracting features and learning a regression model are often separated and optimized independently in previous work. In this paper, we propose an End-to-End learning approach to address ordinal regression problems using deep Convolutional Neural Network, which could simultaneously conduct feature learning and regression modeling. In particular, an ordinal regression problem is transformed into a series of binary classification sub-problems. And we propose a multiple output CNN learning algorithm to collectively solve these classification sub-problems, so that the correlation between these tasks could be explored. In addition, we publish an Asian Face Age Dataset (AFAD) containing more than 160K facial images with precise age ground-truths, which is the largest public age dataset to date. To the best of our knowledge, this is the first work to address ordinal regression problems by using CNN, and achieves the state-of-the-art performance on both the MORPH and AFAD datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Human age estimation from face images remains to be an active research topic, which has many applications, such as demographics analysis, commercial user management, visual surveillance <ref type="bibr" target="#b20">[22,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b1">3]</ref>, and even aging progression <ref type="bibr" target="#b26">[28]</ref>. In previous methods, age estimation is often cast as a multi-class classification <ref type="bibr" target="#b10">[12]</ref> <ref type="bibr" target="#b13">[15]</ref> or a metric regression problem <ref type="bibr" target="#b9">[11]</ref> <ref type="bibr" target="#b13">[15]</ref> <ref type="bibr" target="#b12">[14]</ref>. In a multi-class classification problem, the class labels are assumed to be independent to one another. However, the age labels have a strong ordinal relationship since they form a well-ordered set, which is not exploited in these multi-class classification methods.</p><p>On the other hand, metric regression approaches treat the age labels as numerical values to utilize such ordinal information for age estimation. However, the human face matures in different ways depending on the person's age <ref type="bibr" target="#b23">[25]</ref>.</p><p>For example, facial aging effects appear as changes in the shape of the face during childhood and changes in skin texture during adulthood. This property makes the random process formed by the aging patterns non-stationary in general. As manifested in <ref type="bibr" target="#b4">[6]</ref>, learning non-stationary kernels for a regression problem is usually difficult since it will easily cause over-fitting in the training process.</p><p>Due to the fact that facial aging process is a nonstationary process, one reliable information we can use would be the relative order among the age labels in addition to their exact values. And hence the age estimation is cast as a ordinal regression problem <ref type="bibr" target="#b2">[4]</ref> <ref type="bibr" target="#b4">[6]</ref>[32] <ref type="bibr" target="#b18">[20]</ref>. For instance, Cao et al. <ref type="bibr" target="#b2">[4]</ref> formulated age estimation as a ranking problem and proposed a novel method based on Rank-SVM <ref type="bibr" target="#b15">[17]</ref>.</p><p>Recently, to directly utilize the well-studied classification algorithms, the ordinal regression problem is transformed into a series of simpler binary classification subproblems <ref type="bibr" target="#b8">[10]</ref> <ref type="bibr" target="#b19">[21]</ref>. For example, a reduction framework is proposed in <ref type="bibr" target="#b19">[21]</ref>. For each rank k ∈ {1, 2, · · · , K − 1} a binary classifier is trained according to whether the rank of a sample is larger than k. Then, the rank of a sample is predicted based on the classification results of the K −1 binary classifiers on this sample. In <ref type="bibr" target="#b19">[21]</ref>, the well-tuned SVM classification algorithm is directly utilized to train those binary classifiers. A benefit of this kind of methods is that new generalization bounds for ordinal regression can be easily derived from known bounds for binary classification.</p><p>Inspired by it, we also transform ordinal regression as a series of binary classification sub-problems in this paper. In particular, the Convolutional Neural Network (CNN) is used to solve those binary classification sub-problems. Moreover, our CNN has multiple output layers where each output layer corresponds to a binary classification task, called Multiple Output CNN in this paper. Therefore, all the binary classifiers can be jointly trained in such a CNN. Since all the tasks share the same mid-level representations in the CNN, the correlation among distinct tasks could be explored, which is beneficial to improving the finial performance.</p><p>On the other hand, for either the metric regression based or the ordinal regression based approaches, the processes of extracting features and learning a regression model is separated and optimized independently. The most successful hand-crafted features for age estimation is the Bioinspired Features (BIFs) <ref type="bibr" target="#b13">[15]</ref>. Nevertheless, due to the unclear mechanism of how humane perceives the different aging pattern, it is still difficult to design good features for age estimation. On the contrary, in our approach we can conduct an End-to-End learning with CNN for age estimation, which could simultaneously optimize feature learning and regression modeling. As a result, we can automatically learn better features from facial images, and avoid directly designing hand-crafted features.</p><p>At last, the lack of a large scale age dataset is always a barrier for pushing the progress of research on age estimation. And most previous algorithmic evaluations were performed on relatively small datasets, mainly due to the difficulties in collecting a large dataset with precise human age ground-truths. The most popular public age datasets include FG-NET <ref type="bibr" target="#b0">[1]</ref> (1002 face images), MORPH I (1690 face images), and MORPH II <ref type="bibr" target="#b24">[26]</ref> (55, 608 face images).</p><p>Even for the largest dataset MORPH II, its ethnic is very unbalanced, i.e., more than 96% faces are African and European, but less than 1% faces from Asian. Thus, the performance of previous methods for age estimation on Asian faces is still unknown. Besides, a large scale age dataset is essential for introducing deep learning algorithm such as CNN to age estimation. In this paper, we publish a new age dataset called Asian Face Age Dataset (AFAD), which includes more than 160K Asian facial images and age labels. Until now, this is the largest public age dataset. Briefly, our contributions are:</p><p>1. We propose to address ordinal regression problems using End-to-End deep learning methods.</p><p>2. We apply it to the task of age estimation, and achieve state-of-the-art results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>A new age dataset is released to the community for age estimation, which is the largest public dataset to date.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Age estimation: Most existing methods estimate the age of face image by two steps: local feature extraction and metric regression (or multi-class classification). Due to that geometry and texture features are helpful to distinguish baby, adult, and senior, many methods were proposed based on the AAM model <ref type="bibr" target="#b6">[8]</ref> since it is a natural tool to simultaneously model the shape and texture of facial images <ref type="bibr" target="#b17">[19]</ref> <ref type="bibr" target="#b10">[12]</ref>. The most successful hand-crafted features for age estimation is the Bio-inspired Features (BIFs) <ref type="bibr" target="#b13">[15]</ref>. On the other hand, much attention were paid on the second step: age classification or regression based on these features. Fu and Huang <ref type="bibr" target="#b9">[11]</ref> applied discriminative manifold learning and quadratic regression to age estimation. Guo et al. introduced many regression methods to predict the age of face image, such as SVR <ref type="bibr" target="#b13">[15]</ref>, PLS <ref type="bibr" target="#b11">[13]</ref> and CCA <ref type="bibr" target="#b12">[14]</ref>.</p><p>Recently, to better handle the non-stationary property of the aging process, ordinal regression is employed for age estimation. Yang et al. <ref type="bibr" target="#b30">[32]</ref> employ the RankBoost algorithm, which is a single hyperplane ranker in the feature space, for age estimation. Chang et al. <ref type="bibr" target="#b3">[5]</ref> employ the parallel hyperplanes model OR-SVM <ref type="bibr" target="#b19">[21]</ref> for age estimation, and further extended it to a more flexible scenario, i.e., several possibly non-parallel hyperplanes <ref type="bibr" target="#b4">[6]</ref>.</p><p>Although deep learning has achieved success on many computer vision tasks (e.g., image recognition, and object detection, etc), there are little works for introducing CNN to age estimation. Yi et al. <ref type="bibr" target="#b31">[33]</ref> firstly proposed to use CNN for age estimation. However, the proposed CNN is very shallow, which only contains 4 layers (i.e., 1 convolution + 1 pooling + 1 local layer + 1 full connection), and only a subset of MORPH II (about 10K facial images) is used to train the shallow CNN. Currently, in <ref type="bibr" target="#b29">[31]</ref> a relatively deeper CNN has been proposed for age estimation. However, in their work, CNN is only used to extract features, which is then fed to another regressor for the final age estimation. But our approach conducts End-to-End learning which could better unleash the discriminative power of the CNN.</p><p>Ordinal regression: Most ordinal regression algorithms are modified from well-known classification algorithms <ref type="bibr" target="#b14">[16]</ref>[9] <ref type="bibr" target="#b25">[27]</ref>. For instance, Herbrich et al. <ref type="bibr" target="#b14">[16]</ref> proposed a method of support vector learning for ordinal regression. In <ref type="bibr" target="#b7">[9]</ref>, the perceptron ranking (PRank) algorithm proposed by Crammer and Singer is to generalize the online perceptron algorithm with multiple thresholds for ordinal regression. In <ref type="bibr" target="#b25">[27]</ref>, Shashua and Levin proposed new support vector machine formulations to handle multiple thresholds.</p><p>On the other hand, to directly utilize the well-studied classification algorithms, the ordinal regression problem is transferred as a series of simpler binary classification subproblems [10] <ref type="bibr" target="#b19">[21]</ref>. For example, several decision trees are employed as binary classifiers for ordinal regression in <ref type="bibr" target="#b8">[10]</ref>. Recently, Li et al. <ref type="bibr" target="#b19">[21]</ref> proposed a framework to reduce an ordinal regression problem as a set of classification problems, and employ an SVM to solve the classification problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Ordinal Regression with CNN</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem Formulation</head><p>Let us assume that the i-th image is represented in an input space x i ∈ X , and there is an outcome space y i ∈ Y = {r 1 , r 2 , · · · , r K } with ordered ranks r K ≻ r K−1 ≻ · · · ≻ r 1 . The symbol ≻ denotes the ordering between different ranks. Given training samples D = {x i , y i } N i=1 , the ordinal regression is to find a mapping from images to ranks h(·) : X → Y such that -using a predefined cost c : X × Y → R -the risk functional R(h) is minimized.</p><p>In this paper, the cost matrix C <ref type="bibr" target="#b19">[21]</ref> is employed to measure the cost between predicted ranks and ground-truth ranks. In particular, C is a K × K matrix with C y,r being the cost of predicting an example (x, y) as rank r. Naturally, it is assumed that C y,y = 0 and C y,r &gt; 0 for r = y. Particularly, the absolute cost matrix, which is defined by C y,r = |y − r|, is a popular choice for general ordinal regression problems. Particularly, each age is often treated as a rank when applying ordinal regression algorithms to age estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Our Approach</head><p>To directly utilize the well-studied classification algorithms, we transform ordinal regression as a series of binary classification sub-problems in this paper. In particular, an ordinal regression problem with K ranks is transformed into K − 1 simpler binary classification sub-problems. For each rank r k ∈ {r 1 , r 2 , · · · , r K−1 }, a binary classifier is constructed to predict whether the rank of a sample y i is larger than r k . And then the rank of an unseen sample is predicted based on the classification results of the K − 1 binary classifiers on this sample.</p><p>Specifically, our approach contains three steps: (a) given the original training data D = {x i , y i } N i=1 , for the k-th binary classification sub-problem a specific training data is constructed as</p><formula xml:id="formula_0">D k = {x i , y k i , w k i } N i=1 , where the y k i ∈ {0,</formula><p>1} is a binary class label indicating whether the rank of the i-th sample y i is larger than r k as follows,</p><formula xml:id="formula_1">y k i = 1, if(y i &gt; r k ) 0, otherwise,<label>(1)</label></formula><p>And the w k i is the weight for the i-th example, i.e.,</p><formula xml:id="formula_2">w k i = |C y,k − C y,k+1 |.<label>(2)</label></formula><p>Since absolute cost matrix is adopted in our approach, we have ∀(i, k), w k i = 1. (b) the K − 1 binary classifiers are trained with their corresponding training data. It is noticed that we adopt one CNN to collectively implement these binary classifiers in our approach. In particular, our CNN has a multiple-output structure where each output corresponds to a binary classifier. Thus, these binary classifiers are jointly trained in such a CNN (refers to Sec.3.4); (c) the</p><formula xml:id="formula_3">Input: training data D = {xi, yi} N i=1 and testing images D ′ = {x ′ j } M j=1</formula><p>• Loop for k = 1, 2, · · · , K − 1:</p><formula xml:id="formula_4">-Build a distinct training data D k = {xi, y k i , w k i } N i=1</formula><p>for the k-th binary classification task according to Eq.1 and Eq.2.</p><p>• The learning of the multiple output CNN:</p><p>-The proposed multiple output CNN is trained with D k , (k = 1, 2, · · · , K − 1) according to the proposed learning algorithm (refers to Sec.3.4).</p><p>• For each testing image x ′ j ∈ D ′ : -Forward x ′ j to the trained CNN, and get the</p><formula xml:id="formula_5">K − 1 binary labels f k (x ′ j ) ∈ {0, 1}, (t = 1, 2, · · · , K − 1); -Predict its rank h(x ′ j ) with previous binary labels {f k (x ′ j )} K−1 k=1 according to Eq.3.</formula><p>Output: the predicted ranks for testing images rank for an unseen sample x ′ is predicted as follows,</p><formula xml:id="formula_6">{h(x ′ j )} M j=1 .</formula><formula xml:id="formula_7">h(x ′ ) = r q (3) q = 1 + K−1 k=1 f k (x ′ ), where f k (x ′ ) ∈ {0, 1}</formula><p>is the classification result of the k-th binary classifier for the sample x ′ (i.e., the k-th output of our multiple-output CNN). Ideally, these f k (x ′ ) should be consistent. However, ensuring the consistency in the training phase would significantly increase the training complexity. Hence we just apply Eq. 3 without explicitly ensuring the consistency among the different classifiers as in <ref type="bibr" target="#b19">[21]</ref>. The benefits of our approach is two-fold: (1) an ordinal regression problem is solved by using an End-to-End deep learning method, so that we can automatically learn better features from facial images and avoid directly designing hand-crafted features. (2) the K − 1 classification subproblems are treated as K − 1 tasks, which are simultaneously solved with our multiple output CNN. Due to that all the tasks share the same mid-level representations in such a CNN, the correlation of distinct tasks could be explored, which is beneficial to improve the finial performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Architecture of the Multiple Output CNN</head><p>As shown in <ref type="figure" target="#fig_1">Fig.2</ref>, our network consists of 3 convolutional, 3 local response normalization, and 2 max pooling layers followed by a fully connected layer with 80 neurons. At the input level, aligned face images of size 60 × 60 × 3 are fed to the network as input. It is noted that color face images are used in this paper, which is different from the gray images used in <ref type="bibr" target="#b29">[31]</ref>. At the first convolutional layer, 20 kernels of size 5 × 5 × 3 with stride of 1 pixels is applied on the input images. And after local response normalization and max pooling operations, the feature maps of size 28 × 28 × 20 are obtained.</p><p>The similar operations are conducted at the second and third convolutional layers with different kernel size (refers <ref type="figure" target="#fig_1">Fig.2 for the details)</ref>. And then a fully connected layer with 80 neurons is used to generate a mid-level representation.</p><p>After that, the network branches out K − 1 output layers, where each output layer contains 2 neurons and corresponds to a binary classification task. The k-th task is to predict whether the age of the i-th facial image is larger than the rank r k . For each task, the softmax normalized cross entropy loss is employed as loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Learning the Multiple Output CNN</head><p>For a CNN with single output, we have N samples</p><formula xml:id="formula_8">{x i , y i } N i=1</formula><p>, where x i denotes the i-th image and y i denotes the corresponding class label. For binary class label y i ∈ {0, 1}, it is reasonable to employ cross-entropy as the loss function,</p><formula xml:id="formula_9">E s = − 1 N N i=1 1{o i = y i }w i log(p(o i |x i , W )),<label>(4)</label></formula><p>where o i indicates the output of the CNN for the i-th image, w i indicates the weight of the i-th image, and W indicates the parameters of the entire CNN. Let W l denotes the parameters of the l-th layer in the CNN, and hence we have</p><formula xml:id="formula_10">W = {W 1 , W 2 , · · · , W L−1 }. The Boolean test 1{·} is 1</formula><p>if the inner condition is true, and 0 otherwise. For a CNN with K − 1 outputs, each output corresponds to a distinct task. All the T = K − 1 tasks (outputs) share the same N input images {x i } N i=1 , but have different class </p><formula xml:id="formula_11">labels {{y t i } N i=1 } T t=1 .</formula><p>Let λ t denotes the importance coefficient of the t-th task, the loss function of our multiple output CNN can be written as</p><formula xml:id="formula_12">E m = − 1 N N i=1 T t=1 λ t 1{o t i = y t i }w t i log(p(o t i |x i , W t )),<label>(5)</label></formula><p>where o t i indicates the output of the t-th task for the i-th image, w t i indicates the weight of the i-th image for the t-th task, and W t indicate the parameters of the t-th task.</p><p>According to the architecture of our multiple output CNN, each task has a distinct output layer, but all the tasks share the same intermediate layers. Thus, only the parameters of the output layers for distinct tasks W t L−1 are different from each other, i.e., we have</p><formula xml:id="formula_13">W L−1 = {W 1 L−1 , W 2 L−1 , · · · , W T L−1 }.</formula><p>And the parameters of previous layers are the same as one another for all the tasks, i.e., ∀l ∈ {1, · · · , (L − 2)}, W 1 l = W 2 l = · · · = W T l = W l .</p><p>As shown in <ref type="figure" target="#fig_2">Fig. 3</ref>, the learning procedure of the parameters for the output layer W L−1 = {W t L−1 } T t=1 is similar to that of a single output CNN. For the t-th task, if the  cross-entropy loss function is employed, the gradient of the weight from the j-th neuron in the layer L − 1 to the k-th neuron in the layer L (i.e., W t L−1 (j, k)) is computed as,</p><formula xml:id="formula_14">∂E m ∂W t L−1 (j, k) = δ t L (k)o(j) (6) δ t L (k) = p(o t (k)|x k , W t L−1 ) − 1{o t = y t },<label>(7)</label></formula><p>where o(j) is the output of the j-th neuron in the layer L−1, and δ t L (k) is the error of the k-th neuron in the output layer. The key is the learning procedure of the parameters for the penultimate layer. Since each neuron in the penultimate layer (i.e., layer L − 1) is connected to all the neurons in the output layer (i.e., layer L), the error of the penultimate layer δ L−1 is the integration of all the errors of output layers, as shown in <ref type="figure" target="#fig_2">Fig. 3</ref>. Specifically, the gradient of the weight from the i-th neuron in the layer L − 2 to the j-th neuron in the layer L − 1 (i.e., W L−2 (i, j)) is computed as,</p><formula xml:id="formula_15">∂E m ∂W L−2 (i, j) = δ L−1 (k)o(i) (8) δ L−1 (j) = T t=1 λ t k∈L t δ t L (k)W t L−1 (j, k) ,<label>(9)</label></formula><p>where o(i) is the output of i-th neuron in the layer L − 2, and δ L−1 (j) is the error of the j-th neuron in the layer L−1.</p><p>It is noticed that δ L−1 (j) is the weighted sum of the errors of output layers δ t L (k) over all the tasks, where the taskspecific weights are λ t , (t = 1, · · · , T ).</p><p>The learning procedure of the weights for previous layers (i.e., W L−3 , W L−4 , · · · ) is the same as the standard learning procedure of CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The AFAD Dataset</head><p>We tested our method on the MORPH II Dataset <ref type="bibr" target="#b24">[26]</ref>. This dataset contains 55, 608 face images, including 42, 589 African faces (77%), 10, 559 European faces (19%), 1, 769 Hispanic faces (3%), and only 154 Asian faces (0.2%). Compared to other datasets such as FG-NET <ref type="bibr" target="#b0">[1]</ref> (1002 face images) and MORPH I (1690 face images) dataset, the MORPH II dataset is the largest public dataset for age estimation. However, its ethnic is very unbalanced, i.e., less than 1% Asian faces. Thus, the performance of previous methods for age estimation on Asian faces is not sufficiently studied. Therefore, in this paper we collect a new dataset called Asian Face Age Dataset (AFAD) for age estimation, which includes more than 160k images and aging labels for Asian.</p><p>Specifically, we build this dataset by collecting facial images on a particular social network, i.e., RenRen Social Network <ref type="figure" target="#fig_1">(RSN) [2]</ref>. The RSN is a social network for students to connect with each other, upload photos, and make comments, etc. It is widely used by Asian students including middle school, high school, undergraduate, and graduate students. Even after leaving from school, some people still access their RSN account to connect with their old classmates. So, the age of the RSN user crosses a wide range from 15to more than 40-years old, which is beneficial to building a dataset with a wide aging range.</p><p>Moreover, as a user creating an account on the RSN, he/she is required to provide his/her Data-of-Birth (DoB),  <ref type="figure">Figure 6</ref>. The comparison of age estimation with CS metric on MORPH II dataset which is utilized by the RSN to recommend classmates or friends to the user. In addition, there is a special photo album (i.e., selfie album) for each user to upload his/her selfie photo to the RSN. Therefore, it is easy to get the groundtruth age of each selfie photo, i.e., the difference between the uploading date of the selfie photo and the user's DoB.</p><p>Since the selfie photos are noisy, e.g., some user may upload other photo as his/her selfie photo (e.g., uploading a photo of a celebrity, an object, or even a landmark) or upload a photo taken long time ago, thus we employ some workers to manually filter out noisy data. At last, we collect a dataset with 164, 432 well-labeled photos. It consist of 63, 680 photos for female as well as 100, 752 photos for male, and the ages range from 15 to 40. The distribution of photo counts for distinct ages are illustrated in <ref type="figure" target="#fig_5">Fig. 5</ref>. Some samples are shown in <ref type="figure" target="#fig_4">Fig. 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Preprocessing and Experimental Setting</head><p>The preprocessing of the facial image dataset is necessary. First, all images in the datasets are processed by a face detector <ref type="bibr" target="#b27">[29]</ref>. Then the facial landmarks of face images are localized by AAM <ref type="bibr" target="#b6">[8]</ref>, and all the facial images are aligned that the two eyeballs stay at the same image position for all faces. After that, a region with the size of 64 × 64 is cropped from the aligned facial images to make the nose point stays at the center of the cropped images. Moreover, before being fed to the CNN the images patches with the size of 60 × 60 are randomly cropped from the 64 × 64 regions, which slightly reduced overfitting when training our CNN.</p><p>Following the experimental setting in <ref type="bibr" target="#b4">[6]</ref>[7] <ref type="bibr" target="#b29">[31]</ref>, for both MORPH II and AFAD datasets, we randomly divide the whole dataset into two parts: one part (i.e., 80% of the whole data) is used for training, and the other one (i.e., 20% of the whole data) is used for testing. There is no overlap between the training and testing data. For statistical analysis, this procedure is done 100 times to evaluate the variance of MAE.</p><p>Besides, our algorithm is implemented based on Caffe <ref type="bibr" target="#b16">[18]</ref>, where a new layer is implemented according to Eq. 8 and Eq. 9. It is noted that the parameters for task importance λ t , (t = 1, · · · , T ) are set according to Eq. 11, which will be discussed in details at Section. 5.4.1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Age Estimation</head><p>In this section, the performance of age estimation is compared among several methods including metric regression based and ordinal regression based methods. For each kind of methods, they can be further categorized into two subcategories based on whether they used CNN learning algorithm.</p><p>The performance is measured by the Mean Absolute Error (MAE) metric and the Cumulative Score (CS). The MAE is calculated using the average of the absolute errors between the estimated result and the ground truth. The cu-mulative score is calculated as follows:</p><formula xml:id="formula_16">CS(n) = − K n K × 100%,<label>(10)</label></formula><p>where K is the total number of test images, and K n is the number of testing facial images whose absolute error between the estimated age and the ground truth age is not greater than n years.</p><p>In particular, we compare with the method in <ref type="bibr" target="#b13">[15]</ref> (denoted as 'BIFs + LSVR') which trains a linear Support Vector Regression (SVR) on the extracted BIFs features. For extracting BIFs features, we adopt the similar setting of 8 bands and 4 orientations, which produces features with more than 4000 dimensions. And the Liblinear software is used to train the linear SVR, where the L2-regularized L1loss is adopted.</p><p>We also compare with the method in <ref type="bibr" target="#b12">[14]</ref> (denoted as 'BIFs + CCA'). This is a multi-task learning approach which can simultaneously predict the age, gender, and race of a facial image. We evaluate this method to conduct the 3 tasks on the MORPH II dataset. Since the AFAD dataset only contains Asian faces, we evaluate this method to conduct only 2 tasks (i.e., age estimation and gender classification) on our AFAD dataset. From <ref type="table" target="#tab_0">Table 1</ref>, we can see that the 'BIFs + LSVR' achieves better performance than 'BIFs + CCA' on both datasets.</p><p>The third method <ref type="bibr" target="#b29">[31]</ref> (denoted as 'CNN + LSVR') is the first work to develop a relatively deeper CNN (i.e., 3 convolution + 2 pooling + full connection) to address the problem of age estimation. However, the proposed CNN is only used to extract features, which is then fed to a regressor (i.e., a linear SVR regressor) for final age prediction. Thus, it is not an End-to-End learning method. We have re-implemented the method in <ref type="bibr" target="#b29">[31]</ref>, but find out that its MAE on MORPH is 5.13 instead of 4.77 reported in <ref type="bibr" target="#b29">[31]</ref>, which may be due to some differences in details.</p><p>We also compare with two typical ordinal regression based methods, denoted as the 'BIFs + OR-SVM' <ref type="bibr" target="#b3">[5]</ref> and the 'BIFs + OHRank' <ref type="bibr" target="#b4">[6]</ref> respectively. Both of them transform an ordinal regression problem as a series of binary classification sub-problems, which are solved by using a linear SVM. It is noted that the hyperplanes are restricted to parallel to each other in <ref type="bibr" target="#b3">[5]</ref> but the OHRank <ref type="bibr" target="#b4">[6]</ref> allows some possibly non-parallel hyperplanes.</p><p>From <ref type="table" target="#tab_0">Table 1</ref>, we have the following conclusions: (1) the ordinal regression based methods outperform the metric regression based methods in general; (2) more importantly, the integration of ordinal regression and deep learning methods could boost the performance significantly. And our approach achieves the state-of-the-art on both MORPH II and AFAD datasets.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Comparing Metric and Ordinal Regression</head><p>Our approach presents an End-to-End CNN learning method, which transforms ordinal regression into a series of binary classification sub-problems. So it is still unclear which factor gives more contributions to the final improvement of performance. To take apart their distinctive contributions, we propose another baseline method, which only keeps the End-to-End CNN learning part and drops the part of transforming framework, i.e., it casts age estimation as a metric regression problem instead of an ordinal regression problem, and addresses the metric regression problem with an End-to-End CNN learning algorithm. For clarity, the baseline method is called Metric Regression with CNN (MR-CNN), while the proposed approach is called Ordinal Regression with CNN (OR-CNN).</p><p>For the MR-CNN, we need to solve a general metric regression problem with CNN, so we make a little modification on the architecture of our multiple-output CNN. Specifically, the fully connected layer is directly connected to one (the only one) output layer, and previous layers (i.e., three convolutional, local response normalization, max pooling layers) are kept. The output layer contains only one neurons, and its output indicates the regressed age for the input facial image. To train the MR-CNN, the L2-norm loss between ground-truth age and the regressed age is employed as the loss function. The architecture of the MR-CNN is shown in <ref type="figure" target="#fig_7">Fig.8</ref>.</p><p>The comparison between MR-CNN and OR-CNN is conducted on both the MORPH II and AFAD datasets. From <ref type="table" target="#tab_1">Table 2</ref>, we can find that the OR-CNN outperforms MR-CNN on the two datasets. In addition, we have done some statistical analysis for our OR-CNN model. In particular, the dataset is randomly split into training and  <ref type="formula" target="#formula_1">(1)</ref> it is necessary to cast age estimation as ordinal regression rather than a general metric regression problem. Moreover, from the comparison between the 'BIFs + OHRank' and our 'OR-CNN', it is clear that (2) the integration of ordinal regression and deep learning methods could significantly boost the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Task importance analysis</head><p>In our approach, each task has a specific parameter λ t , which indicates the relative importance among different tasks. These parameters will affect the error backward propagation for the network training (refers to Eq.9). In our approach, the importance parameters are set according to the reliability of classifiers corresponding to different tasks.</p><p>In particular, the k-th task corresponds to a binary classifier, which is trained to distinguish samples with rank larger than k from samples with rank smaller than k. Thus, for the k-th classifier, the number of samples with ranks nearby k, e.g., samples with rank {(k − 1), k, (k + 1)}, is more important than other samples for the training of k-th classifier. In other words, if more samples are with rank close to k, we could better train the corresponding classifier, and hence it is better to give a relatively larger importance to this task.</p><p>In practice, we obtain the distribution of sample number over their ranks, and propose to set the importance parameters according to this distribution, which is called dataspecific scheme. In other words, we set</p><formula xml:id="formula_17">λ t = √ N k K k=1 √ N k ,<label>(11)</label></formula><p>where N k is the number of samples with rank k, and N is the total number of samples.</p><p>On the contrary, we also evaluate the performance of our method when the importance parameters are set as a constant, which is called uniform scheme in this paper. From <ref type="table" target="#tab_2">Table 3</ref>, we can find out that the performance could be slightly improved by choosing task importance parameters according to data-specific distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">The color information</head><p>It is noticed that color face images are directly fed into our CNN, which is different from previous methods that the color images are first converted into gray before fed into CNN <ref type="bibr" target="#b29">[31]</ref> <ref type="bibr" target="#b31">[33]</ref>. In previous methods, it is believed that color information is unstable and useless for age estimation <ref type="bibr" target="#b31">[33]</ref>.</p><p>To investigate whether the color information is helpful for age estimation, in this section we try the case of converting color images into gray images. The performance is compared on both MORPH II and AFAD datasets. From <ref type="table" target="#tab_3">Table 4</ref>, we can find out that color information is helpful to improve performance of age estimation. It is possible that our convolutional neural network managed to extract useful information from color images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we have proposed to address ordinal regression problem by using End-to-End deep learning methods. In particular, an ordinal regression problem is transformed into a series of binary classification sub-problems, which are collectively solved with the proposed multiple output CNN learning algorithm. We apply it to the task of age estimation, and achieve better performance avoiding directly designing hand-crafted features. In addition, we publish an Asian Face Age Dataset (AFAD), which is the largest public age dataset until now. Our approach is evaluated on two large scale benchmark datasets and outperforms the stateof-the-art by a large margin. The promising performance of our approach demonstrates the potential of applying it towards other ordinal regression related applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Our approach for solving ordinal regression with the multiple output CNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>The architecture of the proposed Multiple Output CNN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>The back-propagation procedure for our Multiple Output CNN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Some samples from our AFAD dataset including for 19-year, 23-year, 27-year, 31-year, 35-year, and 39-year old facial photos for (a) female and (b) male.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>The distribution of age and gender for the AFAD dataset. There are 164, 432 well-labeled photos, including 63, 680 photos for female as well as 100, 752 photos for male. And the ages range from 15 to 40. Ages range from 16 to 77 with a median age of 33. The average number of images per individual is 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>The comparison of age estimation with CS metric on AFAD dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>The architecture of network used in the method of Metric Regression with CNN (MR-CNN).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 .</head><label>1</label><figDesc>The comparison of age estimation between metric regression and ordinal regression methods. The performance is measured by the Mean Absolute Error (MAE) metric.</figDesc><table>Dataset 

Metric Regression 
Ordinal Regression 
BIFs + 
BIFs + 
CNN + 
BIFS + 
BIFS + 
Ours 
LSVR [15] CCA [14] 
LSVR [31] 
OR-SVM [5] OHRank [6] (OR-CNN) 
MORPH II 
4.31 
4.73 
5.13 (4.77 in [31]) 
4.21 
3.82 
3.27 
AFAD 
4.13 
4.40 
5.56 
4.36 
3.84 
3.34 

0 
2 
4 
6 
8 
10 
12 
14 
0.1 

0.2 

0.3 

0.4 

0.5 

0.6 

0.7 

0.8 

0.9 

1 

BIFs + SVR 
BIFs + CCA 
BIFs + OR−SVM 
Ours (OR−CNN) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 .</head><label>2</label><figDesc>The comparisons between metric regression and ordinal regression based methods. The performance is measured by the Mean Absolute Error (MAE) metric.</figDesc><table>Methods 
MORPH II AFAD 
BIFs + OHRank [6] 
3.82 
3.84 
Proposed MR-CNN 
3.42 
3.51 
Proposed OR-CNN 
3.27 
3.34 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 .</head><label>3</label><figDesc>The analysis of the task importance. The performance is measured by the Mean Absolute Error (MAE) metric.testing subsets 100 times for cross-validation. We obtain MAE=3.27 ± 0.02 and MAE=3.34 ± 0.08 on the MORPH-II and AFAD dataset respectively. Compared with the OHRank, our analysis shows that the proposed algorithm significantly outperform it at significance level α = 0.01.Those promising results illustrate that</figDesc><table>Datasets 
Uniform Data-specific Scheme 
MORPH II 
3.30 
3.27 
AFAD 
3.41 
3.34 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 .</head><label>4</label><figDesc>The analysis of the image color information. The performance is measured by the Mean Absolute Error (MAE) metric.</figDesc><table>Datasets 
Gray Image Color Image 
MORPH II 
3.42 
3.27 
AFAD 
3.44 
3.34 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Acknowledgements</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<ptr target="http://sting.cycollege.ac.cy/alanitis/fgnetaging.html" />
		<title level="m">The fg-net aging database</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Attribute-assisted reranking for web image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>ACM Multimedia</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Human age estimation using ranking svm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CCBR</title>
		<imprint>
			<biblScope unit="page" from="324" to="331" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A ranking approach for human age estimation based on face images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>ICPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ordinal hyperplanes ranker with cost sensitivities for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="page" from="585" to="592" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cumulative attribute space for age and crowd density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="page" from="2467" to="2474" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Active appearance models. ECCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="484" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<title level="m">Pranking with ranking. NIPS</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="641" to="647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A simple approach to ordinal classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="page" from="145" to="156" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Human age estimation with regression on discriminative aging manifold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="page" from="578" to="584" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic age estimation based on facial aging patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smith-Miles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="page" from="2234" to="2240" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Simultaneous dimensionality reduction and human age estimation via kernel partial least squares regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="657" to="664" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Joint estimation of age, gender and ethnicity: Cca vs. pls. FG</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Human age estimation using bio-inspired features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="page" from="112" to="119" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">support vector learning for ordinal regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Obermayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Artif. Neural Netw</title>
		<meeting>Int. Conf. Artif. Neural Netw</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Large margin rank boundaries for ordinal regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Obermayer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5093</idno>
		<title level="m">Caffe: Convolutional architecture for fast feature embedding</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Comparing different classifiers for automatic age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lanitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Draganova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Christodoulou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE SMC-B</title>
		<imprint>
			<biblScope unit="page" from="621" to="628" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning ordinal discriminative features for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="page" from="2570" to="2577" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ordinal regression by extended binary classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="page" from="865" to="872" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Context-aware topic model for scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Semi-supervised relational topic model for weakly annotated image recognition in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<title level="m">Visual topic network: Building better image representations for images in social media. CVIU</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Age progression in human faces: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Biswas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>JVLC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Morph: A longitudinal image database of normal adult age-progression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ricanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tesafaye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Automatic Face and Gesture Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="341" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Ranking with large margin principle: Two approaches. NIPS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shashua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="961" to="968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Illuminationaware age progression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shlizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suwajanakorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seitz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Rapid object detection using a boosted cascade of simple features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Automatic salient object extraction with contextual cue. ICCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Deeply-learned feature for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kambhamettu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>WACV</publisher>
			<biblScope unit="page" from="534" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Ranking model for facial age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>ICPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Age estimation by multi-scale convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACCV</title>
		<imprint>
			<biblScope unit="page" from="144" to="158" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
