<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sparse Coding for Classification via Discrimination Ensemble *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Quan</surname></persName>
							<email>csyhquan@scut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">South China Univ. of Tech</orgName>
								<address>
									<postCode>510006</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>117542</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">South China Univ. of Tech</orgName>
								<address>
									<postCode>510006</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuping</forename><surname>Sun</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Automation Science &amp; Engineering</orgName>
								<orgName type="institution">South China Univ. of Tech</orgName>
								<address>
									<postCode>510006</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>117542</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">South China Univ. of Tech</orgName>
								<address>
									<postCode>510006</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>117542</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Ji</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>117542</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Sparse Coding for Classification via Discrimination Ensemble *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Discriminative sparse coding has emerged as a promising technique in image analysis and recognition, which couples the process of classifier training and the process of dictionary learning for improving the discriminability of sparse codes. Many existing approaches consider only a simple single linear classifier whose discriminative power is rather weak. In this paper, we proposed a discriminative sparse coding method which jointly learns a dictionary for sparse coding and an ensemble classifier for discrimination. The ensemble classifier is composed of a set of linear predictors and constructed via both subsampling on data and subspace projection on sparse codes. The advantages of the proposed method over the existing ones are multi-fold: better discriminability of sparse codes, weaker dependence on peculiarities of training data, and more expressibility of classifier for classification. These advantages are also justified in the experiments, as our method outperformed several recent methods in several recognition tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, as a promising technique for efficiently representing high-dimensional data, sparse coding has seen its successful usages in a variety of recognition tasks, e.g., face recognition <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b2">3]</ref>, object classification <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b2">3]</ref>, texture classification <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b24">25]</ref>, and action recognition <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b38">39]</ref>. Given a set of input data, sparse coding aims at expressing each input data by a linear combination of only a few elements from a set of representative patterns. These representative patterns are called atoms, the set of all the atoms is called dictionary, and the coefficients of the linear combi- nations are called sparse codes. More specifically, consider a set of input signals {y 1 , y 2 , . . . , y P } ⊂ R N , sparse coding is about determining a set of atoms {d 1 , d 2 , . . . , d M } ⊂ R N , together with a set of coding vectors {c 1 , . . . , c P } ⊂ R M , so that each input vector y j can be approximated by the linear combination y j ≈ M ℓ=1 c j (ℓ)d ℓ , where most entries of c j are zeros or close to zeros. Let · 0 denote the pseudo-norm that counts the number of non-zero elements. Then, the classic sparse coding problem can be formulated as the following optimization problem (e.g. <ref type="bibr" target="#b0">[1]</ref>):</p><formula xml:id="formula_0">min D,C Y − DC 2 F , s.t. ∀i, c i 0 ≤ T,<label>(1)</label></formula><p>where D = [d 1 , d 2 , . . . , d M ] ∈ R N ×M denotes the dictionary to be learned, Y = [y 1 , y 2 , . . . , y P ] ∈ R N ×P denotes a matrix containing the input samples as column vectors, C = [c 1 , . . . , c P ] ∈ R M ×P denotes the matrix containing the corresponding coding vectors, and the parameter T controls the sparsity degree on each coding vector. Furthermore, the normalization constraint on each atom is often imposed to avoid possible unbounded solutions, which states d j 2 = 1 for all j.</p><p>It can be seen that the dictionary learned using (1) only cares about the approximation error between the input data and the resultant succinct expression. In other words, the sparse codes obtained under the learned dictionary can be viewed as the cleaned up version of the input data. One may use such sparse codes as the features for classification. However, the additional discriminative information provided by these sparse codes over the original input signals is limited when being used in complex classification tasks, as they do not take account of the discriminability needed in classification. In recent years, there have been an abundant literature on discriminative sparse coding which is to learn a dictionary whose resultant sparse codes possess improved discriminative power; see e.g. <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b14">15]</ref>. The basic idea of discriminative sparse coding for classification is to include some supervised learning processes into sparse coding. Most existing approaches for discriminative sparse coding consider the following variational model:</p><formula xml:id="formula_1">min D,C Y − DC 2 F + γJ (C; L)<label>(2)</label></formula><p>subject to c i 0 ≤ T , d j 2 ≤ 1, for all i and j, where γ is a weight, L is a matrix that encodes the label information of each training sample, and J (·; L) denotes a penalty function that measures the discriminative error between the codes and labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Motivation</head><p>In recent years, several supervised learning techniques have been incorporated into discriminative sparse coding, such as linear prediction in <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b12">13]</ref>, softmax regression in <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, logistic regression in <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b19">20]</ref>, and maximum margin learning in <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b32">33]</ref>. All these techniques focus on feeding back classification performance of a single classifier, which is rather rudimentary considering the great advances in supervised learning in recent years. For example, the powerful ensemble learning <ref type="bibr" target="#b5">[6]</ref>, a machine learning paradigm where a set of base classifiers are trained and combined as an ensemble classifier to gain extra performance, has not been fully exploited.</p><p>The benefits of introducing ensemble learning to sparse coding are multi-fold. Firstly, the size of training data is often limited in real applications, which could be due to the cost of data collection (e.g. face images <ref type="bibr" target="#b30">[31]</ref>) or the computational cost of using a training set of large size (e.g. classifying objects of over thousands of categories <ref type="bibr" target="#b6">[7]</ref>). As a result, the dictionary learning, as well as the single classifier training, is often sensitive to the shape of training data. Ensemble learning allows the combination of multiple classifiers which can effectively reduce such sensitivity. Secondly, when using a single classifier, the applicability of discriminative sparse coding is often limited owing to the imperfectness of the used learning algorithms, e.g., the linear classifier used in <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b13">14]</ref> is inappropriate for linearly inseparable data, and the fisher discriminant used in <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b33">34]</ref> is optimal only when the data from each category are realized from the normal distribution. In contrast, using ensemble learning can avoid such imperfectness by integrating multiple classifiers. Lastly, the hypothesis space being searched might not contain the true target function, while ensembles can give some good approximation <ref type="bibr" target="#b5">[6]</ref>.</p><p>Motivated by the likely benefits of ensemble learning over single classifier training, there have been several attempts to incorporate ensemble learning into discriminative sparse coding; see e.g. <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref>. However, there are plenty of room for further improvement in all these methods in both theoretical and applied perspectives. For example, the supervised information is not fully utilized in <ref type="bibr" target="#b40">[41]</ref>, a two-stage scheme used in <ref type="bibr" target="#b39">[40]</ref> does not feed back classification performance for dictionary learning, and an iterative re-sampling scheme is directly used in <ref type="bibr" target="#b37">[38]</ref>   <ref type="figure">Figure 1</ref>. Motivation of sparse coding with discriminative ensemble. (a) Reconstructive sparse coding only considers minimizing the reconstruction error. Thus, inter-class signals which have high correlations are likely to share atoms during dictionary leaning, which yields similar inter-class sparsity patterns and decreases the discrimination of sparse codes, e.g., green points and black points are mixed together in the K-SVD <ref type="bibr" target="#b0">[1]</ref> coding space. (b) Jointly learning a linear classifier could address the issue, as labels of signals are utilized to enforce the separability of inter-class sparsity patterns, e.g., green points and black points are separated in the D-KSVD <ref type="bibr" target="#b36">[37]</ref> coding space. (c) However, discrimination terms based on a single linear classifier are insufficient in many scenarios, as inter-class sparsity patterns are unnecessarily linearly separable due to the multi-modal distribution (e.g. black points or red points are distributed in two clusters in the D-KSVD <ref type="bibr" target="#b36">[37]</ref> coding space), peculiarity and outliers of training data. On the other hand, using highly nonlinear classifier would result in complex optimization models that are challenging to solve. In contrast, integrating multiple linear classifiers can overcome the weakness of single linear classifier while keeping the simplicity of the model. multiple dictionaries and classifiers, which lacks an unified variational model. All these inspired us to study new variational approaches for ensemble learning based discriminative sparse coding. See <ref type="figure">Figure 1</ref> for an illustration of our motivation to introduce ensemble learning to sparse coding.</p><formula xml:id="formula_2">d 2 d 3 (a) (b) (c)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Main Contributions</head><p>This paper aims to develop a new discriminative sparse coding method which is built upon ensemble learning. We first construct a new variational model of the form (2) that embeds ensemble learning into sparse coding by considering an ensemble classifier in defining the term J . Then, we propose an alternating iterative scheme to solve the resultant optimization problem. The proposed discriminative sparse coding method can be applied to classification by voting the predictions from all base classifiers in the ensemble. Compared to the classic sparse coding methods, e.g. the K-SVD method <ref type="bibr" target="#b0">[1]</ref> and the proximal method <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, the sparse codes from the proposed method are much more discriminative when being used in classification. Compared to the single classifier based discriminative sparse coding methods <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b13">14]</ref>, the proposed method is built upon multiple classifiers in an ensemble setting, which is capable to tackle the insufficiency of training data and improve the robustness of classification. Compared to the methods that assign labels to atoms for adding discrimination <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b12">13]</ref>, the proposed method can be regarded as a generalization which projects the sparse codes to a set of subspaces and learns a classifier on each subspace, yielding a compact dictionary without explicit label assignment. In comparison to other existing ensemble-based dictionary learning methods <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b39">40]</ref>, the proposed method provides a variational model with better theoretical justification, and avoids learning multiple dictionaries for ensemble as done in <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Discriminative Sparse Coding</head><p>Nowadays, sparse coding has emerged as one promising technique in a wide range of applications, including image recovery, analysis, and classification. In classic sparse modeling problem, the sparse coding aims at finding sparse representation of input data under an adaptive dictionary. There has been an abundant literature on its analysis and algorithms. For example, the SRC method <ref type="bibr" target="#b30">[31]</ref> considers the sparse approximation problem with the dictionary constructed by concatenating all training samples. The wellknown K-SVD method <ref type="bibr" target="#b0">[1]</ref> considers the model (1) and provides a fast numerical solver, and the proximal method for solving the same problem is proposed in <ref type="bibr" target="#b1">[2]</ref> with rigorous convergence analysis. All these methods only concern the sparse approximation of input data. The label information of the training samples in supervised setting are ignored. As a result, the obtained sparse codes often do not provide additional discriminative information over the input feature vectors when used for classification. Thus, many methods have been proposed to utilize the labels of data for discriminative sparse coding, e.g. <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b12">13]</ref>. In the next, we give a brief review on the existing discriminative sparse coding techniques, which can be mainly classified into two categories based on the usage of label information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Joint dictionary learning and classifier training</head><p>There are two approaches for combining classification and sparse coding. One is a two-stage approach which first runs sparse coding and then uses the obtained sparse codes as the features to train classifiers; see e.g. <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b29">30]</ref>. Such a two-stage scheme is not optimal for discrimination as it does not relate classifiers to the process of sparse coding. Thus, a better approach is to simultaneously run classifier training and sparse coding, which often can be formulated as a variational model:</p><formula xml:id="formula_3">min D,W ,C Y − DC 2 F + γJ (C, W ; L) s.t. c i 0 ≤ T, d j 2 ≤ 1, for all i, j,<label>(3)</label></formula><p>where J (·, ·; L) denotes a classification loss function, W denotes the classifier parameters related to J , and L = [l 1 , l 2 , . . . , l P ] ∈ R K×P is the binary label matrix of P training samples from K categories, where l p = [0, 0, . . . , 1, . . . , 0, 0] ⊤ ∈ R K denotes the binary label vector of the pth sample y p in which nonzero occurs at the kth entry if y p belongs to the kth category. As a discriminative term, the classification loss function J (C, W ; L) in (3) varies in different methods -softmax discriminative cost <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, linear prediction error <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b12">13]</ref>, hinge loss <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b32">33]</ref>, and logistic loss <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b19">20]</ref>, to name a few. Take the linear prediction error for example, the classification loss function L is defined as</p><formula xml:id="formula_4">J (C, W ; L) = L − W C 2 F ,<label>(4)</label></formula><p>where W ∈ R K×M is a classic multi-class linear predictor. Such a simple discrimination term has demonstrated moderate performance improvement in face recognition <ref type="bibr" target="#b36">[37]</ref>. But a global linear classifier is often still not powerful enough in many challenging classification tasks. Most existing approaches solve the problem (3) via an alternating iteration scheme which alternatively updates the estimations in three submodules, i.e. sparse coding, dictionary learning and classifier training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Associating dictionary atoms with class labels</head><p>The discriminability in sparse codes can be further improved by learning a dictionary with labeled atoms. More specifically, each dictionary atom is associated with one or more class labels. During the process of dictionary learning, each input signal is encouraged to have significant responses on the atoms whose class labels are shared with the signal. In this scheme, a dictionary is partitioned into several discriminative sub-dictionaries, and distinct sparsity patterns (e.g. positions or magnitude spectrum of non-zero elements) are induced in the sparse coefficients of interclass signals, which is likely to increase the distance of sparse codes among different classes.</p><p>When they are disjoint and learned independently from inner-class samples, sub-dictionaries become naive classspecific dictionaries, which have been employed in many previous studies; see e.g. <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b27">28]</ref>. The main drawback of these methods is that the learned class-specific dictionaries do not encode correlation between classes. On the one hand, the learned class-specific dictionary in each class might also represent data from other classes equally well, which results in decreased discriminative power of sparse codes. On the other hand, the samples from different classes do not share any dictionary atom, which makes the resultant representation less efficient in terms of characterizing the underlying structures. Several schemes have been proposed to tackle these issues -adding an additional globally shared pool of atoms <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b15">16]</ref>, reducing mutual coherence between atoms and detecting shared atoms among class-specific dictionaries <ref type="bibr" target="#b25">[26]</ref>, etc.</p><p>A promising alternative to using naive class-specific dictionaries is to jointly learn sub-dictionaries, e.g. <ref type="bibr" target="#b34">[35]</ref>. To induce discriminability in sparse codes according to subdictionaries, one way is to group sparse codes according to the label consistency between dictionary atoms and data samples. Then group sparsity is imposed on the grouped sparse codes, e.g. <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref>. The resultant structured sparse codes are more discriminative for classification than the purely sparse ones. Another way is to induce separability in sparse codes with certain class separation criterion, see e.g. <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b4">5]</ref>. Take the label consistency criterion <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b12">13]</ref> for example, the discrimination term is defined as follows:</p><formula xml:id="formula_5">J (C, A; B) = B − AC 2 F ,<label>(5)</label></formula><p>where A is a linear transformation matrix to be learned, B ∈ R M ×P is a predefined binary matrix for label consistency where B m,p is nonzero if the atom d m is expected to share class label with the signal y p .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Main Body</head><p>In this section, we develop an ensemble based discriminative sparse coding method for classification. Instead of learning a single linear classifier defined in (4), we train multiple linear classifiers based on different subspaces of sparse codes from different subsets of input signals during dictionary learning. By jointly learning a dictionary for sparse coding and training an ensemble classifier for classification, the benefits of the proposed method are two-fold: better discriminability of sparse coding and better robustness in classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Ensemble based discriminative sparse coding</head><p>Let {W z ∈ R K×Mz } Z z=1 be a set of multi-class linear classifiers to be learned. We propose the following variational model for discriminative sparse coding:</p><formula xml:id="formula_6">min D,{Wz} Z z=1 ,C Y − DC 2 F + Z z=1 γ z W z 2 F + Z z=1 β z LQ z − W z P z C Q z 2 F<label>(6)</label></formula><formula xml:id="formula_7">s.t. c i 0 ≤ T, d j 2 ≤ 1, for all i, j,</formula><p>where β z s and γ z s are the scalars controlling relative contribution of each term, P z ∈ R Mz×M is a subspace ensemble constructor which projects coding vector of each sample (i.e. each column of C) onto certain subspace, and Q z ∈ R P ×P is a subsample ensemble constructor which selects coding vectors of certain samples ( i.e. some columns of C) for classification. There are three main terms in <ref type="formula" target="#formula_6">(6)</ref>:</p><p>• The first term is a fidelity term for the consistency between signals and codes; • The second term is a discrimination term built upon an ensemble of classifiers, where {P z } Z z=1 is used for constructing subspace ensemble while {Q z } Z z=1 for constructing subsample ensemble; • The last term is to control the energy of the classifiers to avoid over-fitting.</p><p>Compared to the single linear classifier based approaches (e.g. <ref type="bibr" target="#b36">[37]</ref>), by using the ensemble of linear classifiers, the proposed method is able to reduce the dependence of sparse codes on peculiarities of training set and learn more expressive concepts for further performance gain in classification.</p><p>Remark -An interesting observation on the connection between label consistency and ensemble learning. The label consistency term defined in <ref type="formula" target="#formula_5">(5)</ref> can be also understood from the viewpoint of ensemble learning. First, assuming each class shares label with H atoms and each atom only shares label with one class, it is easy to verify that there exists a permutation matrix R such that R(1 Z ⊗ L) = B. Then we can rewrite <ref type="formula" target="#formula_5">(5)</ref> as</p><formula xml:id="formula_8">J (C,Ā; L) = H h=1 L −Ā h C 2 F ,<label>(7)</label></formula><p>whereĀ h ∈ R K×P is the hth block ofĀ which is defined asĀ = [Ā 1 ,Ā 2 , ...,Ā H ] = RA. Thus, the label consistency term can be viewed as a discrimination term defined as the summation of prediction errors from a set of linear classifiers {A h } H h=1 , which is a special case of the ensemble discrimination term in <ref type="bibr" target="#b5">(6)</ref>. Note that the base learners {A h } H h=1 learned in LC-KSVD are utilized in learning but not classification. In comparison, we utilize the base learners in both learning and classification for improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Construction of ensemble classifier</head><p>We now give a detailed description on the implementation of the ensemble construction operators {P z } Z z=1 and {Q z } Z z=1 in <ref type="bibr" target="#b5">(6)</ref>. As suggested in <ref type="bibr" target="#b5">[6]</ref>, the correlation of each pair of base classifiers in the ensemble should be as low as possible for promising diversity and improvement. One often-used technique to form ensemble with independent bases is done by random injection. In this paper, we configure {P z } Z z=1 and {Q z } Z z=1 as follows 1 : • Identical projection: Set P 1 = I M and Q 1 = I P .</p><p>This is an ordinary base which results in (4). • Feature selection: For z = 2, ..., H 1 + 1, set Q z = I P and set P z ∈ R K×M to be a feature selection matrix such that P z C selects K rows from C. More specifically, P z is a binary matrix with K nonzeros generated by randomly deleting M − K rows from I M . The row positions of 1s in P z indicate the selected dimensions of sparse codes for training W z . • Random projection: For z = H 1 + 2, ..., H 2 + H 1 + 1, set Q z = I P and set P z ∈ R M 2 ×M to be a random Gaussian matrix with zero mean. Compared to the feature selection, the random projection can guarantee a global preservation of inter-point distances.</p><p>• Data subsampling: For z = H 2 +H 1 +2, ..., H 3 +H 2 + H 1 +1, set P z = I M and set Q z ∈ R P ×P to be a diagonal projection matrix that selects sparse codes from a subset of training samples from each class. More concretely, Q z is a binary diagonal matrix where the pth diagonal element being 1 indicates that the pth signal is used for training W z . <ref type="bibr" target="#b1">2</ref> The Q z s are generated by thresholding randomly permuted indices.</p><p>Empirically, the performance of our method is insensitive to the randomness from the generation schemes above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Algorithm</head><p>We use an alternating iterative scheme to solve the problem (6), which alternatively updates the unknowns D, C and {W z } Z z=1 as follows 3 : for ℓ = 1, 2, . . . ,</p><formula xml:id="formula_9">                     C (ℓ+1) = argmin C Z z=1 βz L − W (ℓ) z PzC (ℓ) Qz 2 F + Y − D (ℓ) C 2 F , s.t. ci 0 ≤ T for all i; D (ℓ+1) = argmin D Y − DC (ℓ) 2 F , s.t. dj 2 = 1 for all j; W (ℓ+1) z = argmin W L − W PzC (ℓ) Qz 2 F + γz βz W 2 F .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Sparse approximation</head><p>At the beginning of the (l + 1)th iteration, we update the sparse codes with the learned dictionary and classifiers from the previous step by solving the following problem:</p><formula xml:id="formula_10">C (ℓ+1) = argmin C Z z=1 β z L − W (ℓ) z P z CQ z 2 F + Y − D (ℓ) C 2 F s.t. ∀i, c i 0 ≤ T.</formula><p>This problem is column separable with respect to C. Thus, we update C = [c 1 , . . . , c P ] column by column as follows:</p><formula xml:id="formula_11">for i = 1, . . . , P , c (ℓ+1) i = argmin c Z z=1 Qz (i)=1 β z l i − W (ℓ) z P z c 2 2 + y i − D (ℓ) c 2 2 , s.t. c 0 ≤ T<label>(8)</label></formula><p>2 Setting Qz rectangular instead of square is more succinct. However, we adopt the square case for the convenience of presenting our algorithm. <ref type="bibr" target="#b2">3</ref> In the following parts, we omit Qz in LQz for the convenience of presenting our algorithm. This does not affect the optimization procedure due to the nature of Qz.</p><p>where Q z (i) denotes the ith diagonal element of Q. This problem can be rewritten as</p><formula xml:id="formula_12">c (ℓ+1) i = argmin c x − U (ℓ) i c 2 F , s.t. c 0 ≤ T, (9) where U (ℓ) i = (D ⊤(ℓ) , . . . , √ β z (W (ℓ) z P z ) ⊤ , . . . ) ⊤ and x = (y ⊤ i , . . . , √ β z l ⊤ i , .</formula><p>. . ) ⊤ for all possible zs subject to Q z (i) = 1. This is a classic sparse coding problem which is solved by OMP <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Dictionary refinement</head><p>After the sparse codes have been updated, the refinement of dictionary becomes the following problem:</p><formula xml:id="formula_13">D (ℓ+1) = argmin D Y − DC (ℓ) 2 F , s.t. ∀j, d j 2 = 1.</formula><p>By applying projected gradient descent, we update the dictionary atom by atom as follows:</p><formula xml:id="formula_14">for j = 1, . . . , M ,    s (ℓ) j = d (ℓ) j − 1 µ ℓ j ∇ dj F(C (ℓ+1) , D (ℓ) j ; Y ), d (ℓ+1) j = argmin dj 2 =1 d j − s (ℓ) j 2 ,<label>(10)</label></formula><p>where µ ℓ j is the step size,</p><formula xml:id="formula_15">F(C, D; Y ) = Y − DC 2 F , D (ℓ) j = [d (ℓ+1) 1 , · · · , d (ℓ+1) j−1 , d (ℓ) j , d (ℓ) j+1 , · · · , d (ℓ) m ],</formula><p>The problem (10) has a closed-form solution</p><formula xml:id="formula_16">d (ℓ+1) j = s (ℓ) j / s (ℓ) j 2 .<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Classifier training</head><p>With the sparse codes fixed, the training of classifiers is about solving the following problem:</p><formula xml:id="formula_17">W (ℓ+1) z = argmin W L − W M (ℓ) z 2 F + γ z β z W 2 F , where M (ℓ) z = P z C (ℓ) Q z .</formula><p>This is a ridge regression problem with the explicit solution given by</p><formula xml:id="formula_18">W (ℓ+1) z = LM (ℓ)⊤ z (M (ℓ) z M (ℓ)⊤ z + γ z β z I) −1 ,<label>(12)</label></formula><p>which can be efficiently computed by the conjugate gradient method as (M </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Classification strategy</head><p>Once the dictionary D and the classifiers {W z } Z z=1 have been learned, the classification is done as follows. Given a test sample y test , we compute the corresponding sparse code c test by solving the sparse approximation problem</p><formula xml:id="formula_19">c test = argmin c y test − Dc 2 2 , s.t. c 0 ≤ T,<label>(13)</label></formula><p>using OMP <ref type="bibr" target="#b28">[29]</ref>. Then the prediction score of c test on the zth classifier W z is computed by</p><formula xml:id="formula_20">s test z = W z P z c test ,<label>(14)</label></formula><p>and all the scores are voted as follows:</p><formula xml:id="formula_21">s test = Z z=1 β z (V • s test z ),<label>(15)</label></formula><p>where V is an operator that sets the maximum element of the input vector to 1 and sets the remaining elements to 0s.</p><p>The label of y test is finally determined by taking the class index which corresponds to the maximal value in s test .</p><p>Remark -The convergence of the above algorithm cannot be guaranteed. In fact, the proximal method <ref type="bibr" target="#b1">[2]</ref> with theoretically guaranteed convergence can be adapted to our settings with very little modifications. However, the theoretical convergence does not provide any practical benefit and it indeed performs slightly worse than our algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In existing literature, there are various protocols for evaluating discriminative sparse coding methods. We adopted the experimental setting from <ref type="bibr" target="#b12">[13]</ref>, which uses five datasets and covers a variety of recognition tasks ranging from face recognition and object classification to scene classification and action recognition. The datasets and protocols are detailed in the next subsection.</p><p>Throughout the experiments, we set H 1 = H 2 = H 3 = H for simplicity. The resultant number of base classifiers is Z = 3H + 1. The weights of all the classifiers are set the same, i.e. β z = β and γ z = γ for all possible z. Then, the parameters of our method are reduced to five scalars: the number of base classifiers Z, the discrimination weights β and γ, the sparsity degree T , and the dictionary size M . The parameters β and γ are determined by cross-validation, M is set to be a multiple of the number of categories on the dataset, T is set according to <ref type="bibr" target="#b12">[13]</ref>, and H is set 10 when the dimensions of input signals are over 1000 and set 8 otherwise. For initialization, we calculate D (0) and C (0) using K-SVD and initialize W (0) using (12) with C (0) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets and protocols</head><p>• Ex. YaleB The dataset is randomly split into two halves. One half which contains 32 images per person is used for training, and the other half for test. We set T = 40 and M = 532.</p><p>• AR Face <ref type="bibr" target="#b12">[13]</ref>: The AR Face dataset consists of over 4000 frontal images from 126 individuals, in which 26 pictures were taken in two separate sessions for each individual. A subset with 2600 images from 50 male subjects and 50 female subjects is used. Each image is cropped to 165 × 120 and then projected onto a 540-dimensional feature vector by random projection. For each person, 20 images are collected for training and the rest are for test. We set T = 40 and M = 500. • Caltech-101 <ref type="bibr" target="#b6">[7]</ref>: The Caltech-101 dataset is composed of 8677 images from 101 object categories and 467 images from an additional background category. The number of samples per category is greatly unbalanced, varying from 31 to 800. The 3000-dimensional SIFT-based spatial pyramid feature <ref type="bibr" target="#b17">[18]</ref> is used to represent each image. We trained on 15 samples per category and tested on the rest. The dictionary size is set equal to the size of training set (i.e. 1530). The parameter T is set to 45.  <ref type="bibr" target="#b26">[27]</ref> is extracted from each sample and then projected onto a 100-dimensional vector by PCA. The performance is measured by the five-fold cross validation (i.e. one fold for test and the remaining four folds for training). We set M = 50 and T = 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Methods for comparison</head><p>Our purpose here is not to compete with the top recognition systems like deep networks, but to demonstrate the improvement of the proposed method over the related ones. Thus, our method is compared against some recent sparse coding methods that are closely-related to ours, including 4</p><p>• SRC <ref type="bibr" target="#b30">[31]</ref>, sparse representation based classification via stacking training samples as a dictionary, which was implemented with two different dictionary configurations: SRC for the case where all training samples are used for dictionary construction, and SRC* for the case where the dictionary size is the same as ours; • K-SVD <ref type="bibr" target="#b0">[1]</ref>, reconstructive sparse coding via solving (1), which is applied to classification via a two-stage strategy: sparse coding followed by single linear classifier training;</p><p>• Joint <ref type="bibr" target="#b23">[24]</ref>, unifying classifier learning and sparse representation into one optimization framework; • D-KSVD <ref type="bibr" target="#b36">[37]</ref>, simultaneously learning a dictionary and a linear classifier by solving <ref type="formula" target="#formula_3">(3)</ref> and (4) via K-SVD; • L0DL <ref type="bibr" target="#b1">[2]</ref>, a convergent sparse coding method that jointly learns a single classifier and a dictionary; • LC-KSVD <ref type="bibr" target="#b12">[13]</ref>, sparse coding with label consistency regularization (5) and single linear classifier training (4); • DLSI <ref type="bibr" target="#b25">[26]</ref>, class-specific dictionary learning with incoherence control on dictionary atoms; • FDDL <ref type="bibr" target="#b34">[35]</ref>, Fisher discriminant dictionary learning;</p><p>• LLC <ref type="bibr" target="#b29">[30]</ref>, coding with locality but not sparsity of codes.</p><p>In the next, we denote our method by EasyDL (Ensemble Classifier based Dictionary Learning; 'EC' and 'easy' are homophones). For fair comparison, the dictionary sizes of all the compared methods except SRC are set the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results and analysis</head><p>Overall performance. The classification accuracies of all the compared methods are summarized in <ref type="table" target="#tab_1">Table 1</ref>. It can be seen that our method is very competitive among all the compared methods. In the evaluation on face recognition, EasyDL outperformed all other compared methods except SRC. The impressive performance of SRC is attributed to its large dictionary size. It can be found from the results of SRC* that, the performance of SRC decreases dramatically when the dictionary size gets small.</p><p>Regarding object classification, our method achieved the best result. We tested the performance on the smaller-size training sets. The results show that EasyDL performs consistently well, even in the case where training samples are insufficient, e.g., accuracy of 54.4% is achieved using 5 samples for training. The most competitive method to ours is LC-KSVD, which can be viewed as an ensemble-based method during learning, as shown in Section 3.1. In comparison, EasyDL achieved better results by integrating all base learners for classification and learning compact dictionaries without explicit assignment of labels. We also tested the performance of our method on Caltech with 30 training samples per class and compared it with all the methods reviewed in <ref type="bibr" target="#b3">[4]</ref>. The results show that our method performs worse than <ref type="bibr" target="#b3">[4]</ref> with a gap of 1.86%, but outperforms other compared methods. It is noted that <ref type="bibr" target="#b3">[4]</ref> tackles the feature pooling stage in image classification, which is different from ours, and our method can be used as a classification module and combined with <ref type="bibr" target="#b3">[4]</ref> for improvement.</p><p>On Scene-15 and UCF, EasyDL performs slightly better than FDDL and shows noticeable improvement over other compared methods. The Fisher discriminant used in FDDL is optimal only when signals from each category are sampled from the normal distribution, implying that FDDL is vulnerable to outliers presented in training data. In contrast, EasyDL tackles imperfectness of data by using ensemble classifiers. Therefore, noticeable performance improvement of EasyDL over FDDL is observed on other datasets.</p><p>In summary, all the experimental results demonstrate the effectiveness of our method. Contribution of ensemble components. The performance of EasyDL was tested with the identical projection plus different combinations of the other three ensemble components (i.e. feature selection, random projection and data subsampling). The results on Extended YaleB are listed in <ref type="table" target="#tab_2">Table 3</ref>. It is seen that a single component yields moderately good results, and further performance improvement can be gained by combining different ensemble components. This verifies the necessity of using different types of ensemble in EasyDL. Notice that the improvement by the combination of feature selection and random projection is very marginal, as these two components are similar in that they are both for subspace ensemble. Also notice that the subspace ensemble and subsample ensemble are complementary in EasyDL, as noticeable improvement can be observed from the combination of data subsampling and feature selection (or random projection). We also varied the value of H and tested the performance changes of EasyDL. The results are shown in <ref type="figure" target="#fig_4">Fig. 2(d)</ref>. We can see that the performance of EasyDL increases with more classifiers involved, and it becomes saturate when H is sufficiently large. Influence of parameters. We analyze the influence of the parameters β, T and M by alternatively adjusting one while fixing the other two. The results on Extended YaleB are shown in <ref type="figure" target="#fig_4">Fig. 2</ref>. We can see from <ref type="figure" target="#fig_4">Figure 2</ref>(a) that the performance of EasyDL is not sensitive to β within a small range, but exhibits some disturbances due to the non-convexity of the learning model. As β becomes larger, the discrimination of sparse codes increases while the representative power of the dictionary decreases. Thus, an acceptable β should balance the discrimination and representation. In <ref type="figure" target="#fig_4">Fig. 2(b)</ref>, the performance of EasyDL drops a lot when T is small. The reason is obvious: the subspaces of data cannot be fully characterized by a limited number of atoms, making the sparse codes lose discriminability. When T is larger than 50, the performance of EasyDL decreases slightly. This is not surprising as representing samples by many atoms might cause over-fitting. From <ref type="figure" target="#fig_4">Fig. 2(c)</ref> we can see that the classification accuracy increases as the dictionary becomes larger. But the increment becomes ignorable when the dictionary is sufficiently large. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Efficiency</head><p>The computational efficiency of EasyDL is compared to D-KSVD, LC-KSVD, SRC, and FDDL. All the compared methods are tested under the same environment: MATLAB on an Intel Quad-Core CPU. Both the time costs of dictionary learning and classification are reported in <ref type="table">Table 2</ref>. In dictionary learning, EasyDL is slower than LC-KSVD and D-KSVD. The time cost of EasyDL on Extended YaleB is around seven times of D-KSVD on average, yet acceptable. In classification, the time cost of EasyDL is slightly worse than D-KSVD and LC-KSVD but significantly less than SRC. The scalability of EasyDL is better than FDDL and SRC, but still with noticeable increase of the computational time as the scale of problem gets large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>As the proverb goes, the wisdom of the masses exceeds that of the wisest individual. We introduced ensemble classifier to discriminative sparse coding, where an ensemble classifier composed of multiple linear predictors is learned during dictionary learning. The integration of sparse coding and ensemble classifier learning not only reduces the bias of classifier but also improves the discriminability of dictionary. The proposed method was tested on several image classification tasks, and it consistently outperformed many existing sparse coding approaches. In future, we would like to further investigate the integration of ensemble learning and sparse coding, such as ensemble of nonlinear classifiers, iterative ensemble construction during learning, and unsupervised ensemble learning with dictionary learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>* The corresponding author Yong Xu thanks the supports by National Nature Science Foundations of China (61273255 and 61070091), Engineering &amp; Technology Research Center of Guangdong Province for Big Data Analysis and Processing (2013-1589-1-11), Project of High Level Talents in Higher Institution of Guangdong Province (2013-2050205-47) and Guangdong Technological Innovation Project (2013KJCX0010).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>βz I) is positive definite.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc><ref type="bibr" target="#b8">[9]</ref>: The extended YaleB dataset contains 2414 images of 38 human frontal faces. There are about 64 images taken under different illumination conditions and expressions for each person. Each original face image is cropped to 192 × 168 pixels and then projected onto a 504-dimensional feature vector by random projection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>•</head><label></label><figDesc>Scene-15 [18]: The Scene-15 dataset contains 4485 images of 15 categories of scenes. The number of samples per category varies from 210 to 410. Similar to the case in Caltech-101, a 3000-dimensional SIFT-based spatial pyramid feature [18] is extracted from each image. From each category, 100 images are collected for training and the rest for test. The parameters are set as follows: T = 50 and M = 600. • UCF Action [23]: The UCF Sports Action dataset consists of 150 action videos of 10 categories. The number of samples per category varies from 14 to 35. The action bank feature</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 .</head><label>2</label><figDesc>Influence of parameter selection in EasyDL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 .</head><label>1</label><figDesc>Classification accuracies (%) of the compared methods on the test datasetsTable 2. Training time (seconds per iteration) and test time (milliseconds per sample) of the tested methods on five datasets.NameDim×#Sample #Training #Class D-KSVD LC-KSVD FDDL EasyDL D-KSVD LC-KSVD SRC EasyDL</figDesc><table>Dataset 
SRC 
SRC* K-SVD 
Joint 
D-KSVD L0DL LC-KSVD 
DLSI 
FDDL 
LLC 
EasyDL 

Ex. YaleB 
97.20 
80.50 
93.10 
93.88 
94.10 
95.66 
95.00 
89.00 
91.90 
90.70 
96.22 
AR Face 
97.50 
68.50 
86.50 
88.24 
88.80 
94.40 
93.70 
89.80 
92.00 
88.70 
94.40 
Caltech-101 
64.90 
64.90 
65.20 
52.10 
65.10 
67.58 
67.70 
61.39 
66.80 
65.43 
68.40 
Scene-15 
91.80 
77.62 
86.70 
88.20 
89.10 
88.84 
92.90 
92.46 
98.35 
89.20 
98.46 
UCF Action 90.40 
80.62 
86.80 
86.00 
88.10 
86.85 
91.20 
88.74 
91.32 
87.50 
91.40 

Dataset 
Training time (s) per iteration 
Test time (ms) per sample 

Ext. YaleB 
504 × 2414 
1216 
38 
2.39 
0.83 
80.22 
21.79 
0.10 
0.25 
30.34 
0.43 
AR Face 
540 × 2600 
2000 
100 
2.64 
1.20 
153.1 
64.80 
0.06 
0.24 
91.12 
0.50 
Caltech-101 3000 × 9144 
1515 
102 
14.82 
8.52 
9891 601.83 
0.84 
0.85 
247.54 
1.37 
Scene-15 
3000 × 4485 
1500 
15 
28.47 
3.24 
60.75 
44.64 
0.34 
0.34 
202.83 
0.43 
UCF Action 
100 × 150 
140 
10 
0.14 
0.01 
0.31 
0.16 
0.04 
0.03 
0.53 
0.30 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 .</head><label>3</label><figDesc>Classification results on the extended YaleB dataset obtained by using different combinations of ensembles.</figDesc><table>Ensemble type 
Switch [Y=Yes, N=No] 
Feature selection 
Y 
N 
N 
Y 
Y 
N 
Y 
Random projection 
N 
N 
Y 
N 
Y 
Y 
Y 
Data subsampling 
N 
Y 
N 
Y 
N 
Y 
Y 

Accuracy (%) 
94.6 94.8 94.2 96.0 94.7 95.7 96.2 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Recall that M /P /K are the number of atoms/signals/categories.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We observed noticeable improvement from state-of-the-art deep networks over our method. But such a comparison is not fair, as deep networks learn features from the data while our method uses handcrafted features.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An algorithm for designing overcomplete dictionaries for sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bruckstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>K-Svd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">l0 norm based dictionary learning by proximal methods with global convergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A convergent incoherent dictionary learning algorithm for sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="302" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ask the locals: multi-way local pooling for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2651" to="2658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Support vector guided dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="624" to="639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Ensemble methods in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multiple Classifier Systems</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COM-PUT VIS IMAGE UND</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Local features are not lonely -Laplacian sparse coding for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-T</forename><surname>Chia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">From few to many: Illumination cone models for face recognition under variable lighting and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Georghiades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="643" to="660" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning with structured sparsity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J MACH LEARN RES</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3371" to="3412" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sparse representation for signal classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Aviyente</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Proximal methods for sparse hierarchical dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jenatton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Obozinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Label consistent K-SVD: Learning a discriminative dictionary for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning a discriminative dictionary for sparse coding via label consistent K-SVD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1697" to="1704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Submodular dictionary learning for sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3418" to="3425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A dictionary learning approach for classification: separating the particularity and the commonality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="186" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Discriminative affine sparse codes for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1609" to="1616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2169" to="2178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Max-margin dictionary learning for multiclass image categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-C</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Probabilistic models for supervised dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-C</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Discriminative learned dictionaries for local image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Supervised dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Action mach: A spatiotemporal maximum average correlation height filter for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Joint learning and dictionary construction for pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-S</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dynamic texture recognition via orthogonal tensor dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="73" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Classification and clustering via dictionary learning with structured incoherence and shared features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sprechmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="3501" to="3508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Action bank: A high-level representation of activity in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sadanand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Corso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1234" to="1241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Positive definite dictionary learning for region covariances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sivalingam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Morellas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papanikolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1013" to="1019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Signal recovery from random measurements via orthogonal matching pursuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Tropp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Locality-constrained linear coding for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Linear spatial pyramid matching using sparse coding for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Supervised translationinvariant sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Latent dictionary learning for sparse representation based classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fisher discrimination dictionary learning for sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="543" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Robust sparse coding for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="625" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Discriminative K-SVD for dictionary learning in face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="2691" to="2698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning non-redundant codebooks for classifying complex objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Surve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning structured low-rank representations for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="676" to="683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning inter-related visual dictionary for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Ensemble dictionary learning for saliency detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IMAGE VISION COMPUT</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
