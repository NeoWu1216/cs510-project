<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Multiverse Loss for Robust Transfer Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etai</forename><surname>Littwin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electrical Engineering</orgName>
								<orgName type="department" key="dep2">The Blavatnik School of Computer Science</orgName>
								<orgName type="institution" key="instit1">Tel-Aviv University Lior Wolf</orgName>
								<orgName type="institution" key="instit2">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The Multiverse Loss for Robust Transfer Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning techniques are renowned for supporting effective transfer learning. However, as we demonstrate, the transferred representations support only a few modes of separation and much of its dimensionality is unutilized. In this work, we suggest to learn, in the source domain, multiple orthogonal classifiers. We prove that this leads to a reduced rank representation, which, however, supports more discriminative directions. Interestingly, the softmax probabilities produced by the multiple classifiers are likely to be identical. Experimental results, on CIFAR-100 and LFW, further demonstrate the effectiveness of our method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>One of the hallmarks of the recent success of deep learning methods in computer vision is the ability to learn effective representations in one domain and apply these on another domain <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b15">16]</ref>. The source and target domains might differ in the underlying probability distribution, the imaging modality, and, often, in the task performed. A striking example is image captioning <ref type="bibr" target="#b11">[12]</ref>, in which image representations trained on ImageNet <ref type="bibr" target="#b3">[4]</ref> are transferred along with word embeddings trained on Wikipedia and other corpora <ref type="bibr" target="#b20">[21]</ref> in order to solve a seemingly complex task of describing images with sentences.</p><p>Another task where transfer learning has been shown to be effective is face recognition. In this task, face representations are trained on large datasets collected from social networks or search engines. The representations are trained to solve the multiclass classification problem using a cross entropy loss and are then transferred to a different domain, e.g., the celebrity images of the LFW dataset <ref type="bibr" target="#b10">[11]</ref>. Moreover, the task changes post-transfer to face verification (same/not-same).</p><p>An effective algorithm for face verification based on engineered or learned representations is the Joint Bayesian (JB) method <ref type="bibr" target="#b1">[2]</ref>. JB, similarly to other Bayesian methods, such as Linear Discriminant Analysis (LDA), is based on the interplay between the within class covariance matrix S w and the between class covariance matrix S b . We prove (Thm. 5) that JB fails to be discriminative whenever LDA fails, i.e., when the Fisher ratio (Eq. 20 below) is low.</p><p>When empirically observing the spectrum of Fisher ratios associated with the transferred representations, we noticed that only a handful of the generalized eigenvectors of S b and S w present large eigenvalues. The other directions are therefore non-discriminative and the representation can be considered flat.</p><p>To amend this situation, we propose to employ, in the source domain, a generalization of the cross entropy loss. In this generalization, multiple sets of classifiers are learned, such that the group of classifiers for each class is orthogonal. Each set of classifiers is trained using a separate cross entropy loss, and gives rise to its own set of probabilities.</p><p>When performing such training a few non-trivial properties emerge: (i) For each training sample, the vector of probabilities obtained is identical across the classifier sets; (ii) The dimensionality of the representation is reduced and (iii) The Fisher Spectrum displays multiple directions with high Fisher scores. In a series of theorems, we expose how the new loss leads to these properties.</p><p>Finally, we demonstrate experimentally the both the effectiveness of our method and the consequences of the emerging properties. For example, using a single network, we obtain 2nd best results for a single network on LFW <ref type="bibr" target="#b10">[11]</ref>. This is achieved using a a training set that is a few orders of magnitude smaller than that of the leading literature network <ref type="bibr" target="#b22">[23]</ref>, and using a very compact representation of only 51 dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Compound losses for training deep neural networks that are created by combining multiple losses are now commonplace. In the very deep GoogLeNet network <ref type="bibr" target="#b29">[30]</ref> multiple cross entropy losses are distributed at different intermediate layers of the deep network in order to help avoid vanishing gradients. In contrast, our work supports multiple cross entropy losses at the top layer and for different reasons.</p><p>In many other cases, multiple losses are used in order to support multiple tasks by the same network. For example, in object detection and object segmentation, the location of the object is recovered jointly with the associated detection probability <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b30">31]</ref>. This is in contrast to our case, where the same loss is used multiple times in order to improve the performance of one task.</p><p>In our work, we create multiple losses by constructing multiple top classification layers on top of a shared network representation. Each classification layer has one output neuron per class. The weights from the representation to this neuron are the classifier weights for this specific classifier. In order to enforce multiplicity among the classifiers of the same class, we add an orthogonality constraint, which is enforced either in the representation space or in a Fisher spectrum aligned space. A number of ways to encourage diversity in a classifier ensemble by enforcing orthogonality have been studied in the machine learning literature <ref type="bibr" target="#b0">[1]</ref> and in computer vision <ref type="bibr" target="#b16">[17]</ref>. However, note that in our case orthogonality does not lead to diversity since all classifiers end up presenting the same set of probabilities.</p><p>A prominent example of the success of transfer learning can be seen in the task of face recognition. Starting with the work of Taigman et al. <ref type="bibr" target="#b31">[32]</ref>, a neural network has been employed for extracting representations from face images that are shown to outperform humans. Sun et al. <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b25">26]</ref> further improve the state-of-art by extracting features from multiple face patches, incorporating architectures into the domain of deep face recognition that are inspired by recent architectures that are used for object recognition <ref type="bibr" target="#b23">[24]</ref>, and most relevant to our work, combining, during training, both classification and contrastive loss. Another recent work <ref type="bibr" target="#b22">[23]</ref> further improves the training criterion by using a triplet cost to increase the discriminability between identities. The idea presented here, of combining multiple copies of the same loss, was not pursued in previous works.</p><p>The deep face networks mentioned above, are all trained on large scale proprietary datasets, which are not publicly available. Yi et al. <ref type="bibr" target="#b40">[41]</ref> built a publicly available dataset by mining images from the internet. Furthermore, they demonstrated the quality of the data collected by training a stateof-the-art network on it. Their network architecture is similar to that of the VGG model <ref type="bibr" target="#b23">[24]</ref>. JB is used to effectively enhance performance. In our work, we use the same architecture suggested in <ref type="bibr" target="#b40">[41]</ref> as the basis of our face recognition experiments. We also employ JB to learn similarities for faces and other objects. A recent paper using JB outside the domain of face recognition is <ref type="bibr" target="#b39">[40]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminaries and notation</head><p>The notations used in this work are summarized in Tab. <ref type="bibr" target="#b0">1</ref> The aggregated loss function: </p><formula xml:id="formula_0">n i=1 L i . F * , b *<label>(</label></formula><formula xml:id="formula_1">1] c×1 . p i (j)</formula><p>Vector of probabilities associated with d i . S b (S w ) The between (within) class covariance matrix.  </p><formula xml:id="formula_2">= n i=1 L i (F, b, d i , y i ).</formula><p>The loss function L is a convex function of F, b <ref type="bibr" target="#b2">[3]</ref>. F and b do not define the mapping from sampled d i to probability vectors p i in a unique way, and there are multiple minimizers for L as the following lemma shows. Lemma 1. The minimizers F * , b * of L are not unique, and it holds that for any vector v ∈ R c and scalar s, the solu-</p><formula xml:id="formula_3">tions F * + v1 ⊤ c , b * + s1 c are also minimizers of L.</formula><p>Proof. This proof and all other omitted proofs are provided in the supplementary material.</p><p>In this work, we study the compound loss that is obtained as m r=1 L(F r , b r , D, y) for m different sets of classifiers F r , b r . More specifically, let the set of classifier parameters be</p><formula xml:id="formula_4">F 1 = f 1 1 . . . f 1 c ,b 1 , ...F m = [f m 1 . . . f m c ]</formula><p>,b m , we enforce orthogonality for each class. This is done either in the conventional way: ∀jrs f r⊤ j f s j = 0, or in the domain of the within class covariance matrix ∀jrs f r⊤ j S w f s j = 0. We call the second type of orthogonality "S w -orthogonality".</p><p>The S w orthogonality is directly related to our goal of improving the number of distinct discriminative directions, as captured by the Fisher ratios. This is explored in Sec. 5. It resembles, other methods that down-regulate the contribution of the directions in the vector space that account for much of the within class covariance, such as WCCN <ref type="bibr" target="#b8">[9]</ref>.</p><p>In practice, this orthogonality is enforced by adding loss terms of the form λ|f r⊤ j f s j | or λ|f r⊤ j S w f s j |. The value of λ used throughout our experiments is 0.005, which is, for comparison, 10 times larger than the weight decay used during training. This value is high enough to ensure solutions that are very close to orthogonality (normalized dot products lower than 10 −3 ) in all of our experiments. Higher weights might hinder an effective exploration of the parameter space during optimization.</p><p>For the S w orthogonality, S w depends on the representation and is estimated for each train mini-batch separately.</p><p>In all experiments, a mini-batch of 200 samples was used.</p><p>While the values of S w change between mini-batches, we found the estimations to be reliable.</p><p>Since multiple copies of the same loss are used, we term our loss "the multiverse loss". The choice of term is further motivated by the property, discussed below, that all copies are different (due to orthogonality) but provide the same probabilistic outcome.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Properties of the learned representation</head><p>When employing the multiverse loss m r=1 L(F r , b r , D, y) for training the neural network, under either orthogonality constraint, the learned representation displays a few desirable properties. The first property is that for every two classifiers F r ,b r and F s ,b s the parameters are intimately related. The nature of this link depends on the rank of D. For a full rank D, the solutions are highly constrained, which can be seen as a very restrictive form of regularization. This leads to a lower rank representation, where orthogonal solutions are linked by rank-1 modifications.</p><p>We will be using the following Lemma in order to prove Thm 1.</p><formula xml:id="formula_5">Lemma 2. Let K = n i=1 d i d ⊤ i be a full rank d×d matrix, i.e.,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>it is PD and not just PSD, then for all vector</head><formula xml:id="formula_6">q ∈ R n such that ∀i q i &gt; 0, the matrixK = n i=1 q i d i d ⊤ i is also full rank. Proof. For every vector v ∈ R d , v ⊤K v ≥ (min i q i )v ⊤ Kv &gt; 0.</formula><p>The following theorem links any two optimal solutions in the case in which D is full rank. Note that the orthogonality constraint is not assumed. there exists some vector v ∈ R c and some scalar s such that</p><formula xml:id="formula_7">F 1 − F 2 = v1 ⊤ c and b 1 − b 2 = s1 c .</formula><p>Proof. For simplicity we prove the case where</p><formula xml:id="formula_8">b 1 = b 2 = 0, the case where b 1 , b 2 = 0 is similar. Let Ψ = [ψ 1 , ψ 2 , .</formula><p>. . , ψ c ] = F 2 − F 1 , and let ψ denote the concatenation of the column vectors ψ j into a single column vector. Given that F 1 , F 2 achieve minimal loss, from convexity it must hold that:</p><formula xml:id="formula_9">ψ T ∇ 2 L(D, y) F 1 ψ = ψ T ∂L(D, y) 2 ∂F ∂F F 1 ψ = 0 (1)</formula><p>where ∇ 2 L * (D, y) is the hessian of the loss. We will show that in order for ψ to lie in its kernel it must hold that</p><formula xml:id="formula_10">ψ 1 = ψ 2 . . . = ψ c . Recall that p i (j)is the vector of softmax probabilities associated with d i . ∂ ∂F ju L(D, y) = − n i=1 d iu p i (j) − i,yi=u d iu (2) ∂ 2 ∂F ju F j ′ v L(D, y) = − n i=1 d iu d iv p i (j)(δ j=j ′ (1 − p i (j)) − δ j =j ′ p i (j ′ ))<label>(3)</label></formula><p>Therefore:</p><formula xml:id="formula_11">ψ ⊤ ∂ 2 ∂F ∂F L(D, y)ψ = c j=1 ψ ⊤ j n i=1 d i d ⊤ i p i (j)(1−p j (u))ψ j − c j=1 j ′ =j ψ ⊤ j n i=1 d i d ⊤ i p i (j)p j ′ (v)ψ j ′ (4) Since (1 − p i (j)) = j ′ =j p i (j ′ )</formula><p>, the first term of Eq. 4 can be written as follows:</p><formula xml:id="formula_12">c j=1 ψ ⊤ j n i=1 d i d ⊤ i p i (j)(1 − p i (j))ψ j = c j=1 j ′ =j ψ ⊤ j n i=1 d i d ⊤ i p i (j)p i (j ′ )ψ j = c j=1 c j ′ =j+1 [ψ ⊤ j n i=1 d i d ⊤ i p i (j)p i (j ′ )ψ j + ψ ⊤ j ′ n i=1 d i d ⊤ i p i (j)p i (j ′ )ψ j ′ ]<label>(5)</label></formula><p>Similar manipulation can be done with the second term of Eq. 4:</p><formula xml:id="formula_13">− c j=1 j ′ =j ψ ⊤ j n i=1 d i d ⊤ i p i (j)p i (j ′ )ψ j ′ = − c j=1 c j ′ =j+1 2ψ ⊤ j n i=1 d i d ⊤ i p i (j)p i (j ′ )ψ j ′ (6)</formula><p>Adding the two term we get:</p><formula xml:id="formula_14">ψ ⊤ ∂ 2 ∂F ∂F L(D, y) F 1 ψ = c j=1 c j ′ =j+1 (ψ j − ψ j ′ ) ⊤ n i=1 d i d ⊤ i p i (j)p i (j ′ )(ψ j − ψ j ′ )<label>(7)</label></formula><p>Since ∀i, j p i (j) &gt; 0 and since rank(D) is full,</p><formula xml:id="formula_15">n i=1 d i d ⊤ i p i (j)p i (j ′ )</formula><p>is PD. Eq 7 is therefor the sum of positive values, and can only vanish if and only if ψ j = ψ j ′ for all j, j ′ .</p><p>In our method, we require that the multiple solutions found F 1 ,F 2 (possibly more) lead to orthogonal (or S worthogonal) separating hyperplanes for each class. The theorem below shows that unless D is degenerate, this requirement leads to either an increase of the total loss, or to a very specific and limiting type of regularization on F 1 . Such a stringent regularization would hinder effective learning. For convenience, we state and prove Thm. 2, 3, 4 for the case of conventional orthogonality. The analog theorems for S worthogonality are stated in the same way, and proven similarly, after applying the transformation S Theorem 2. Assume that rank(D) = d, that d &lt; c, and that the minimal loss L * (D, y) is obtained at a solution F 1 , b 1 . If there exists a second minimizer F 2 , b 2 such that for all j ∈ [1...c] the orthogonality constraint f 1 j ⊥ f 2 j holds, then F 1 admits to a stringent second order constraint.</p><p>The situation described in Theorem 2 is even worse for more than two sets of orthogonal weights on top of the representation D. The solution in the case of m orthogonal sets would be restricted to lie on the intersection of m 2 hyperellipses.</p><p>The crux of Theorem 2 is the full rank property of D. As the theorems below show, if D has m − 1 low singular values, we can construct solutions with m orthogonal sets of weights that present loss that is only slightly higher than mL * <ref type="figure">(D, y)</ref>.</p><p>Specifically, let λ 1 , λ 2 , ..., λ d denote the (all nonnegative) eigenvalues of the kernel matrix K = DD ⊤ , ordered from largest to smallest. We can bound the loss based on the last eigenvalues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 3. There exist sets of weights</head><formula xml:id="formula_16">F 1 = f 1 1 , f 1 2 , ..., f 1 c , b 1 , F 2 = f 2 1 , f 2 2 , .</formula><p>.., f 2 c , b 2 which are orthogonal as follows ∀j f 1 j ⊥ f 2 j , for which the joint loss:</p><formula xml:id="formula_17">J(F 1 , b 1 , F 2 , b 2 , D, y) = L(F 1 , b 1 , D, y)+L(F 2 , b 2 , D, y) (8) is bounded by 2L * (D, y) ≤ J(F 1 , b 1 , F 2 , b 2 , D, y) ≤ 2L * (D, y)+Aλ d<label>(9)</label></formula><p>where A is a bounded parameter.</p><p>Proof. We prove the theorem by constructing such a solution. Let v be the eigenvector of K corresponding to the smallest eigenvalue λ d . We consider the solution</p><formula xml:id="formula_18">F 1 = F * ,b 1 = b 2 = b * , F 2 = F 1 + vα ⊤ , for some vector α j = − ||f 1 j || 2 v ⊤ f 1 j .</formula><p>From the construction, it is clear that L(F 1 , b 1 , D, y) = L * (D, y) and that the orthogonality constraints (f 1 j + α j v) ⊤ f 1 j = 0 hold for all j. Let Ψ = [ψ 1 , ψ 2 , . . . , ψ c ] = F 2 − F 1 , and let ψ denote the concatination of the column vectors ψ j into a single column vector. The expansion of L(F 1 + Ψ, b 1 ) into a multivariate taylor series is as follows:</p><formula xml:id="formula_19">L(F 1 +Ψ, b 1 ) = L(F 1 , b 1 )+( ∇·ψ)L(D, y) F 1 ,b 1 +R(ψ).<label>(10)</label></formula><p>Where R(ψ) represents the remainder term, and can be written in the Lagrange form <ref type="bibr" target="#b12">[13]</ref> as follows:</p><formula xml:id="formula_20">R(ψ) = 1 2 ( ∇·ψ) 2 L(D, y) ρ,b 1 = ψ ⊤ 2 ∂ 2 ∂F ∂F L(D, y) ρ,b 1 ψ<label>(11)</label></formula><p>where the derivatives are evaluated at some point ρ, b 1 such that ||ρ − F 1 || F ≤ ||Ψ − F 1 || F . The first order terms in Eq. 10 vanishes due to the optimality of F 1 , b 1 . Therefore:</p><formula xml:id="formula_21">L(F 1 +Ψ, b 1 ) = L * (D, y)+ 1 2 ψ ⊤ ∂ 2 ∂F ∂F L(D, y) ρ,b 1 ψ<label>(12)</label></formula><p>Using Eq. 7 we can form a bound on the remainder term that does not depend on ρ:</p><formula xml:id="formula_22">L(F 1 + Ψ, b 1 ) = L * (D, y) + 1 2 c j=1 c j ′ =j+1 (ψ j − ψ j ′ ) ⊤ n i=1 d i d ⊤ i p i (j)p i (j ′ )(ψ j − ψ j ′ ) ≤ L * (D, y) + 1 2 c j=1 c j ′ =j+1 (ψ j − ψ j ′ ) ⊤ K(ψ j − ψ j ′ )<label>(13)</label></formula><p>Since ψ j = α j v we get:</p><formula xml:id="formula_23">L(F 1 +Ψ, B 1 ) ≤ L * (D, y)+ 1 2 c j=1 c j ′ =j+1 (α j −α j ′ ) 2 v T Kv = L * (D, y) + 1 2 c j=1 c j ′ =j+1 (α j − α j ′ ) 2 λ d (14) Denoting A = 1 2 c j=1 c j ′ =j+1 (α j − α j ′ ) 2 we have: J(F 1 , B 2 , F 1 , B 2 , D, y) ≤ L * (D, y) + Aλ d<label>(15)</label></formula><p>Thm. 3 can be generalized to the case of m cross entropy losses as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 4. There exist a set of weights</head><formula xml:id="formula_24">F 1 = f 1 1 , f 1 2 , ..., f 1 C , b 1 , F 2 = f 2 1 , f 2 2 , ..., f 2 C , b 2 ...F m = [f m 1 , f m 2 , ..., f m C ] , b m which are orthogonal ∀jrs f r j ⊥ f s j</formula><p>for which the joint loss:</p><formula xml:id="formula_25">J(F 1 , b 1 ...F m , b m , D, y) = m r=1 L(F r , b r , D, y) (16)</formula><p>is bounded by: <ref type="formula" target="#formula_0">(17)</ref> where [A 1 . . . A m−1 ] are bounded parameters.</p><formula xml:id="formula_26">mL * (D, y) ≤ J(F 1 , b 1 ...F m , b m , D, y) ≤ mL * (D, y) + m−1 l=1 A l λ d−j+1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Fisher spectrum properties</head><p>We next tie the outcome of the multiverse minimization to the Fisher scores used in LDA classification, which served as motivation to our approach. The Fisher spectrum γ 1 . . . γ d is obtained by solving the generalized eigenproblem S b v = γS w v, where S b and S w may be approximated by the between class and within class covariance matrices:</p><formula xml:id="formula_27">S b = 1 n c j=1 n j (µ − µ j )(µ − µ j ) ⊤ (18) S w = 1 n c j=1 i∈Ij (d i − µ j )(d i − µ j ) ⊤<label>(19)</label></formula><p>where µ = n i=1 di n is the mean of all data points, and µ j = i∈I j di nj is the mean of class j. S b and S w are the same matrices used in LDA.</p><p>The Fisher ratio is defined for any vector v as:</p><formula xml:id="formula_28">σ(v, S b , S w ) = v T S b v v T S w v<label>(20)</label></formula><p>In the JB formulation, an instance of a class member is influenced by two factors, its class identity and interclass variation. Each class member d i is modeled as the sum of two Gaussian variables: d i = µ yi +ǫ, where µ yi is the mean of class y i , and ǫ represents the intraclass variation. The two terms are modeled as multivariate <ref type="figure">Gaussians N (0, S b )</ref>, N (0, S w ).</p><p>Given the above multivariate Gaussian distribution for d i , the joint distribution (d i , d i ′ ) is also a zero mean multivariate Gaussian. Let H represent the hypothesis that d i and d i ′ belong to the same class, and I represent the hypothesis that they belong to different classes. Under the JB formulation, the covariance matrix of the probability distributions P (d i , d i ′ |H) and P (d i , d i ′ |I) can be derived:</p><formula xml:id="formula_29">Σ H = S b + S w S b S b S b + S w , Σ I = S b + S w 0 0 S b + S w (21) Letd = ((d i − µ) ⊤ , (d i ′ − µ) ⊤ ) ⊤ .</formula><p>The log probabilities of the two hypotheses are given, up to a const, byd ⊤ Σ −1</p><formula xml:id="formula_30">Hd andd ⊤ Σ −1</formula><p>Id . The following theorem links the Fisher spectrum to the success of the JB method.</p><p>Theorem 5. Given data representation D, mean µ and labels y, for any centered data pointd i = d i − µ, we denote</p><formula xml:id="formula_31">d ′ i = (S b + S w ) −1d</formula><p>i . Given two centered data pointsd 1 ,d 2 such that the fisher ratios σ(d ′ 1 , S b , S w ), σ(d ′ 2 , S b , S w ) &lt; T , it holds that:</p><formula xml:id="formula_32">1 − 2T ≤ log P (d 1 , d 2 |H) + η 1 log P (d 1 , d 2 |I) + η 2 ≤ 1 + 6T<label>(22)</label></formula><p>Where η1, η2 are fixed constants.</p><p>Theorem 5 indicates that in the directions of low Fisher ratio the JB method cannot distinguish between the two competing hypotheses and determine whether the two samples d i and d i ′ belong to the same class.</p><p>We observed during experiments performed on a number of datasets, that training of a CNN using a single cross entropy loss produces a representation that has a rapidly decreasing Fisher spectrum, and is highly discriminative in only a few directions. Reducing the representation dimension, i.e., using a bottleneck technique helps in reducing the total number of dimensions but does not seem to increase the number of discriminative dimensions. We next show that by optimizing for multiple orthogonal solutions, we promote more directions that have high Fisher scores.</p><p>Since the hyperplanes f r i learned during optimization are discriminative, we can expect most of these to have high Fisher ratios. The multiplicity created by the multiverse loss, leads to multiple orthogonal hyperplanes. Since the probabilities produced by the matching hyperplanes are identical, it is likely that all matching hyperplanes f r j , and f s j have similar Fisher ratios. The theorem below shows that adding more S w -orthogonal classifiers with high Fisher ratios increases the L1 norm of the Fisher spectrum.</p><p>Theorem 6. Let f 1 ...f m be a set of m classifiers that are S w -orthogonal for data D and labels y, and let γ = [γ 1 ...γ d ] denote the Fisher spectrum. Given that ∀1 ≤ r ≤ m, for some value θ, σ(f r ,</p><formula xml:id="formula_33">S b , S w ) ≥ θ, it holds that d k=1 γ k ≥ √ mθ .</formula><p>In Thm. 6 we used the S w orthogonality of the solutions to guarantee the result, however it is not a necessary condition. From our experiment we noticed an improved Fisher spectrum when both S w and the standard orthogonality condition were used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>In order to evaluate the effect of using the multiverse loss on performance, we have conducted experiments on two widely used datasets: CIFAR-100 and LFW. While the CIFAR-100 experiments are performed using a new transfer learning protocol, the LFW experiments provide a direct empirical comparison to a large body of previous work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Network architecture</head><p>In our experiments, we employ three network architectures. For the CIFAR-100 experiments, we use the architecture of network in network <ref type="bibr" target="#b17">[18]</ref>; for the face recognition experiments, we use an architecture similar to the scratch architecture <ref type="bibr" target="#b40">[41]</ref> for most of our experiments (Denoted by N 1). We also use a higher capacity network similar to <ref type="bibr" target="#b23">[24]</ref> for further evaluation (Denoted by N 2). The networks were trained from scratch at each experiment, using the MatCon-vNet framework <ref type="bibr" target="#b36">[37]</ref>.</p><p>All networks are fully convolutional, and we added a hidden layer on top of the N 1 network to apply our method on top of a vector of activations. This modification is not strictly needed and was made for implementation convenience. This top layer was used as the representation. The architectures used are fully described in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Results</head><p>The CIFAR-100 <ref type="bibr" target="#b13">[14]</ref> contains 50,000 32 × 32 color images, split between 100 categories. The images were extracted from the tiny image collection <ref type="bibr" target="#b34">[35]</ref>. Throughout our experiments, the first 90 classes (class ids 0 to 89) are used as the source domain, and the last 10 as the target domain. Our experiments compare six architectures: a baseline with one cross entropy loss ("M1"); four multiverse architectures with 2-5 such losses ("M2-M5"); and an ensemble of five networks with a single cross entropy loss each. The last method was added to demonstrate that our method's benefit is greater than that of combining multiple networks. Note, however, that when compounding losses, the overall network architecture resembles that of a single network and is almost as efficient to train and deploy as the baseline network. One can easily create ensembles of networks with multiverse losses, as we do for the LFW benchmark.</p><p>We report the methods' performance in multiple ways. The validation error reports the error rate obtained, in the source domain of 90 classes, on the 10% of the data reserved for this purpose. In the target domain, two metrics are used: same/not-same accuracy using either the cosine distance or the JB method. Note that the cosine distance is unsupervised, and that we train the JB on the validation set of the source domain. Hence, no training was done in the target domain. For the same/not-same evaluation, 3000 matching and 3000 non-matching pairs were randomly sampled from the 10 classes of the target domain.</p><p>As can be seen in Tab. 2, the multiverse method outperform the baseline and the ensemble methods on the target domain, in each of the accuracy metrics. It is also evident that adding more cross entropy losses improves performance. The preferable separation between the classes is also depicted visually in <ref type="figure" target="#fig_2">Fig. 1</ref>, where the 2D embedding of the baseline (M1) representation is compared to that obtained using the M5 multiverse method. For the purpose of this visualization, the TSNE <ref type="bibr" target="#b35">[36]</ref> embedding method is used.</p><p>As mentioned above, for the face recognition experiments, we use the scratch model <ref type="bibr" target="#b40">[41]</ref>. The networks are trained on the CASIA dataset <ref type="bibr" target="#b40">[41]</ref>; LFW dataset <ref type="bibr" target="#b10">[11]</ref> is used as the target domain.</p><p>Models are evaluated in the source domain by measuring the classification accuracy on the CASIA dataset, which we split to 90% training and 10% validation. For the target domain, the LFW benchmark in the unrestricted mode <ref type="bibr" target="#b9">[10]</ref> is used (we do not use person ID from LFW, but do use the IDs of the CASIA dataset). The LFW results are mean and Standard Error estimated over the fixed ten cross-validation splits. JB is either trained on the CASIA validation split or on the LFW dataset itself in a cross validation manner.</p><p>In the LFW experiments, we performed the M1 (baseline), M3, and M5 experiments multiple times, in order to show the stability of the results and to support ensembles. The S w -orthogonality multiverse method, which is slower to train, was not tested on LFW by the submission date. As can be seen in Tab. 3, the multiverse loss outperforms, in the target domain, the baseline method and also outperforms the ensemble of multiple baseline networks. This is true for the cosine similarity, as well as for the two JB experiments. Interestingly, multiverse does not show an advantage in the source domain (this does not weaken our claims).</p><p>In face recognition, the effect of the training dataset sometimes overshadows that of the method. We, therefore, employed a proprietary 800k images 3rd party dataset, which does not intersect the identities of the LFW dataset. In comparison to CASIA's 500k images, the 3rd party dataset is slightly larger and contains fewer tagging mistakes. As can be seen in Tab. 3, this leads to an improvement in performance.</p><p>The results we obtained are compared in Tab. 4 to the state of the art as reported on the LFW webpage on the date of the submission. Our results, which use a fairly simple fully convolutional architecture, achieves the highest ranking for a single network outperforming all results, except one result <ref type="bibr" target="#b22">[23]</ref>, which was obtained using 200 million images. In addition to performance, we also examined the effect of the multiverse loss on the properties of the representation. <ref type="figure" target="#fig_5">Fig. 2</ref> demonstrate the singular values of the data representation in the transfer domain on (a) CIFAR-100 using conventional orthogonality and (b) LFW. As can be seen, the multiverse network (M5) has larger singular values. However, these drop to zero abruptly whereas the spectrum of the baseline representation continues to decay gradually. As a result, the representation of our method is of a lower dimension, and is more balanced among the dimensions. <ref type="figure" target="#fig_5">Fig. 2 (c) and (d)</ref> show the generalized eigenvalues of S b and S w in the target domain. As can be seen, the multiverse method promotes larger Fisher ratios.</p><p>The sharp drop in the data dimensionality that is promoted by the multiverse method leads to very compact representations. The dimensionality of our best single network (M5, 3rd party dataset), is only 51 <ref type="figure">(Fig. 4(b)</ref>). This is a very compact representation, which is much lower than any other state of the art network.  <ref type="table">Table 4</ref>. Comparison to state of the art results on LFW. We present the best result for a single network, with the exception of FaceNet, which was trained on a dataset which is a hundred times larger than ours. A star (*) indicates commercial systems whose claimed results were not peer reviewed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>This work presented the emergence of surprising and desirable properties of the representation layer of a deep neural network when learning multiple orthogonal solutions. The practical implications of our work are far reaching since the suggested method is easy to incorporate into almost any architecture.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>any) global minimizers of L(D, y). L * (D, y) The minimum value of L given D, y, i.e L(F * , b * , D, y). K The linear kernel matrix of the data: DD ⊤ . 1 c An all 1 vector of length c: [1, 1 . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Classification is performed by projecting the representations d i by a d × c classifier matrix F = [f 1 . . . f c ] and adding biases b ∈ R c . Softmax probabilities are obtained asp i (y i ) = e d ⊤ +b j .The training loss of a single example is the negativelog likelihood and is a function of the classifier parameters F ,b, the representation D, and the labels y: L i (F, b, D, y) = − log p i (y i ). The aggregated cross entropy loss is L(F, b, D, y)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Theorem 1 .</head><label>1</label><figDesc>Assume the minimal loss L * (D, y) is obtained at two solutions F 1 , b 1 and F 2 , b 2 . If rank(D) = d, then</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 .</head><label>1</label><figDesc>2D embedding (TSNE<ref type="bibr" target="#b35">[36]</ref>) of the representation of (a) conventional cross entropy and (b) multiverse (M5). The 10 target classes of the CIFAR-100 experiment are shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 .</head><label>2</label><figDesc>Various spectrums obtained in the target domain. Each plot shows singular values (first row) or generalized eigenvalues (second row), sorted separately for each of three methods. Solid blue is the result obtained for M5. The dotted red line is the M3 result, and the baseline M1 is shown as dashed green. (a-b) For CIFAR-100 employing conventional orthogonality, CIFAR-100 Sw orthogonality, and LFW, respectively, the singular values of the kernel matrix K = DD ⊤ are shown. The multiverse loss leads to higher values until it drops to zero earlier than the conventional spectrum. (c-d) The Fisher spectrum, i.e., the generalized eigenvalues of Sw and S b for the same datasets:(c) CIFAR conventional orthogonality and (d) LFW. As a result of applying the multiverse method, there is an increase in the magnitude of the eigenvalues..</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>. n training samples, indexed by i = 1 . . . n are represented, using a network of any depth as "neural code" vectors of length d, D d×n = [d 1 . . . d n ]. Each sample is associated with a label y i ∈ [1 . . . c].</figDesc><table>Symbol 
c 
Number of classes, typically indexed by j. 
n 
Number of data points, typically indexed by i. 
y 
n × 1 vector of labels. Each label is y i . 
d 
Dimensionality of the representation vectors. 
D 
d × n features matrix. 
d i 
A column of D, the representation of sample i. 
F 
d × c classifier matrix of weights. 
f i 
A column of F ; A normal to the separating hy-
perplane of class i. 
b 
c × 1 vector of parameters (biases). 
L i 
Loss function value evaluated for data point i. 
L 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 .</head><label>1</label><figDesc>Summary of notations.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>Table 3. Face recognition results. Shown are the validation error on CASIA, and transfer results on LFW. The cosine similarity as well as learned JB similarities are shown. The JB was either trained on CASIA or on the LFW training splits. The LFW results confirm with the unrestricted mode and report mean and Standard Error of the accuracy obtained for the ten cross validation splits. Network architecture N1 is the scratch architecture<ref type="bibr" target="#b40">[41]</ref>; N2: a VGG style network<ref type="bibr" target="#b23">[24]</ref>.</figDesc><table>Domain 

Source 
Target (transfer) 
Metric 
Network Val error 
Cosine 
JB on source 
JB on LFW splits 
CASIA trained M1 
N 1 
0.07 
0.962 ± 0.0032 0.966 ± 0.0022 
0.970 ± 0.0016 
CASIA trained M1 (2) 
N 1 
0.07 
0.962 ± 0.0021 0.966 ± 0.0019 
0.971 ± 0.0022 
CASIA trained M1 (3) 
N 1 
0.07 
0.961 ± 0.0022 0.966 ± 0.0013 
0.971 ± 0.0015 
Ensemble of 3 CASIA M1 
N 1 
0.968 ± 0.0019 0.972 ± 0.0021 
0.975 ± 0.0025 
CASIA trained M2 
N 1 
0.08 
0.970 ± 0.0021 0.974 ± 0.0017 
0.976 ± 0.0016 
CASIA trained M3 
N 1 
0.11 
0.972 ± 0.0012 0.977 ± 0.0015 
0.980 ± 0.0034 
CASIA trained M3 (2) 
N 1 
0.11 
0.971 ± 0.0031 0.977 ± 0.0028 
0.979 ± 0.0027 
CASIA trained M5 (1) 
N 1 
0.12 
0.973 ± 0.0011 0.978 ± 0.0014 
0.981 ± 0.0019 
CASIA trained M5 (2) 
N 1 
0.12 
0.972 ± 0.0015 0.977 ± 0.0019 
0.980 ± 0.0031 
3rd party DB, M5 
N 2 
0.12 
0.982 ± 0.0034 0.986 ± 0.0031 
0.988 ± 0.0035 

Method 
Single network 
Ensemble result #nets Training dataset 
M5 
0.9814 ± 0.0019 
-
CASIA [41] 
M5, 3rd party DB 
0.9883 ± 0.0035 0.9905 + 0.0027 
2 
proprietary 800k images 
DeepFace [32] 
0.9700 ± 0.0087 0.9735 ± 0.0025 
7 
proprietary, 4M images 
DeepID [28] 
-
0.9745 ± 0.0026 
25 
proprietary,160k 
Original scratch [41] 
0.9773 ± 0.0031 
-
1 
CASIA [41] 
Web-Scale Training [33] 
0.9800 
0.9843 
4 
proprietary, 500M images 
MSU TR [38] 
0.9745 ± 0.0099 0.9823 ± 0.0068 
7 
CASIA [41] 
MMDFR [5] 
0.9843 ± 0.0020 0.9902 ± 0.0019 
8 
CASIA [41] 
DeepID2 [25] 
0.9633 
0.9915 ± 0.0013 
25 
proprietary,160k 
DeepID2+ [29] 
0.9870 
0.9947 ± 0.0012 
25 
proprietary,290k 
FaceNet [23] 
0.9967 ± 0.0015 0.9963 ± 0.0009 
8 
proprietary, 200M 
FR+FCN [43](*) 
-
0.9645 ± 0.0025 
5 
CelebFaces [27], 88k 
betaface.com(*) 
-
0.9808 ± 0.0016 
NA 
NA 
Uni-Ubi(*) 
-
0.9900 ± 0.0032 
NA 
NA 
Face++ [42](*) 
-
0.9950 ± 0.0036 
4 
proprietary, 5M face images 
DeepID3 [26](*) 
-
0.9953 ± 0.0010 
25 
proprietary,300k 
Tencent-BestImage(*) 
-
0.9965 ± 0.0025 
20 
proprietary, 1M face images 
Baidu [19](*) 
-
0.9977 ± 0.0006 
10 
proprietary, 1.2M face images 
AuthenMetric(*) 
-
0.9977 ± 0.0009 
25 
proprietary, 500k face images 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research is supported by a 2015 IBM Faculty Award. We are thankful for RealFace for providing the 3rd party DB mentioned in Sec. 6.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Diversity creation methods: a survey and categorisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wyatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="20" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bayesian face revisited: A joint formulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Elements of Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Series in Telecommunications and Signal Processing)</title>
		<imprint>
			<publisher>Wiley-Interscience</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR09</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Robust face recognition via multimodal deep face representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<idno>abs/1509.00244</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">One-shot learning of object categories. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="594" to="611" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fast R-Cnn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corr</surname></persName>
		</author>
		<idno>abs/1504.08083</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Within-class covariance normalization for svm-based speaker recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">O</forename><surname>Hatch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kajarekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICSLP</title>
		<meeting>of ICSLP</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">14711474</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
		<title level="m">Labeled faces in the wild: Updates and new reporting procedures. UM-CS-2014-003</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Labeled faces in the wild: A database for studying face recognition in unconstrained environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007-10" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<pubPlace>Amherst</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report 07-49</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep visual-semantic alignments for generating image descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Calculus: an intuitive and physical approach. Courier Corporation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kline</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning Multiple Layers of Features from Tiny Images. Master&apos;s thesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">From n to n+ 1: Multiclass transfer incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kuzborskij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3358" to="3365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Minimal correlation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2012</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="29" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Network in network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Targeting ultimate accuracy: Face recognition via deep embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<idno>abs/1506.07310</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Model adaptation with least-squares SVM for adaptive hand prosthetics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Castellini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Fiorilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics and Automation, 2009. ICRA&apos;09. IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2897" to="2903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep learning face representation by joint identification-verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1988" to="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Deepid3: Face recognition with very deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<idno>abs/1502.00873</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hybrid deep learning for face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2013 IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2013-12" />
			<biblScope unit="page" from="1489" to="1496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep learning face representation from predicting 10,000 classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deeply learned face representations are sparse, selective, and robust</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Scalable, high-quality object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<idno>abs/1412.1441</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deepface: Closing the gap to human-level performance in face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition, CVPR &apos;14</title>
		<meeting>the 2014 IEEE Conference on Computer Vision and Pattern Recognition, CVPR &apos;14<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1701" to="1708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Web-scale training for face identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Safety in numbers: Learning categories from few examples with multi model knowledge transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">80 million tiny images: A large data set for nonparametric object and scene recognition. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1958" to="1970" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Visualizing highdimensional data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Matconvnet -convolutional neural networks for matlab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lenc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Face search at scale: 80 million gallery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<idno>abs/1507.07242</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Cross-domain video concept detection using adaptive svms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th international conference on Multimedia</title>
		<meeting>the 15th international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="188" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">A large-scale car dataset for fine-grained categorization and verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Learning face representation from scratch. CoRR, abs/1411</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">7923</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Naive-deep face recognition: Touching the limit of LFW benchmark or not? CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yin</surname></persName>
		</author>
		<idno>abs/1501.04690</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Recover canonicalview faces in the wild with deep neural networks. CoRR, abs/1404</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">3543</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
