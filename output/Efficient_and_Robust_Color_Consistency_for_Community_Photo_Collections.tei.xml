<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficient and Robust Color Consistency for Community Photo Collections</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaesik</forename><surname>Park</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Microsoft Research In So Kweon KAIST</orgName>
								<orgName type="institution">Intel Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><forename type="middle">Tai</forename><surname>Sensetime</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Microsoft Research In So Kweon KAIST</orgName>
								<orgName type="institution">Intel Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudipta</forename><forename type="middle">N</forename><surname>Sinha</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Microsoft Research In So Kweon KAIST</orgName>
								<orgName type="institution">Intel Labs</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Efficient and Robust Color Consistency for Community Photo Collections</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present an efficient technique to optimize color consistency of a collection of images depicting a common scene. Our method first recovers sparse pixel correspondences in the input images and stacks them into a matrix with many missing entries. We show that this matrix satisfies a rank two constraint under a simple color correction model. These parameters can be viewed as pseudo white balance and gamma correction parameters for each input image. We present a robust low-rank matrix factorization method to estimate the unknown parameters of this model. Using them, we improve color consistency of the input images or perform color transfer with any input image as the source. Our approach is insensitive to outliers in the pixel correspondences thereby precluding the need for complex pre-processing steps. We demonstrate high quality color consistency results on large photo collections of popular tourist landmarks and personal photo collections containing images of people.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Nowadays, the growing popularity of photo sharing and social networks makes it easy to crowdsource photo collections of popular locations and social events. This has led to applications ranging from virtual tourism and navigation <ref type="bibr" target="#b34">[35]</ref>, image completion <ref type="bibr" target="#b18">[19]</ref>, colorization <ref type="bibr" target="#b6">[7]</ref> and photo uncropping <ref type="bibr" target="#b31">[32]</ref>. However, the color statistics of each image in the collection could differ due to different scene illumination at capture time or due to different non linear camera response functions <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b24">25]</ref>. Such photometric inconsistencies cause visual artifacts in applications that require seamless alignment of multiple overlapping images.</p><p>Although modern image editing packages provide some color correction, and tone adjustment functionalities, these techniques usually require indirect user interaction <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b19">20]</ref>, or direct adjustment of color balance or manipulation of the tone curve. Consequently, these interactive techniques * Part of this work was done while the first and second author were in KAIST. This work was supported in part by the National Research are too tedious for large image collections. On the other hand, individual color correction is likely to produce images with inconsistent colors across the whole collection. Recently, HaCohen et al. <ref type="bibr" target="#b16">[17]</ref> proposed a method to optimize color consistency across an image collection with respect to a reference image that relies on recovering dense pixel correspondence across multiple images <ref type="bibr" target="#b15">[16]</ref>. This method is computationally expensive and not ideal for processing large collections involving thousands of images.</p><p>In this paper, we present a new matrix factorization based approach to automatically optimize color consistency for multiple images using sparse correspondence obtained from multi-image sparse local feature matching. For rigid scenes, we leveraging structure from motion (SfM) although it is an optional step. We stack the aligned pixel intensities into a vector whose size equals the number of images. Such vectors are stacked into a matrix, one with many missing entries. This is the observation matrix that will be factorized. Under a simple color correction model, the logarithm of this matrix satisfies a rank two constraint under idealized conditions (perfect correspondences, no noise, constant illumination). The rank two matrix can be expressed as a sum of two rank one matrices -one that depends on the color correction parameters and another that depends on the albedos of the scene points associated with the sparse correspondences. The color correction parameters can be viewed as pseudo white balance and gamma correction parameters of the image. Here, pseudo indicates that the estimates do not necessarily coincide with the ground truth values.</p><p>Our method is based on the low-rank matrix factorization technique proposed in <ref type="bibr" target="#b3">[4]</ref> that is robust to outliers. Robustness is key to the success of our method since in real conditions, several factors -lighting change, shadows, saturated pixels, incorrect feature correspondences, etc. produce outliers that corrupts the low rank structure of the observation matrix. We also analyze ambiguities in the matrix factorization formulation and suggest ways to resolve them practically. The low rank matrix formulation and the application of the L 1 -norm based robust factorization technique are the main contributions of our work.</p><p>Unlike the previous quadratic optimization problem formulation <ref type="bibr" target="#b16">[17]</ref> which relies on dense and accurate correspon- dence, our technique only requires sparse correspondence. Further more, the inherent robustness of our method makes it less sensitive to outliers and removes the need for complex pre-processing. Our approach is computationally much more efficient than <ref type="bibr" target="#b16">[17]</ref> and is practical for large collections exceeding a thousand images. It can also handle smaller sets of images with significant variation in scale, viewpoint, object pose and deformation, where the recovery of outlierfree dense correspondence is challenging <ref type="bibr" target="#b15">[16]</ref>.</p><p>We evaluate our technique on diverse datasets ranging from large image sets of tourist landmarks ( <ref type="figure" target="#fig_1">Fig. 1</ref> and <ref type="figure" target="#fig_2">Fig. 2)</ref>, Internet images of celebrities as well as personal photo collections. We also demonstrate that color correction and color transfer achieved with our method improves the quality of image stitching, multi-view stereo, and image-based rendering when using crowdsourced photos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>We now review existing methods for color correction categorized by the need or absence of user interaction.</p><p>Single image methods. A popular approach for color correction <ref type="bibr" target="#b2">[3]</ref> utilizes a reference image of a white object to adjust the white balance of other images captured by the same camera under similar illumination. Modern techniques <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b29">30]</ref> exploit statistical relationships between light and colors to estimate illumination of a scene for white balance correction. These methods are automatic, but they are designed for single images and cannot enforce consistent corrections on multiple overlapping images.</p><p>An interactive system used to locally edit tonal values in an image <ref type="bibr" target="#b26">[27]</ref> performs local white balance correction for images with mixed illumination. Another approach proposed by Boyadzhiev et al. <ref type="bibr" target="#b1">[2]</ref> involves a two light source mixture model that is used to correct spatially varying white balance with minimal user input <ref type="bibr" target="#b19">[20]</ref>. However, interactive methods are impractical for very large image collections.</p><p>Batch methods. A few automatic color correction methods exist for large photo collections of rigid scenes. Garg et al. <ref type="bibr" target="#b11">[12]</ref> observe that scene appearance often has low dimensionality and exploit that fact for color correction. Laffont et al. <ref type="bibr" target="#b23">[24]</ref> estimate coherent intrinsic images and transfer localized illumination using the decomposed layers. Díaz et al. <ref type="bibr" target="#b8">[9]</ref> performs batch radiometric calibration using the empirical prior on camera response functions <ref type="bibr" target="#b14">[15]</ref>. Shi et al. <ref type="bibr" target="#b32">[33]</ref> handles the effect of nonlinear camera response using a shape prior. Kim and Pollefeys <ref type="bibr" target="#b21">[22]</ref> introduce a decoupled scheme for radiometric calibration and the vignetting correction. In contrast to <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b32">33]</ref>, our method only requires sparse correspondence. Moreover, images of non-rigid scenes can be handled. For rigid scenes, we optionally use SfM for more accurate correspondence but neither surface normals nor dense 3D models are needed.</p><p>For more general scenes, the non-rigid dense correspondence (NRDC) algorithm proposed by HaCohen et al. <ref type="bibr" target="#b15">[16]</ref> was used to optimize color consistency for image pairs using a linear color transform. Their work in <ref type="bibr" target="#b16">[17]</ref> then targets photo collections by propagating colors of a reference image to other images. This involves estimating optimal parameters of three piecewise-quadratic splines which minimize color differences between all correspondences. However, their quadratic energy formulation is sensitive to errors in matching, and therefore rely on accurate and dense correspondences obtained using a computationally expensive algorithm such as NRDC. This makes their approach less suited for very large photo collections <ref type="bibr" target="#b8">[9]</ref>.</p><p>Instead of using high quality correspondences recovered by NRDC <ref type="bibr" target="#b16">[17]</ref>, our technique uses sparse correspondences and it is also less sensitive to erroneous correspondences due to the underlying robust optimization framework. According to <ref type="bibr" target="#b16">[17]</ref>, an accelerated implementation of NRDC took more than 6 hours to construct the underlying match graph for a set of 865 images on a MacBook Pro (2.3 Ghz Core i7 CPU and 8GM RAM). In contrast, for our TREVI FOUNTAIN (1500 images) dataset, feature matching and SfM in our implementation together took 50 minutes on a desktop PC with about 30 minutes for feature matching. For non-rigid scenes, the SfM stage is replaced by a much faster graph algorithm described in the paper.</p><p>Applications. Both geometric alignment of overlapping images as well as color and gamma correction is crucial for visual aesthetics in applications such as virtual tourism and navigation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref>, photo-realistic rendering <ref type="bibr" target="#b30">[31]</ref>, scene completion <ref type="bibr" target="#b18">[19]</ref>, image colorization <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b27">28]</ref>, image restoration <ref type="bibr" target="#b7">[8]</ref>, image montage <ref type="bibr" target="#b5">[6]</ref>, photobio <ref type="bibr" target="#b20">[21]</ref> and photo uncrop <ref type="bibr" target="#b31">[32]</ref>. Color correction prior to image alignment can further improve the alignment accuracy in these methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Color Correction Model</head><p>We adopt a global color correction model for reasons discussed in <ref type="bibr" target="#b16">[17]</ref>, namely robustness to alignment errors, ease of regularization and higher efficiency due to fewer unknown parameters. Our simple model is as follows:</p><formula xml:id="formula_0">I ′ =(cI) γ<label>(1)</label></formula><p>where I ′ is the input image, I is the desired image, c is a scale factor equivalent to the white balance function <ref type="bibr" target="#b19">[20]</ref> and (.) γ is the non-linear gamma mapping. Equation <ref type="formula" target="#formula_0">(1)</ref>is independently solved for each color channel. We assume that the surface reflectance of a scene point is constant across the images. Given m input images {I i } m i=1 , n 3D points {p j } n j=1 and their 2D image projections {x ij }, the intensity at a particular pixel x ij in image I i ,is</p><formula xml:id="formula_1">I i (x ij )=(c i a j e ij ) γi ,<label>(2)</label></formula><p>where a j is the constant albedo of the j-th 3D point and c i and γ i are the unknown global parameters for the i-th image. The per-pixel error term denoted as e ij captures unmodeled color variation due to factors such as lighting and shading change that cannot be modeled with Eq. (1). Taking logarithms on both sides of Eq. (2), we get:</p><formula xml:id="formula_2">log(I i (x ij )) = γ i log(c i )+γ i log(a j )+γ i log(e ij ).<label>(3)</label></formula><p>Rewriting Eq. (3) in matrix form, by grouping image intensities by scene point into sparse column vectors of length m and stacking the n columns side by side, we get:</p><formula xml:id="formula_3">I = C + A + E.<label>(4)</label></formula><p>Here, n denotes the number of 3D points or equivalently the number of correspondence sets. I ∈ R m×n is the observation matrix, where each entry</p><formula xml:id="formula_4">I ij = log(I i (x ij )). C ∈ R m×n is the color coefficient matrix where C ij = γ ij log c ij . A ∈ R m×n is the albedo matrix where A ij = γ ij log a ij . Finally, E ∈ R m×n is the residual matrix where E ij = γ ij log e ij .</formula><p>Here, the row index i denotes the i-th image, and the column index j denotes the j-th 3D point.</p><formula xml:id="formula_5">Lemma 1. Rank of C + A =2.</formula><p>Proof. Since c and γ are global parameters for an image,</p><formula xml:id="formula_6">c i1 = c i2 = ··· = c in , and γ i1 = γ i2 = ··· = γ in . Thus, each row of C is identical. Hence, C is a rank-1 matrix.</formula><p>Similarly, a ij represents surface albedo of a scene point and a 1j = a 2j = ··· = a mj . Since each row of A is multiplied by the same value, γ i , the rows of A are linearly dependent but have different linear coefficients γ 1 /γ i . Thus, A is also a rank-1 matrix. Further, since the linear dependence of C and A are independent of each other, the rank of C + A is equal to 2. This concludes the proof.</p><p>Assumptions. The matrix C should be viewed as a set of global image parameters for optimizing color consistency across the input images. In general, our estimate of C will not match the camera's true white balance and gamma settings. Similarly, our estimate of A is unlikely to match the true albedos. We now discuss our assumptions regarding unmodeled color variation caused by lighting change, etc.</p><p>Consider the situation where the images of a scene point are mostly captured in bright lighting. In this case, its albedo estimate is likely to be greater than the true value. In fact, the dominant bright illumination would be absorbed into the albedo term. The implicit assumption we make is that most 3D scene points have a somewhat dominant mode in their color distribution and that for most points, the estimated albedos will be consistent with the dominant color modes. This is true for example if most of the images were captured during daytime in bright lighting. <ref type="figure" target="#fig_3">Fig. 3</ref> shows an example where the input images have two very different dominant color modes. In this case, the outputs for a specific image (see <ref type="figure" target="#fig_3">Fig. 3</ref>(a)) present in both sets will be differ- ent. This is because we aim at optimizing color consistency across the majority of images in the input set.</p><p>According to Lemma 1, if matrix I has rank greater than 2, then the matrix E must encode the per-element deviations from the rank 2 structure. Based on the assumption stated earlier, we expect most entries in E to be close to zero since most observations will have relatively small deviations from the dominant color. Large, non-zero entries in E are caused by outliers due to shadows, saturation, pixel mismatches etc. The occurrence of such entries will be sparse. Our experiments on diverse Internet image datasets reported later on in Sec. 6.2 validates these hypotheses and our assumptions about scene illumination changes. Ambiguities in the Solution. The solution {C, A} has a multiplicative ambiguity. If γ * and c * are the true values (assuming that we have the correct estimate of C), then κγ * and 1 κ log(c * ) are also a correct decomposition of C for any arbitrary positive scale factor κ. Note that the multiplication by κ does not increase the rank of C. Thus, it is impossible to recover γ * and c * simultaneously, without making assumptions on γ * or c * . A similar multiplicative ambiguity also exists for A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Matrix Factorization-based Formulation</head><p>In order to estimate γ, c, and a, we define two augmented matrices − P := [c⊙g, g] ∈ R m×2 is a m×2 matrix which concatenates two column vectors c ⊙ g and g, c ∈ R m×1 , c i =l o gc i , g ∈ R m×1 , g i = γ i , ⊙ denotes an elementwise multiplication operator, and Q := [1, a] ∈ R n×2 is a n × 2 matrix which concatenates two column vectors, 1 ∈ R n×1 is a vector filled with 1, and a ∈ R n×1 , a j =l o ga j . By this definition, the augmented matrices satisfy PQ T = C+A. We can solve P and Q by applying the factorization based low-rank matrix completion <ref type="bibr" target="#b3">[4]</ref> method.</p><formula xml:id="formula_7">P * , Q * =argmin P,Q W⊙(I−PQ T ) p + λ 2 ( P 2 F + Q 2 F ),<label>(5)</label></formula><p>where W is a binary indicator matrix of E = I−PQ T , · p denotes the L p -norm, · 2 F denotes the Frobenius norm of a matrix, and λ is a parameter which controls the sparsity of the solution. We use the L 1 -norm here (i.e. p =1 )t o deal with outliers in E. W ij =1if the j-th correspondence appears in the i-th image, and W ij =0otherwise.</p><p>The optimal solution of Eq. (5) still contains the multiplicative ambiguity. In order to obtain the correct solution, we introduce a new constraint on Q:</p><formula xml:id="formula_8">P * , Q * =argmin P,Q W ⊙ (I − PQ T ) 1 + λ 1 2 ( P 2 F + Q 2 F )+ λ 2 2 ( Q − Q ′ 2 F ),<label>(6)</label></formula><p>where Q ′ := [1, a ′ ] and a ′ is an approximate solution of surface albedo which imposes regularization on a. The multiplicative ambiguity in g and c is then resolved sequentially after obtaining the correct solution of a. Approximate Solution of a. Without any prior information on a, we use the same assumption as <ref type="bibr" target="#b27">[28]</ref>, that median intensities provide an approximate estimate of surface albedo if a scene is observed from multiple viewpoints under changing illuminations. We also encourage the albedo estimates to be spatially smooth. Thus, we have</p><formula xml:id="formula_9">a ′ =argmin a i (a i −a i,med ) 2 + i j∈Ni w i,j (a i −a j ) 2 (7)</formula><p>where a i,med is the median value of pixel intensities in logarithm domain across the images, the spatial weight w i,j is inversely proportional to the 2D Euclidean distance between i-th and j-th points in an image (if the correspondences are estimated from SfM, the 3D distance is used instead), and N i is a set of local neighbor of i-th point. Optimization Procedures. In order to solve Eq. (6) efficiently, we utilize the Augmented Lagrange Multiplier (ALM) method <ref type="bibr" target="#b25">[26]</ref> and rewrite Eq. (6) as:</p><formula xml:id="formula_10">argmin Z,P,Q,Y,α W ⊙ (I − Z) 1 + λ 1 2 P 2 F + Q 2 F + λ 2 2 Q−Q ′ 2 F + Y, Z−PQ T + α 2 Z−PQ T 2 F ,<label>(8)</label></formula><p>where Z, Y, and α are auxiliary variables. The optimization procedure of the ALM method <ref type="bibr" target="#b25">[26]</ref> is summarized in Algorithm 1. First, it involves decomposing Eq. (8) into separate subproblems for P, Q, and Z which are solved iteratively. This is called the inner-loop. Next, using the estimates of P, Q, and Z in the current iteration, the values of Y and α are updated. Finally, the inner-loop repeats with updated values of Y and α until convergence. This is called the outer-loop. We now derive the solutions for each of the independent subproblems. The sub-problems involving finding optimal values of P and Q ( Eq. (8)) can be solved in closed form by setting the  <ref type="bibr" target="#b15">[16]</ref> is similar to our result shown in (f) but was obtained using dense correspondences.</p><formula xml:id="formula_11">(a) (b) (c) (f) (g) (e) (d)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Factorization based low-rank matrix completion</head><p>Input : I ∈ R m×n ,λ1 =1/ min(m, n), and λ2 =10λ1.</p><formula xml:id="formula_12">Initialize P 0 =[0, 1], Q 0 =[1, a ′ ]</formula><p>, and Z 0 as a random matrix sampled from a unit normal distribution, Y =0, α 0 =10 −3 . while not converged do while not converged do Update P, Q, and Z via Eq. (9, 10, and 12). end while Update Y via Eq. (13). α = min(1.5α, 10 20 ). end while Output : (P * , Q * , E * = I−P * Q * ).</p><p>first order derivatives of Eq. (8) with respect to P and Q respectively to zero. We obtain the following expressions. <ref type="formula" target="#formula_0">(10)</ref> where I 2×2 is a 2 × 2 identity matrix. This derivation is possible because the expression in Eq. (8) is quadratic in P and Q. In our implementation, we follow the suggested parameter value by <ref type="bibr" target="#b37">[38]</ref> and set λ 1 =1 / min(m, n), and we set λ 2 =10λ 1 . Also, since the first column of Q should be equal to 1, we substitute the first column of Q by 1 after each iteration. This makes the inner loop converge faster.</p><formula xml:id="formula_13">P =(αZ+Y)Q(αQ T Q+λ 1 I 2×2 ) −1 ,<label>(9)</label></formula><formula xml:id="formula_14">Q =((αZ+Y) T P+λ 2 Q ′ )(αP T P+(λ 1 +λ 2 )I 2×2 ) −1 ,</formula><p>After substituting the values of P and Q, we can rewrite Eq. (8) as a subproblem of Z, which is as follows.</p><formula xml:id="formula_15">argmin Z W ⊙ (I−Z) 1 + α 2 Z− PQ T − Y α 2 F .<label>(11)</label></formula><p>Eq. (11) has the following closed form solution <ref type="bibr" target="#b3">[4]</ref>.</p><formula xml:id="formula_16">Z = W⊙ O−S 1 α (I−PQ T + Y α ) +W⊙(PQ T − Y α ),<label>(12)</label></formula><p>where S d (b)=max(0,b− d) denotes an element-wise shrinkage operator, and W denotes the complement of W.</p><p>We repeat the inner-loop, which solves Eq. (9), Eq. (10) and Eq. (12) sequentially, until the decrease in residual error e of Eq. (8) is very small. We stop iterating when |e t − e t−1 | &lt; 10 −12 × e t−1 , where e t and e t−1 are the residuals after the t-th and (t−1)-th iterations, respectively. After optimizing P, Q, and Z, Y is updated as follows.</p><formula xml:id="formula_17">Y = Y + α(Z − PQ T ),<label>(13)</label></formula><p>where α is reset to min(1.5α, 10 20 ). Using the updated value of Y and α, we repeat the inner-loop if I − PQ 2 F &gt; 10 −9 × I F . After the optimization procedure converges, we can retrieve estimates, a * from Q * := [1, a * ] and g * from P := [c * ⊙ g * , g * ]. Then c * is also obtained from c * ⊙ g * by dividing by g * obtained in the previous step. By applying the inverse functions associated with the estimated g * and c * on the input images, we can achieve color consistency across the entire set of images. Outlier detection. The residual errors in E in Eq. (4) can be used to detect outlier observations that do not follow our model. This can be due to shadows, saturated pixels or erroneous correspondences. For such observations, applying our color correction leaves a large residual. The top 10% pixels in terms of larger residual error are classified as outliers. <ref type="figure" target="#fig_5">Figure 5</ref> shows an example of outliers in an image from the TREVI FOUNTAIN dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implementation Details</head><p>We now describe the steps for recovering sparse correspondence and construction of the observation matrix I. SfM pre-processing. For landmarks or in general rigid scenes, we use scale invariant feature matching <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b36">37]</ref> and structure from motion (SfM) <ref type="bibr" target="#b34">[35]</ref> to obtain multi-image correspondences. Although the estimated sparse 3D reconstruction is not used, the SfM pipeline filters outliers effectively and retains globally optimized correspondences geometrically consistent over many images.</p><p>Non-rigid scenes. For such input images, we extract SIFT features <ref type="bibr" target="#b28">[29]</ref> and run nearest neighbor (NN) descriptor matching on image pairs. For each pair, we do the matching both ways and retain the matches for the reciprocal nearest neighbors 1 . Next, we construct an undirected match graph G =( V, E), where V represents all the SIFT features, and E denotes all the pairwise matches. Within this graph, we then find the maximal cliques of size three and above. The maximal cliques are computed using a variant of the Bron-Kerbosch algorithm <ref type="bibr" target="#b35">[36]</ref> and these provide the correspondences used to construct the observation matrix.</p><p>Building the matrix I. Using the scale and orientation of matched keypoints, we resample patches 30 × 30 pixels wide from the associated input images which are often well aligned (see <ref type="figure" target="#fig_2">Figures 2(b) and 2(c)</ref>). We sample intensities from these patches to construct I. For reliable correspondences such as those obtained from SfM, we select one observation from each patch in a feature track to construct a new row for the matrix I. Specifically, we use the median intensity of each patch; this provides some robustness to misalignments, occlusion, shadows and JPEG artifacts.</p><p>Data Augmentation. For scenes with sparser feature matches there are too few observations to estimate all the unknowns, as noted in <ref type="bibr" target="#b15">[16]</ref>. <ref type="figure" target="#fig_4">Fig. 4</ref> shows a two image example with only nine feature matches 2 . Here, single pixel sampling produces unsatisfactory results <ref type="figure" target="#fig_4">(Fig. 4(c)</ref>). We address this issue by augmenting the observations using additional pixels sampled from the aligned patches using a predefined sampling pattern <ref type="figure" target="#fig_4">(Fig. 4(e)</ref>). This assumes reasonable patch alignment and local surface smoothness but is quite effective since the subsequent optimization step is robust to outliers. The improved result is shown in <ref type="figure" target="#fig_4">Fig. 4</ref>(f).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experimental Results</head><p>We first analyze the robustness of our method on synthetic data. Next, selected color correction results are presented. A detailed comparison with <ref type="bibr" target="#b16">[17]</ref> is reported highlighting the higher efficiency and robustness of our method followed by an analysis of running times. The supplementary material has additional results and shows improved results for image stitching, multi-view stereo and imagebased rendering made possible by our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Robustness Analysis</head><p>We conducted synthetic experiments with sparse observation matrices generated according to our model (Eq. (2)) with image intensities scaled to the range [0, 1]. We sample a j ∼U(0, 1), c i ∼U(0.5, 1.5), and γ i ∼U(0.5, 4), where U (a, b) denotes an uniform distribution over [a, b]. These 1 a, b are reciprocal nearest neighbors, when a's NN is b and vice versa. <ref type="bibr" target="#b1">2</ref> In this case, we use the intensity of the image in (a) as the approximate solution of a ′ . Hence, the correction is with respect to the image in (a).  <ref type="table">Table 1</ref>. Comparisons between L1 and L2-norm in the first term of Eq. (6). Using L1-norm consistently gives more accurate results than using L2-norm. The image intensities are normalized to [0,1]. matrices have size R m×n with the number of points n fixed (=1000), the number of images m, varying from 50 to 500 and the fraction of missing entries fixed (=95%). To simulate per-element deviations from the rank 2 structure, we sample e ij ∼N (1,σ 2 ) with varying σ where N (µ, σ 2 ) denotes normal distribution with mean µ and variance σ 2 . Finally, we sample random outliers in e ij from U (0.5, 1.5) given a target outlier ratio. To evaluate the importance of the robust L 1 -norm in Eq. <ref type="formula" target="#formula_8">(6)</ref>, we also test a variant of our algorithm that instead uses the L 2 -norm in Eq. <ref type="bibr" target="#b5">(6)</ref>. <ref type="table">Table 1</ref> summarizes the mean residual errors ( W ⊙ (G − P * Q * T ) 1 ) for various runs where the outlier fraction was set to 10% and 20% for three different settings of σ. Here G denotes ground truth. The mean residual errors are always less than 0.05 across all runs. The L 1 -norm is consistently more robust than the L 2 -norm especially when σ is small and the improvement margin increases when the outlier fraction increases. In general, accuracy increases when more images are used. Larger values of σ as expected causes moderate increase in error but the L 1 -norm still performs the best.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Batch Color Correction</head><p>We first show selected color correction results on subsets of photos from five collections of tourist landmarks in <ref type="figure" target="#fig_1">Figures 1 and 6</ref> -NOTRE DAME (715 images) <ref type="bibr" target="#b34">[35]</ref>, TREVI FOUNTAIN (1500 images), ST.B ASIL CATHEDRAL (1700 images), STATUE OF LIBERTY (2362 images), and DRES-DEN FRAUENKIRCHE (2025 images) <ref type="bibr" target="#b2">3</ref> . The latter four also contain Flickr images downloaded as part of the public dataset (landmark3d.codeplex.com) from <ref type="bibr" target="#b17">[18]</ref>. We used our own state of the art SfM implementation.</p><p>We have confirmed the assumptions made in our lowrank model by analyzing E, the residual matrix for the five datasets. <ref type="figure">Figure 7</ref> shows the error distributions on these datasets. Only 0.75%, 0.96%, 2.88%, 0.31% and 1.89% of observations have residual error greater than 0.2 respectively (where image intensities lie in [0, 1]). <ref type="figure">Figures 8 and 9</ref> show results on the WEDDING <ref type="bibr" target="#b16">[17]</ref>, and ICE SKATER datasets. The ICE SKATER dataset contains 36 images obtained using Google Image Search and contain noticeable variations in colors, contrast, human pose and appearance. On these two datasets, we used the implementation of SIFT features in VLFeat (www.vlfeat. org). An additional example, the BUSH sequence can be found in our supplementary material.</p><p>Inspecting the results qualitatively, we see that despite the huge input variability, darker images are brightened and the images with unusual colors are successfully corrected to be consistent with the other images. Once each image in the input set is corrected, we can treat those images as if they were taken from a single virtual camera. <ref type="figure" target="#fig_1">Figure 1</ref> shows a color transfer example on the TREVI FOUNTAIN dataset. The corrected images were transformed with the inverse camera function of the selected reference image.</p><p>Comparison with <ref type="bibr" target="#b16">[17]</ref>. We compare our method with that of HaCohen et al. <ref type="bibr" target="#b16">[ 17]</ref> on a small subset of the WED-DING dataset (9 images) published on their project website and the ICE SKATER dataset (36 images). Here, we use our own re-implementation of <ref type="bibr" target="#b16">[17]</ref> based on quadprog,a Matlab quadratic programming package. We test two baselines by running their method using both NRDC <ref type="bibr" target="#b15">[16]</ref> correspondences as well as our sparse correspondences as input. Both WEDDING and ICE SKATER are small datasets and the huge variation in image scale, composition and the subject's pose makes it difficult to obtain high quality results using NRDC <ref type="bibr" target="#b15">[16]</ref>. Since the sparse SIFT correspondences are fewer, we perform data augmentation on it (30× samples) as described earlier in the paper.</p><p>The results shown in <ref type="figure">Fig. 8</ref> and <ref type="figure">Fig. 9</ref> demonstrate that our approach is quite effective and performs better than both baselines. In contrast, the baseline method <ref type="bibr" target="#b16">[17]</ref> performs moderately with NRDC correspondences <ref type="figure" target="#fig_2">(Fig. 8 2nd</ref> row) but shows a lack of color consistency when used with sparse correspondences <ref type="figure" target="#fig_3">(Fig. 8 3rd row)</ref>. The cost function based on the L 2 norm used in <ref type="bibr" target="#b16">[17]</ref> appears to be sensitive to outliers producing inconsistent colors even for the most similar images (e.g. the highlighted columns in <ref type="figure">Fig. 8</ref> and <ref type="figure">Fig. 9</ref>). Increasing the weight of the regularization term in their method <ref type="bibr" target="#b16">[17]</ref> also tends to produce darker images as their energy function penalizes pairwise intensity differences and hence can favor a color transform function that makes the image intensities darker.</p><p>Running Times. For TREVI FOUNTAIN (1500 images), SfM reconstructs 1467 cameras. When we test our factorization method on these images, the observation matrix has size 1467 × 52092. Our Matlab implementation took 56 minutes on a desktop PC with Intel i7-4790 CPU @ 3.6 GHz and 16 GB RAM. For an image-based rendering application described in the supplementary material, we selected a subset of 390 images. This time the 390 × 44827 matrix was factorized in about 18 minutes. The results on the common 390 images are almost identical. The timings for ICE SKATER (36 images) were 47 seconds for feature matching, 0.4 seconds for finding maximal cliques and 153 seconds for factorizing the matrix built from 146K correspondences (with 30× augmented samples). The SVD inside each inner loop iteration is the main computational bottleneck and can be sped up using fast singular value thresholding <ref type="bibr" target="#b4">[5]</ref>.</p><p>Limitations. Our approach has the same limitations as that of HaCohen et al. <ref type="bibr" target="#b16">[17]</ref>. It may be ineffective when the input photos have low overlap. Also, our method may be less effective for certain input photos which have drastic lighting changes such as with daytime and night photos. Nevertheless the problem is somewhat mitigated by our ability to handle large photo collections. For rigid scenes, for surfaces always under shadow, the estimated albedo tends to be darker. This is because our estimation of white balance and gamma coefficients is biased by the initial albedo estimates and we cannot guarantee that the estimated parameters will always be accurate with respect to ground truth camera pa-rameters. Finally, when brightening a dark image using the estimated values, brighter pixels may become saturated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We have presented a novel and practical approach to optimize color consistency of a photo collection. Our key contribution is the novel rank-2 formulation of the problem and the proposed robust matrix factorization-based technique. Our robust formulation alleviates the need for dense correspondences as required by <ref type="bibr" target="#b16">[17]</ref>. It is shown to be effective on Internet photo collections of tourist landmarks, celebrities as well as personal photo collections. In the future, we plan to conduct a user study to evaluate our method on more diverse photo collections.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Foundation of Korea(NRF) grant funded by the Korea government(MSIP) (No.2010-0028680).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>First row: A selection from a large Internet photo collection (1500 images) of the Trevi fountain (images captured with different cameras on different days under different lighting). Second row: Our automatic technique performs consistent color correction on large image sets. Third row: The color of a target image (with a red boundary) can then be efficiently transferred to all the other images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Overview: (a) Selected input images. (b) Keypoints extracted in an image. (c) Local feature descriptors are matched to obtain sets of aligned image patches from which the low-rank matrix is constructed. (d) We factorize this matrix using our robust technique and jointly estimate color correction parameters for each image. (d) The same set of images after color correction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Our correction result depends on the color distribution of the input image set. (a) One of the input images I. (b) The result when I is processed along with a specific set of 16 bright and 4 dark images. (c) A different result is produced when a different set of 19 image (16 dark and 4 bright images) are used. A few aligned patches and the estimated color correction curves are shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Color transfer example: (a-b) Image pair taken from [16]. (c) Our color transfer result using nine SIFT correspondences. (d) the nine associated patches. (e) The yellow dot indicates the center pixel whereas orange dots indicate additional pixels sampled using augmentation. (f) Our result with augmented correspondences. Note the significant improvement over our result shown in (c). (g) The result from</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>(a) An image from TREVI FOUNTAIN. (b) Color and gamma corrected result. (c) Inliers to our model are marked in blue whereas outlier pixels (mostly in shadows) are marked in red.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .Figure 7 .</head><label>67</label><figDesc>Results on four other landmark photo collections. In each case, five images are shown. The upper row shows the original images, the lower row shows our auto correction results. More results are shown in the supplementary material. Residual error ( W ⊙ (I − P * Q * T ) 1) distribution on five real datasets. The percentages of elements in the residual vector with magnitude greater than the threshold τ are plotted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .Figure 9 .</head><label>89</label><figDesc>Comparison with<ref type="bibr" target="#b16">[17]</ref> on the WEDDING dataset(9 images). (Row 1): Input images. (Row 2): Results from HaCohen et al.'s technique<ref type="bibr" target="#b16">[17]</ref> using NRDC<ref type="bibr" target="#b15">[16]</ref> and (Row 3) using sparse correspondences (same as the input to our method). (Row 4): Our results. The overall color consistency of our results are noticeably higher even though sparse correspondences were used. ICE SKATER dataset (36 images): (Row 1) Selection of nine input images. (Row 2) Results of HaCohen et al.<ref type="bibr" target="#b16">[17]</ref> using dense correspondences<ref type="bibr" target="#b15">[16]</ref>. (Row 3): Results obtained using our method where significant color variations are consistently corrected.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The numbers in brackets are the input sizes for SfM.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Crowdcam: Instantaneous navigation of crowd images using angled graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arpa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ballan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3DTV-Conference, 2013 International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="422" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">User-guided white balance for mixed lighting conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Boyadzhiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2012" />
			<publisher>TOG</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A spatial processor model for object colour perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Buchsbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of The Franklin Institute</title>
		<imprint>
			<biblScope unit="volume">310</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unifying nuclear norm and bilinear factorization approaches for low-rank matrix decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>La Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast singular value thresholding without singular value decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-F</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods and Applications of Analysis</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="335" to="352" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sketch2photo: internet image montage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-M</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semantic colorization with internet images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y S</forename><surname>Chia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-Y</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image restoration using online photo collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sunkavalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Matusik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2217" to="2224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Radiometric calibration using photo collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Díaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sturm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computational Photography (ICCP)</title>
		<meeting>IEEE International Conference on Computational Photography (ICCP)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Color by correlation: A simple, unifying framework for color constancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Finlayson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Hordley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Hubel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1209" to="1221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A novel algorithm for color constancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="5" to="36" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The dimensionality of scene appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bayesian color constancy revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">V</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sharp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Color constancy using natural image statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gijsenij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Modeling the space of camera response functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grossberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Nonrigid dense correspondence with applications for image enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hacohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="70" to="71" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Optimizing color consistency in photo collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hacohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">3d visual phrases for landmark recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="3594" to="3601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Scene completion using millions of photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Light mixture estimation for spatially varying white balance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mertens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploring photobios</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robust radiometric calibration and vignetting correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="562" to="576" />
			<date type="published" when="2008-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kushal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Self</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gallup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Photo tours. In 3DImPVT</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Coherent intrinsic images from photo collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Laffont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bousseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Drettakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (SIGGRAPH Asia)</title>
		<imprint>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Revisiting Radiometric Calibration for Color Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Susstrunk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The augmented lagrange multiplier method for exact recovery of corrupted low-rank matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical Programming</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Interactive local adjustment of tonal values</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Farbman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Uyttendaele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="646" to="653" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Intrinsic colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-T</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-S</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<idno>152:1-152:9</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2008-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bayesian color constancy with non-gaussian models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ladsariya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Conference on Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The visual turing test for scene reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on 3D Vision (3DV)</title>
		<meeting>International Conference on 3D Vision (3DV)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Photo uncrop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hernandex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Photometric stereo using internet images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Inose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-K</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on 3D Vision (3DV)</title>
		<meeting>International Conference on 3D Vision (3DV)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Finding paths through the world&apos;s photos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Photo tourism: Exploring photo collections in 3d</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="835" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A new algorithm for generating all the maximal independent sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tsukiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ariyoshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shirakawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal of Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="505" to="517" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Picking the best daisy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Winder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="178" to="185" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Robust principal component analysis: Exact recovery of corrupted low-rank matrices via convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Conference on Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
