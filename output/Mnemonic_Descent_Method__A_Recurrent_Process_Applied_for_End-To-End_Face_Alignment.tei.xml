<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mnemonic Descent Method: A recurrent process applied for end-to-end face alignment</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Trigeorgis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Snape</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihalis</forename><forename type="middle">A</forename><surname>Nicolaou</surname></persName>
							<email>†m.nicolaou@gold.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">University of London</orgName>
								<address>
									<settlement>Goldsmiths</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Epameinondas</forename><surname>Antonakos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">⋆</forename><surname>Stefanos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Center for Machine Vision and Signal Analysis</orgName>
								<orgName type="institution">University of Oulu</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zafeiriou</forename><forename type="middle">⋆</forename></persName>
							<email>s.zafeiriou@imperial.ac.uk</email>
						</author>
						<title level="a" type="main">Mnemonic Descent Method: A recurrent process applied for end-to-end face alignment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cascaded regression has recently become the method of choice for solving non-linear least squares problems such as deformable image alignment. Given a sizeable training set, cascaded regression learns a set of generic rules that are sequentially applied to minimise the least squares problem. Despite the success of cascaded regression for problems such as face alignment and head pose estimation, there are several shortcomings arising in the strategies proposed thus far. Specifically, (a) the regressors are learnt independently, (b) the descent directions may cancel one another out and (c) handcrafted features (e.g., HoGs, SIFT etc.) are mainly used to drive the cascade, which may be sub-optimal for the task at hand. In this paper, we propose a combined and jointly trained convolutional recurrent neural network architecture that allows the training of an end-to-end to system that attempts to alleviate the aforementioned drawbacks. The recurrent module facilitates the joint optimisation of the regressors by assuming the cascades form a nonlinear dynamical system, in effect fully utilising the information between all cascade levels by introducing a memory unit that shares information across all levels. The convolutional module allows the network to extract features that are specialised for the task at hand and are experimentally shown to outperform hand-crafted features. We show that the application of the proposed architecture for the problem of face alignment results in a strong improvement over the current state-of-the-art.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Non-linear least squares optimisation problems often arise in computer vision, including but not limited to Structure-from-Motion <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b22">23]</ref>, rigid and deformable image alignment <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b34">35]</ref>, optical flow estimation <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b44">45]</ref>,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CNN RNN</head><p>Input image aligned with the mean face Final shape estimate <ref type="figure">Figure 1</ref>: Mnemonic Descent Method learns to align a shape estimate to a facial image 1 in an end-to-end manner using a jointly learnt convolutional recurrent network architecture. and estimation of camera parameters for calibration <ref type="bibr" target="#b43">[44]</ref>. The application of standard Newton-type methods for retrieving the optimal parameters is challenging due to the highly non-convex nature of the cost functions and the lack of differentiability of commonly used image operators (such as HoGs <ref type="bibr" target="#b16">[17]</ref>, SIFT <ref type="bibr" target="#b31">[32]</ref>, etc.). Recently, in order to address the drawbacks of Newton/Gauss-Newton methods a set of generic "descent directions" is learnt through the application of a cascade of regressors <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b10">11]</ref>. Generally, these directions are learnt independently per cascade via simulation. That is, in the case of deformable face alignment, the ground-truth facial shapes of the training images are randomly perturbed (according to a fixed variance). The descent directions are then estimated independently and seek to progress from the perturbed shapes to the ground-truth. In their simplest form, these rules can be learnt through the application of successive stages of linear regression, each minimising the average error over all training samples. The use of regression/learning basedmethods for solving non-linear optimisation problems has a <ref type="bibr" target="#b0">1</ref> Depicted is the muse Mnemosene which was the personification of memory in Greek mythology. The painting is an interpretation of the muse by the the father of the Pre-Raphaelite brotherhood Dante Gabriel Rossetti. rich history in computer vision, beginning with the first Active Appearance Models (AAMs) <ref type="bibr" target="#b12">[13]</ref>, where average Jacobians were learnt from the training set 2 . Cascaded regression methodologies have been also proposed in the recent works of <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b49">50]</ref>. However, to the best of our knowledge, the only work that proposes a generic framework for solving non-linear least squares is the socalled Supervised Descent Method (SDM) <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57]</ref>.</p><p>Several shortcomings can be identified in the state-ofthe-art cascade methods for deformable face alignment:</p><p>• The cascade steps are learnt independently. Each linear regressor simply learns how to regress from a particular fixed variance of shape perturbations to the ground-truth <ref type="bibr" target="#b2">[3]</ref>. Thus, correlations between semantically related image characteristics, such as facial pose, are not taken into account.</p><p>• The result of the optimisation is tightly coupled with the image features chosen to drive the regression.</p><p>Hand-crafted features are not data-driven and thus not necessarily optimal for the face alignment task. In contrast, binary/tree-based features <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b19">20]</ref> are data-driven and have shown to be effective for face alignment. However, these simple pixel intensity differences can not be learnt in an end-to-end manner. The success seen by convolutional features for various computer vision tasks has yet to be realised for face alignment. In particular, no currently proposed system trains end-to-end convolutional features.</p><p>In this paper, we propose the Mnemonic Descent Method (MDM) to address the issues above. In particular, MDM models deformable face alignment as a non-linear dynamical system 3 . MDM maintains an internal memory unit that accumulates information extracted from the history of all past observations of the input space. This has the advantage that descent directions are naturally partitioned according to the previously calculated descent directions. This paradigm maps to a very intuitive justification when applied to the problem of face alignment. For example, it seems reasonable that the alignment of any near profile face from a frontal initialisation will have an extremely similar sequence of descent directions. This is validated experimentally in <ref type="figure">Fig. 3</ref>. MDM leverages this rich information and trains an end-to-end face alignment method that learns <ref type="bibr" target="#b1">2</ref> The team led by Prof. Tim Cootes has proposed many variants for learning descent directions <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref> 3 The only alignment method that uses a dynamical system, and in particular a Linear Dynamical System (LDS), to model the shape estimates during model fitting is <ref type="bibr" target="#b33">[34]</ref>. The LDS is used to infer the posterior distribution of the global warp and used in a Constrained Local Model (CLM) framework. CLMs have not achieved state-of-the-art results in recent challenges such as the 300-W competition <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref>, even when trained in a cascaded regression <ref type="bibr" target="#b3">[4]</ref>. a set of data driven features, using a Convolutional Neural Network (CNN), directly from the images in a cascaded manner and most importantly uses a Recurrent Neural Network (RNN) to impose a memory constraint on the descent directions as illustrated in <ref type="figure">Fig.1</ref>. Our work is also motivated by the success of end-to-end training of convolutional recurrent networks for the tasks of image caption generation <ref type="bibr" target="#b11">[12]</ref>, scene parsing <ref type="bibr" target="#b35">[36]</ref>, and image retrieval/annotation generation <ref type="bibr" target="#b20">[21]</ref>. To the best of our knowledge this is the first endto-end recurrent convolutional system for deformable object alignment. In summary, the contributions of this work are:</p><p>1. We propose a non-linear cascaded framework for endto-end learning of the descent directions of non-linear functions. These types of functions are widely applicable in computer vision and existing works such as SDM <ref type="bibr" target="#b55">[56]</ref> have shown that descent direction learning can be highly effective.</p><p>2. This is the first work on face alignment where a single model is trained end-to-end i.e. from the raw image pixels to the final predictions. We incorporate problem-specific information in the training procedure by learning new image features via a CNN.</p><p>3. We introduce the concept of memory into descent direction learning. We believe this is highly discriminative and one of the major strengths of our approach.</p><p>4. We improve on the state-of-the-art in face alignment on the challenging test-set of 300W competition <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref> by a large margin.</p><p>The remainder of this paper is organised as follows. In Sec.2, we provide an overview of related work, with particular emphasis on SDM (Sec.3). Subsequently, in Sec.4, we introduce the proposed Mnemonic Descent Method (MDM) and, without loss of generality, describe its application to face alignment. Finally, in Sec.5, we provide rigorous evaluations of our model, in order to demonstrate the advantages of the proposed MDM over the state-of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The area of deformable face alignment constitutes a very intuitive domain for the application of this work and is thus chosen as the main application domain for evaluation.</p><p>Face alignment has a long and rich history that includes the introduction of many important works in computer vision such as Active Appearance Models <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b1">2]</ref>, Constrained Local Models <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b40">41]</ref> and 3D Morphable Models <ref type="bibr" target="#b7">[8]</ref>. In recent years, the problem of face alignment has seen substantial improvement, partially due to the introduction of large datasets of unconstrained (in-thewild) images <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b64">65]</ref>, which have been consistently re-annotated <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b37">38]</ref>. This increase in data variability and quantity has expanded the power of discriminative methods, such as regression based methods. In particular, many recently successful techniques chain a number of regressors together sequentially, in what is commonly called a cascade. Cascaded regression strategies constitute a large portion of the most popular facial alignment algorithms, as they are highly efficient and generalise well <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b49">50]</ref>. The most efficient cascaded regression methods are those that achieve regression via boosting of weak learners such as random ferns <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b9">10]</ref> or random forests <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b25">26]</ref>. However, a seminal work in this area which generalises to a multitude of problems and can efficiently deal with a large battery of non-linear least squares problems, is that of SDM <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57]</ref>. SDM was the first work to describe the cascaded regression problem as a more general learning framework in terms of optimising non-linear objective functions utilising learnt descent directions from training data. In particular, the regressors at each cascade are assumed to be linear and model average descent directions in the space of the objective function. However, the learnt descent directions, despite being chained in a cascade, are only related to one another via the variance remaining from the previous cascade. Therefore, the initial cascade levels are prone to large descent steps which may not generalise well. This was addressed in <ref type="bibr" target="#b56">[57]</ref> by partitioning the descent directions into cohesive groups during training. At test time, a partition is chosen that represents the correct descent direction. For example, for face alignment this requires an initial estimate of the shape and the descent directions are partitioned according to facial pose. However, this implies that <ref type="bibr" target="#b56">[57]</ref> is only useful for tracking scenarios where the previous frame provides the prior information for selecting the correct partition.</p><p>Asthana et al. <ref type="bibr" target="#b2">[3]</ref> proposed an incremental learning framework for SDM type methods which supports the total independence of each cascade level. They assume that each cascade is independent and therefore cascade levels can be learnt in parallel by merely simulating the residual variance remaining after applying the previous cascade. Although the independence of each level may be attractive for incremental learning, we propose that descent directions should be influenced by prior knowledge from previous descent steps. We propose to model the procedure as a non-linear dynamical system where a continuous latent state variable appropriately drives the procedure. In this paper, we show that it is possible to obtain large improvements when, instead of utilising hand-crafted features, optimal features for the given problem are learnt in an end-to-end fashion.</p><p>Our proposed method is also reminiscent of previously proposed deep learning methods for face alignment <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b61">62]</ref>. Sun et al. <ref type="bibr" target="#b46">[47]</ref> and Zhou et al. <ref type="bibr" target="#b62">[63]</ref> propose to use independent Convolutional Neural Networks (CNN) to perform coarse-to-fine shape searching. Zhang et al. <ref type="bibr" target="#b60">[61]</ref> also utilise a coarse-to-fine shape search using first a global and then a set of local stacked autoencoders. However, each autoencoder is trained in isolation. Zhang et al. <ref type="bibr" target="#b61">[62]</ref> propose a novel approach that involves incorporating auxiliary information into the fitting process. Unlike other related methods, they do not incorporate a cascade of networks but instead frame the problem as a multi-task learning problem. Wu et al. <ref type="bibr" target="#b54">[55]</ref> use a deep belief network to train a more flexible shape model, but do not learn any convolutional features. Finally, Baoguang Shi et al. <ref type="bibr" target="#b42">[43]</ref> propose to jointly learn a cascade of linear regressors. Although the regressors are updated jointly via back-propagation, <ref type="bibr" target="#b42">[43]</ref> uses linear regressors and employs hand crafted HoG features <ref type="bibr" target="#b16">[17]</ref> rather than learning the features directly from the images. Also, via close inspection of the results reported in <ref type="bibr" target="#b42">[43]</ref>, we found that their joint cascade methodology did not lead to any improvements in alignment accuracy over cascade regression methods that were trained independently, e.g. 6.32 mean error on the 300W fullset <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b37">38]</ref> for <ref type="bibr" target="#b36">[37]</ref> vs. 6.31 for <ref type="bibr" target="#b42">[43]</ref>. In the following section (Sec. 3), we formally introduce the face alignment problem and provide a brief description of the SDM algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Cascaded Regression</head><p>Face alignment is defined as the problem of localising a set of l sparse fiducial points,</p><formula xml:id="formula_0">l i = [x i , y i ]</formula><p>⊤ on an image, I ∈ R w×h , of a face. Given an image and an initial estimate of the shape within the image,</p><formula xml:id="formula_1">x (0) = [l 1 ⊤ , . . . , l l ⊤ ] ⊤ where x (0) ∈ R d×1 with d = 2l</formula><p>, face alignment seeks to recover the ground-truth facial shape x * . In the case of cascaded regression methods such as SDM, the optimisation from x (0) to x * is learnt from a large training set of images by successively learning a series of linear regressors. Most commonly, the regression parameters are optimised based on a set of complex features extracted from each image around the local area of each of the l fiducial points. We denote the extraction of these features for fixed sized patches (local square regions) from an image as φ(</p><formula xml:id="formula_2">I i ; x i ) ∈ R f ×1 .</formula><p>Since SDM proposes to learn a cascade of regressors, the target variables for regression are expressed as shape increments, defined by ∆x</p><formula xml:id="formula_3">(k) i = x * i −x (k) i , where k is the current cascade index and, thus, x (k) i</formula><p>is the current shape estimate of the i-th image. Finally, given n input training images, the design matrix is formulated as</p><formula xml:id="formula_4">Φ = [φ(I 1 ; x 1 ), . . . , φ(I n ; x n )] where Φ ∈ R f ×n .</formula><p>The matrix encapsulating the target shape increments is also denoted as ∆X = [∆x 1 , . . . , ∆x n ] where ∆X ∈ R d×n . SDM <ref type="bibr" target="#b55">[56]</ref> proposes to learn a series of k linear regressions formulated as arg min</p><formula xml:id="formula_5">R (k) ∆X (k) − R (k) Φ (k) 1 2 F ,<label>(1)</label></formula><formula xml:id="formula_6">x 1 = x 0 + Δx 1 x 2 = x 1 + Δx 2 x 3 = x 2 + Δx 3 Δx t h t h t+1 f c (θ c ) f r (θ r ) Δx 1 h 0 h 1 h 2 f c (θ c ) f r (θ r ) Δx 2 f c (θ c ) f r (θ r ) Δx 3 f c (θ c ) f r (θ r )</formula><p>Initial estimate x 0 , which in turn produces a representation that is robust to changes in appearance variation. Based on the current state h t , the mnemonic module (implemented as a recurrent network) generates a new state h t+1 and a new set of descent directions ∆x t+1 that indicates where the network should focus next. After a total of T = 3 time-steps, MDM successfully estimates the landmark locations. An important distinction from the previous work on cascade models <ref type="bibr" target="#b55">[56]</ref> is that the weights of the network θ = {θ c , θ r , x} are shared across time.</p><p>where R (k) ∈ R d×(f +1) and 1 is an f × 1 vector of ones that forces the regression matrix to absorb the bias as its final column. Solving for R (k) reduces to a simple linear least squares problem and is given by R (k) = ∆X (k) Φ (k) † where the bias term is concatenated in the design matrix as in Eq. 1 and is thus omitted for brevity. The next cascade step updates the current shape estimate by x</p><formula xml:id="formula_7">(k+1) i = x * i − (x (k) i + ∆x (k)</formula><p>i ) and then recomputes the feature matrix using the new shape estimates,</p><formula xml:id="formula_8">Φ (k+1) = [φ(I 1 ; x (k+1) 1 ), . . . , φ(I n ; x (k+1) n )].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Mnemonic Descent Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Feature extraction</head><p>Cascaded regression techniques for face alignment begin with a feature extraction stage, where typically a set of hand-crafted features representing image patches are extracted (e.g., HoG <ref type="bibr" target="#b16">[17]</ref>, SIFT <ref type="bibr" target="#b31">[32]</ref>, etc.). The feature extraction stage is required because the images are captured under unconstrained settings and so are likely to contain appearance variations (e.g., in illumination, skin-variations, occlusions etc.), which in turn generate local minima in the energy landscape. The aforementioned representations smooth the landscape in order to minimise the effect of such variations <ref type="bibr" target="#b1">[2]</ref>. We note that MDM is feature agnostic and may be straightforwardly used with any such nonlinear representations. Nevertheless, although conventional hand-crafted features have proved effective for a multitude of tasks in computer vision <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b55">56]</ref>, this process can still be considered sub-optimal given that these representations are also extracted independently of the task-at-hand. The proposed MDM aims to alleviate this issue by means of providing an end-to-end training methodology, in effect jointly discovering both the appropriate non-linear image representations as well as the optimal landmark locations. The feature extraction stage is replaced with a convolutional network module which facilitates learning directional filters leading to the function optimum. Since the training is performed in an end-to-end manner through back-propagation, we essentially learn filters that are used to convolve the image patches jointly with the fitting process.</p><p>As discussed in the previous section, the proposed algorithm has several advantages over other state-of-the-art algorithms. One of the core contributions is the discovery of the optimal feature representations, since this eliminates the requirement of utilising hand-crafted features which may be sub-optimal. In the next sections, we introduce the MDM algorithm (Sec.4.2) and its end-to-end training in Sec.4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Model</head><p>The main motivation of the proposed MDM is to facilitate smooth convergence by essentially treating the previously independent cascade steps as time-steps under a nonlinear dynamical system (i.e., modelling dependencies over iterations). Under this paradigm, we essentially learn a single model instead of an independent regressor at each iteration, and by preserving a mnemonic module, MDM enables the steps taken at each iteration to be dependent on the previous ones. Effectively, this discourages pitfalls such as missing the function optimum by "stepping-over" it. To this end, we implement the MDM by utilising Recurrent Neural Networks (RNN), which are well-known to be universal approximators for non-linear dynamical systems <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b21">22]</ref>. In essence, RNNs facilitate feedback connections and thus generate loops and cycles within the network. This enables recurrent networks to account for temporal dependencies arising in the data. In terms of the MDM, this enables modelling dependencies between the iterations and thus the descent directions. Whilst RNNs maintain the topology of feed forward networks (e.g., input, hidden, and output layers), the feedback connections enable the representation of the current state of the system which encapsulates the information from the previous inputs. The employment of RNNs has proved highly successful on many applications including machine translation <ref type="bibr" target="#b47">[48]</ref>, speech recognition <ref type="bibr" target="#b24">[25]</ref> and image captioning <ref type="bibr" target="#b52">[53]</ref>.</p><p>In the simplest form, an RNN observes z t corresponding to the current time-step t, and based on the previous state h t−1 generates the next hidden state, h t . Eq. 2 is considered the fundamental equation of a recurrent network (also known as the step function or the recurrence equation)</p><formula xml:id="formula_9">h (t+1) = f r (z (t) , h (t) ; θ r ) h (t+1) = tanh(W ih z (t) + W hh h (t) ).<label>(2)</label></formula><p>Let us now consider the above in the context of cascaded regression, and in particular, in the case of face alignment. The goal of MDM is, given an initial rough estimate of the minimum of the energy landscape, to produce a series of descent directions that iteratively lead to the optimum. We denote this initial estimate as x (0) , which for face alignment is commonly a mean face aligned to the output of a face detector <ref type="bibr" target="#b59">[60]</ref>. At each time-step t, the mnemonic module partially observes the energy landscape z (t) . Based on this observation, the internal state of MDM is updated accordingly, by adapting the recurrence expression of Eq.2. Given a new training sample, the recurrence equation becomes,</p><formula xml:id="formula_10">h (t+1) = tanh(W hi φ(z; x (t) ) + W hh h (t) )<label>(3)</label></formula><p>where W hi ∈ R f ×u is the hidden-to-input matrix which is used to condition the partial observation of the energy landscape, W hh ∈ R u×u the hidden-to-hidden matrix which 30°1 5°-15°-30°0°F igure 3: A t-SNE depiction of the internal states (T = 1) of MDM when asked to align 2000 randomly selected images of CMU Multi-PIE <ref type="bibr" target="#b23">[24]</ref>. Each colour corresponds to a cluster of head pose. This visualisation demonstrates that MDM is effectively partitioning the input data based on the head pose. Best viewed in colour.</p><p>conditions the output of the previous time-step and u corresponds to the dimensionality of the internal state of the recurrent module.</p><p>During training, the network updates the current shape displacements by projecting the hidden state, which corresponds to the mnemonic element of the algorithm, to the hidden-to-output matrix W ho ∈ R u×d , as</p><formula xml:id="formula_11">∆x (t+1) = x (t) + W ho h (t) .<label>(4)</label></formula><p>This estimate essentially constitutes the observation for the new time-step and translates to the network observing the local energy landscape around x (t+1) = x (t) + ∆x (t+1) . Note that in this case, the traditional SDM would simply train an independent regressor, and thus fail to utilise the previous states of the algorithm. In fact, in our experimental analysis (c.f. Sec. 5.2) we found, by means of visualisation, that the hidden state of the network at the early stages of the fitting process encapsulates the head pose information. This can then be utilised in subsequent stages to partition the energy landscape and thus enable the model to choose the appropriate descent path to follow. The process is then repeated for a predefined number of time-steps T and is trained by employing Back-propagation Through-Time (BPTT) <ref type="bibr" target="#b53">[54]</ref>. In conclusion, the objective function of MDM can be thus defined as 4 <ref type="bibr" target="#b3">4</ref> We omit the bias terms for brevity of notation.</p><formula xml:id="formula_12">min θ X * − X (0) + T −1 t=0 W ho H (t) 2 F<label>(5)</label></formula><p>where</p><formula xml:id="formula_13">H (t) = [h (t) 1 , . . . , h (t)</formula><p>n ] ∈ R u×n represents the matrix of all states corresponding to each of the n images at time t, and θ all the parameters of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">End-to-end training for face alignment</head><p>In <ref type="figure" target="#fig_0">Fig. 2</ref>, we illustrate the application of MDM for the task of face alignment. Given an initial estimate x (0) , which corresponds to the mean face shape, a collection of patches is extracted and propagated through the convolutional module f c (·; x (0) , θ c ) to obtain the appropriate non-linear feature representations. The recurrent module, f r (·; h (0) , θ r ), then generates the next state h (1) and the process is repeated for a fixed number of time-steps. We found through experiments on the validation set that unrolling the network for T = 4 time steps was sufficient for our task. This is consistent with prior work in cascaded regression where 4 cascade levels are widely deemed sufficient <ref type="bibr" target="#b55">[56]</ref>. As the whole network is differentiable end-to-end, we can employ BPTT <ref type="bibr" target="#b53">[54]</ref> to learn the parameters of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental analysis</head><p>In order to evaluate the efficacy of the proposed MDM, we perform rigorous evaluations against the state-of-the-art methods for face alignment (Sec.5.1) where we find a strong improvement against the best performing methods of the 300W competition <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b37">38]</ref>. In Sec. 5.2 we further examine our model by (i) studying the effect of an increasing number of time-steps T , (ii) by comparing the outcome of learning a feature extractor (using convolutional features) vs. hand-engineered features (dense-SIFT <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b51">52]</ref>), and (iii) by visualising the internal state of the fitting process, which reveals that it encapsulates the head pose information which the network can employ to partition the space of descent directions in subsequent time-steps. Datasets. To provide a fair comparison against other recent face alignment methods, we concentrate on the 68-point annotations provided by Sagonas et al. <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40]</ref>. These annotations are provided for 3 existing in-the-wild datasets (LFPW <ref type="bibr" target="#b6">[7]</ref>, HELEN <ref type="bibr" target="#b29">[30]</ref> and AFW <ref type="bibr" target="#b64">[65]</ref>) which were originally annotated using different and incompatible markups. Sagonas et al. also introduced a new challenging dataset called IBUG <ref type="bibr" target="#b38">[39]</ref>, also annotated with the 68-point CMU MultiPIE markup <ref type="bibr" target="#b23">[24]</ref>. Commonly, these annotations are split into the following subsets: (i) the training set (3148 images) consisting of LFPW training images (811), HELEN training images (2000) and AFW (337) (ii) the challenging subset (135) of IBUG (135) (iii) the common subset (554) of LFPW testing set (224) and HELEN testing set (330) and (iv) the full set (689) of the union of the common (554) and challenging subsets (135). We do not consider the original annotations of LFPW (29-point markup) or HELEN (194point markup) as recent works <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b61">62]</ref> have shown that these databases have become saturated for the original an-  <ref type="table">Table 1</ref>: Quantitative results on the test set of the 300W competition using the AUC (%) and failure rate (calculated at a threshold of 0.08 of the normalised error).</p><p>notations. The above annotations were actually provided as a training/validation set for the 300W face alignment competition <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b37">38]</ref>, which used another set of images strictly for evaluation, called 300W test-set <ref type="bibr" target="#b4">5</ref> . The 300W test-set consists of 600 images split into two subsets, indoor and outdoor, which are said to have been drawn from a similar distribution as the IBUG dataset. Evaluation. Unfortunately, there is no consistent way of reporting errors for face alignment, even with regards to the common 300W test sets. This is mostly due to variations in error normalisation. To maintain consistency with the results of the 300W competition <ref type="bibr" target="#b38">[39]</ref> we use their definition of the interocular distance i.e. the distance between the outer eye corners. We believe that mean errors, particularly without accompanying standard deviations, are not a very informative error metric as they can be highly biased by a low number of very poor fits. Therefore, we provide our evaluation in the form of CED curves, as this is consistent with the results we received from the authors of <ref type="bibr" target="#b38">[39]</ref>. We have calculated some further statistics from the CED curves such as the area-under-the-curve (AUC) and the failure rate of each method (we consider any fitting with a point-to-point error greater than 0.08 as a failure). We believe that these are more representative error metrics for the problem of face alignment. We also note that there is a significant difference between 68-point and 49/51-point error metrics due to the inherent difficulty in fitting the boundary points of the face contour. Therefore, where possible, we present both 68 and 49/51 point errors. Implementation Details. Unless otherwise specified, our network topology consists of two convolutional layers for <ref type="bibr" target="#b25">[26]</ref> [50] <ref type="bibr" target="#b63">[64]</ref> Baltrusaitis et al. <ref type="bibr" target="#b4">[5]</ref> Face++ <ref type="bibr" target="#b62">[63]</ref> Yan et al. <ref type="bibr" target="#b57">[58]</ref> Intra-face <ref type="bibr" target="#b55">[56]</ref> Chehra <ref type="bibr" target="#b2">[3]</ref> ERT the feature extraction. Each layer employs 32 filters, each with a kernel of 3 × 3. Each convolutional layer is followed by a rectified linear (ReLU) unit and a 2 × 2 max-pooling operation. We have added a skip-connection and concatenated the activations from the central crop of the first convolutional layer with the output of the second pooling layer to retain more relevant localisation information that we would otherwise lose from using the max-pooling layers. As a relatively small number of time steps is required to reach convergence we found it sufficient to use a vanilla recurrent module with a state vector of dimensionality 512 units. Finally, a linear projection layer is used to produce the descent directions ∆x (t) at each time-step. We provide an example implementation and a pretrained MDM model at http://trigeorgis.com/mdm. For learning the weights of the network we employ stochastic optimisation with Adam <ref type="bibr" target="#b27">[28]</ref> with the default hyperparameters, an initial learning rate of 0.001 with exponential decay of 0.95 every 20 000 iterations, and minibatch size of 50 images. We choose the best model according to our validation set (300W full set).</p><p>For all experiments, our network was trained on the 3148 images of the 300W training set with 68-point markup and the bounding boxes provided by the 300W competition were used for training and testing. Training images were augmented in order to provide extra training data by adding per-pixel Gaussian noise of σ = 0.5, by mirroring around the vertical axis, and finally with random in-plane rotations ±15 • generated from a uniform distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Comparison with State-of-the-art</head><p>We compare against state-of-the-art methods in two separate experiments. To provide a relatable benchmark, we evaluated MDM on the full set of 300W. In <ref type="figure" target="#fig_4">Fig.6</ref> we provide comparison CED curves against the state-of-the-art methods of Project-Out Cascaded Regression (PO-CR) <ref type="bibr" target="#b49">[50]</ref>, Coarse-to-fine shape searching (CFSS) <ref type="bibr" target="#b63">[64]</ref>, Explicit Regression Trees (ERT) <ref type="bibr" target="#b25">[26]</ref>, Intraface <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b18">19]</ref>, Chehra <ref type="bibr" target="#b2">[3]</ref> and a baseline SDM that we implemented using Menpo <ref type="bibr" target="#b0">[1]</ref> employing dense-SIFT features. All methods were initialised with the same bounding boxes, as provided by the 300W competition. All methods were chosen due to being publicly available. ERT was re-trained using the implementation provided by DLib <ref type="bibr" target="#b26">[27]</ref> with the 300W bounding boxes using the 300W training set. We believe that this experiment demonstrates that the currently available face alignment datasets are becoming saturated, as there is little difference between three of the most recently proposed methods (CFSS, PO-CR, and MDM). Historically, face alignment methods have struggled with not having sufficient training data, and this may have led authors to use the above test-sets as both validation sets (for hyperparameter tuning) and as evaluation sets.</p><p>Our primary experiment was evaluated on the test set of the 300W competition <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b37">38]</ref>. <ref type="figure" target="#fig_1">Fig. 4</ref> illustrates the 68point and 51-point plots of the provided results. The results show that MDM outperforms the rest of the face alignment methods for both the 68-point and 51-point error metrics, setting a new state-of-the-art on the problem of face alignment. It should be noted that the participants of the competition did not have any restrictions on the amount of training data employed which further illustrates the effectiveness of our approach.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Self Evaluations</head><p>In this section we performed a number of self evaluation experiments to explore the behaviour of our model. Effect of adding time-steps. In <ref type="figure" target="#fig_3">Fig. 5</ref> we show the effect of increasing the number of time-steps for the recurrent network. The mean interocular distance is reported over the whole of the 300W full set. Here we see that only 4 iterations are necessary before the performance plateaus.</p><p>Effect of learning features. In <ref type="figure" target="#fig_3">Fig. 5</ref> we study the effect of learning features using the CNN in comparison to the SIFT <ref type="bibr" target="#b31">[32]</ref> features which are commonly used in many of the cascaded regression algorithms for face alignment <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b63">64]</ref>. <ref type="figure" target="#fig_3">Fig. 5</ref> provides the CED curve on the 300W full set and clearly shows that the learnt features are much more discriminative than the hand-crafted SIFT features.</p><p>Partitioning. In <ref type="figure">Fig.3</ref> we plot a t-SNE <ref type="bibr" target="#b50">[51]</ref> visualisation of the T = 1 internal states of MDM for 2000 randomly selected images from CMU Multi-PIE <ref type="bibr" target="#b23">[24]</ref>. The images were uniformly sampled over a range of out-of-plane head poses in the range {−30 • , −15 • , 0 • , 15 • , 30 • }. <ref type="figure">Fig. 3</ref> clearly shows that MDM is able to partition the space of descent directions according to the head pose. Previously <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b58">59]</ref>, partitioning by pose estimates was considered separately and thus external information was required to perform face alignment. In contrast, MDM naturally learns this partitioning and benefits from improved fitting performance likely due to the implicit clustering of related semantic attributes such as head pose. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>We presented the Mnemonic Descent Method (MDM), a non-linear unified model for end-to-end learning of descent directions of non-linear functions. In contrast to existing cascaded regression frameworks, MDM is able to model dependencies between iterations of the cascade by introducing the concept of memory into descent direction learning.</p><p>We employ MDM in the area of deformable object alignment. We have proposed the first convolutional recurrent architecture that is able to be trained in an end-to-end manner i.e., from the raw image pixel intensities to the final predictions. By utilising the convolutional module, we have shown that MDM can learn a set of robust features that outperform hand-crafted features for face alignment. Additionally, the recurrent module appears to leverage past information, such as head pose in order to partition the space of descent directions in a data-driven manner. Finally, our approach outperforms the current state-of-the-art for face alignment on the challenging test-set of the 300W competition <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b37">38]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>An illustrative example of MDM for a total of T = 3 time-steps. Initially the network input consists of a partial image observation, consisting of the patches extracted at the mean face x 0 . The extracted patches (30 × 30) at each time-step are passed through a subsequent convolutional network f c (·; θ c )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Quantitative results on the test set of the 300W competition (indoor and outdoor combined)<ref type="bibr" target="#b38">[39]</ref> for both 68-point (left) and 51-point (right) plots. Only the top 3 performing results from the original competition are shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Top: Comparison between hand-crafted SIFT features vs. end-to-end CNN features tailored for face alignment. Bottom: Increasing the number of time-steps decreases the average error but stabilises after four iterations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Results on the full testing set of the 300W competition, which was used as a validation set(49-points).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Note that the 300W test-set is different than the 300W full set commonly used in literature. The former is the test-set used for the 300W competition, which was hidden during the competition and recently made publicly available. The latter refers to the common set of LFPW train, HE-LEN train and AFW, which was the main training set of the 300W competition. All datasets are available in http://ibug.doc.ic.ac.uk/ resources/facial-point-annotations/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>G. Trigeorgis was supported by EPSRC DTA award at Imperial College London. The work of P. Snape was partially funded by an EPSRC DTA and by the European Community Horizon 2020 [H2020/2014-2020] under grant agreement no. 688520 (TeSLA). The work of E. Antonakos was partially funded by the EPSRC project EP/J017787/1 (4D-FAB). The work of S. Zafeiriou was funded by the FiDiPro program of Tekes (project number: 1849/31/2015). We thank the NVIDIA Corporation for donating a Tesla K40 GPU used in this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Menpo: A comprehensive platform for parametric image alignment and visual deformable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alabort-I-Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Booth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Snape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Multimedia, MM &apos;14</title>
		<meeting>the ACM International Conference on Multimedia, MM &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="679" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Feature-based lucas-kanade and active appearance models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alabort-I-Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2617" to="2632" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Incremental face alignment in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Asthana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1859" to="1866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">From pixels to response maps: Discriminative image filtering for face alignment in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Asthana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Constrained local neural fields for robust facial landmark detection in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Baltrusaitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision Workshops (ICCVW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="354" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Localizing parts of faces using a consensus of exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2930" to="2940" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Localizing parts of faces using a consensus of exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2930" to="2940" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">In the proceedings of siggraph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Blanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics and Interactive Techniques</title>
		<imprint>
			<publisher>ACM Press/Addison-Wesley Publishing Co</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="187" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Damped Newton Algorithms for Matrix Factorization with Missing Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Buchanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="316" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Robust face landmark estimation under occlusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">P</forename><surname>Burgos-Artizzu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1513" to="1520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Face alignment by explicit shape regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="177" to="190" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learning a recurrent visual representation for image caption generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.5654</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Active appearance models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="681" to="685" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Robust and Accurate Shape Model Matching Using Random Forest Voting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Ionita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lindner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="278" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Comparing variations on the active appearance model algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kittipanya-Ngam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic feature localisation with constrained local models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cristinacce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cootes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3054" to="3067" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Histograms of Oriented Gradients for Human Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Human detection using oriented histograms of flow and appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="428" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Intraface</surname></persName>
		</author>
		<title level="m">Automatic Face and Gesture Recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cascaded Pose Regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1078" to="1085" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Long-Term Recurrent Convolutional Networks for Visual Recognition and Description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2625" to="2634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Approximation of dynamical systems by continuous time recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-I</forename><surname>Funahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="801" to="806" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dense variational reconstruction of non-rigid surfaces from monocular video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roussos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Agapito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1272" to="1279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Multi-Pie. Image and Vision Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="807" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. Signal Processing Magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="82" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">One Millisecond Face Alignment with an Ensemble of Regression Trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1867" to="1874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dlib-ml: A machine learning toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1755" to="1758" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Interactive facial feature localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="679" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Interactive facial feature localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2012</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="679" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Face Alignment using Cascade Gaussian Process Regression Trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4204" to="4212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Distinctive Image Features from Scale-Invariant Keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An iterative image registration technique with an application to stereo vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="1981" />
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="674" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Discriminative bayesian active shape models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="57" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Active appearance models revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="164" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Recurrent Convolutional Neural Networks for Scene Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2625" to="2634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Face alignment at 3000 fps via regressing local binary features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1685" to="1692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">300 faces in-the-wild challenge: Database and results. Image and Vision Computing, Special Issue on Facial Landmark Localisation &quot;In-The-Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Pantic. 300 faces in-the-wild challenge: The first facial landmark localization challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision Workshops (ICCVW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="397" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A semi-automatic methodology for facial landmark annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition Workshops (CVPR-W)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="896" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deformable model fitting by regularized landmark mean-shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Saragih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="200" to="215" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep learning in neural networks: An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="85" to="117" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Deep Regression for Face Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.5230</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Manual of photogrammetry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Theurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Henriksen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
		</imprint>
	</monogr>
	<note>Number Ed. 4. American Society of photogrammetry</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Face flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Snape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roussos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Panagakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2993" to="3001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A quantitative analysis of current practices in optical flow estimation and the principles behind them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="137" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep Convolutional Network Cascade for Facial Point Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3476" to="3483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Sequence to Sequence Learning with Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Real-Time Facial Feature Tracking on a Mobile Device</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Tresadern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Ionita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="280" to="289" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Project-Out Cascaded Regression With an Application to Face Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3659" to="3667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">85</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">VLFeat: An open and portable library of computer vision algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fulkerson</surname></persName>
		</author>
		<ptr target="http://www.vlfeat.org/" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Show and Tell: A Neural Image Caption Generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Backpropagation Through Time: what it does and how to do it</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Facial Feature Tracking Under Varying Facial Expressions and Face Poses Based on Restricted Boltzmann Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3452" to="3459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Supervised descent method and its applications to face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="532" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Global Supervised Descent Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2664" to="2673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Learn to combine multiple hypotheses for accurate face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision Workshops (ICCVW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="392" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Face Alignment Assisted by Head Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Patras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gunes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A survey on face detection in the wild: past, present and future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Coarse-to-fine auto-encoder networks (CFAN) for real-time face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Learning Deep Representation for Face Alignment with Auxiliary Attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Extensive facial landmark localization with coarse-to-fine convolutional network cascade</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision Workshops (ICCVW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="386" to="391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Face Alignment by Coarse-to-Fine Shape Searching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4998" to="5006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Face detection, pose estimation, and landmark localization in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2879" to="2886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Revisiting Horn and Schunck: Interpretation as Gauss-Newton Optimisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zikic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kamen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
