<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Recovery of Dense Correspondence and Cosegmentation in Two Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsunori</forename><surname>Taniai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">The University of Tokyo</orgName>
								<orgName type="institution" key="instit2">The University of Tokyo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudipta</forename><forename type="middle">N</forename><surname>Sinha</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">The University of Tokyo</orgName>
								<orgName type="institution" key="instit2">The University of Tokyo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Microsoft</forename><surname>Research</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">The University of Tokyo</orgName>
								<orgName type="institution" key="instit2">The University of Tokyo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoichi</forename><surname>Sato</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">The University of Tokyo</orgName>
								<orgName type="institution" key="instit2">The University of Tokyo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Joint Recovery of Dense Correspondence and Cosegmentation in Two Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a new technique to jointly recover cosegmentation and dense per-pixel correspondence in two images. Our method parameterizes the correspondence field using piecewise similarity transformations and recovers a mapping between the estimated common "foreground" regions in the two images allowing them to be precisely aligned. Our formulation is based on a hierarchical Markov random field model with segmentation and transformation labels. The hierarchical structure uses nested image regions to constrain inference across multiple scales. Unlike prior hierarchical methods which assume that the structure is given, our proposed iterative technique dynamically recovers the structure along with the labeling. This joint inference is performed in an energy minimization framework using iterated graph cuts. We evaluate our method on a new dataset of 400 image pairs with manually obtained ground truth, where it outperforms state-of-the-art methods designed specifically for either cosegmentation or correspondence estimation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recovering dense per-pixel correspondence between image regions in two or more images is a central problem in computer vision. While correspondence estimation for images of the same scene (stereo, optic flow, etc.) is well studied, there has been growing interest in the case where the images portray semantically similar but different scenes or depict semantically related but different object instances <ref type="bibr" target="#b35">[36]</ref>. Due to the variability in appearance, shape and pose of distinct object instances, camera viewpoint, scene lighting and backgrounds in the images, the task is quite challenging in the unsupervised setting. Yet, correspondence estimation enables fine-grained image alignment crucial in tasks such as non-parametric scene parsing and label transfer <ref type="bibr" target="#b35">[36]</ref>, 3D shape recovery <ref type="bibr" target="#b50">[51]</ref>, image editing <ref type="bibr" target="#b18">[19]</ref> and unsupervised visual object discovery <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b49">50]</ref>.</p><p>In parallel to advances in correspondence estimation, there has also been rapid progress in image cosegmentation <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b45">46]</ref> methods that automatically segment similar "foreground" areas in two or more images. These methods often require the foregrounds depicting common objects to have similar region statistics. Most cosegmentation methods do not explicitly recover dense pixel correspondence and alignment in the region labeled foreground. On the other hand, correspondence estimation methods <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b22">23]</ref> align all the pixels without explicitly inferring which pixels in the two images actually have valid correspondence. Thus, recovering cosegmentation along with a dense alignment of the common foregrounds can be viewed as a holistic approach to solving both tasks.</p><p>In this paper, we present insight into how image cosegmentation and correspondence (or flow) estimation can be tackled within a unified framework by framing it as a labeling problem ( <ref type="figure" target="#fig_0">Figure 1</ref>). We show that jointly solving the two tasks in this way can improve performance on both of them. This paper deals with the case where only two input images are given. The setting is unsupervised and we do not assume a priori information about the objects or the scene.</p><p>Our contributions are three folds. First, we propose a new hierarchical Markov random field (MRF) model for joint cosegmentation and correspondence recovery. The hierarchy is defined over nested image regions in the reference image and the nodes representing these regions take segmentation and flow labels. In our method, the hierarchy itself is inferred in conjunction with the labeling and is crucial for achieving robustness to dissimilar appearance of different object instances. Precomputed hierarchical structures <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b26">27]</ref> are unsuitable for our task because pixels inferred as background must be excluded from matching.</p><p>Second, we propose a new optimization technique for the joint inference of the graph structure and labeling. Per-forming exact inference jointly on the whole hierarchical structure is intractable. In the proposed approach, layers of the hierarchy are incrementally estimated with the labeling in an energy minimization framework using iterated graph cuts <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b30">31]</ref> (alpha expansion moves).</p><p>Finally, we release a new dataset with 400 image pairs for which we provide ground truth cosegmentation masks and flow maps. The original images and some of the segmentation masks are taken from existing datasets <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b19">20]</ref>. The remaining segmentation masks were obtained using interactive image segmentation. The flow maps were obtained by selecting sparse keypoint correspondence with our interactive annotation tool and applying natural neighbor interpolation <ref type="bibr" target="#b43">[44]</ref> on the sparse data. Poor flow maps were discarded by visually inspecting the flow-induced image warping result. The ground truth flow maps makes it possible to directly evaluate dense image alignment. Even SIFT Flow <ref type="bibr" target="#b35">[36]</ref> and other correspondence estimation methods <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b53">54]</ref> are evaluated indirectly on tasks such as segmentation transfer and scene parsing using datasets that lack ground truth pixel correspondence.</p><p>The paper is organized as follows. We describe related work in Section 2 and our proposed model in Section 3. Section 4 presents our optimization method whereas implementation details and the images features used are described in Section 5. Finally, in Section 6, we report experimental evaluation and comparisons with existing approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>We are not aware of any existing method that explicitly solves both cosegmentation and dense correspondence recovery together. However, the motivation behind our work is similar to that behind some recent cosegmentation methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b42">43]</ref>. We review those and other broadly related works on cosegmentation and correspondence estimation. Cosegmentation. Rubio et al. <ref type="bibr" target="#b42">[43]</ref> formulate cosegmentation in terms of region matching. However, the matches are computed independently using graph matching <ref type="bibr" target="#b15">[16]</ref> and then exploited in their cosegmentation algorithm. Faktor and Irani <ref type="bibr" target="#b16">[17]</ref> describe a model where common foregrounds in multiple images can be composed from interchangeable image regions. Although region matching is a key element of their method, it is primarily used to estimate unary potentials (foreground/background likelihoods) for a standard image segmentation method. While, Dai et al. <ref type="bibr" target="#b12">[13]</ref> propose to cosegment images by matching foregrounds through a codebook of deformable shape templates, it involves learning a codebook requiring external background images. While a notion of correspondence implicitly exists in all these works, none of them explicitly compute dense correspondence maps between the cosegmented regions, which is an important distinction to our work.</p><p>Cosegmentation methods originally proposed by Rother et al. <ref type="bibr" target="#b40">[41]</ref> have been applied in broader settings <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b51">52]</ref> and also on large sets of Internet images <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b10">11]</ref>.</p><p>Interesting convex formulations have also been proposed for a variant of cosegmentation -the object co-localization task <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b45">46]</ref>, which aims to find a bounding box around related objects in multiple images. Correspondence Estimation. SIFT Flow <ref type="bibr" target="#b35">[36]</ref> generalizes optic flow to images of different scenes and estimates complete flow maps with 2D translations at every pixel. Their energy function uses local matching costs based on dense SIFT features, and smoothness terms encoding standard pairwise potentials. SIFT Flow uses loopy belief propagation (BP) <ref type="bibr" target="#b17">[18]</ref> for inference in a coarse-to-fine pipeline but other inference techniques <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b52">53]</ref> have also been explored. HaCohen et al. <ref type="bibr" target="#b18">[19]</ref> propose an extension of Patch-Match <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> that handles images of identical scenes with large motions. However, their method is often unable to handle different scenes as it lacks regularization on correspondence fields. As another extension, DAISY filter flow (DFF) <ref type="bibr" target="#b52">[53]</ref> proposes to use efficient cost-volume filtering <ref type="bibr" target="#b37">[38]</ref> for enforcing smoothness, instead of adding explicit regularization. Deformable spatial pyramid (DSP) matching <ref type="bibr" target="#b28">[29]</ref> and its generalization <ref type="bibr" target="#b22">[23]</ref> propose hierarchical regularization using a regular grid-cell pyramid for flow estimation. Correspondence maps are parameterized using similarity transformations in <ref type="bibr" target="#b22">[23]</ref> similarly to our work. Images with scale differences are handled by <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23]</ref>. Cosegmentation has been used to guide sparse feature correspondence recovery <ref type="bibr" target="#b9">[10]</ref>. However, such methods do not aim to accurately segment common regions. Hierarchical Models. To exploit multi-scale image cues or to add flexible regularization, hierarchical conditional random fields (CRFs) have been proposed for single image segmentation <ref type="bibr" target="#b21">[22]</ref>, image matching <ref type="bibr" target="#b48">[49]</ref>, stereo correspondence <ref type="bibr" target="#b32">[33]</ref>, and much recently for optic flow <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b26">27]</ref> and more general correspondence estimation <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b22">23]</ref>. These methods use precomputed hierarchical structures such obtained by an external hierarchical oversegmentation method <ref type="bibr" target="#b1">[2]</ref>, or spatial pyramids as used in DSP <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b22">23]</ref>. Optimization Techniques. Discrete optimization is commonplace in stereo but often problematic in general dense correspondence estimation because of the large label spaces involved. For this issue, SIFT Flow <ref type="bibr" target="#b35">[36]</ref> performs hierarchical BP <ref type="bibr" target="#b17">[18]</ref> on the image pyramid from coarse to fine levels using limited translation ranges. Recently, inspired by randomization search and label propagation schemes of PatchMatch <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b6">7]</ref>, optimization methods using BP <ref type="bibr" target="#b5">[6]</ref> or graph cuts <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b46">47]</ref> have been proposed for efficient inference in pairwise MRFs with large label spaces. However, they are not directly applicable to our hierarchical model. We extend graph cut techniques <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b46">47]</ref> for our inference task where we recover both the graph structure as well as the labeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Model</head><p>Given two images I and I ′ our goal is to find dense correspondence and cosegmentation of a common object shown in the two images. The reference image I is represented by a set of superpixel nodes i ∈ V where Ω i ⊆ Ω denotes a superpixel region in the image domain Ω ⊂ Z 2 .</p><p>In the reference image, we seek a labeling involving a geometric transformation T i ∈ T and a foreground alphamatte value α i ∈ [0, 1] for each superpixel i ∈ V . We formulate this as a mapping function</p><formula xml:id="formula_0">f i = f (i) : V → {T × [0, 1]} that assigns each node a pair of labels f i = (T i , α i ).</formula><p>Here, α i is continuous during inference and binarized at the final step 1 . T i denotes a similarity transform parameterized using a quadruplet (t u , t v , s, r). Slightly abusing the notation, we express the warped pixel location of p ′ in the other image as follows.</p><formula xml:id="formula_1">p ′ = T i (p) = sR r (p − c i ) + c i + t.<label>(1)</label></formula><p>Here, c i is the centroid of pixels in region Ω i , and centering at this point, p is rotated by the 2D rotation matrix R r of angle r and scaled by s, and then translated by t = (t u , t v ).</p><p>In following sections we present the proposed model, by first defining a standard 2D MRF model in Section 3.1 and later generalizing it to a hierarchical model in Section 3.2. We discuss the allowed hierarchical structure in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Single Layer Model</head><p>Let L = (V, E) be a graphical representation of the image I, where nodes i ∈ V and edges (i, j) ∈ E represent superpixels and spatial neighbors, respectively. Given this graph, our single layer model is defined as a standard 2D MRF model:</p><formula xml:id="formula_2">E mrf (f |L) =λ flo i∈V E i flo (f i ) + λ seg i∈V E i seg (f i ) + (s,t)∈E w st E st reg (f s , f t ),<label>(2)</label></formula><p>which consists of the flow data term, cosegmentation data term and the spatial regularization term described below. Flow Data Term. E i flo measures similarity between corresponding regions in the image pair. We define it as</p><formula xml:id="formula_3">E i flo (f i ) = p∈Ωi α i ρ(p, p ′ ) +ᾱ i λ occ ,<label>(3)</label></formula><p>whereᾱ i = 1 − α i and λ occ is a constant penalty for background pixels to avoid trivial solutions where all pixels are labeled background. The ρ(p, p ′ ) robustly measures visual dissimilarity between p and its correspondence p ′ as where truncation using the threshold τ D adds robustness. D(p) is a local feature descriptor extracted at p in the image I, and D ′ (p ′ ) is extracted in I ′2 . We use a variant of the HOG descriptor <ref type="bibr" target="#b13">[14]</ref>. See Section 5.1 for the details.</p><formula xml:id="formula_4">ρ(p, p ′ ) = min{ D(p) − D ′ (p ′ )) 2 2 , τ D },<label>(4)</label></formula><p>Cosegmentation Data Term. The foreground and background likelihoods for each node are defined as follows.</p><formula xml:id="formula_5">E i seg (f i ) = − p∈Ωi α i ln P (I p |θ F ) +ᾱ i ln P (I p |θ B ) . (5)</formula><p>Here, P (·|θ) is likelihood given a foreground or background color model {θ F , θ B } of the image I, which is implemented as 64 3 bins of RGB color histograms. The color models are estimated during initialization (Section 5.3). Spatial Regularization Term. The term E st reg encourages flow and alpha values of neighboring nodes to be similar.</p><formula xml:id="formula_6">E st reg (f s , f t ) =λ st1 min{α s , α t } p∈Bst ψ st (p)/|B st | +λ st2 |α s − α t |.<label>(6)</label></formula><p>Here, B st = ∂Ω s ∩ ∂Ω t is the set of pixels on the boundary of two adjoining regions Ω s and Ω t , and ψ st (p) penalizes flow discontinuities at these pixels. It is defined as</p><formula xml:id="formula_7">ψ st (p) = min{ T s (p) − T t (p) 2 , τ st }.<label>(7)</label></formula><p>If α were binary, then the first term in Eq. (6) would enforce flow smoothness when two adjoining regions are labeled foreground (α s = α t = 1), and the second term would give a constant penalty λ st2 only when α s = α t . However, Eq. (6) generalizes this idea to continuous valued α.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Hierarchical Model</head><p>Now we introduce the notion of a layered graph and generalize the single layer model to a full hierarchical model. As illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>, our hierarchical graph G = (V, E) consists of multiple layered subgraphs {L 0 , L 1 , · · · , L H }. Each layer L l = (V l , E l ) represents a superpixel graph of the image. In addition to spatial edges within each layer E l , our hierarchy G contains parent-child edges (p, c) ∈ E pc l that connect parent nodes p ∈ V l to their children nodes c ∈ V l−1 (green edges in <ref type="figure" target="#fig_1">Figure 2</ref>).</p><p>Using a layered graph G and the model E mrf (f |L) defined in Eq. (2), we define our hierarchical model as</p><formula xml:id="formula_8">E(f, G) = H l=0 E mrf (f |L l ) + E l reg (f |G) + E l gra (V l ) . (8)</formula><p>Here, we treat the hierarchical graph G as a variable that is dynamically estimated together with f . Our construction is fundamentally different from prior work <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29]</ref>, where the hierarchical structure is computed before flow inference.</p><p>Multi-layer Regularization Term. Similar to the spatial regularization term in Eq. <ref type="formula" target="#formula_6">(6)</ref>, the term E l reg enforces smoothness between parent child pairs of V l and V l−1 as</p><formula xml:id="formula_9">E l reg (f |G) = (p,c)∈E pc l w pc E pc reg (f p , f c ),<label>(9)</label></formula><p>where E pc reg is defined using Eq. <ref type="formula" target="#formula_7">(7)</ref> and c's centroid c c as</p><formula xml:id="formula_10">E pc reg (f p , f c ) = λ pc1 min{α p , α c }ψ pc (c c ) + λ pc2 |α p − α c |. (10) Graph Validity Term. The term E l gra measures validity of the layer structure V l as E l gra (V l ) = λ nod β l |V l | − λ col i∈V l p∈Ωi ln P (I p |θ i ). (11)</formula><p>The first term reduces nodes in the higher layers. We set β = 2 to reduce the node count approximately by half at each layer. The second term enforces color consistencies within each region Ω i . θ i represents the RGB color histogram of the region Ω i . Our definition of Eq. (11) is motivated by work in multi-region segmentation <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Hierarchical Structure</head><p>Here we describe the form of hierarchical graphs allowed in our method. The nodes i ∈ V l in each layer divide the image domain Ω into |V l | connected regions Ω i ⊆ Ω. Our hierarchical superpixels have a nested (or tree) structure, i.e., a superpixel (parent) in a layer V l consists of the union of superpixels (children) in its sublayer V l−1 . The lowest layer V 0 named the pixel layer is special because each node i ∈ V 0 represents a pixel p i ∈ Ω. The finest region layer V 1 has about 500 nodes which are set to SLIC superpixels <ref type="bibr" target="#b0">[1]</ref>.</p><p>For parent-child edges (p, c) ∈ E pc l (l = 1, · · · , H), the edge weights w pc are assigned to the area of child regions</p><formula xml:id="formula_11">w pc = |Ω c |.<label>(12)</label></formula><p>At the two lowest layers (l = 0, 1), edges (s, t) ∈ E l between adjoining nodes are assigned edge weights w st as</p><formula xml:id="formula_12">w st = e − Is−It 2 2 /κ ,<label>(13)</label></formula><p>where I i ∈ R 3 is the mean color of the region Ω i . Following <ref type="bibr" target="#b39">[40]</ref>, we set κ to the expected value of 2 I s − I t 2 2 over (s, t) ∈ E l . For the upper layers (l ≥ 2), the edge weights w st are set to the sum of the children's edge weights as</p><formula xml:id="formula_13">w st = w s ′ t ′ ,<label>(14)</label></formula><p>where (s ′ , t ′ ) ∈ E l−1 are children of s and t, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Optimization</head><p>Optimizing E(f, G) in Eq. (8) has two main difficulties. 1) The joint inference of f and G is intractable due to the dependency of f on G.</p><p>2) The label space of f resides in a 5-dimensional continuous domain and the number of candidate labels is essentially infinite. To practically address these issues, we propose two-pass bottom-up and top-down optimizing procedures that approximately optimize the energy. In the bottom-up phase, we construct a hierarchical structure G by incrementally adding layers from lower to higher levels, while simultaneously estimating the labeling f . In the top-down phase, we refine the labeling f while keeping the structure G fixed. The optimization procedure is summarized in Algorithm 1. Next we discuss the details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Bottom-Up Hierarchy Construction</head><p>To formally describe our bottom-up procedure, we denote G k = (V k , E k ) as a hierarchy consisting of k+1 layered subgraphs {L 0 , · · · , L k } where L l = (V l , E l ). We also define it sequentially, i.e., G k and G k+1 share the same structure for the bottom k+1 layers.</p><p>At a high level, our bottom-up procedure is presented as a sequence of subtasks, where given a current solution {f, G k } we estimate {f, G k+1 } as illustrated in <ref type="figure">Figures 3 (a)</ref> and (d), respectively. We estimate {f, G k+1 } as approximate minimizers of E(f, G k+1 ) in Eq. <ref type="bibr" target="#b7">(8)</ref>.</p><p>Here, E(f, G k+1 ) given G k can be separated into two parts</p><formula xml:id="formula_14">E(f, G k+1 ) = E(f |G k ) + E top (f, L k+1 ),<label>(15)</label></formula><p>where E(f |G k ) is energy involved in the known graph G k while E top (f, L k+1 ) refers to the unknown top layer L k+1 .</p><formula xml:id="formula_15">E top (f, L k+1 ) = E mrf (f |L k+1 )+E k+1 reg (f |G k+1 )+E k+1 gra (V k+1 ).<label>(16)</label></formula><p>Jointly inferring G k+1 and its labeling f is difficult. Therefore, we assume a known temporary graphĜ k+1 for unknown G k+1 , and we replace this joint problem by a simpler labeling problemf onĜ k+1 .</p><formula xml:id="formula_16">E(f |Ĝ k+1 ) = E(f |G k ) + A(f ).<label>(17)</label></formula><p>Here, E(f |G k ) is equivalent to E(f |G k ) in Eq. <ref type="bibr" target="#b14">(15)</ref>, and A is an approximation of the top layer energy E top .</p><p>In following three sections, we detail lines 4-10 of Algorithm 1 and explain how we deriveÊ(f |Ĝ k+1 ), optimize it, and obtain the desired solution {f, G k+1 } from {f ,Ĝ k+1 }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Opimizaion on temporary graph</head><p>(a) Graph G k and its labeling f (b) Temporary graphĜ k+1 (c)Ĝ k+1 and optimized labelingf (d) Graph G k+1 with new layer <ref type="figure">Figure 3</ref>. Bottom-up Graph Construction (one step). Each rectangular cell in the illustration represents a node i ∈ V l and a set of contiguous cells represents a graph layer V l . The arrows and colors denote flow and alpha labels fi (red: foreground, blue: background).</p><p>(a) Graph G k and its labeling f . (b) By duplicating the top layer V k of G k , we create a temporary graphĜ k+1 as an approximation of G k+1 . (c) We optimize the labelingf onĜ k+1 . The number of unique labels in V ′ k is reduced by label costs <ref type="bibr" target="#b14">[15]</ref> to induce region merging. (d) V ′ k is converted into a new layer V k+1 , by merging nodes of V ′ k assigned the same label that form connected components inĜ k+1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Energy Approximation using Temporary Graphs</head><p>We now briefly explain the conversion from E(f, G k+1 ) in Eq. (15) toÊ(f |Ĝ k+1 ) in Eq. <ref type="bibr" target="#b16">(17)</ref>. For detailed derivations, please refer to the supplementary material.</p><p>To relax the joint inference of E(f, G k+1 ), we create a temporary graphĜ k+1 as an approximation of G k+1 , by duplicating the top layer of G k as L <ref type="figure">Figures 3 (a)</ref> and (b), respectively. Here, a labelingf onĜ k+1 (or V ′ k ) can equivalently express all possible f on G k+1 (or V k+1 ), because V ′ k is the finest form of any possible V k+1 . The labelingf is copied from f at line 5.</p><formula xml:id="formula_17">′ k = (V ′ k , E ′ k ) ← (V k , E k ) (line 4 of Algorithm 1). We illustrate G k and G k+1 in</formula><p>Substituting</p><formula xml:id="formula_18">G k+1 ←Ĝ k+1 into E(f, G k+1 ), we derive its approximationÊ(f |Ĝ k+1 ) in Eq. (17) with following A. A(f ) = E mrf (f |L ′ k )+E k+1 reg (f |Ĝ k+1 )+E k+1 gra (f |V ′ k ). (18)</formula><p>The conversion from E top in Eq. <ref type="bibr" target="#b15">(16)</ref> to this A is provably exact except for only terms E k+1 gra and E st reg in E mrf of Eq. (2). Here, conversion of E k+1 gra is tricky because we need to convert variables from V k+1 to a labelingf on V ′ k . We observe that the region of each node i ∈ V k+1 should optimally 1) be a connected component, 2) assigned a single label unique from neighbors, and 3) be the union of regions in V ′ k . Thus, we can treat nodes i ∈ V k+1 as connected components C i of nodes in V ′ k assigned the same label, i.e.,</p><formula xml:id="formula_19">V k+1 ≡ C i nodes ∀ c ∈ C i in V ′</formula><p>k are assigned the same labelf c and connected.</p><p>.</p><p>This property allows us to rewrite E k+1 gra (V k+1 ) in Eq. (11) as a function off . To further make inference tractable, we relax the connectivity of |V k+1 | and treat |V k+1 | as label costs <ref type="bibr" target="#b14">[15]</ref> off , i.e., the number of unique labelsf i in V ′ k without considering their spatial connections. In this manner, the formulation of Eq. (11) becomes the same as that of multi-region segmentation <ref type="bibr" target="#b14">[15]</ref>. Following their model fitting approach based on alpha expansion moves <ref type="bibr" target="#b8">[9]</ref>, we treat the label costs and the likelihood terms of Eq. (11) as pairwise submodular terms and unary terms, respectively. See more discussions in the supplementary.  </p><formula xml:id="formula_21">(Ê,f ,Ĝ k+1 , V ′ k ) f ← argminÊ(f |Ĝ k+1 ) ;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimization of Approximation Energy</head><p>In <ref type="figure">Figure 3</ref> (c) and at line 6 of Algorithm 1, we minimize the approximation energyÊ(f |Ĝ k+1 ) of Eq. <ref type="formula" target="#formula_1">(17)</ref> with known G k+1 . To efficiently infer the continuous 5dof labels inf , we use the local expansion move method of <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b46">47]</ref>.</p><p>In its general form, the local expansion move algorithm repeatedly solves the following binary labeling problem for each target node i ∈ V visited in sequence.</p><formula xml:id="formula_22">f (t+1) = argmin E(f |f j ∈ {f (t)</formula><p>j , ℓ} for j ∈ R i ). <ref type="bibr" target="#b19">(20)</ref> Here, R i ⊂ V is a set of local nodes around the target node i (named expansion region), and this operation tries to improve the labels of the local nodes j ∈ R i by assigning them either their current label f (t) j or a candidate label ℓ. We use graph cuts <ref type="bibr" target="#b7">[8]</ref> to solve this binary problem.</p><p>Our version of local expansion moves is summarized in Algorithm 2. During the bottom-up process, we randomly visit all nodes in the top layer V ′ k (i.e., target layer V T ) at line 1, and update the labeling of local nodes. In order to apply the local expansion move algorithm for our hierarchical MRF model, we extended it in two ways. First, the expansion region R i is extended from i's neighbors (N i at line 2) to include all their descendants (line 3). Second, when generating candidate labels ℓ for the target node i (line 5), we use four types of candidate proposers listed below.</p><p>• Expansion proposer generates a label by copying the current label as ℓ ← f i . This tries to propagate the current label f i to nearby nodes in R i as explained in <ref type="bibr" target="#b47">[48]</ref>. • Cross-view proposer refers to the current labeling f ′ of the other image, and uses a label f ′ i ′ that gives warping to the target node region Ω i as a candidate ℓ, using inverse warp of f ′ i ′ . This is similar to view propagation in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b5">6]</ref>. • Merging proposer generates labels ℓ ← w i f i + w j f j as weighted sums of i's current label f i and its neighbors' labels f j , j ∈ N i . The weights w i , w j ∈ [0, 1] are proportional to their region sizes |Ω i |, |Ω j |. This is a new extension for promoting better region merging. • Perturbation proposer generates labels ℓ ← f i + ∆ by randomly perturbing the current label f i . Similarly to <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b6">7]</ref>, we iterate between lines 5 and 6 several times while reducing the perturbation size |∆| by half.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Incremental Layer Construction</head><p>In <ref type="figure">Figure 3</ref> (d) and at line 7 of Algorithm 1, we create a new graph G k+1 by merging nodes of V ′ k inĜ k+1 . Here, V k+1 is created from V ′ k andf using the variable conversion of Eq. <ref type="bibr" target="#b18">(19)</ref>. After merging regions, we check the number of new foreground regions at the top layer. If it is zero (line 8), we reject the new solution and stop the graph construction process. Otherwise, we adopt the new solution {f , G k+1 } as {f, G} (line 9). Later we check the foreground count again and if it is one or not reduced from the previous iteration (line 10), we stop the graph construction process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Top-Down Labeling Refinement</head><p>After the bottom-up phase, we further refine the labeling f during the top-down phase shown at lines 12-14 of Algo-rithm 1. Since G is held fixed during this step, we can directly optimize E(f |G) using local expansion moves without requiring the energy conversion described in Sec. 4.1. During this phase, we visit layers V k in G in top-down order (from k = H to k = 1) and apply local expansion moves with V k as a target layer V T . Here, the labeling f for the higher layers V l (l &gt; k) does not change, because the expansion regions R i only contain nodes in layers V k and below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implementation Details</head><p>We now discuss initialization steps and features used in our method. See the supplementary material for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Local HOG Features</head><p>The images are first resized so that their larger dimension becomes 512 pixels. A Gaussian pyramid is then built for each image (we use 1 octave and 1 sub-octave). From each pyramid layer, we densely extract local histogram of gradient (HOG) feature descriptors <ref type="bibr" target="#b13">[14]</ref>. These features are extracted at every pixel on the image grid from patches of size 27 × 27 pixels. Our HOG descriptors are 96-dimensional. We use a 3×3 cell grid for each patch and 16 equally spaced bins for the oriented gradient histograms. Each gradient histogram thus has 16 bins for signed gradients and 8 bins for unsigned gradients. The histograms for each contiguous 2 × 2 block of the 3 × 3 cell grid are aggregated to form a 24-dimensional vector. These are then L2-normalized followed by element-wise truncation (using a threshold of 0.5). Four such vectors are concatenated to form the final 96-dimensional HOG descriptor. These HOG features are used to compute the flow data terms E i flo described earlier. They are also used to construct bag of visual words (BoW) histogram features required during the initialization stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">BoW Histogram Features</head><p>Each HOG descriptor is vector-quantized using a Kmeans codebook of size 256. Next, BoW histograms are computed from several overlapping image patches of size 64 × 64 pixels. These patches are sampled every 4 pixels (both horizontally and vertically) in the image. We use integral images (one per visual word) to speed up the BoW histogram computation. All the visual words are aggregated into a histogram. This is repeated for 2×2 sub-regions. The five BoW histograms are then L2-normalized followed by element-wise square root normalization 3 . The 256dimensional histograms are concatenated to form 1280dimensional BoW histogram features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Initialization</head><p>During initialization, initial flow candidates and foreground/background color models for each image are com- puted as follows. First, dense matching is done using the BoW features at three levels in the image pyramid. The Euclidean distances between each pixel feature in the first image and features for all pixels within a search window in the second image are computed. Fortunately this is quite fast due to the sparsity of the BoW features. The best match is stored as a flow candidate. The ratio of the Euclidean distances of the best and worst match is computed. We use this heuristic to predict the probability of a true match, motivated by the ratio test <ref type="bibr" target="#b36">[37]</ref> (see <ref type="figure" target="#fig_4">Figure 4</ref>).</p><p>Areas with high and low match probabilities are likely to be the "foreground" and "background" respectively. By thresholding the ratio values, we create foreground/background soft seeds and initial segmentations as input to GrabCut <ref type="bibr" target="#b39">[40]</ref> and learn color models {θ F , θ B } for each image. Geodesic distance from the image boundary is used as an additional unary background likelihood term <ref type="figure" target="#fig_4">(Figure 4, right)</ref>. See the supplementary material for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Efficient Implementation</head><p>Three key ideas allow our optimization method to be efficiently implemented. First, unary terms E i flo (f i ) and E i seg (f i ) in Eq. (2) can be efficiently computed using the tree structure of G. Specifically, the unary cost E p (ℓ) of a node p ∈ V l is computed as the sum c E c (ℓ) over its children c ∈ V l−1 , if their labels ℓ are the same. This constant-label property is satisfied during local expansion moves because the candidate label ℓ is the same for all nodes in an expansion region R i . Thus, at line 6 of Algorithm 2, we compute the unary costs E j (ℓ) for j ∈ R i by sequentially summing them up from bottom to top layer nodes. Second, we exclude the pixel layer L 0 / V 0 from the graph G during the main iterations. We add it to G just before the last refinement step in the top-down phase (k = 1 at line 13 of Algorithm 1). Finally, we use efficient graph cuts <ref type="bibr" target="#b7">[8]</ref> at line 6 of Algorithm 2, instead of QPBO <ref type="bibr" target="#b29">[30]</ref>. This is possible because our energy is submodular under (local) expansion moves <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b46">47]</ref>. The proofs are in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>We evaluate our method for flow and segmentation accuracy and compare it to existing methods on our new dataset. Dataset. Our dataset comprises of 400 image pairs divided into three groups -FG3DCar contains 195 image pairs of vehicles from <ref type="bibr" target="#b34">[35]</ref>. JODS contains 81 image pairs of airplanes, horses, and cars from <ref type="bibr" target="#b41">[42]</ref>. PASCAL contains 124 image pairs of bicycles, motorbikes, buses, cars, trains from <ref type="bibr" target="#b19">[20]</ref>. See <ref type="figure">Figure 6</ref> for some examples from each group. Flow accuracy. We evaluate flow accuracy by the percentage of pixels in the true foreground region that have an error measure below a certain threshold. Here, we compute the absolute flow endpoint error (i.e., the Euclidean distance between estimated and true flow vectors) in a normalized scale where the larger dimensions of images are 100 pixels. Segmentation accuracy. We use the standard intersectionover-union ratio metric for segmentation accuracy. As existing flow estimation methods do not recover common foreground regions, we compute them by post-processing the estimated flow maps. Specifically, given the two flow maps, we do a left-right consistency check with a suitable threshold and treat pixels that pass this test as foreground. Settings. We strictly fixed all the parameters throughout the experiments as follows. For the data and graph term parameters, we set {λ flo , λ occ , τ D , λ seg , λ nod , λ col } ← {0. <ref type="bibr" target="#b24">25</ref> See the supplementary material for our strategy of tuning parameters. Our method is implemented using C++ and run by a single thread on a Core i7 CPU of 3.5 GHz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Comparison with Existing Approaches</head><p>For correspondence, we compare our method with SIFT Flow <ref type="bibr" target="#b35">[36]</ref>, DSP <ref type="bibr" target="#b28">[29]</ref> and DFF <ref type="bibr" target="#b52">[53]</ref>  <ref type="bibr" target="#b3">4</ref> . We also evaluate our method using only the single layer model without hierarchy, which can be done by skipping the bottom-up construction step in Algorithm 1. This single layer method can be seen as a variant of <ref type="bibr" target="#b47">[48]</ref>. For cosegmentation, we compare our method with Joulin et al. <ref type="bibr" target="#b23">[24]</ref>  <ref type="bibr" target="#b4">5</ref> and Faktor and Irani <ref type="bibr" target="#b16">[17]</ref> based only on segmentation accuracies 6 . We summarize average accuracy scores for each subset in the upper part of <ref type="table">Table 1</ref>, where flow accuracy is evaluated using a threshold of 5 pixels. The plots in <ref type="figure">Figure 5</ref> show average flow accuracies with varying thresholds. As shown here, our method achieves the best performance on all three groups at all thresholds. Our average flow accuracies for FG3DCar, JODS and PASCAL, respectively, are up to 45%, 19% and 34% higher than SIFT Flow (best existing method). Su- <ref type="table">Table 1</ref>. Benchmark results. FAcc is flow accuracy rate for an error threshold of 5 pixels in a normalized scale. SAcc is segmentation accuracy by intersection-over-union ratios. SAcc scores (⋆) of optic flow mothods are computed by post-processing using left right consistency check.   <ref type="figure">Figure 5</ref>. Average flow accuracies evaluated by endpoint errors with varying thresholds. Ours always shows best scores. DFF <ref type="bibr" target="#b52">[53]</ref> is not robust due to lack of explicit regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>Ground Truth perior results to our single layer method shows the effectiveness of our hierarchical model and inference. DFF <ref type="bibr" target="#b52">[53]</ref> cannot handle large appearance differences of objects due to lack of explicit regularization. We show qualitative comparisons with SIFT Flow <ref type="bibr" target="#b35">[36]</ref> and DSP <ref type="bibr" target="#b28">[29]</ref> in <ref type="figure">Figure 7</ref>.</p><p>We report average segmentation scores in the lower part of <ref type="table">Table 1</ref>. <ref type="figure">Figure 8</ref> shows qualitative comparisons with Faktor and Irani <ref type="bibr" target="#b16">[17]</ref> and Joulin et al. <ref type="bibr" target="#b23">[24]</ref>. Although our model for segmentation is quite simple compared to other methods, our method is competitive or has higher accuracy due to joint inference of foreground correspondence.</p><p>Running time of our method is about 7 minutes for obtaining a pair of flow-alpha maps of 512 × 384 pixels, including 1 minute for the feature extraction and initialization, 3 minutes for the final refinement step with the pixel layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We have presented a joint method for cosegmentation and dense correspondence estimation in two images. Our method uses a hierarchical MRF model and jointly infers the hierarchy as well as segmentation and correspondence using iterated graph cuts. Our method outperforms a number of methods designed specifically either for correspondence recovery <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b52">53]</ref> or cosegmentation <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b12">13]</ref>. We provide a new dataset for quantitative evaluation. Enforcing left-right consistencies on flow and segmentation maps for two images, or by using multiple images <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b24">25]</ref> are promising avenues for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Joint recovery of dense correspondence and cosegmentation where foregrounds are segmented and aligned. We show our results and corresponding ground truth (GT) from our new dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Hierarchical model. Each layer (2D MRF) estimates a dense flow and alpha map f , which is regularized by higher-level estimates and the final estimates are obtained at the bottom layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1 :</head><label>1</label><figDesc>TWO-PASS OPTIMIZATION PROCESS input : Two images I, I ′ output : Hierarchical graph G and flow-alpha map f 1 Initialize the graph: G ← G 1 2 Initialize the labeling f and color models θ F , θ B (Sec. 5.3) 3 for k = 1, 2, · · · do ♦ bottom-up graph construction ♦ 4 Create temporaryĜ k+1 by duplicating V k of G k ; 5Initialize temporaryf by copying labels from f ;<ref type="bibr" target="#b5">6</ref> Perform local expansion moves</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>7</head><label></label><figDesc>Create G k+1 by merging nodes of V ′ k inĜ k+1 ;<ref type="bibr" target="#b7">8</ref> if rejection criterion is met then break;9 Update solution {f, G} ← {f , G k+1 } ; 10 if any stopping criteria is met then break; 11 end 12 for k = H, · · · , 1 do ♦ top-down label refinement ♦ 13 Perform local expansion moves (E, f , G, V k ) f ← argmin E(f |G) with fi fixed for ∀i ∈ V l&gt;k ; 14 end Algorithm 2: LOCAL EXPANSION MOVES [48, 47] argments: (model E, labeling f , graph G, target layer VT ) 1 for each target node i ∈ VT do 2 Make neighborhood: Ni ← {i's neighbors}∪{i} ; 3 Make expansion region: Ri ← {Ni's descendants}∪Ni ; 4 for each candidate proposer do 5 Generate a candidate label ℓ = (T, α) ; 6Apply a local expansion move using min-cut:f ← argmin E(f |G) with fj ∈ {fj, ℓ} for j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Min/Max ratios of BoW feature matching distances in local windows (middle). Low ratios (blue) are likely to suggest foreground. Geodesic distances from the image boundary (right) are used to add background clues (black regions).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .Figure 7 .Figure 8 .</head><label>678</label><figDesc>DatasetCorrespondence results.OursFaktor et al.<ref type="bibr" target="#b16">[17]</ref> Joulin et al.<ref type="bibr" target="#b23">[24]</ref> Cosegmentation results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>, 2.4, 6.5, 0.8, 125, 1}. For regularization parameters {λ st1 , λ st2 , τ st , λ pc1 , λ pc2 , τ pc } associated with the pixel layer (edges E 0 and E pc 1 ) we use {0.5, 20, 20, 0.005, 10, 200}, and for the other edges we use {0.1, 4, 20, 0.04, 8, 200}.</figDesc><table></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">To avoid degenerate flow solutions, we set α i always larger than 0.1 during inference. See supplementary for a detailed explanation.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">As suggested in<ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b52">53]</ref>, D ′ (p ′ ) can be more accurately computed by using the scale s and rotation r of the similarity transformation T i .</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">This is equivalent to using a Hellinger kernel instead of the Euclidean distance to measure the similarity of two feature vectors.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We omit results of HaCohen et al.<ref type="bibr" target="#b18">[19]</ref> for its low performance on our dataset. It could not find any correspondence for many image pairs.<ref type="bibr" target="#b4">5</ref> For Joulin et al.<ref type="bibr" target="#b23">[24]</ref> that cannot identify the "foreground" label from {0, 1}, we refer to ground truth and choose for each image pair either 0 or 1 to maximize the scores. Results of their extension method<ref type="bibr" target="#b24">[25]</ref> are omitted since we could not observe improvemnts over<ref type="bibr" target="#b23">[24]</ref> in our settings.<ref type="bibr" target="#b5">6</ref> We omit results of Dai et al.<ref type="bibr" target="#b12">[13]</ref> as it did not work for many image pairs. The method seems to fail in finding matches with learned templates.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Slic superpixels compared to state-of-the-art superpixel methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sustrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2274" to="2282" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Contour detection and hierarchical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="898" to="916" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">PatchMatch: a randomized correspondence algorithm for structural image editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldman</surname></persName>
		</author>
		<idno>24:1-24:11</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graph</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The generalized patchmatch correspondence algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of European Conf. on Computer Vision (ECCV)</title>
		<meeting>of European Conf. on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="29" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">icoseg: Interactive co-segmentation with intelligent scribble guidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Univerity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kowdle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">PMBP: patchmatch belief propagation for correspondence field estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Besse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="13" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">PatchMatch Stereo -Stereo Matching with Slanted Support Windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bleyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of British Machine Vision Conf. (BMVC)</title>
		<meeting>of British Machine Vision Conf. (BMVC)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="14" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1124" to="1137" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast approximate energy minimization via graph cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1222" to="1239" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient sequential correspondence selection by cosegmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perdoch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1568" to="1581" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Enriching visual knowledge bases via object discovery and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2035" to="2042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised object discovery and localization in the wild: Part-based matching with bottom-up region proposals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1201" to="1210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cosegmentation and cosketch by unsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Int&apos;l Conf. on Computer Vision (ICCV)</title>
		<meeting>of Int&apos;l Conf. on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1305" to="1312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Fast approximate energy minimization with label costs. Int&apos;l Journal of Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Delong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Osokin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">N</forename><surname>Isack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A tensor-based algorithm for high-order graph matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Duchenne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I.-S</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2383" to="2395" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Co-segmentation by composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Faktor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Int&apos;l Conf. on Computer Vision (ICCV)</title>
		<meeting>of Int&apos;l Conf. on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1297" to="1304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient belief propagation for early vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="54" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Non-rigid dense correspondence with applications for image enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hacohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<idno>70:1- 70:10</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graph</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2011-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semantic contours from inverse detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Int&apos;l Conf. on Computer Vision (ICCV)</title>
		<meeting>of Int&apos;l Conf. on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On sifts and their scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mayzels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multiscale conditional random fields for image labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Á</forename><surname>Carreira-Perpiñán</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="695" to="702" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generalized deformable spatial pyramid: Geometry-preserving dense correspondence estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1392" to="1400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Discriminative clustering for image co-segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multi-class cosegmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Efficient image and video co-localization with frank-wolfe algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of European Conf. on Computer Vision (ECCV)</title>
		<meeting>of European Conf. on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hierarchically-constrained optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Distributed cosegmentation via submodular optimization on anisotropic diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Int&apos;l Conf. on Computer Vision (ICCV)</title>
		<meeting>of Int&apos;l Conf. on Computer Vision (ICCV)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="169" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deformable spatial pyramid matching for fast dense correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2307" to="2314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Minimizing nonsubmodular functions with graph cuts-a review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1274" to="1279" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">What energy functions can be minimized via graph cuts?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zabin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="159" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multiple view object cosegmentation using appearance and stereo cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kowdle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of European Conf. on Computer Vision (ECCV)</title>
		<meeting>of European Conf. on Computer Vision (ECCV)<address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="789" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Region-tree based stereo using dynamic programming optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Selzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2378" to="2385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Optical flow estimation on coarse-tofine region-trees using discrete optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Int&apos;l Conf. on Computer Vision (ICCV)</title>
		<meeting>of Int&apos;l Conf. on Computer Vision (ICCV)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1562" to="1569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Jointly optimizing 3d model fitting and fine-grained classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">I</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of European Conf. on Computer Vision (ECCV)</title>
		<meeting>of European Conf. on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">SIFT Flow: Dense Correspondence across Scenes and Its Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="978" to="994" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Patch match filter: Efficient edge-aware filtering meets randomized search for fast correspondence field estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1854" to="1861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Scale-space sift flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1112" to="1119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">grabcut&quot;: Interactive foreground extraction using iterated graph cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graph</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="309" to="314" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Cosegmentation of image pairs by histogram matching -incorporating a global constraint into mrfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="993" to="1000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Unsupervised joint object discovery and segmentation in internet images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1939" to="1946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Unsupervised co-segmentation through region matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Rubio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Serrat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="749" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A Brief Description of Natural Neighbour Interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interpreting multivariate data</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1981" />
			<biblScope unit="page" from="21" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Discovering objects and their location in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="370" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Co-localization in real-world images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Graph cut based continuous stereo matching using locally shared labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Taniai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Naemura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1613" to="1620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Taniai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Naemura</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.08328</idno>
		<ptr target="http://arxiv.org/abs/1603.08328" />
		<title level="m">Continuous Stereo Matching Using Local Expansion Moves</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Region-based hierarchical image matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Todorovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="66" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Unsupervised object discovery: A comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Buntine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="284" to="302" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Reconstructing PASCAL VOC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Agapito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Object cosegmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2217" to="2224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">DAISY filter flow: A generalized discrete approach to dense correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3406" to="3413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning for dense correspondences across scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Flowweb: Joint image set alignment by weaving consistent, pixel-wise correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1191" to="1200" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
