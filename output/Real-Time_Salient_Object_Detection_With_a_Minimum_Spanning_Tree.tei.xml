<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Real-Time Salient Object Detection with a Minimum Spanning Tree</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Tu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate Institute of Electronics Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengfeng</forename><surname>He</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">City University of Hong</orgName>
								<address>
									<settlement>Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingxiong</forename><surname>Yang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Information Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shao-Yi</forename><surname>Chien</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate Institute of Electronics Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Real-Time Salient Object Detection with a Minimum Spanning Tree</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present a real-time salient object detection system based on the minimum spanning tree. Due to the fact that background regions are typically connected to the image boundaries, salient objects can be extracted by computing the distances to the boundaries. However, measuring the image boundary connectivity efficiently is a challenging problem. Existing methods either rely on superpixel representation to reduce the processing units or approximate the distance transform. Instead, we propose an exact and iteration free solution on a minimum spanning tree. The minimum spanning tree representation of an image inherently reveals the object geometry information in a scene. Meanwhile, it largely reduces the search space of shortest paths, resulting an efficient and high quality distance transform algorithm. We further introduce a boundary dissimilarity measure to compliment the shortage of distance transform for salient object detection. Extensive evaluations show that the proposed algorithm achieves the leading performance compared to the state-of-the-art methods in terms of efficiency and accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The goal of salient object detection is to identify the most important objects in a scene. Recently, it has attracted much attention <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b3">4]</ref> for its wide range of applications such as image retargeting <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b6">7]</ref>, object recognition <ref type="bibr" target="#b21">[22]</ref> and image segmentation <ref type="bibr" target="#b8">[9]</ref>, to name a few. As a preprocessing step, a desirable saliency detection algorithm should be computational efficient for practical usage.</p><p>In general, previous works can be categorized into bottom-up or top-down methods. Top-down methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b28">29]</ref> are task-driven and usually require supervised learning with high-level information. Bottom-up methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b11">12]</ref> are usually based on low-level features such as color, gradient or contrast. Most saliency detection methods are * Correspondence author.</p><p>bottom-up models owing to the task-free nature and superior computational efficiency over top-down approach.</p><p>The background and connectivity priors proposed by Wei et al. <ref type="bibr" target="#b25">[26]</ref> have been shown to be effective in bottomup salient object detection. The background prior assumes the image boundaries are mostly background. The connectivity prior describes the fact that background regions are usually large and homogeneous so that pixels in the background can be easily connected to each other. In <ref type="bibr" target="#b25">[26]</ref>, the boundary patches are set as the background seeds and the saliency of a patch is defined as the shortest-path geodesic distance towards the background seeds.</p><p>Many recent approaches <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b33">34]</ref> achieve state-of-the-art results by extending the background and connectivity priors. In <ref type="bibr" target="#b34">[35]</ref>, Zhu et al. also utilize the geodesic distance and take the spatial layout of image patches into consideration for a more robust boundary measurement. Yang et al. <ref type="bibr" target="#b27">[28]</ref> compute the saliency value of a region according to its relevance to boundary patches by manifold ranking. Jiang et al. <ref type="bibr" target="#b11">[12]</ref> formulate the problem as absorbing Markov chain on an image graph model. The boundary nodes are chosen as the absorbing nodes in a Markov chain and the absorbed time is used to measure saliency. In <ref type="bibr" target="#b20">[21]</ref>, they propose a saliency optimization approach based on Cellular Automata. They also leverage the background prior to compute a global color distinction map as well as a spatial distance map. These two maps are integrated into a simple background-based map for initialization. To achieve feasible complexity, all the above methods rely on superpixel abstraction to reduce the processing units. However, the over-segmentation step usually becomes the processing bottleneck and restricted this type of methods from real-time applications. Lately, Zhang et al. <ref type="bibr" target="#b33">[34]</ref> use the minimum barrier distance (MBD) <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b5">6]</ref> for salient object detection. They show that minimum barrier distance is superior to geodesic distance in several numerical evaluation. Instead of processing with superpixels, they demonstrate an efficient pixel-wise raster-scanning algorithm to compute the approximated MBD transform.</p><p>We also tackle the problem from the distance trans-form perspective. Unlike previous works <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b33">34]</ref> which compute the distance on an image, we instead measure the distance between pixels on a minimum spanning tree (MST) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>. This tree representation of an image offers us two main advantages over measuring distance in pixel/superpixel level: (i) We show that the minimum spanning tree representation largely reduce the candidate paths from any starting node to the target seeds so that it can effectively benefit the computational efficiency of the distance transform procedure. Specifically, when the minimum barrier distance is used as the distance metric, it takes only 6 comparisons and 2 subtractions per pixel regardless of the number of candidate paths and the number of target seeds.</p><p>(ii) The structure-aware property of the minimum spanning tree allows the distance measure on a tree able to distinguish objects in a scene. The proposed salient object detection method achieves superior results to the state-of-the-art methods. In the meanwhile, the proposed method takes only 24.6 ms using a single thread CPU for a 300 × 400 image (including the construction of MST) which offers an ideal choice for real-time oriented applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Minimum Spanning Tree for an Image</head><p>The effectiveness of minimum spanning tree (MST) based image representation has been demonstrated in cost aggregation for stereo matching <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref> and edgepreserving filtering <ref type="bibr" target="#b2">[3]</ref>. In this section, we briefly review the MST representation as a preliminary knowledge to the proposed method.</p><p>By treating an image I as a standard 4-connected, undirected graph (planar graph) with nodes being all the image pixels, and the edges between adjacent pixels being weighted by color/intensity differences (absolute gradients), a minimum spanning tree can be constructed by sequentially removing edges with large weights (Kruskal's algorithm <ref type="bibr" target="#b12">[13]</ref>), leaving the remaining edges connecting through all pixels as a tree. More specifically, let s and r be a pair of adjacent pixels, the weight between s and r is ω(s, r) = ω(r, s) = |I(s) − I(r)|. <ref type="bibr" target="#b0">1</ref> (1) <ref type="figure" target="#fig_0">Figure 1</ref> shows a toy example of 4 × 5 pixels. During the tree construction, if two adjacent pixels have large gradient, the edge between these two pixels is likely to be removed and the path to traverse one pixel to another will be long as shown in <ref type="figure" target="#fig_0">Figure 1</ref>(c). As a result, the distance on the MST will be large for these two pixels. On the contrary, if two pixels are similar in appearance, they are likely to be connected on the MST and the distance will be short. For tree construction, Bao et al. <ref type="bibr" target="#b2">[3]</ref> present a linear time approach tailored for 8-bit images (which may have multiple channels) based on Prim's algorithm <ref type="bibr" target="#b19">[20]</ref>. It takes about 0.07 seconds to build a MST using single thread on a modern CPU for a 1-megapixel image. We adopt the same algorithm and it takes in average 5.86 ms in MST construction for a 300 × 400 image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Distance Transform with a Minimum Spanning Tree</head><p>Previously, the geodesic distance (GD) and the barrier distance (BD) are used for salient object detection. In this section, we present a novel distance transform based on the MST representation of an image. The proposed algorithm is able to apply to both kinds of distance metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Basic Definition</head><p>The goal of distance transform is to compute a distance map D with respect to a set of seed nodes 2 S. Again, the input image I is treated as a planar graph. Let π = {π(0), ..., π(k)} denote a path on the graph. π(i) and π(i + 1) are adjacent pixels on image I. Given a distance metric f (π), the distance transform of a node v is</p><formula xml:id="formula_0">D(v) = min π∈ΠS,v f (π),<label>(2)</label></formula><p>where Π S,v denotes the set of all paths connecting v and a seed in S. In general, the distance measure of two nodes u and v has the following properties</p><formula xml:id="formula_1">f (u → v) = f (v → u) (3) f (u → v) &gt;= 0<label>(4)</label></formula><p>In <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b34">35]</ref>, the geodesic distance is used for salient object detection. The geodesic distance accumulates the distance of all traversed pixel pairs on a path. Formally, the geodesic distance metric f GD (π) is defined as</p><formula xml:id="formula_2">f GD (π) = k−1 ∑ i=0 |I(π(i + 1)) − I(π(i))|.<label>(5)</label></formula><p>In <ref type="bibr" target="#b33">[34]</ref>, the minimum barrier distance <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b5">6]</ref> is used for salient object detection. The barrier distance metric f BD (π) is defined as</p><formula xml:id="formula_3">f BD (π) = k max i=0 I(π(i)) − k min i=0 I(π(i)).<label>(6)</label></formula><p>The barrier distance is shown to be more robust than geodesic distance for salient object detection <ref type="bibr" target="#b33">[34]</ref>. However, finding the exact minimum barrier distance (MBD) has high complexity of O(mn log n) <ref type="bibr" target="#b5">[6]</ref>, where n is the number of pixels in the image and m is the number of distinct values the image contains. Zhang et al. <ref type="bibr" target="#b33">[34]</ref> proposed an iterative raster scanning approach to approximate the MBD transform instead of exhaustive search by Dijkstra-like algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The Proposed Distance Transform</head><p>Instead of searching the shortest distance on the image, we propose to find the shortest path on a minimum spanning tree. The proposed MST-based distance transform is an exact solution for distance defined on the tree. It consists of two passes: bottom-up traversal and top-down traversal. <ref type="figure" target="#fig_1">Figure 2</ref> gives a simple illustration using geodesic distance. The counterpart using barrier distance is similar. Given a set of seed nodes S, we initialize the distance values of seed nodes to 0 and all other nodes to ∞ as shown in <ref type="figure" target="#fig_1">Figure 2</ref>(a). For the bottom-up pass, we start from the leaf nodes and update the distance values of their parent nodes by</p><formula xml:id="formula_4">D(p) = min{D(p), f (π v ∪ p)},<label>(7)</label></formula><p>where p denotes the parent node of v, π v denotes the current optimal path connecting v to its nearest seed node and π v ∪ p denotes the same path plus one step further to reach its parent p. As the nearest seed node to p can come from its bottom or from its top, Eq. 7 tests the possible solution from the bottom. If p has multiple child nodes, Eq. 7 will be evaluated for each child node and the minimum distance is stored. One example is shown in the root node of Figure 2(b). In short, the updating process is conducted in bread first search (BFS) order in each node. The bottomup traversal continues until it reaches the root node. The top-down pass is similar while starting from the root node. For each node, we visit its child nodes and update their distance values by</p><formula xml:id="formula_5">D(v) = min{D(v), f (π p ∪ v)}.<label>(8)</label></formula><p>Note that Eq. 8 not only tests for the possible solution from the top, but also propagate potentially better solutions from other branches. One can see the illustration in <ref type="figure" target="#fig_1">Figure 2</ref>(b).</p><p>After the bottom-up pass, many nodes still have ∞ distance from seed nodes. The nearest seed node to a certain node may locate at the top or at the branches splitting from the nodes above it. After the bottom-up pass, a splitting node is expected to record the optimal distance value from one of its branches. And in the top-down pass, the optimal solution will be propagated down to other branches as shown in <ref type="figure" target="#fig_1">Figure 2</ref>(c). This is why we conduct the bottom-up pass first.</p><p>We can learn more rules with this simple illustration. First, the distance of node v 1 is uniquely determined by seed node v 2 . This is based on the fact that traveling across the seed node has the chance to increase the distance for both GD and BD. Therefore v 2 is the optimal seed node for v 1 . For GD, traveling one step further add one more absolute gradient term to its distance computation so the updated distance is non-decreasing. For BD, we track the maximum and minimum values for each node. Traversing one more node may update the maximum or minimum values and thus increase the barrier value, so the final distance is also non-decreasing. It implies another observation that travelling across seed nodes or updating the distance of seed nodes would not give better results and thus is unnecessary.</p><p>Finally, we summarize the rules as follows: 1. Performing the bottom-up traversal and then the topdown traversal results in the optimal distance transform. 2. If a seed node is the only seed node and is located at the root node of a sub-tree, then the distance transform of the nodes on the sub-tree is uniquely determined by this seed node. The corresponding distance transform will be obtained in the top-down pass. 3. During traversal, we can ignore the updating steps in Eq. 7 and Eq. 8 for seed nodes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Complexity Analysis</head><p>We estimate the operation count by considering the case that every node performs bottom-up updating in Eq. 7 and top-down updating in Eq. 8 once. In practice, the root node has no parent and the leaf nodes have no child. Moreover, we can ignore the seed nodes in the updating steps, so the estimated operation count is in fact a loose upper bound.</p><p>If the geodesic distance is adopted, both Eq. 7 and Eq. 8 require one comparison operation and one addition operation. In total, 2 addition operations and 2 comparison operations are required.</p><p>If the barrier distance is adopted, we track the maximum and the minimum values for each node. Each time when a new node is visited, 3 comparison operations are required for bottom-up or top-down pass, including one comparison for the maximum, one for the minimum and one for comparing the optimal distance. Extra subtraction operation is required to compute the barrier distance. As a result, in total 6 comparisons and 2 subtraction operations are required for the minimum barrier distance.</p><p>As a result, the distance transform with a MST has constant complexity for each pixel regardless of the distance metric used. With the linear time construction algorithm described in <ref type="bibr" target="#b2">[3]</ref>, the overall distance transform is also linear in the number of pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Salient Object Detection</head><p>We describe our salient object detection system in this section. Despite of the distance transform presented in previous section, we introduce another simple yet useful auxiliary map based on appearance similarity measure to compliment the shortage of measuring the boundary connectivity. We further utilize the off-the-shelf MST to apply tree filtering <ref type="bibr" target="#b2">[3]</ref> to smooth the map. Finally, we also describe the post-processing in this section. The overall salient object detection system is summarized in <ref type="figure" target="#fig_3">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Measuring the Boundary Connectivity</head><p>We set all pixels along the image boundary as a set of seed nodes to exploit the background and connectivity priors for salient object detection. We have tested our MSTbased distance transform using both GD and BD. When computing the GD transform, we also account for the internal edge weight clipping step similar to <ref type="bibr" target="#b25">[26]</ref>. We compute the average edge weight of all remaining edges on the MST as the clipping threshold. The barrier distance is not based on accumulation so it does not contain this step.</p><p>Example results of our MST-based distance transform using GD or BD are shown in <ref type="figure">Figure 4</ref>. As one can see, the BD transform is more robust to texture and has the ability to capture the geometry information better. Thus the BD <ref type="figure">Figure 4</ref>: Distance transform result. Boundary pixels are set as seed nodes. From left to right: input images, distance transform using GD, distance transform using BD. The results using BD is usually more robust than GD.</p><p>transform is more favoured in salient object detection and we adopt the BD transform in our final experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Boundary Color Dissimilarity Measure</head><p>The distance map alone sometimes can not produce satisfying results when the background has many cluttered and isolated regions or the salient object touches the image boundary. To compliment the shortage of distance transform, we introduce another auxiliary map computed by pixel-wise color similarity measure to improve the saliency detection quality.</p><p>Again, we assume most image boundary pixels are background. First of all, boundary pixels are clustered into K groups by their color values in Lab color space. We have found that 3 clusters is enough and set K = 3 for all evaluation. The boundary size between 10 − 30 pixels produces similar results. We simply set boundary size = 10 pixels. Let n k be the number of pixels in each group after clustering. For each group, we compute the mean color µ k and covariance matrix C k . Then, the pixel-wise color dissimilarity map of boundary group k is computed using the Ma-halanobis distance:</p><formula xml:id="formula_6">S k (i) = √ (I(i) − µ k )C −1 k (I(i) − µ k ) T .<label>(9)</label></formula><p>S k is normalized and the final boundary color dissimilarity map S is obtained by weighted sum of S k maps.</p><formula xml:id="formula_7">S = ∑ K k=1 n k S k ∑ K k=1 n k .<label>(10)</label></formula><p>Since the map is computed in pixel-wise fashion, sometimes it appears noisy due to image noise or image compression artifact. We utilize the off-the-shelf MST data structure previously built for distance transform. The map is smoothed using tree filtering <ref type="bibr" target="#b2">[3]</ref>. Note that the MST data structure is built once and can be used multiple times for distance transform as well as tree filtering. It is our advantage over other distance transform based methods. Example results are shown in <ref type="figure" target="#fig_4">Figure 5</ref>. Note that even when the foreground object touches the image boundary, the proposed boundary color dissimilarity measure is able to distinct the object from the background. This is due to the boundary clustering step and weighted sum scheme. Even the foreground touches the image border, usually the majority part of boundary pixels are still background. The preliminary clustering step separates boundary pixels that have distinctive color appearance. The potential foreground pixel group is usually small, so after the weighted summation step, the final boundary dissimilarity map can still reveal the foregroundness of a scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Post-processing</head><p>The post-processing is similar to <ref type="bibr" target="#b33">[34]</ref>. The distance map D and the boundary dissimilarity map S are added together to form an intermediate map M . This map accounts for the object geometry information from the distance transform as well as the global distinctiveness of appearance from the boundary color dissimilarity map.</p><p>We further apply a pixel location dependent masking to emphasize the photographic bias that photographers tend to locate important objects ta the center of the image. Let the image resolution be H × W . This mask is simply a twodimensional Gaussian fall-off with variance H 3 and W 3 respectively. The masked intermediate map is further normalized so that the maximum value is 1.</p><p>Finally, we apply an adaptive contrast enhancement with the following sigmoid mapping:</p><formula xml:id="formula_8">g(x) = 1 1 + exp(−γ(x − τ )) ,<label>(11)</label></formula><p>where τ is an adaptive threshold obtained using Otsu's binary threshold method <ref type="bibr" target="#b17">[18]</ref> and γ controls the overall sharpness. We set γ = 20 in our experiments. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Results</head><p>We evaluate the proposed method on three datasets. The first one is the MSRA-1000 dataset <ref type="bibr" target="#b0">[1]</ref>, which contains 1000 images. The second one is the ECSSD dataset <ref type="bibr" target="#b22">[23]</ref>, which also contains 1000 images. Moreover, it has many semantically meaningful yet structurally complicated images. The last one is the PASCAL-S <ref type="bibr" target="#b13">[14]</ref> dataset, which contains 850 natural images with complex background. The PASCAL-S dataset is designed to avoid the dataset design bias and is the most challenging among these three datasets. These datasets all have accurate human-labelled masks for salient objects.</p><p>We compare our method with twelve classic or state-ofthe-art saliency detection algorithms. They are BL <ref type="bibr" target="#b24">[25]</ref>, MB+ <ref type="bibr" target="#b33">[34]</ref>, SO <ref type="bibr" target="#b34">[35]</ref>, BMS <ref type="bibr" target="#b31">[32]</ref>, HS <ref type="bibr" target="#b26">[27]</ref>, RC <ref type="bibr" target="#b3">[4]</ref>, GC <ref type="bibr" target="#b4">[5]</ref>, AMC <ref type="bibr" target="#b11">[12]</ref>, MR <ref type="bibr" target="#b27">[28]</ref>, GS <ref type="bibr" target="#b25">[26]</ref>, SF <ref type="bibr" target="#b18">[19]</ref> and FT <ref type="bibr" target="#b0">[1]</ref> methods. Among them, GS, SO, MB+ use distance transform and BMS is closely related to the minimum barrier distance <ref type="bibr" target="#b32">[33]</ref>. The saliency maps of different methods are provided by authors or obtained from available software. Note that we use the implementation of SF provided by the author of <ref type="bibr" target="#b34">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Processing Time Evaluation</head><p>We evaluate the processing time using a 3.6 GHz Core i7-4790 CPU with 8GB memory to process color images  of 300 × 400 resolution. FT, RC, GC and our method is evaluated with C code. MB+ is evaluated using the software provided by the author. And the rest use MATLAB and C. For those methods using superpixel segmentation as preprocessing, we use the default settings in the provided code. They all use SLIC superpixel <ref type="bibr" target="#b1">[2]</ref> in the implementation. The processing time of different methods is sorted and shown in <ref type="figure" target="#fig_5">Figure 6</ref>. Note that we remove the processing time of BL from the plot due to its higher order. It takes 11.784 seconds to process an image. Our method achieves real-time detection (more than 30 FPS). It takes in average 24.6 ms to process an image. The MST construction, tree filtering and distance transform presented in this paper all have complexity linear in the number of pixels. As we discussed earlier, the MST is constructed once and can be used for different purposes many times. For more detail, it takes 5.86 ms for MST construction using Prim's algorithm, 1.12 ms for filtering a single channel image and 1.75 ms for single channel MBD transform. With low complexity, the proposed MST-based distance transform along with other MST-based algorithms provides an ideal tool for applications with speed requirement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Quantitative and Qualitative Evaluations</head><p>We compute the precision and recall scores by binarizing the saliency maps with a threshold sliding from 0 to 255 and compare the binary maps with ground truth maps. Usually, precision and recall are both important and therefore F-measure is used as the overall performance measure:</p><formula xml:id="formula_9">F β = (1 + β 2 ) · precision · recall β 2 · precision + recall .<label>(12)</label></formula><p>We set β 2 = 0.3 as suggested in <ref type="bibr" target="#b0">[1]</ref> to emphasize the precision. <ref type="figure">Figure 7</ref> shows the results in three datasets. In our evaluation, no single method outperforms others in all datasets. Nevertheless, one can still see that our method achieves comparable results to the leading methods over all thresholds.</p><p>As neither precision nor recall measure consider the true negative saliency assignments, the mean absolute error (MAE) is also introduced as a complementary. The MAE score calculates the average difference between the saliency </p><formula xml:id="formula_10">M AE = 1 H × W H×W ∑ i=1 |M (i) − GT (i)|.<label>(13)</label></formula><p>The MAE scores of compared methods are sorted and shown in <ref type="figure">Figure 8</ref>. Our method has the lowest MAE scores among all compared methods in all datasets. We also evaluate all methods with the weighted F βmeasure proposed in <ref type="bibr" target="#b16">[17]</ref>. The weighted F β -measure serves as a more reliable metric than previously used metrics like area under the curve (AUC), average precision (AP) or F βmeasure to evaluate foreground maps. We use the code and default parameters provided by the author <ref type="bibr" target="#b16">[17]</ref> to evaluate saliency maps. The sorted results are shown in <ref type="figure">Figure 9</ref>. Our method achieves the highest scores than all other com-petitors in all datasets.</p><p>From above evaluation, the proposed method achieves state-of-the-art in terms of efficiency and accuracy. <ref type="figure" target="#fig_0">Figure 10</ref> shows some sample saliency maps from three datasets for reference. Our model is able to detect salient objects in the scene with complex or highly textured background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Limitations</head><p>The background and connectivity priors work because of the photographic biases that photographers tend to locate important objects at the center of the image. If the salient objects touch the image boundary, the proposed method may produce bad results due to bad boundary connectivity measure. As shown in <ref type="figure" target="#fig_0">Fig. 11</ref>, the boundary color dissimilarity measure is helpful to enhance the final results.  However, it still cannot fully handle such situation. This limitation can be observed in other background prior based methods as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we present a novel distance transform method using the minimum spanning tree representation of an image. Instead of finding the shortest paths on the image using Dijkstra-like algorithms, we compute distance on the tree paths. The MST structure largely reduces the search space of shortest paths. We show that the MST-based dis-tance transform has constant complexity for each pixel using either geodesic distance or barrier distance (the overall complexity is linear in the number of pixels). Together with previously proposed linear time MST construction and tree filtering. The family of MST-based algorithms is an ideal choice for applications with real-time demand.</p><p>We apply the proposed distance transform to measure boundary connectivity for salient object detection. The proposed salient object detection is evaluated and compared with state-of-the-art algorithms and achieves comparable or better results in numerical evaluation. Moreover, the proposed method runs at over 30 FPS. In summary, the proposed method is an accurate and efficient algorithm with the built-in MST structure being our powerful advantage over other distance transform based algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A toy example showing the construction of a minimum spanning tree for an image. (a) A planar graph in which nodes are image pixels and edges are weighted by color/intensity differences between adjacent pixels. (b) The MST is constructed by sequentially removing edges with large weights. (c) The distance of the two red pixels is defined on the tree path (the dashed line).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 (</head><label>2</label><figDesc>b) and (c) demonstrate the bottom-up traversal and the top-down traversal respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>A simple illustration of the proposed two-pass distance transform algorithm. For simplicity, let all edge weights be 1 and assume the geodesic distance is used. (a) Initially, the distance values of seed nodes are set to 0 and ∞ for others. (b) Bottom-up updating. The updated distance is labeled in yellow. (c) Top-down updating.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>An overview of our MST-based saliency detection framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Examples of color dissimilarity map. From left to right: input images, boundary clustering results, color dissimilarity maps against boundary group 1 − 3, and final boundary dissimilarity maps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>The average time to process a 300 × 400 color image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :Figure 8 :Figure 9 :</head><label>789</label><figDesc>The F β scores with sliding threshold.Ours SO MR MB+AMC RC GS BMS HS GC BL SF The mean absolute error (MAE) scores. Ours SO MR MB+AMC GC RC GS BMS HS BL SF The weighted-F β scores. map M and the ground truth GT :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 :</head><label>10</label><figDesc>Comparison of our saliency maps with other classic or state-of-the-art methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 :</head><label>11</label><figDesc>From left to right: input images, distance transform results, boundary color dissimilarity measure, final results.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For color images, the maximum value computed separately from three channels is used as the weight.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We use node and pixel interchangeably when we discuss the graph or the image. They are the same in this paper since the proposed algorithm is a pixel-wise algorithm.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. This work was partially supported by the Early Career Scheme through the Research Grants </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Frequency-tuned salient region detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hemami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Estrada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Susstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Slic superpixels compared to state-of-the-art superpixel methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Susstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2274" to="2282" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Tree filtering: Efficient structure-preserving smoothing with a minimum spanning tree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="555" to="569" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Global contrast based salient region detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-M</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="569" to="582" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient salient region detection with soft image abstraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Warrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Crook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Efficient algorithm for finding the exact minimum barrier distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">C</forename><surname>Ciesielski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Strand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Malmberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Saha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="53" to="64" />
		</imprint>
		<respStmt>
			<orgName>CVIU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Importance filtering for image retargeting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discriminant saliency, the detection of suspicious coincidences, and applications to visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="989" to="1005" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Context-aware saliency detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goferman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1915" to="1926" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Saliency detection with flash and noflash image pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Supercnn: A superpixelwise convolutional neural network for salient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="330" to="344" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Saliency detection via absorbing markov chain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On the shortest spanning subtree of a graph and the traveling salesman problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the American Mathematical society</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="50" />
			<date type="published" when="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The secrets of salient object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning to detect a salient object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="353" to="367" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A framework for visual saliency detection with applications to image thumbnailing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marchesotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cifarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">How to evaluate foreground maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Margolin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A threshold selection method from gray-level histograms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Otsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="23" to="27" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Saliency filters: Contrast based filtering for salient region detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pritch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hornung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Shortest connection networks and some generalizations. Bell system technical journal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Prim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1957" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1389" to="1401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Saliency detection via cellular automata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Is bottom-up attention useful for object recognition? In CVPR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Rutishauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hierarchical image saliency detection on extended cssd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="717" to="729" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The minimum barrier distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Strand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">C</forename><surname>Ciesielski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Malmberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Saha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="429" to="437" />
		</imprint>
		<respStmt>
			<orgName>CVIU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Salient object detection via bootstrap learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Geodesic saliency using background priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hierarchical saliency detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Saliency detection via graph-based manifold ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Top-down visual saliency via joint crf and dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A non-local cost aggregation method for stereo matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Stereo matching using tree filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="846" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">saliency detection: a Boolean map approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Exploiting surroundedness for saliency detection: a Boolean map approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Minimum barrier salient object detection at 80 fps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mȇch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Saliency optimization from robust background detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
