<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Soft-Segmentation Guided Object Motion Deblurring</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinshan</forename><surname>Pan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Dalian University of Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Merced</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Hu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Merced</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixun</forename><surname>Su</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Dalian University of Technology</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">National Engineering Research Center of Digital Life</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Ying</forename><surname>Lee</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Merced</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Soft-Segmentation Guided Object Motion Deblurring</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Object motion blur is a challenging problem as the foreground and the background in the scenes undergo different types of image degradation due to movements in various directions and speed. Most object motion deblurring methods address this problem by segmenting blurred images into regions where different kernels are estimated and applied for restoration. Segmentation on blurred images is difficult due to ambiguous pixels between regions, but it plays an important role for object motion deblurring. To address these problems, we propose a novel model for object motion deblurring. The proposed model is developed based on a maximum a posterior formulation in which soft-segmentation is incorporated for object layer estimation. We propose an efficient algorithm to jointly estimate object segmentation and camera motion where each layer can be deblurred well under the guidance of the soft-segmentation. Experimental results demonstrate that the proposed algorithm performs favorably against the state-of-the-art object motion deblurring methods on challenging scenarios.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recent years have witnessed significant advances in deblurring <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b24">25]</ref>. Numerous methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b49">50]</ref> have been proposed to address this problem, but most of them are designed for camera motion blur. Considerably fewer methods have been proposed to remove image blur caused by moving objects, panning cameras, or both.</p><p>Object motion blur is caused by relative motion between a camera and objects, which usually results in different blur effects on moving objects and the background (See <ref type="figure" target="#fig_0">Figure 1(a)</ref>). Uniform deblurring methods (e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b46">47]</ref>) cannot be effectively applied to this problem directly as objects in the scene undergo different motion blurs. Although non-uniform deblurring methods (e.g., <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b47">48]</ref>) consider different blur effects across an image that are caused by camera rotations and translations, they are less effective for abrupt blur changes caused by fast moving objects or panning cameras. Several methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b43">44]</ref> have been proposed to solve the object motion deblurring problem by (a) Blurred image (b) Xu and Jia <ref type="bibr" target="#b46">[47]</ref> (c) Kim et al. <ref type="bibr" target="#b20">[21]</ref> (d) Ours directly segmenting a blurred image into different regions and deblurring each segmented region. However, it is difficult to identify correct contours of moving objects from a blurred image. The recent method <ref type="bibr" target="#b20">[21]</ref> adopts a novel nonlocal regularization on the residual of estimated results and blurred image to handle object segmentation for dynamic scene deblurring. However, it may not segment the objects undergoing large blurs and affect the deblurred results (See <ref type="figure" target="#fig_0">Figure 1</ref>(c)). Although segmentation plays a critical role in object motion deblurring, existing methods directly consider it as a pre-processing step and its role in object motion deblurring can be better explored.</p><p>In this paper, we propose a novel algorithm for object motion deblurring in which both segmentation as well as deblurring are considered and optimized within one framework. The object layer estimation is achieved by a softsegmentation method, and the relationship between the softsegmentation and deblurring is naturally explored and modeled in a maximum a posterior (MAP) framework. Furthermore, we develop an efficient numerical algorithm to solve the problem. The deblurring component benefits from improving soft-segmentation of the scene, which enables the proposed method to handle large blur caused by fast moving objects or panning cameras. One challenging example is shown in <ref type="figure" target="#fig_0">Figure 1</ref>, where the background contains large blur. The proposed algorithm is able to recover the characters on the board in the background whereas the state-ofthe-art dynamic scene deblurring method <ref type="bibr" target="#b20">[21]</ref> cannot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work and Problem Context</head><p>In this section we discuss the most relevant algorithms and put this work in the proper context.</p><p>Since blind deblurring is an ill-posed problem, it requires certain assumptions or additional information to constrain the solution space. To solve this issue, numerous regularizations have been developed. One representative work by Chan and Wong <ref type="bibr" target="#b3">[4]</ref> uses the total variation to regularize both blur kernels and latent images, and this approach is analyzed in details <ref type="bibr" target="#b33">[34]</ref>. Recently, a mixture of Gaussians by Fergus et al. <ref type="bibr" target="#b9">[10]</ref> is used to approximate the image gradient prior for the latent image and the blur kernels are estimated by a variational Bayesian method. Comprehensive analysis in <ref type="bibr" target="#b28">[29]</ref> shows that variational Bayesian based deblurring methods (e.g., <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b29">30]</ref>) are able to remove trivial solutions in comparison to other approaches with naive MAP formulations. Due to the high computational load of the variational Bayesian inference, some methods improve the MAP based approach by carefully designing image priors and likelihood functions <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b50">51]</ref> for deblurring.</p><p>It has been shown that object boundaries help estimate blur kernels with a transparency (alpha matting) map <ref type="bibr" target="#b17">[18]</ref>. The effectiveness of this method hinges on whether a transparency map can be extracted well or not, and improvements have been made <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b46">47]</ref>. These methods explicitly select sharp edges for kernel estimation and perform well on a recent benchmark dataset <ref type="bibr" target="#b22">[23]</ref>. Instead of using priors from natural image statistics, exemplar based methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b41">42]</ref> are proposed to exploit properties for specific object classes or scenes. The aforementioned methods are not formulated for practical camera motion blur, including rotational and translational movements, which lead to spatially variant blur effects.</p><p>To deal with spatially variant blur, a general projective motion model is proposed in <ref type="bibr" target="#b44">[45]</ref>. Whyte et al. <ref type="bibr" target="#b45">[46]</ref> simplify this model and solve the deblurring problem in a variational Bayesian framework as <ref type="bibr" target="#b9">[10]</ref>. Gupta et al. <ref type="bibr" target="#b11">[12]</ref> use a motion density function to represent the camera motion trajectory for the non-uniform deblurring. In <ref type="bibr" target="#b38">[39]</ref>, Shan et al. solve the rotational motion blur using a transparency map. Since the optimization steps in the non-uniform deblurring methods are computationally expensive, locally uniform patch-based methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b15">16]</ref> are developed where the deconvolution step can be efficiently computed by the fast Fourier transform. We note that the aforementioned deblurring methods are developed for the camera motion blur and not effective to account for object motion blur.</p><p>Several deblurring methods have been proposed to deal with object motion blur. In <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b42">43]</ref>, hybrid camera systems are designed to acquire additional information from moving objects. Although images can be deblurred well by hybrid camera systems, these methods require specially designed hardwares. Levin <ref type="bibr" target="#b25">[26]</ref> proposes a new method that first segments blurred regions by comparing likelihoods with a set of one dimensional box filters, and then applies the Richardson-Lucy deconvolution algorithm to each segmented region with its blur kernel. This method is limited by the quality of segmented regions as the segmentation and deblurring are carried out independently. The transparency map <ref type="bibr" target="#b27">[28]</ref> is employed by <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b43">44]</ref> to separate an image into the foreground and background to deal with object motion blur. In <ref type="bibr" target="#b7">[8]</ref>, Dai and Wu first estimate blur kernels using <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7]</ref> and then alternatively estimate the transparency map, foreground, and background of latent images. While this method is effective for images with partial blur, the kernel estimation and segmentation processes are independent, which limits the refinement of the segmentation results and accordingly affects the recovered image. Chakrabarti et al. <ref type="bibr" target="#b2">[3]</ref> use a mixture of Gaussians to model the heavy-tail properties of natural image gradients for deblurring which is able to deal with certain blur (e.g., Gaussian blur with small kernel width). Kim et al. <ref type="bibr" target="#b20">[21]</ref> alternatively estimate blur kernels and segmentation to handle the dynamic scene deblurring problems. However, this method is less effective for large object motion blur as discussed earlier. In <ref type="bibr" target="#b21">[22]</ref>, a method based on a local linear motion without segmentation is proposed, which incorporates the optical flow method to guide the blur kernel estimation. Although this method is able to deal with certain object motion blur, the specific assumption on the blur kernel limits the application domains.</p><p>We note that Favaro and Soatto <ref type="bibr" target="#b8">[9]</ref> develop a unified model to jointly estimate blur and occlusion. However, this method focuses on defocus blur and it has difficulty in handling the blur caused by moving objects.</p><p>In this paper, we focus on handling the blur caused by moving objects. Different from existing methods, the proposed algorithm is designed to consider both segmentation and deblurring. We propose a novel formulation that accommodates the soft-segmentation technique to guide the deblurring process in a unified framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Algorithm</head><p>Since the object blur is mainly caused by moving objects, the blur is not uniform (e.g., the background and foreground in <ref type="figure" target="#fig_0">Figure 1</ref> undergo different blurs). Our goal is to split an image into different layers according to moving objects and assume that each layer corresponds to a blur kernel.</p><p>We formulate the object motion deblurring problem within a MAP framework. Given a blurred image B, we estimate the latent image I and the blur kernel k,</p><formula xml:id="formula_0">(I, k) = arg max I,k p(k, I|B) = arg max I,k p(B|k, I)p(k)p(I) = arg max I,k N i=1 p(B, l i |k, I)p(I)p(k) = arg max I,k N i=1 p(B|l i , k i , I)p(l i |k i , I)p(I)p(k i ),<label>(1)</label></formula><p>where N denotes the number of segmented layers; l i is a binary mask for the i-th layer which has the same size as the input image; k i denotes the blur kernel corresponding to the i-th layer; and</p><formula xml:id="formula_1">k = {k i } N i=1 . For the likelihood p(B|l i , k i , I), we assume that pixels of an image are independent. So we have p(B|l i , k i , I) = u p(B u |l iu , k i , I u )</formula><p>, where u denotes the spatial location of a pixel. The probability p(B u |l iu , k i , I iu ) is formulated as the data fitting errors:</p><formula xml:id="formula_2">p(B u |l iu , k i , I iu ) = 1 Z d exp(−|(B − I * k i ) u |) l iu = 1, C l iu = 0, (2) where Z d is a normalization term, C is a positive constant,</formula><p>* is a convolution operator, and the Laplacian distribution is used to handle large noise <ref type="bibr" target="#b46">[47]</ref>. Based on (2), p(B|l i , k i , I) can be equivalently expressed as</p><formula xml:id="formula_3">p(B|l i , k i , I) = 1 Z d exp − u l iu |(B − I * k i ) u | . (3)</formula><p>For the prior p(l i |k i , I), we introduce an auxiliary segmentation confidence map s i of the latent image I, which is related to l i . That is, we set l iu = 0, if s iu is close to zero and l iu = 1, otherwise. According to the law of total probability, we have</p><formula xml:id="formula_4">p(l i |k i , I) = si∈Si p(l i , s i |k i , I) = si∈Si p(l i |s i , k i , I)p(s i |I, k i ),<label>(4)</label></formula><p>where S i is the space of all possible configurations of s i .</p><p>Since we assume that s i is a segmentation confidence map of the latent image I, it is independent of the blur kernel k i . Thus, we have p(s i |I, k i ) = p(s i |I) and define the prior p(s i |I) in this paper as</p><formula xml:id="formula_5">p(s i |I) = 1 Z si exp(−ηs T i Ls i ),<label>(5)</label></formula><p>where Z si is a normalization term, η is a weight parameter, s i is the vector form of s i , L is an Laplacian matrix, and it is defined by L = diag(W) − W, where diag(W) is a diagonal matrix of W, and W is defined by</p><formula xml:id="formula_6">W uv = exp(−β I u − I v 2 ),<label>(6)</label></formula><p>where β is a positive weight; u and v denote the spatial locations of image pixels. We note that W is the affinity matrix which is used in normalized cuts <ref type="bibr" target="#b39">[40]</ref> and random walk image segmentation method <ref type="bibr" target="#b10">[11]</ref>. Levin et al. <ref type="bibr" target="#b27">[28]</ref> show that the matting Laplacian matrix generates better image segmentation results than those of (6). The affinity matrix in matting is defined by</p><formula xml:id="formula_7">W uv = m:(u,v)∈wm 1 C(w m ) 1 + (I u − µ m )(I v − µ m ) ε + σ 2 m ,<label>(7)</label></formula><p>where w m is the m-th patch of I; C(w m ) denotes the number of pixels in w m ; µ m and σ m are the mean as well as variance of the intensities in w m ; and ε is a weight which controls the smoothness of segmentation boundaries. In this paper, we use the matrix <ref type="formula" target="#formula_7">(7)</ref> to construct L in (5) (See analysis in Section 6).</p><p>The likelihood p(l i |s i , k i , I) measures the similarity of l i and s i . Since s i is independent of k i , it has similar properties to l i according to its definition. Therefore, we assume that l i is independent with respect to k i and have</p><formula xml:id="formula_8">p(l i |s i , k i , I) = p(l i |s i , I) which is defined by p(l i |s i , I) = 1 Z li exp −α u D u (l iu − s iu ) 2 ,<label>(8)</label></formula><p>where Z li is a normalization constant and D u is a weighted parameter. In this paper, we define D u which is used in the alpha matting methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b27">28]</ref> as</p><formula xml:id="formula_9">D u = m:(u,u)∈wm 1 C(w m ) 1 + (I u − µ m ) 2 ε + σ 2 m .<label>(9)</label></formula><p>We note that when an image patch w m covers only a smooth region, the value D u is close to 1. Otherwise, it is larger than 1, which penalizes more on the inconsistence of l iu and l iu in (8).</p><p>Based on above discussions, the remaining task is to define the priors p(I) and p(k i ) of the latent image I and the blur kernel k i . We use the sparsity image gradient prior <ref type="bibr" target="#b26">[27]</ref> for the latent image I and an Laplacian prior for the blur kernel k i , which are defined by</p><formula xml:id="formula_10">p(I) = 1 Z I exp(−λφ I (I)), p(k i ) = 1 Z k exp(−γφ k (k i )),<label>(10)</label></formula><p>where</p><formula xml:id="formula_11">φ I (I) = u (|∂ x I u | 0.8 + |∂ y I u | 0.8 ), φ k (k i ) = u |k iu |</formula><p>; ∂ x and ∂ y denote the differential operators along the x and y directions; and Z I as well as Z k are normalization terms; λ and γ are weights.</p><p>We take negative log likelihood of (1) and have the pro-posed deblurring model as follows,</p><formula xml:id="formula_12">min I,k,l,s N i=1 u,v l iu |(I * k i − B) u | + αD u (l iu − s iu ) 2 + γ|k iu | +ηW uv (s iu − s iv ) 2 + λ(|∂ x I u | 0.8 + |∂ y I u | 0.8 ).<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Optimization</head><p>In this section, we propose an efficient algorithm to solve (11) for object motion deblurring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Soft-Segmentation Estimation</head><p>Given the estimates of latent image I, blur kernel k i , and label l i , the soft-segmentation problem can be modeled as</p><formula xml:id="formula_13">min s i u,v D u (l iu − s iu ) 2 + η α W uv (s iu − s iv ) 2 .<label>(12)</label></formula><p>We note that the optimization problem with respect to s i of each layer can be solved separately. For the i-th layer, the problem can be equivalently expressed by</p><formula xml:id="formula_14">min si (l i − s i ) ⊤ D(l i − s i ) + η α s ⊤ i Ls i ,<label>(13)</label></formula><p>where l i is the vector form of l i and D is a diagonal matrix whose element is defined as D uu = D u . By setting the derivative with respect to s i to zero, the solution to this optimization problem is given by solving a linear system,</p><formula xml:id="formula_15">D + η α L s i = Dl i .<label>(14)</label></formula><p>We note that directly solving <ref type="formula" target="#formula_0">(14)</ref> is computationally expensive due to the large matrix L. He et al. <ref type="bibr" target="#b14">[15]</ref> prove that this linear equation can be approximated by a linear edgepreserving filter. In this work, we use the fast approximation algorithm <ref type="bibr" target="#b14">[15]</ref> to solve <ref type="bibr" target="#b13">(14)</ref> and obtain s i . After obtaining s i , the problem with respect to l i is</p><formula xml:id="formula_16">min li N i=1 u l iu |(I * k i − B) u | + αD u (l iu − s iu ) 2 .<label>(15)</label></formula><p>Note that this is a least-squares problem and the closed-form solution of l i is</p><formula xml:id="formula_17">l iu = s iu − 1 2αD u |(I * k i − B) u |.<label>(16)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Intermediate Latent Image Estimation</head><p>With the estimates of k i and l i , the latent image estimation can be written as  Since <ref type="formula" target="#formula_0">(17)</ref> is highly non-convex, we use the iteratively reweighed least squares (IRLS) method <ref type="bibr" target="#b26">[27]</ref> to solve it. In each iteration, we need to minimize the weighted quadratic problem,</p><formula xml:id="formula_18">min I N i=1 u l iu ω du |(I * k i − B) u | 2 + λ(ω x u |∂ x I u | 2 + ω y u |∂ y I u | 2 ),<label>(18)</label></formula><p>where the weights ω du = |(I * k i − B) u | −1 , ω x u = |∂ x I u | −1.2 , and ω y u = |∂ y I u | −1.2 are computed from the results in last iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Kernel Estimation</head><p>In the kernel estimation step, image gradients have been shown to be more effective than the intensities <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b47">48]</ref>. Thus, we use image derivatives in the data fitting term and remove small gradient values according to <ref type="bibr" target="#b4">[5]</ref>. The blur kernel can be estimated by</p><formula xml:id="formula_19">min k N i=1 u l iu (∇I * k i − ∇B) u 1 + γ|k iu |.<label>(19)</label></formula><p>We employ the IRLS method to solve <ref type="bibr" target="#b18">(19)</ref>. Similar to the state-of-the-art methods, kernel estimation is carried out in a coarse-to-fine manner using an image pyramid <ref type="bibr" target="#b4">[5]</ref> to achieve better performance. Algorithm 1 shows the main steps for the kernel estimation algorithm on one image pyramid level.</p><p>Initialization: Since one subproblem of the proposed algorithm involves the soft-segmentation method, the initialization step is important. Similar to <ref type="bibr" target="#b10">[11]</ref>, we first select seed points as shown in <ref type="figure" target="#fig_3">Figure 2</ref>(a) and then compute a convex hull to include these points <ref type="figure" target="#fig_3">(Figure 2(b)</ref>). Another way to initialize l i is to use rectangular bounding boxes similar to <ref type="bibr" target="#b35">[36]</ref> (e.g., the bounding box shown in <ref type="figure" target="#fig_3">Figure 2</ref>(e)). We show that these two initializations generate similar deblurring results in the following and the supplementary document. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Results</head><p>We present experimental evaluations of the proposed algorithm against several state-of-the-art methods for object motion deblurring. More experimental results and the code can be found at our project website.</p><p>Parameter Settings and Implementation Details: In all the experiments, we set α = 2, λ = 0.5, and γ = 0.001, respectively. The number of layers N is set according to the number of moving objects. As l i is a binary mask for the i-th layer, we apply the OTSU method to find the threshold for l i after obtaining l i by <ref type="bibr" target="#b15">(16)</ref>. In steps 6 and 7 of Algorithm 1, we estimate the latent image and blur kernel independently at each layer. In <ref type="bibr" target="#b13">(14)</ref>, we use the estimated RGB image by <ref type="bibr" target="#b16">(17)</ref> to compute s i . Due to separate estimation for each label l i , the proposed method allows overlapping regions for different layers, which will result in obvious ringing artifacts in the recovered image. To deal with boundaries, we normalize the overlapping regions for different layers so that the sum of each label satisfies N i=1 l i = 1 in the intermediate latent image estimation step, where 1 has the same size as each label l i and its element value is 1.</p><p>Quantitative Evaluation: We first evaluate the proposed algorithm using 16 synthetic images. To synthesize blurred images, we use the matting method <ref type="bibr" target="#b27">[28]</ref> to separate each clear image into background and foreground regions, to which different blur kernels are applied. Finally, we merge the background and foreground regions using the alpha map to generate the blurred images according to <ref type="bibr" target="#b27">[28]</ref> (See <ref type="figure" target="#fig_4">Figure 3(a)</ref>). We use the PSNR metric to measure the quality of each restored image. <ref type="table" target="#tab_0">Table 1</ref> shows the quantitative evaluation results of each method. The proposed algorithm generates the deblurred images with higher PSNR values 1 . One example is shown in <ref type="figure" target="#fig_4">Figure 3</ref> for visual comparisons. The deblurred image by the proposed algorithm is clearer (e.g., the vehicle wheel in <ref type="figure" target="#fig_4">Figure 3(c)</ref>) and the segmentation results are similar to the ground truth.</p><p>Real Images: We then evaluate the proposed algorithm using real blurry images. <ref type="figure" target="#fig_5">Figure 4</ref>(a) shows one example where the background contains large blur. Because the image blur cannot be described by a uniform blur kernel, stateof-the-art uniform deblurring methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b46">47]</ref> do not perform well on this image. Although the non-uniform deblurring methods <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b47">48]</ref> are able to deal with the blur caused by camera rotation and translation, they are less effective in handling the abrupt blur changes caused by moving objects. The deblurred image generated by the object motion deblurring method <ref type="bibr" target="#b20">[21]</ref> still contains blur effects and the boundaries of the cyclist contain ringing artifacts due to the failure of segmentation. In contrast, the proposed algorithm generates clearer results both in the background and foreground regions. The persons in the background can be recognized and the foreground (e.g., the head in the blue box of <ref type="figure" target="#fig_5">Figure 4(g) and (h)</ref>) is also comparable to other methods. The results shown in <ref type="figure" target="#fig_5">Figure 4</ref>(g) and (h) demonstrate that the proposed algorithm is robust to different initializations. <ref type="figure">Figure 5</ref>(a) shows another example with moving objects and large blur in the background. Since the blur in this image is different at each region, the uniform <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b46">47]</ref> and nonuniform <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b47">48]</ref> deblurring methods do not generate clear results. The deblurred images are similar to the blurred image in <ref type="figure">Figure 5</ref>(a). Compared to the camera shake deblurring methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48]</ref> and the recent object motion deblurring approach <ref type="bibr" target="#b20">[21]</ref>, the proposed algorithm generates a clear image where the type of contents in the background (e.g., people) can be identified.</p><p>Comparisons with Segmentation-Free Object Deblurring Methods: Recently, Kim and Lee <ref type="bibr" target="#b21">[22]</ref> propose a deblurring method to deal with dynamic scenes without using segmentation. As the blur model is based on local linear motion flow vectors, it is difficult to deal with complex object and camera motions. <ref type="figure">Figure 6</ref>(a) shows an example from <ref type="bibr" target="#b21">[22]</ref>. The deblurred image generated by the non-uniform camera shake deblurring method <ref type="bibr" target="#b45">[46]</ref> contains ringing artifacts due to the influences of moving objects. Compared with the reported results in <ref type="bibr" target="#b21">[22]</ref>, the proposed algorithm generates a sharper image with more details (e.g., door, window, and grass regions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Analysis and Discussion</head><p>In this section, we present more analysis on how the proposed algorithm performs on object motion deblurring and discuss its connection to the most relevant methods. In addition, we discuss the limitations and extensions of the proposed algorithm.</p><p>Compared to the existing MAP-based deblurring methods, the proposed algorithm introduces an additional term l i , which helps segment an image into different layers. This is mainly because that the sub-problem (12) is the alpha matting method in <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b27">28]</ref>, which provides softsegmentation of an object in the input image. After optimizing <ref type="bibr" target="#b14">(15)</ref>, the label l i is obtained based on the segmentation  (a) Blurred image (b) Cho and Lee <ref type="bibr" target="#b4">[5]</ref> (c) Xu and Jia <ref type="bibr" target="#b46">[47]</ref> (d) Whyte et al. <ref type="bibr" target="#b45">[46]</ref> (e) Xu et al. <ref type="bibr" target="#b47">[48]</ref> (f) Kim et al. <ref type="bibr" target="#b20">[21]</ref> (g) Ours with rectangular boxes (h) Ours with convex hulls We note that the work <ref type="bibr" target="#b20">[21]</ref> also focuses on the object motion deblurring problem in which regular patches are used at first and refined iteratively. The segmentation results are achieved by solving an optimization problem with non-local regularization on the data fidelity term. Since the data fidelity term is based on the residual of estimated results and a blur image, it is not robust to large motion blur. As shown in <ref type="figure">Figure 7</ref>(b), this method is less effective when segmenting moving objects. The segmented foreground contain not only clear regions but also blurred ones, which affect kernel estimation and lead to the blurry results (See <ref type="figure">Figure 7(g)</ref>).</p><p>To deal with partial blur, Schelten and Roth <ref type="bibr" target="#b36">[37]</ref> segment an image by a variational Bayesian method, which is computationally expensive. Furthermore, the inference step is still based on the residual of estimated results and a blurred image <ref type="bibr">((14)</ref> in <ref type="bibr" target="#b36">[37]</ref>), which is not robust to large blur. We also note that the matting method has been used in <ref type="bibr" target="#b16">[17]</ref>. However, this method mainly focuses on camera shake re-moval that takes scene depth into consideration. As the layers for different depth are pre-computed using matting and are fixed during the optimization, the algorithm does not update the segment of moving objects. In addition, global constraints on all the layers in <ref type="bibr" target="#b16">[17]</ref> are enforced based on the camera motion which is different from our scenarios. Different from prior work, our method is formulated within a unified probabilistic framework for both blur and softsegmentation estimations. It explicitly incorporates the segmentation method (i.e., matting method <ref type="bibr" target="#b27">[28]</ref>) which relies on the estimated latent image, thereby facilitating the segmentation task (See <ref type="figure">Figure 7(c)</ref>). Moreover, the proposed segmentation problem has a closed-form solution, which can be efficiently solved by <ref type="bibr" target="#b14">[15]</ref>. <ref type="figure">Figure 7</ref>(i) shows that our deblurred image recovers fine textures.</p><p>We also note that several approaches (e.g., <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b40">41]</ref>) first detect blur regions and then use existing methods (e.g., <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b46">47]</ref>) to deblur images. However, these methods are limited by whether image regions can be identified well (a) Blurred image (b) Cho and Lee <ref type="bibr" target="#b4">[5]</ref> (c) Xu and Jia <ref type="bibr" target="#b46">[47]</ref> (d) Whyte et al. <ref type="bibr" target="#b45">[46]</ref> (e) Levin et al. <ref type="bibr" target="#b29">[30]</ref> (f) Xu et al. <ref type="bibr" target="#b47">[48]</ref> (g) Kim et al. <ref type="bibr" target="#b20">[21]</ref> (h) Ours <ref type="figure">Figure 5</ref>. An example with a fast moving object and the background contains large blur.</p><p>(a) Blurred image (b) Whyte et al. <ref type="bibr" target="#b45">[46]</ref> (c) Kim and Lee <ref type="bibr" target="#b21">[22]</ref> (d) Ours <ref type="figure">Figure 6</ref>. Comparisons with the segmentation-free dynamic scene deblurring method <ref type="bibr" target="#b21">[22]</ref>.</p><p>or not. <ref type="figure">Figure 8</ref> shows one example from <ref type="bibr" target="#b20">[21]</ref>. We compare the blur detection method <ref type="bibr" target="#b40">[41]</ref> and the proposed deblurring method without using soft-segmentation. <ref type="figure">Figure 8</ref>(a) shows that the approach in <ref type="bibr" target="#b40">[41]</ref> does not always generate clear results. The result in <ref type="figure">Figure 8</ref>(b) suggests that it is not effective to deblur an image with only a pre-detected region.</p><p>Although the soft-segmentation step using <ref type="formula" target="#formula_6">(6)</ref> is able to generate segmentation results (See <ref type="figure">Figure 8</ref>(h)), the algorithm using the matting Laplacian matrix generates better results. Thus, we use (7) in the soft-segmentation step. In addition, the segmentation results shown in <ref type="figure">Figure 8</ref>(e)-(g) indicate that the proposed algorithm has good convergence in practice.</p><p>The proposed method can also be incorporated with a clustering method <ref type="bibr" target="#b51">[52]</ref>. If we solve the sub-problem (12) on a super-pixel level and consider each pixel as a graph node, this becomes the saliency detection problem considered in <ref type="bibr" target="#b48">[49]</ref>.</p><p>Limitations and Extensions. The object motion deblurring method described in Section 3 is based on the assumption that each layer has a uniform blur kernel. This assumption holds for dynamic scenes with the translation motion. However, it is less effective if moving objects involve the rotation and non-rigid motion. For a complex scene, the blur caused by moving objects is often spatially variant <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44]</ref>. We can use the geometric model of camera motion <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46]</ref> to approximate the non-uniform object motion blur caused by panning cameras. According to <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46]</ref>, the blur process is modeled by</p><formula xml:id="formula_20">B = t j=1 w j K θj I + e,<label>(20)</label></formula><p>where B, I, and e denote the vector forms of the blurred image, latent image, and noise, respectively; {θ j } t j=1 denote the sampled camera poses; {K θj } t j=1 are the warping matrixes corresponding to different sampled camera poses, which transform the latent image I accordingly; and {w j } t j=1 are weights that satisfy w j ≥ 0 as well as  <ref type="formula" target="#formula_7">(7)</ref>. (d) Result by the proposed algorithm using <ref type="bibr" target="#b5">(6)</ref>. (e)-(g) show some segmentation results using <ref type="formula" target="#formula_7">(7)</ref> over iterations. (h) Estimated segmentation result using (6).</p><formula xml:id="formula_21">(a) (b) (c) (d) (e) (f) (g) (h) (i)</formula><p>(a) Blurred image (b) Dai and Wu <ref type="bibr" target="#b6">[7]</ref> (c) Ours <ref type="figure">Figure 9</ref>. Comparisons with optical flow based object motion deblurring method <ref type="bibr" target="#b6">[7]</ref>.</p><formula xml:id="formula_22">j w j = 1.</formula><p>Based on <ref type="bibr" target="#b19">(20)</ref>, our non-uniform deblurring method is similar to Algorithm 1, where we only need to replace <ref type="bibr" target="#b15">(16)</ref>, <ref type="bibr" target="#b16">(17)</ref>, and <ref type="bibr" target="#b18">(19)</ref> with</p><formula xml:id="formula_23">l iu = αs iu +   t j=1 w j K θ j I − B   u /2,<label>(21)</label></formula><formula xml:id="formula_24">min I N i=1 u l iu   t j=1 w j K θ j I − B   u + λ(|∂xIu| 0.8 + |∂yIu| 0.8 ),<label>(22)</label></formula><p>and</p><formula xml:id="formula_25">min w j N i=1 u l iu   t j=1 w j K θ j (∇I) − ∇B   u + γ t j=1</formula><p>|w j |. <ref type="bibr" target="#b22">(23)</ref> We use the fast forward approximation approach with the locally-uniform assumption in <ref type="bibr" target="#b15">[16]</ref> to solve the above models. This extension is able to handle some examples with non-rigid motion to some extent. <ref type="figure">Figure 9</ref>(a) shows a blurred example from <ref type="bibr" target="#b6">[7]</ref> where the blur is caused by the non-rigid motion of the hand. Although our deblurred image contains some blur effect (e.g., the area near the little finger), it has fewer ringing artifacts compared to the result generated by <ref type="bibr" target="#b6">[7]</ref>.</p><p>We note that the proposed method can also be applied to deblur images caused by camera rotation and translation. More experimental results are included in the supplemental material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>In this paper, we propose an object motion deblurring algorithm within a MAP framework. The proposed method incorporates a soft-segmentation method to take moving objects and background regions into account for kernel estimation. We present an efficient algorithm to solve the proposed model. Experimental results show that the proposed algorithm performs favorably against the state-of-the-art object motion deblurring methods as well as non-uniform deblurring approaches.</p><p>We note that the proposed algorithm is based on softsegmentation and may fail for the images where the blur is caused by both depth variation and moving objects (e.g., <ref type="figure">Figure 9</ref>). Our future work will focus on exploiting the depth information to facilitate the kernel estimation for object motion deblurring.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Object motion blur caused by a panning camera.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>liu|(I * ki − B)u| + λ(|∂xIu| 0.8 + |∂yIu| 0.8 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( 17 )</head><label>17</label><figDesc>Algorithm 1 Proposed object motion deblurring algorithm Input: Blurred image B and the number of layers: N . Output: Latent image I and blur kernel k i . 1: Initialize I, k i , s i , l i with the results from the coarser level. 2: for t 1 = 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Different initializations in the proposed method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Visual comparisons on an example from the synthetic dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>An object motion deblurring example where the background contains large blur. result s i . Figure 7(c) shows one intermediate result of l i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .Figure 8 .</head><label>78</label><figDesc>The effectiveness of the proposed soft-segmentation in object deblurring. (a) Blurred image. (b) One intermediate result of [21]. (c) One intermediate result of li by the proposed algorithm. (d) The segmentation results of [21]. (e) Our segmentation results. (f)-(h) Results of Xu and Jia [47] and dynamic scene deblurred results [21, 22], respectively. (i) Ours. Deblurring methods with pre-detected blur regions. (a) Result of the blur detection method [41]. (b) Result by the proposed algorithm with fixed initialization in (e). (c) Result by the proposed algorithm using</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 .</head><label>1</label><figDesc>Quantitative comparisons on the synthetic examples.</figDesc><table>Blur images 
Cho and Lee [5] 
Xu and Jia [47] 
Whyte et al. [46] 
Xu et al. [48] 
Kim and Lee [22] 
Ours 
Average PSNRs 
22.27 
21.40 
21.71 
13.25 
21.90 
21.66 
22.79 

(a) Blurred image 
(b) Kim and Lee [22] 
(c) Ours 
(d) Our segments 
(e) Ground truth segments 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Since the code of existing deblurring methods (e.g.,<ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b36">37]</ref>) is not available, we compare the most related method<ref type="bibr" target="#b21">[22]</ref> based on our implementation on this dataset.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Defocus magnification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="571" to="579" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Framelet based blind motion deblurring from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-F</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="562" to="572" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Analyzing spatially-varying blur</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zickler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2512" to="2519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Total variation blind deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="370" to="375" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast motion deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH Asia</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page" from="1" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Blur kernel estimation using the radon transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K P</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="241" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Motion from blur</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Removing partial blur in a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2544" to="2551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Seeing beyond occlusions (and other marvels of a finite lens aperture)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="579" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Removing camera shake from a single photograph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="787" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Random walks for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Grady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1768" to="1783" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Curless. Single image deblurring using motion density functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="171" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deblurring by example using dense correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hacohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2384" to="2391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Spacevariant single-image blind deconvolution for removing camera shake</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="829" to="837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Guided image filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1397" to="1409" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fast removal of non-uniform camera shake</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="463" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Joint depth estimation and camera shake removal from single blurry image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2893" to="2900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Single image motion deblurring using transparency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Mathematical models and practical solvers for uniform motion deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">PSF estimation using sharp edge prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dynamic scene deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3160" to="3167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Segmentation-free dynamic scene deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2766" to="2773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Recording and playback of camera shake: Benchmarking blind deconvolution with a real-world database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Mohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="27" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Blind deconvolution using a normalized sparsity measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2657" to="2664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Recent advances in image deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH Asia</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Blind motion deblurring using image statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="841" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Image and depth from a conventional camera with a coded aperture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="70" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A closed form solution to natural image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Understanding and evaluating blind deconvolution algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Efficient marginal likelihood optimization in blind deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2657" to="2664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Direct sparse deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Bertozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An iterative technique for the rectification of observed distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Lucy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Astronomy Journal</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="745" to="754" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deblurring face images with exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="47" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Total variation blind deconvolution: The devil is in the details</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Perrone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2909" to="2916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Coded exposure photography: motion deblurring using fluttered shutter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tumblin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="795" to="804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">GrabCut&quot;: interactive foreground extraction using iterated graph cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="309" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Localized image blur removal through non-parametric kernel estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schelten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="702" to="707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">High-quality motion deblurring from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Rotational motion deblurring of a rigid object from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Discriminative blur detection features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2965" to="2972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Edge-based blur kernel estimation using patch priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Correction of spatially varying image and video motion blur using a hybrid camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1012" to="1028" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Coded exposure imaging for projective motion deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2408" to="2415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Richardson-lucy deblurring for scenes under a projective motion path</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1603" to="1618" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Non-uniform deblurring for shaken images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Whyte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="168" to="186" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Two-phase kernel estimation for robust motion deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="157" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Unnatural L0 sparse representation for natural image deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1107" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Saliency detection via graph-based manifold ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3166" to="3173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Multi-image blind deblurring using a coupled adaptive sparse prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Wipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1051" to="1058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Sparse representation based blind image deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICME</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Ranking on data manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="169" to="176" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
