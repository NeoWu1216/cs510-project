<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">In Defense of Sparse Tracking: Circulant Sparse Tracker</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianzhu</forename><surname>Zhang</surname></persName>
							<email>tianzhu.zhang@kaust.edu.sa</email>
							<affiliation key="aff0">
								<orgName type="institution">King Abdullah University of Science and Technology (KAUST)</orgName>
								<address>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences (CASIA)</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adel</forename><surname>Bibi</surname></persName>
							<email>adel.bibi@kaust.edu.sa</email>
							<affiliation key="aff0">
								<orgName type="institution">King Abdullah University of Science and Technology (KAUST)</orgName>
								<address>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
							<email>bernard.ghanem@kaust.edu.sa</email>
							<affiliation key="aff0">
								<orgName type="institution">King Abdullah University of Science and Technology (KAUST)</orgName>
								<address>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">In Defense of Sparse Tracking: Circulant Sparse Tracker</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sparse representation has been introduced to visual tracking by finding the best target candidate with minimal reconstruction error within the particle filter framework. However, most sparse representation based trackers have high computational cost, less than promising tracking performance, and limited feature representation. To deal with the above issues, we propose a novel circulant sparse tracker (CST), which exploits circulant target templates. Because of the circulant structure property, CST has the following advantages: (1) It can refine and reduce particles using circular shifts of target templates. <ref type="formula">(2)</ref> The optimization can be efficiently solved entirely in the Fourier domain.</p><p>(3) High dimensional features can be embedded into CST to significantly improve tracking performance without sacrificing much computation time. Both qualitative and quantitative evaluations on challenging benchmark sequences demonstrate that CST performs better than all other sparse trackers and favorably against state-of-the-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Visual object tracking is a fundamental research topic in computer vision and is related to a wide range of applications including video surveillance, auto-control systems, and human computer interaction. Given the initial state of a target in the first frame, the goal of tracking is to predict states of the target over time. Despite very promising advances over the past decade, it remains a challenging problem to design a fast and robust tracker due to factors such as illumination changes, deformations, partial occlusions, fast motion, and background clutter.</p><p>Recently, sparse representation has been developed for object tracking <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b17">18]</ref>. The seminal work in <ref type="bibr" target="#b26">[27]</ref> was the first to successfully apply sparse representation to visual tracking using particle filtering. Here, the tracker represents each target candidate as a sparse linear combination of dictionary templates that can be dynamically updated to maintain an up-to-date target ap- <ref type="figure" target="#fig_0">Figure 1</ref>. Comparison of our CST tracker with state-of-the-art methods (KCF, Struck, SCM, ASLA, L1APG, and TLD) on two videos from a visual tracking benchmark <ref type="bibr" target="#b31">[32]</ref>. On the Jogging sequence, only TLD and CST can track well when partial occlusion happens. On the Tiger sequence, our CST can track the target throughout the whole sequence, while other trackers suffer from drift. The sparse trackers (ASLA, L1APG, SCM) fail to track these sequences. Overall, the proposed CST method performs favorably against the state-of-the-art trackers. pearance model. This representation has been shown to be robust against partial occlusions, thus, leading to improved tracking performance. However, sparse trackers generally suffer from the following drawbacks: (1) They remain computationally expensive, despite recent speedup attempts <ref type="bibr" target="#b4">[5]</ref>. Sparse trackers perform computationally expensive ℓ 1 minimization at each frame. In a particle filter framework, computational cost grows linearly with the number of particles sampled. It is this computational bottleneck that precludes the use of these trackers in real-time scenarios. (2) They have limited overall performance. Based on results in the VOT2014 challenge <ref type="bibr" target="#b23">[24]</ref> and the visual tracking benchmark <ref type="bibr" target="#b31">[32]</ref>, sparse trackers do not achieve a better accuracy than other types of trackers, such as KCF <ref type="bibr" target="#b15">[16]</ref> and Struck <ref type="bibr" target="#b14">[15]</ref>. <ref type="bibr" target="#b2">(3)</ref> They are limited in the features they can use for representation. Due to the high computational cost, most sparse trackers make use of gray-scale pixel appearance and cannot adopt more representative features, such as, HOG <ref type="bibr">Figure 2</ref>. Examples on three video sequences to show particle refinement via the proposed CST method. The bounding boxes with red color are the sampled particles. Due to random sampling, the sampled particles are far away from the target object. With the proposed CST method, these particles can be refined and translated to better state denoted with bounding boxes with green color. and SIFT. As a result, sparse trackers have a bottleneck in tracking performance due to their limited feature representation. Due to these issues, sparse trackers cannot achieve promising results as shown in <ref type="figure" target="#fig_0">Figure 1</ref> and are viewed as inadequate solutions to robust visual tracking.</p><p>To deal with the above issues, we propose a novel circulant sparse tracker (CST) with robustness and computational efficiency for visual tracking using particle filters. Here, learning the representation of each particle is again viewed as a sparse encoding problem. Similar to the above work, the next target state is decided by particles that have high similarity with a dictionary of target templates. Unlike previous methods that need to sample more and more candidates to refine the target's location, we embed translated versions of the templates in the dictionary using circulant matrices. By doing this, an accurate sparse representation of each particle can be efficiently estimated and the target object can be collectively localized using a small number of particles. Given an object image patch a of M × N pixels, where all the circular shifts of am ,n , (m,n) ∈ {0, 1, . . . , M − 1} × {0, 1, . . . , N − 1}, are generated as target templatesÂ = [a 0,0 , . . . , a M −1,N −1 ]. These circulant shifts approximate the translated versions of a. Then, each particle can be represented as a sparse linear combination of dictionary templatesÂ. Based on the learned sparse coefficient, we know which element ofÂ has the highest similarity with the target candidate. The circular shift of these elements can be adopted to translate and refine each particle to make it more similar to the target.</p><p>In <ref type="figure">Figure 2</ref>, we show three examples of this particle refinement. Since particles are sampled randomly from a posterior distribution, they can be far away from the target object as shown in red bounding boxes. If we estimate the target's state based on only a few of these particles, the tracker can easily drift. By embedding circulant versions of the target templates in the dictionary, particles can be refined as shown (in green). Because of this refinement, the number of particles needed for tracking can be reduced dramatically, thus, making the tracker much more efficient. Moreover, by exploiting the blockwise circulant structure of the dictionary, all computation can be efficiently done in the Fourier domain. Also, this allows us to seamlessly exploit more sophisticated feature representations (e.g. HOG or SIFT) which existing sparse trackers cannot because of the prohibitive computational cost. As a result, the proposed CST tracker can achieve much better tracking performance than state-of-the-art trackers as shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions:</head><p>The contributions of this work are threefold. (1) We propose a novel circulant sparse tracker, which is a robust and effective sparse coding method that exploits circulant structure in target templates to obtain better tracking results than traditional sparse trackers. To the best of our knowledge, this is the first work to exploit the circulant structure of target templates for sparse representation.</p><p>(2) Due to the circular shifts of target templates, we can refine particles and reduce their number. Moreover, due to the circulant property, we can apply CST efficiently in the Fourier domain. This makes our tracking method computationally attractive in general and faster than traditional sparse trackers in particular. (3) Because all the computation can be performed efficiently in the Fourier domain, we can use more sophisticated feature representations, which significantly improve tracking performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Visual tracking has been studied extensively in the literature <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31]</ref>. In this section, we briefly overview trackers that are most relevant to our work.</p><p>Generative vs. Discriminative Tracking: Visual tracking algorithms can be generally categorized as either generative or discriminative. Generative trackers typically search for the best image regions, which are similar to the tracked targets <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b29">30]</ref>. Black et al. <ref type="bibr" target="#b6">[7]</ref> learn an off-line subspace model to represent the target object for tracking. In <ref type="bibr" target="#b9">[10]</ref>, the mean shift tracking algorithm represents a target with nonparametric distributions of color features and locates the object with mode shifts. Kwon et al. <ref type="bibr" target="#b20">[21]</ref> decompose the observation model into multiple basic observation models to cover a wide range of pose and illumination variation. In <ref type="bibr" target="#b29">[30]</ref>, the IVT tracker learns an incremental subspace model to adapt appearance changes. As compared to generative trackers, discriminative approaches cast tracking as a classification problem that distinguishes the tracked targets from the background <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b16">17]</ref>. Avidan <ref type="bibr" target="#b1">[2]</ref> combines a set of weak classifiers into a strong one to do ensemble tracking. Grabner et al. <ref type="bibr" target="#b12">[13]</ref> introduce an online boosting tracking method with discriminative feature selection. The Struck tracker <ref type="bibr" target="#b14">[15]</ref> adopts an online structured output support vector machine for adaptive visual tracking. In <ref type="bibr" target="#b15">[16]</ref>, the KCF tracker exploits the circulant structure of adjacent image patches in a kernel space with HOG features. Zhang et al. <ref type="bibr" target="#b34">[35]</ref> utilize multiple experts using entropy minimization to address the model drift problem in visual tracking. Hong et al. <ref type="bibr" target="#b16">[17]</ref> cooperate short-term processing and long-term processing in visual tracking.</p><p>Sparse Tracking: Sparse linear representation has recently been introduced to object tracking with demonstrated success <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b43">44]</ref>. In the seminal ℓ 1 tracking work <ref type="bibr" target="#b26">[27]</ref>, a candidate region is represented by a sparse linear combination of target and trivial templates where the coefficients are computed by solving a constrained ℓ 1 minimization problem with nonnegativity constraints. As this method entails solving one ℓ 1 minimization problem for each particle, the computational complexity is significant. An efficient ℓ 1 tracker with minimum error bound and occlusion detection was subsequently developed <ref type="bibr" target="#b27">[28]</ref>. In addition, methods based on dimensionality reduction, as well as, orthogonal matching pursuit <ref type="bibr" target="#b21">[22]</ref> and accelerated proximal gradient descent <ref type="bibr" target="#b3">[4]</ref> have been proposed to make ℓ 1 tracking more efficient. Recently, several tracking algorithms have been proposed to learn the sparse representations of all particles jointly <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b17">18]</ref>. In <ref type="bibr" target="#b37">[38]</ref>, learning the representation of each particle is viewed as an individual task and a multi-task learning formulation for all particles is proposed based on joint sparsity. In <ref type="bibr" target="#b17">[18]</ref>, a multi-task multi-view joint sparse representation for visual tracking is introduced. Based on the results in the VOT2014 challenge <ref type="bibr" target="#b23">[24]</ref> and online tracking benchmark <ref type="bibr" target="#b31">[32]</ref>, sparse trackers clearly have drawbacks in both efficiency and accuracy. In defense of this type of tracker, we propose an effective and efficient circulant sparse tracker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Circulant Sparse Tracking</head><p>In this section, we give a detailed description of our particle filter based circulant sparse tracking method that makes use of the circulant structure of target templates to represent particles. Similar to <ref type="bibr" target="#b26">[27]</ref>, we assume an affine motion model between consecutive frames. Therefore, the state of a particle s t consists of six affine transformation parameters (2D linear transformation and translation). By applying an affine transformation based on s t , we crop the region of interest y t from the image and normalize it to the same size as the target templates in our dictionary, i.e. the target size in the first frame). The state transition distribution p(s t |s t−1 ) is modeled using a zero-mean Gaussian with diagonal covariance. The observation model p(y t |s t ) reflects the similarity between an observed image region y t corresponding to a particle s t and target templates of the current dictionary. In this work, p(y t |s t ) is computed based on the distance between the refined particle and the template dictionary. At each frame, the target's state is estimated as a weighted average of the states of the refined particles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Circulant Sparse Model</head><p>In the t th frame, we sample n particles. Consider one of these particles as an example. Its feature representation is denoted as x ∈ R d . Here, for simplicity, we assume x is a 1D signal with pixel color values; however, this can be easily extended to the 2D case with HOG features, as we will discuss in Section 3.2. Each x is represented as a linear combination z of dictionary templates D, such that x = Dz. In many visual tracking scenarios, target objects are often corrupted by noise or partially occluded. To address this issue, an error term e can be added to indicate the pixels in x that are corrupted or occluded: x = Dz + e. Then, we can rewrite:</p><formula xml:id="formula_0">x = Ac, where A = [D I], c = [z; e]</formula><p>, and I is a d × d identity matrix. Dictionary D can be constructed from an overcomplete sampling of the target. Given K of these base samples</p><formula xml:id="formula_1">a k with k = 1, . . . , K each having M × N pixels, A can be constructed as A = [A 1 , . . . , A k , . . . , A K ]. Here, A k contains all the circular shifts of the k-th base sample am ,n k , where (m,n) ∈ {0, 1, . . . , M − 1} × {0, 1, . . . , N − 1}, A k = [a 0,0 k , . . . , a M −1,N −1 k ]</formula><p>, and A K+1 = I to represent the trivial templates. Therefore, each A k ∈ R d×d is circulant, and A ∈ R d×Kd is blockwise circulant. As mentioned earlier, the circulant shifts of the base templates approximate their 2D translations. The particle representation can be obtained by solving the ℓ 1 minimization problem <ref type="bibr" target="#b0">(1)</ref>.</p><formula xml:id="formula_2">min c 1 2 x − Ac 2 2 + λ c 1<label>(1)</label></formula><p>Solving <ref type="formula" target="#formula_2">(1)</ref> with large-scale A is infeasible in the visual tracking task. To deal with this issue, we solve the dual problem of (1) in the Fourier domain. We introduce a dummy variable r along with a set of equality constraints:</p><formula xml:id="formula_3">min c,r 1 2 r 2 2 + λ c 1 s.t. r = Ac − x<label>(2)</label></formula><p>Using z to denote the Lagrange multipliers, we can write the Lagrangian of this problem as</p><formula xml:id="formula_4">L(c, r, z) = 1 2 r 2 2 + λ c 1 + z ⊤ (Ac − x − r) (3)</formula><p>Distributing z across the subtraction and grouping terms involving c and r, the resulting dual function is:</p><formula xml:id="formula_5">max z min c,r z ⊤ Ac + λ c 1 + 1 2 r 2 2 − z ⊤ r − z ⊤ x (4)</formula><p>Using the definition of the conjugate function to the ℓ 1norm and ℓ 2 -norm squared <ref type="bibr" target="#b8">[9]</ref>, we get the dual problem of (1) as shown in <ref type="formula" target="#formula_6">(5)</ref>.</p><formula xml:id="formula_6">min z 1 2 z ⊤ z + z ⊤ x s.t. A ⊤ z ∞ ≤ λ<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Optimization in the Fourier Domain</head><p>In this section, we present algorithmic details on how to efficiently solve the optimization problem <ref type="bibr" target="#b4">(5)</ref> in the Fourier domain using the fast first-order Alternating Direction Method of Multipliers (ADMM) <ref type="bibr" target="#b7">[8]</ref>. We introduce a variable θ to make θ = A ⊤ z and θ ∞ ≤ λ. By introducing augmented Lagrange multipliers to incorporate the equality constraints into the objective function, we obtain a Lagrangian function that can be optimized through a sequence of simple closed form update operations in <ref type="formula" target="#formula_7">(6)</ref>, where c and u &gt; 0 are the Lagrange multiplier and penalty parameter, respectively. Since the dual solution to the dual problem of a convex optimization is the primal solution in general, then the Lagrange multiplier here is actually the sparse code vector c from (1) <ref type="bibr" target="#b32">[33]</ref>.</p><formula xml:id="formula_7">L(c, z, θ) = z ⊤ z 2 + z ⊤ x + c ⊤ (A ⊤ z − θ) + u 2 A ⊤ z − θ 2 2 ⇒ max c min z,θ L(c, z, θ)<label>(6)</label></formula><p>The ADMM method iteratively updates the variables θ and z (one at a time) by minimizing <ref type="formula" target="#formula_7">(6)</ref> and then performs gradient ascent on the dual to update c. By updating these variables iteratively, convergence can be guaranteed <ref type="bibr" target="#b7">[8]</ref>. Consequently, we have three update steps corresponding to all three variables as follows.</p><p>Update θ: Given (c, z), θ is updated by solving the optimization problem <ref type="formula">(7)</ref> with the solution <ref type="formula" target="#formula_8">(8)</ref>.</p><formula xml:id="formula_8">θ = arg min θ u 2 A ⊤ z − θ 2 2 − c ⊤ θ (7) ⇒ θ = P B ∞ λ (A ⊤ z + c u )<label>(8)</label></formula><p>Here, P B ∞ λ represents the projection operator onto B ∞ λ , and</p><formula xml:id="formula_9">B ∞ λ = {x ∈ R n : x ∞ ≤ λ}.</formula><p>Note that, all circulant matrices are made diagonal by the Discrete Fourier Transform (DFT), regardless of the generating vector <ref type="bibr" target="#b13">[14]</ref>. If X is a circulant matrix, it can be expressed with its base sample x as</p><formula xml:id="formula_10">X = Fdiag(x)F H ,<label>(9)</label></formula><p>where F is a constant matrix that does not depend on x, andx denotes the DFT of the generating vector:x = Fx. The constant matrix F is known as the DFT matrix. X H is the Hermitian transpose, i.e., X H = (X * ) ⊤ , and X * is the complex-conjugate of X. For real numbers, X H = X T . In <ref type="bibr" target="#b7">(8)</ref>,</p><formula xml:id="formula_11">A ⊤ z = [A ⊤ 1 z; . . . ; A ⊤ K+1 z]</formula><p>, and it can be obtained via <ref type="bibr" target="#b9">(10)</ref>. Here, F −1 denotes the inverse DFT, while ⊙ denotes the element-wise product. The a ⊤ k is the base sample of circulant matrix A k . Update c as in <ref type="formula" target="#formula_2">(14)</ref>; 5 end Update z: Given (c, θ), updating z can be shown to be a least squares problem, whose solution is given by <ref type="bibr" target="#b10">(11)</ref>.</p><formula xml:id="formula_12">θ = P B ∞ λ (F −1 [â * 1 ⊙ẑ + 1 uĉ 1 ; . . . ;â * K+1 ⊙ẑ + 1 uĉ K+1 ])<label>(10)</label></formula><formula xml:id="formula_13">z = (AA ⊤ + 1 u I) −1 (Aθ − 1 u x − 1 u Ac)<label>(11)</label></formula><formula xml:id="formula_14">Here, Aθ = K k=1 A k θ k = F K k=1â * k ⊙θ * k , Ac = K k=1 A k c k = F K k=1â * k ⊙ĉ * k , and AA ⊤ = K k=1 A k A ⊤ k = Fdiag( K k=1â k ⊙â * k )F H .</formula><p>Therefore, the update z in <ref type="formula" target="#formula_2">(11)</ref> can be computed as z = F −1 (ẑ), wherê z is defined in <ref type="bibr" target="#b11">(12)</ref>. The fraction denotes element-wise division. Note that no expensive matrix inversion is required here. This is the defining difference between sparse representation on a traditional dictionary and that on a blockwise circulant one.</p><formula xml:id="formula_15">z = K k=1 (â k ⊙θ k − 1 uâ k ⊙ĉ k ) − 1 ux K k=1â k ⊙â * k + 1 u<label>(12)</label></formula><p>Update c: Given (z, θ), the sparse code c is updated in <ref type="bibr" target="#b12">(13)</ref>. The penalty parameter is increased from one iteration to the next: u = ρu, where ρ &gt; 1.</p><formula xml:id="formula_16">c = c + u(A ⊤ z − θ)<label>(13)</label></formula><p>In the Fourier domain, c can be updated as <ref type="bibr" target="#b13">(14)</ref>.</p><formula xml:id="formula_17">c = c + u(F −1 [â * 1 ⊙ẑ −θ 1 ; . . . ;â * K+1 ⊙ẑ −θ K+1 ])<label>(14)</label></formula><p>The ADMM algorithm that solves <ref type="formula" target="#formula_7">(6)</ref> is shown in Algorithm 1, where convergence is reached when the change in the objective function or solution z is below a pre-defined threshold (e.g., τ = 10 −3 in this work). Note that, in Algorithm 1, for a 1D signal x, the F and F −1 are the 1D DFT and its inverse. When x is 2D, F and F −1 are the 2D DFT and its inverse. As such, the optimization in the Fourier domain is efficient for 2D image patches with multiple channels, which is a useful property for visual tracking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">The Proposed CST Tracker</head><p>In this section, we give a detailed description of the proposed CST tracker, including the template model update, target state estimation, and feature representation.</p><p>Model Update: In the proposed tracker, the model consists of target templates A, which are updated dynamically to handle frame-to-frame changes in target appearance. For simplicity, we adopt the adaptive strategy in (15) by considering the current target appearance x. We only update the target template a k whose sparse representation has a maximum absolute value among all other templates.</p><formula xml:id="formula_18">F(a k ) t = (1 − η)F(a k ) t−1 + ηF(x)<label>(15)</label></formula><p>Here, η is a learning rate parameter, and the a k is the base sample of circulant matrix A k .</p><p>Target State Estimation: The target state is decided based on the n sampled particles with their states s i and representations c i , i = 1, . . . , n. For the i-th particle, its state s i can be refined tos i by applying the translation corresponding to the circular shift of the target template whose corresponding coefficient in c i has the maximum absolute value. In <ref type="figure">Figure 2</ref>, we show three examples of this particle state refinement. Then, the target state s can be estimated via a weighted average of all the refined particle states: s = i π isi . Here, π i denotes the confidence score of the i-th particle, and it is defined as π i = max(|c i |).</p><p>Once π i of each particle is computed, they are normalized to predict the final target state.</p><p>Image Representation: Most existing sparse trackers make use of vectorized grayscale values to represent the image patch x. It tends to be infeasible to adopt more sophisticated and higher-dimensional features, such as HOG and SIFT, since the added computational cost would be significant. On the other hand, our formulation (1) seamlessly enables the use of richer feature representations, without sacrificing much computationally. Algorithm (1) is used as is but with each target template a k represented using the new feature. Similar to the grayscale case, the optimization can be efficiently solved in the Fourier domain, since only elementwise operations are needed. As such, we make HOG features feasible for sparse trackers. For a more intuitive view of the proposed method, we visualize an empirical example to show how the proposed CST tracker works in <ref type="figure" target="#fig_2">Figure 3</ref>. Clearly, embedding circulant shifts of base templates into the sparse representation is helpful in refining each particle's state and localizing the target accurately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head><p>In this section, we present experimental results.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head><p>All experiments are implemented in MATLAB on an Intel(R) Xenon(R) 2.70 GHz CPU with 64 GB RAM.</p><p>Parameters: The λ in (1) is set to 1. The learning rate η in <ref type="formula" target="#formula_2">(15)</ref> is set to 0.03. We use the same parameter values and initialization for all the sequences. All the parameter settings are available in the source code to be released for accessible reproducible research and comparative analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets and Evaluation Metrics:</head><p>We evaluate our proposed method on a large benchmark dataset <ref type="bibr" target="#b31">[32]</ref> that contains 50 videos with comparisons to state-of-the-art methods. The performance of our approach is quantitatively validated by three metrics used in <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b31">32]</ref> including distance precision (DP), center location error (CLE), and overlap success (OS). The DP is computed as the relative number of frames in the sequence where the center location error is smaller than a certain threshold. As in <ref type="bibr" target="#b31">[32]</ref>, the DP values at a threshold of 20 pixels are reported. The CLE is computed as the average Euclidean distance between the ground-truth and the target's estimated center location. The OS is defined as the percentage of frames where the bounding box overlap surpasses a threshold of 0.5, which correspond to the PASCAL evaluation criterion.We provide results using the average DP, CLE, and OS over all 50 sequences. In addition, we plot the precision and success plots as recommended in <ref type="bibr" target="#b31">[32]</ref>. In the legend, we report the average distance precision score at 20 pixels for each method. The average overlap precision is plotted in the success plot. The area under the curve (AUC) is included in the legend. We also report the speed of the trackers in average frames per second (FPS) over all image sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Particle Refinement Strategy</head><p>In this section, we discuss how the proposed CST can refine particles, thus, effectively reducing the number of particles needed for accurate tracking. This involves two strategies: particle refinement and search region padding. As shown in <ref type="figure" target="#fig_3">Figure 4</ref> (a), particles (denoted in different colors) are translated towards the target object (denoted in green color). The translation of each particle is set to the circular shift corresponding to the highest absolute valued  <ref type="table">Table 1</ref>. Comparison with state-of-the-art trackers on the 50 benchmark sequences. Our approach performs favorably against existing methods in overlap success (OS) (%), distance precision (DP) (%) and center location error (CLE) (in pixels). The first and second highest values are highlighted in red and blue. Additionally, our method is faster compared to the best performing and existing sparse tracker (SCM). sparse coefficient in that particle's sparse code. This allows the sampled particles in the next frame to be closer to the target object. Moreover, the tracked region is 2 times the size of the target, to provide for context and additional search samples. This region determines the total number of possible circulant shifts. As shown in <ref type="figure" target="#fig_3">Figure 4</ref> (b), one particle (denoted in red) is quite far away from the target object (denoted in green). However, its search region (denoted in blue) can still cover the target object well. As a result, the particle can still be shifted towards the target object using our proposed model. In our implementation, both particles and the base samples of target templates have the same search region. In addition, they are also weighted by a cosine window for robustness. Although enlarging the search region increases the computational cost, it adds robustness to the tracker against fast motion, partial occlusion, etc. To balance efficiency and accuracy in visual tracking, we adopt this search strategy using 2 times the size of the target. In the experiments, we test the tracking results with different numbers of particles, n = 10, n = 20, and n = 50. We observe that they have very similar results. Therefore, we set n = 20 in our experiments. In comparison, traditional sparse trackers <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b37">38]</ref>, tend to use hundreds of particles for their representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CST-HOG CST-Color</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Image Feature Evaluation</head><p>Here, we implement the proposed CST method with two different features: HOG (CST-HOG) and gray color (CST-Color). We report the results in one-pass evaluation (OPE) using the distance precision and overlap success rate in <ref type="figure" target="#fig_4">Figure 5</ref>, which shows that replacing the conventional intensity values with HOG features significantly improves the tracking performance by 23.4% and 14.1% in terms of precision and success rate, respectively. Similarly, the HOG based tracker reduces the average CLE from 86.2 to 40.4 pixels as shown in <ref type="table">Table 1</ref>. In summary, our results clearly suggest that the HOG based image representation improves the tracking performance, which is also demonstrated by comparing KCF to CSK <ref type="bibr" target="#b15">[16]</ref>. Their results are also shown in <ref type="figure" target="#fig_4">Figure 5</ref> for comparison. In what follows, we employ HOG features to represent particles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Sparse Tracking Evaluation</head><p>We evaluate the proposed algorithm on the benchmark with comparisons to the top 4 sparse trackers in <ref type="bibr" target="#b31">[32]</ref>, namely SCM <ref type="bibr" target="#b44">[45]</ref>, ASLA <ref type="bibr" target="#b18">[19]</ref>, L1APG <ref type="bibr" target="#b3">[4]</ref>, and MTT <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref>. The details of the 4 trackers in the benchmark evaluation can be found in <ref type="bibr" target="#b31">[32]</ref>. We report the results using average OS, DP, CLE, and FPS over all sequences in <ref type="table">Table 1</ref>, and present the results in OPE using the distance precision and overlap success rate in <ref type="figure" target="#fig_4">Figure 5</ref>, attribute-based evaluation in <ref type="figure" target="#fig_6">Figure 6</ref>, and qualitative comparison in <ref type="figure" target="#fig_5">Figure 7</ref>. Table 1 shows that our algorithm outperforms state-of-the-art sparse trackers. Among the sparse trackers in the literature, the proposed CST method achieves the best results with an average OS of 68.2%, DP of 77.7%, and CLE of 40.4 pixels. Compared with the second-best method (SCM), CST registers a performance improvement of 6.6% in average OS and 12.8% in terms of average DP. In terms of average CLE, CST has a 13.7 pixel improvement over SCM. Moreover, CST achieves much higher frame rate than the secondbest performing sparse tracker. Note that our tracker can be made even faster with some code optimization. <ref type="figure" target="#fig_4">Figure 5</ref> contains the precision and success plots illustrating the mean distance and overlap precision over all 50 sequences. In both precision and success plots, our approach achieves the best results and significantly outperforms the best existing sparse method (SCM). In <ref type="figure" target="#fig_6">Figure 6</ref>, we analyze tracking performance based on some tracking attributes of the video sequences <ref type="bibr" target="#b31">[32]</ref>. Note that the benchmark annotates 11 such attributes to describe different chal-  lenges prevalent in the tracking problem, e.g., occlusions or out-of-view. These attributes are useful for analyzing the performance of trackers in different aspects. Due to space constraints, we present the success and precision plots of OPE for 3 attributes in <ref type="figure" target="#fig_6">Figure 6</ref> and more results can be found in the supplementary material. We note that the proposed tracking method performs well in dealing with challenging factors including fast motion, occlusion, and out-of-view motion.</p><p>In <ref type="figure" target="#fig_5">Figure 7</ref>, we show a qualitative comparison among the sparse trackers on 10 challenging sequences. The SCM tracker performs well in handling scale change (basketball and car4). However, it drifts when the target undergoes heavy occlusion (jogging-1) and fast motion (jumping and tiger1). L1APG is the most similar sparse method to CST, as they both solve an ℓ 1 minimization problem but with different optimization techniques (APG vs. ADMM). It fails to handle fast motion (jumping and tiger1), and background clutter (singer2), where using only grayscale intensity is less effective in discriminating targets from the cluttered background. MTT and ASLA do not perform well with partial occlusion (suv and subway). Overall, the proposed CST tracker performs very well in tracking objects on these challenging sequences. In addition, we compare the center location error frame-by-frame on the 10 sequences, which shows that our method performs well against existing trackers. Due to the space limitation, the results can be found in the supplementary material. Discussion: The above results clearly demonstrate the effectiveness and efficiency of our proposed CST tracker. Here, we highlight the following conclusions among the existing sparse trackers. (1) The circulant structure of target templates can improve tracking performance. L1APG and CST-Color have similar objective functions with grayscale intensity features. The differences are that the L1APG solves the ℓ 1 minimization problem in the spatial domain, while we construct the circulant matrix as target templates and solve the problem in the Fourier domain. Compared with the L1APG tracker, CST registers a 4.8% and 2.7% improvement in average DP and OS, respectively, while <ref type="bibr">Figure 8</ref>. Precision and success plots over all 50 sequences using OPE among 29 trackers in <ref type="bibr" target="#b31">[32]</ref>. The proposed CST method performs favorably against the state-of-the-art trackers. maintaining a very comparable runtime. (2) The circulant structure of target templates can make the HOG feature feasible in sparse trackers, and improve tracking performance significantly. In traditional sparse trackers, it is computationally infeasible to adopt HOG features due to the high computational cost. For example, given a target object with 50 × 50 pixels, if we adopt the HOG feature with 31 bins and vectorize the image patch, the resulting representation has 77, 500 dimensions. As a result, the trivial templates have 77, 500 elements, which certainly increases complexity substantially. However, owing to the circulant structure used in CST, the optimization can be solved efficiently by using 2D image patches with multiple channels in the Fourier domain. Moreover, comparing CST-HOG and CST-Color shows that HOG can significantly improve tracking performance. (3) Compared with the KCF tracker, our CST trackers register a 3.7% and 3.4% improvement in terms of average DP and OS, respectively. This is arguably due to the proposed sparse model with particle filtering, which can better handle partial occlusion and fast motion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Comparison with State-of-the-Art</head><p>We evaluate our CST tracker on the tracking benchmark with comparisons to 29 trackers, whose details can be found in <ref type="bibr" target="#b31">[32]</ref>. We report the precision and success plots in <ref type="figure">Figure 8</ref>, thus, illustrating the mean distance and overlap precision over all 50 sequences. In both precision and success plots, CST registers the best performance among all trackers and significantly outperforms the best existing sparse tracking method (SCM).</p><p>For a more thorough evaluation, we also include in the comparison the following very recent trackers with their corresponding (DP, OS, FPS) results: MEEM (83.5% , 57.6%, 6.2) <ref type="bibr" target="#b34">[35]</ref>, TGPR (71.4% , 51.5%, 0.36) <ref type="bibr" target="#b11">[12]</ref>, RPT (81.9% , 57.9%, 3.1) <ref type="bibr" target="#b22">[23]</ref>, MUSTer (86.5%, 64.1%, 0.34) <ref type="bibr" target="#b16">[17]</ref>, and DSST (73.7%, 55.4%, 32.7) <ref type="bibr" target="#b10">[11]</ref>. Among these trackers, the proposed CST is better than TGPR, and achieves comparable performance as DSST. The MUSTer, MEEM, and RPT methods achieve better performance than our CST method. Compared with the best existing MUSTer tracker, sparse trackers still have room for improvement; however, our proposed tracker is much faster. Moreover, the short-term and long-term strategy used in MUSTer <ref type="bibr" target="#b16">[17]</ref>, as well as, the multiple expert framework proposed in MEEM <ref type="bibr" target="#b34">[35]</ref> are generic schemes that can be adopted in sparse trackers to further improve their precision. For example, CST can exploit a combination of short-term and a longterm dictionaries to obtain much better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we propose a novel circulant sparse appearance model for object tracking under the particle filter framework. Due to the circulant structure property of target templates, the proposed tracker can make use of HOG feature, and effectively refine sampled particles to dramatically reduce the number of particles needed for tracking. Moreover, the optimization can be efficiently solved in Fourier domain. Experimental results compared with several stateof-the-art methods on challenging sequences demonstrate the effectiveness and robustness of the proposed algorithm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Algorithm 1 :</head><label>1</label><figDesc>The optimization for (6) via ADMM. Input : Dictionary A and Particle x. Initialization of λ, θ = 0, z = 0, c = 0, and u &gt; 0. Output: Particle Representation c.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 1 )</head><label>1</label><figDesc>We introduce the experimental setup. (2) We perform a comprehensive evaluation of different features in sparse trackers. (3) We provide quantitative, qualitative, and attributespecific comparisons with state-of-the-art trackers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Illustration for particle refinement: (a) the original sampled particle in red, (b) the learned coefficient c, and (c) the refined particle in green with a circular shift (m = 2,n = 3). Here, K = 5 and x is 41 × 50 × 31 using HOG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Particle reducing strategy via (a) particle refinement and (b) search region padding. See text for more details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Comparisons of different sparse trackers by using precision and success plots over all 50 sequences. The legend contains the area-under-the-curve score for each tracker. Our CST method performs favorably against the state-of-the-art trackers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Tracking results of the top 5 sparse trackers (denoted in different colors and lines) in our evaluation on 10 challenging sequences (from left to right and top to down are basketball, singer2, car4, jogging-1, subway, david3, liquor, suv, jumping, and tiger1 respectively).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Overlap success plots over three tracking challenges of fast motion, occlusion, and out-of-view. The legend contains the AUC score for each tracker. The proposed CST method performs favorably against the state-of-the-art trackers.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Research in this publication was supported by the King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust fragmentsbased tracking using the integral histogram</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shimshoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="798" to="805" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ensemble tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="494" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visual tracking with online multiple instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Babenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Real time robust l1 tracker using accelerated proximal gradient approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Real time robust l1 tracker using accelerated proximal gradient approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-template scale adaptive kernelized correlation filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Eigentracking: Robust matching and tracking of articulated objects using a view-based representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Jepson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="63" to="84" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peleato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eckstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Kernel-Based Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="564" to="575" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Accurate scale estimation for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Transfer learning based visual tracking with gaussian process regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Real-Time Tracking via On-line Boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Grabner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grabner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Toeplitz and circulant matrices: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Gray</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Now Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Struck: Structured output tracking with kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">High-speed tracking with kernelized correlation filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-store tracker (muster): A cognitive psychology inspired approach to object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Prokhorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="749" to="758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Tracking via robust multi-task multi-view joint sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Prokhorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Visual tracking via adaptive structural local sparse appearance model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Tracking-learningdetection. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1409" to="1422" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visual tracking decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Real-time visual tracking with compressed sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Reliable patch trackers: Robust visual tracking by exploiting reliable patches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="353" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The visual object tracking vot2014 challenge results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Robust visual tracking with local sparse appearance model and k-selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kulikowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Robust and fast collaborative tracking with two stage sparse optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kulikowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Robust Visual Tracking and Vehicle Classification via Sparse Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>TPAMI</publisher>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Minimum error bounded efficient l1 tracker with occlusion detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Blasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Finding the best from the second bests -inhibiting subjective bias in evaluation of visual tracking algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R.-S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<title level="m">Incremental Learning for Robust Visual Tracking. IJCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="125" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Visual tracking: an experimental survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smeulder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Calderara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Deghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1442" to="1468" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Online object tracking: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fast ℓ1-minimization algorithms for robust face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3234" to="3246" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Object tracking: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">MEEM: Robust tracking via multiple experts using entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Real-time compressive tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Low-rank sparse learning for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Robust visual tracking via multi-task sparse learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Robust visual tracking via structured multi-task sparse learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="367" to="383" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Robust visual tracking via exclusive context modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="63" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Object tracking by occlusion detection via structured sparse learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Partial occlusion handling for visual tracking via robust part matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Robust Visual Tracking via Consistent Low-Rank Sparse Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="190" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Structural sparse tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Robust object tracking via sparsity-based collaborative model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
