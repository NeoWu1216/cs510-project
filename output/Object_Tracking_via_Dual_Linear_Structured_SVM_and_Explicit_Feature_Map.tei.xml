<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Object Tracking via Dual Linear Structured SVM and Explicit Feature Map</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Ning</surname></persName>
							<email>jfning@sina.com</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information Engineering</orgName>
								<orgName type="institution">Northwest A&amp;F University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimei</forename><surname>Yang</surname></persName>
							<email>jimyang@adobe.com</email>
							<affiliation key="aff1">
								<orgName type="department">Adobe Research</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Jiang</surname></persName>
							<email>shaojiejiang@126.com</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information Engineering</orgName>
								<orgName type="institution">Northwest A&amp;F University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<email>cslzhang@comp.polyu.edu.hk</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
							<email>mhyang@ucmerced.edu</email>
							<affiliation key="aff3">
								<orgName type="department">Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">University of California at Merced</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Object Tracking via Dual Linear Structured SVM and Explicit Feature Map</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Structured support vector machine (SSVM) based methods have demonstrated encouraging performance in recent object tracking benchmarks. However, the complex and expensive optimization limits their deployment in real-world applications. In this paper, we present a simple yet efficient dual linear SSVM (DLSSVM) algorithm to enable fast learning and execution during tracking. By analyzing the dual variables, we propose a primal classifier update formula where the learning step size is computed in closed form. This online learning method significantly improves the robustness of the proposed linear SSVM with lower computational cost. Second, we approximate the intersection kernel for feature representations with an explicit feature map to further improve tracking performance. Finally, we extend the proposed DLSSVM tracker with multi-scale estimation to address the "drift" problem. Experimental results on large benchmark datasets with 50 and 100 video sequences show that the proposed DLSSVM tracking algorithm achieves state-of-the-art performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Object tracking aims to estimate the locations of a target in an image sequence. It can be applied to numerous tasks such as human-computer interaction, traffic monitoring, action analysis and video surveillance <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b25">26]</ref>. The main issue of object tracking is the incapability to account for large appearance variations due to viewpoint changes, occlusions, deformations and fast motions.</p><p>Existing object tracking algorithms can be broadly categorized as either generative or discriminative. Generative tracking algorithms <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b23">24]</ref> typically learn an appearance model to represent a target and use the model to search for interesting regions in the next frame with min-imal reconstruction error. Instead of constructing a model to represent the appearance of a target, discriminative approaches <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b32">33]</ref> consider the tracking problem as a classification or regression problem of finding the decision boundary that best separates the target from the background. In recent years, the tracking-by-detection approach has attracted more attention due to its strength to deal with targets undergoing large appearance variations.</p><p>Numerous classification algorithms such as support vector machines <ref type="bibr" target="#b0">[1]</ref>, boosting <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b29">30]</ref>, multiple instance learning <ref type="bibr" target="#b2">[3]</ref> and random forests <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b10">11]</ref> have been used in recent tracking-by-detection methods. However, the goal of binary classifiers is not seamlessly aligned with the one of object trackers due to the structured output space of tracking. To overcome this problem, Hare et al. <ref type="bibr" target="#b7">[8]</ref> propose a kernelized Structured SVM (Struck) for object tracking. The Struck method treats object tracking as a structured output prediction problem that admits a consistent target representation for both learning and detection. Especially, in a recent tracking benchmark studies <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32]</ref>, Struck <ref type="bibr" target="#b7">[8]</ref> shows the state-of-the-art performance.</p><p>However, the high complexity of optimization and detection processes for Struck <ref type="bibr" target="#b7">[8]</ref> with nonlinear kernels limits its usage of high dimension features. It is critical to tracking performance because object representation with high dimensional features can model the target better than low dimensional ones. For example, KCF <ref type="bibr" target="#b9">[10]</ref> greatly outperforms its original version CSK <ref type="bibr" target="#b8">[9]</ref> by only replacing the low dimensional image feature with high dimensional HOG feature. On the other hand, the primal SSVM can be learned efficiently with linear kernels, which is very useful for fast training and detection even if it uses high dimensional features to represent the target. However, existing sub-gradients methods <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b20">21]</ref> are sensitive to the step size when applied to online tasks. Therefore, it is of great interest to design a proper SSVM tracking algorithm that can run sufficiently fast with high dimensional features.</p><p>In this work, we propose a simple but effective dual linear SSVM (DLSSVM) tracking algorithm to solve these problems. First, we formulate object tracking as a linear SSVM detection problem to enable fast model updates in its primal form. By analyzing the relationship between the dual and primal variables, we present a closed form solution to compute the step size of the model update, which is critical for the tracking performance of linear SSVMs. Second, to exploit nonlinear kernels while maintaining the linearity of the proposed SSVM, we approximate the nonlinear kernels with explicit feature maps. Third, to overcome the drifting problem caused by large scale changes, we extend the proposed tracker with multi-scale estimation. Experiments on benchmark datasets <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref> of 50 and 100 image sequences show that the DLSSVM tracker achieves the state-of-the-art performance.</p><p>The main contributions of this work are summarized as follows: First, a dual linear SSVM classifier is derived in closed form, which is faster to train and evaluate than non-linear classifiers and this important technique constitutes the basis of this work. Second, with explicit feature maps, the proposed DLSSVM tracker can exploit high dimensional linear features to better represent objects for visual tracking than non-linear SSVM methods in terms of speed and accuracy. Third, the multi-scale estimation further improves the performance by accounting for the large scale changes during tracking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head><p>In this section we briefly introduce the structured SVM formulation of the tracking-by-detection approach before presenting the proposed algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Tracking-by-Detection</head><p>The tracking-by-detection method learns an online classifier to distinguish a target from its local background. We review its main components and discuss the difference between traditional binary discriminative classifiers and structured SVMs. For the ease of illustration, we use the same notations as <ref type="bibr" target="#b7">[8]</ref> in the following. Let p t denote the object central location at frame t, y is a relative transform according to location p t . We represent a new position by p t • y where • is a transformation operator (e.g., displacement, Euclidean or affine transform). At the image location p t • y, we extract image patches x p t •y t . Let h(·) be a learned classifier and r be the radius of a search space Y that contains all candidate locations.</p><p>Assume that we have the initial discriminative classifier according to the first frame. First, we crop out a set of image patches x p t−1 •y t from search space Y with radius y ≤ r and compute feature vectors. Second, we use the discriminative classifier to update tracker location y * = arg max y∈Y h(x t p t−1 •y ) and obtain the location p t = p t−1 • y * in the current frame. Third, members of the sample set x t p t •Y are cropped out around the current tracking position p t to update the discriminative classifier. For a binary classifier <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b37">38]</ref>, the image patches x t p t •Y are divided into two groups, whose labels are respectively +1 and -1. For the structured SVM based classifier <ref type="bibr" target="#b7">[8]</ref>, the label of sample x t is structured, i.e., the candidate positions y of the target. Finally, the discriminative classifier is updated with the newly arrived samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Structured SVM</head><p>In structured prediction, the goal is to predict a structured output y ∈ Y for a given input x ∈ X where y can be arbitrary output for different problems. In our tracker, y is defined as a bounding box. The feature vector Φ(x, y) is a function defined over a pair of input and output (x, y) which encodes the relevant information. We learn a discriminative classifier with parameter w defined by</p><formula xml:id="formula_0">y * = arg max y∈Y h(x,y,w)<label>(1)</label></formula><p>where h(x,y,w) = w ⊤ Φ(x,y) and w can be learned in a large-margin framework from a sample set of {(x 1 , y 1 ), . . . , (x n , y n )} by solving the following global optimization problem:</p><formula xml:id="formula_1">min w 1 2 w 2 + c n i=1 ξ i s.t. ∀i : ξ i ≥ 0 ∀i, ∀y = y i : w, Ψ i (y) ≥ L(y i , y) − ξ i<label>(2)</label></formula><p>where Ψ i (y) = Φ(x i , y i ) − Φ(x i , y) and L(y i , y) denotes the task-dependent structured error of predicted output y instead of the observed output y i . The slack variable ξ i measures the surrogate loss for the i-th data point and c is the regularization parameter. The loss function expresses a finer distinction between y i and y, which plays an important role in the structured SVM. Similar to the Struck method <ref type="bibr" target="#b7">[8]</ref>, we choose to base the loss function on the bounding box overlap rate</p><formula xml:id="formula_2">L(y i , y) = 1 − s o p t (y i , y)<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">s • p t (y i , y) = (p t •y i )∩(p t •y) (p t •y i )∪(p t •y)</formula><p>. The Lagrange dual of the above n-slack formulation is given by</p><formula xml:id="formula_4">min α≥0 f (α):= 1 2 i,y =y i α i,y Ψ i (y) 2 − i,y =y i L(y i , y)α i,y (4a) s.t. ∀i, ∀y = y i : α i,y ≥ 0 (4b)</formula><p>∀i :</p><formula xml:id="formula_5">y =y i α i,y ≤ c<label>(4c)</label></formula><p>In the dual structured SVM, the discriminative classifier can be defined as w = i,y =y i α i,y Ψ i (y). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">SSVM Based Tracking Analysis</head><p>Although dual SSVMs with non-linear kernels usually perform better than ones with linear kernels for tracking, the training and detection processes are more complex. As a result, if a non-linear kernel is used in the SSVM for object tracking, we cannot obtain the classifier parameter w explicitly so that the object detection can be only evaluated in the kernel space with a high computational cost.</p><p>The Struck method <ref type="bibr" target="#b7">[8]</ref> uses low-dimensional features (192-dimensional Haar-like features) to represent target for reducing the computational cost. The sequential minimal optimization (SMO) <ref type="bibr" target="#b18">[19]</ref> used by the Struck method <ref type="bibr" target="#b7">[8]</ref> has a high computational cost as well because it requires finding a violation pair for each update and its convergence rate does not scale well with the size of the output space <ref type="bibr" target="#b38">[39]</ref>.</p><p>To alleviate the computational issue with non-linear kernels, we use a linear SSVM as the discriminative classifier w because it can be obtained explicitly. The use of linear kernels could accommodate high dimensional features for target representation and at the same time maintains a relatively low computational load for both training and detection. In terms of representation power, we note that the explicit feature map <ref type="bibr" target="#b26">[27]</ref> can approximate non-linear kernels for non-linear decision efficiently and effectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Dual Linear SSVM Tracker</head><p>In this section, we first present our algorithm to efficiently solve a dual SSVM with linear kernels. Next, we use an unary representation <ref type="bibr" target="#b14">[15]</ref> to approximate the intersection kernel for modeling object appearance, which improves the performance of the proposed DLSSVM tracker. Finally, we present the proposed tracking algorithm via our online dual linear SSVM optimization process. <ref type="figure" target="#fig_0">Figure 1</ref> summarizes the differences between the Struck and DLSSVM methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dual Linear SSVM Optimization</head><p>We present an online learning algorithm to train a dual linear SSVM for object tracking. We follow the basic dual coordinate descent (DCD) <ref type="bibr" target="#b19">[20]</ref> optimization process for the dual SSVM and consider (4a) as a multivariate function with respect to dual coefficients α i,y .</p><p>Optimization with closed form solution. In the DCD approach, the basic process is that in each iteration only one sample is optimized. For a sample k, the DCD method first selects one violated variable with maximum error as,</p><formula xml:id="formula_6">y * k = argmax y∈Y k L(y, y k ) − w ⊤ Ψ k (y)<label>(5)</label></formula><p>Note that we keep the primal classifier w for efficient model evaluation during tracking.</p><p>To estimate α k,y * k , we first compute the derivative of (4a) with respect to α k,y * k (which is related to structured output y * k ) and set it to zero. As a result, the new coefficient α ′ k,y * k is given by</p><formula xml:id="formula_7">α ′ k,y * k = L(y k , y * k ) Ψ k (y * k ) 2 − i,y =y i (α i,y Ψ ⊤ i (y) − α k,y * k Ψ ⊤ k (y * k ))Ψ k (y * k ) Ψ k (y * k ) 2 According to w = i,y =y i α i,y Ψ i (y)</formula><p>, we obtain a simple α k,y * k update formula (6) for the above equation,</p><formula xml:id="formula_8">α ′ k,y * k = α k,y * k + L(y k , y * k ) − w ⊤ Ψ k (y * k ) Ψ k (y * k ) 2<label>(6)</label></formula><p>With the constraint in (4c), we have α ′ k,y * ∈ [0, c − y =y * α k,y ]. Therefore, the second term on the right hand side of (6), which defines the increment of the dual coefficient by</p><formula xml:id="formula_9">γ = L(y k , y * k ) − w ⊤ Ψ k (y * ) Ψ k (y * ) 2 (7) is normalized as γ ∈ [−α k,y * , c − y α k,y ].</formula><p>Note that in <ref type="formula" target="#formula_6">(5)</ref> and <ref type="formula" target="#formula_8">(6)</ref> we use a linear kernel to explicitly compute the primal parameters w. Compared to non-linear kernels, where w is implicitly represented by the sum of all dual coefficients multiplying kernel transformation of support vectors, the primal classifier only requires simple vector inner products which leads to much less complex training and detection. After optimizing one sample, we obtain the updated primal classifier immediately,</p><formula xml:id="formula_10">w = w + γΨ k (y * )<label>(8)</label></formula><p>In <ref type="formula" target="#formula_10">(8)</ref> the update of w is similar to the sub-gradient descent (SSG) <ref type="bibr" target="#b20">[21]</ref> method <ref type="bibr" target="#b24">[25]</ref>. However, the SSG method is sensitive to the step size γ. Our update step size is derived in closed form in the dual space. It takes advantage of the DCD optimization with linear kernels and offers fast convergence guarantee <ref type="bibr" target="#b19">[20]</ref>. Therefore, after each iteration, we obtain immediately the explicit classifier, which is subsequently used for the next update.</p><p>After learning the discriminative classifier w, we carry out object detection for the frame at time t using learned w via the simple matrix operation defined by</p><formula xml:id="formula_11">y * = argmax y∈Y w ⊤ Ψ t (y).</formula><p>The structured output y * with maximum response is considered as the object location.</p><p>The DCD optimization <ref type="bibr" target="#b19">[20]</ref> used by this work is simpler than the SMO optimization technique <ref type="bibr" target="#b18">[19]</ref> in the Struck tracker <ref type="bibr" target="#b7">[8]</ref>. In our method we only pick up one violation variable each iteration and update its support vector coefficient while the SMO <ref type="bibr" target="#b18">[19]</ref> method needs to carefully find a pair of violated variables and update their coefficients. Compared to Struck <ref type="bibr" target="#b7">[8]</ref>, the process to update and maintain support vectors is simpler as it needs to only optimize one dual coefficient at each step. The main difference between the Struck <ref type="bibr" target="#b7">[8]</ref> and DLSSVM methods is shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>Budget of support vectors. The number of support vectors in the SSVM increases gradually over time and a fixed amount is maintained for memory efficiency. In our method, the number of support vectors does not increase the complexity of the training process because it is only used to control the number of samples, which is different from the Struck method <ref type="bibr" target="#b7">[8]</ref>.</p><p>As each dual coefficient is relatively independent in our linear SSVM optimization, we remove the support vector with the smallest norm, which is irrelevant to other support vectors. When the number of support vectors in the SSVM detector exceeds the budget, we remove one according to the following formula,</p><formula xml:id="formula_12">α * = argmin αi,y∈α α i,y Ψ i (x i , y) 2<label>(9)</label></formula><p>where α i,y is the coefficient of the support vector Ψ i (x i , y) of sample x i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Explicit Feature Map for Non-Linear Kernels</head><p>We employ an image kernel between pairs of the patches cropped from a frame x at location y for the proposed DLSSVM tracker,</p><formula xml:id="formula_13">K image (x, y,x,ȳ) = K(x p•y ,xp •ȳ )<label>(10)</label></formula><p>For each patch, we normalize it to about 400 pixels and employ the feature representation in the MEEM method <ref type="bibr" target="#b35">[36]</ref> based on the CIE Lab color space. In addition, we apply the non-parametric local rank transform (LRT) <ref type="bibr" target="#b34">[35]</ref> to the lightness channel to increase invariance to illumination change.</p><p>We denote z i as the feature vector of one image patch consisting of Lab and LRT channels, and measure the similarity of two image patches using an intersection kernel.</p><formula xml:id="formula_14">K(x p•y ,xp •ȳ ) = K(z i , z j ) = k min(z k i , z k j ),<label>(11)</label></formula><p>where k is the k-th element of feature vector z i . To obtain the primal classifier w in our DLSSVM formulation, we use the explicit feature map Ψ(x p•y ) for the intersection kernel.</p><p>As an additive kernel, the explicit feature map can be approximated by the unary representation <ref type="bibr" target="#b14">[15]</ref>. Let N denote the number of discrete levels, U (n) denote the unary representation of the integer n, e.g., U (3) = {1, 1, 1, 0, 0, 0} when N = 6, and R(·) denote the rounding function. The unary representation of the feature z k is defined by</p><formula xml:id="formula_15">φ(z k ) = 1 N U (R(N z k ))<label>(12)</label></formula><p>Based on this unary representation <ref type="bibr" target="#b14">[15]</ref>, the intersection kernel can be approximated by</p><formula xml:id="formula_16">k min(z k i , z k j ) ≈ k &lt; φ(z k i ), φ(z k i ) &gt;<label>(13)</label></formula><formula xml:id="formula_17">such that Ψ(x p•y ) ≈ [φ(z 1 i ), φ(z 2 i ), . . . , φ(z k i ), . . .]</formula><p>. We set the quantization number N = 4 for color sequences. For grayscale sequences, since the color channels are not available, we set the quantization number N = 8 for more accurate approximation of the intersection kernel.</p><p>For the dimension of features, the original features of color image include four channels (Lab+LRT). Using unary representation with the quantization number N=4, we have 400*4*4=6400 dimensional vectors. For gray image, its original features includes two channels (Gray+LRT). Using unary representation with the quantization number N=8, we also get 400*2*8=6400 dimensional vectors. In contrast, the Struck <ref type="bibr" target="#b7">[8]</ref> with a non-linear Gaussian kernel only uses 192 dimensional feature vectors due to computational loads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Multi-scale Estimation</head><p>It is difficult for tracking methods with a fixed scale representation to deal with target objects undergoing large scale changes. To alleviate the drifting problem caused by large scale changes, we extend the DLSSVM method with a multiple scale estimation. In this work, we use DLSSVMs at three different scales in parallel, and use the maximum responses as the tracking results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Tracking Algorithm</head><p>We follow a common optimization strategy <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b3">4]</ref> to implement our tracking algorithm. <ref type="figure" target="#fig_1">Figure 2</ref> show the main steps of the proposed DLSSVM tracker, and the details are presented in Algorithm 1.</p><p>Especially, because both search region and discriminative classifier w actually belong to image features <ref type="figure" target="#fig_1">(Figure 2b)</ref>, we can use the Fast Fourier Transform (FFT) algorithm to speed up the detection process. However, it is difficult for Struck <ref type="bibr" target="#b7">[8]</ref> because it only gets implicitly discriminative classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head><p>We first discuss the experimental setup, dataset, and evaluation metrics, and then present two sets of experiments:</p><p>• Analysis of proposed DLSSVM and related SSVM trackers; • Comparisons with state-of-the-art trackers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: DLSSVM tracking algorithm</head><p>input : Initial discriminative learner w = 0 and initial object location p 0 . Output: Tracking result location p i of each frame. repeat 1. Estimate change in object location.</p><formula xml:id="formula_18">y t = arg max y∈Y w ⊤ x p t−1 •y t p t = p t−1 • y t 2.</formula><p>Crop samples X t = x p t •y t from current frame and append it to end of dataset. 3. Update DLSSVM discriminative classifier. Get the number n of samples data. For j = 1 : n 1 i = n − ⌊((j − 1) * n/n 1 )⌋ Select a sample X i from sample set X. According to <ref type="bibr" target="#b4">(5)</ref>, select y * from structured labels Y i of sample X i .</p><p>According to <ref type="bibr" target="#b5">(6)</ref>, update α i,y * corresponding to y * .</p><p>According to <ref type="bibr" target="#b7">(8)</ref>, update w. Maintain support vectors budget based on <ref type="bibr" target="#b8">(9)</ref>. Get the number n of samples data. For p = 1 : n 2 i = n − ⌊((p − 1) * n/n 2 )⌋ Select a sample X i from sample set X. According to <ref type="bibr" target="#b4">(5)</ref>, select y * from structured label Y i of sample X i with non-zero dual coefficients .</p><p>According to <ref type="bibr" target="#b5">(6)</ref>, update α i,y * corresponding to y * .</p><p>According to <ref type="bibr" target="#b7">(8)</ref>, update w. End For End For until End of video sequences; Note: n 1 and n 2 are the numbers of iterations of exploring (external loop) and optimization (internal loop) <ref type="bibr" target="#b19">[20]</ref>  <ref type="bibr" target="#b3">[4]</ref>, and are fixed in all experiments.</p><p>More experimental results and videos can be found in the supplementary material. All the MATLAB source codes will be made available to the public.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head><p>Parameter Setting. For all sequences, we use fixed parameter values for fair evaluations. For the SSVM optimization (2), c is set to 100. We set the budget of support vectors to 100. The search radius for training and detection process is automatically determined by square root of the target area. The size of image patch is normalized to 400 pixels according to a trade-off between accuracy and speed. For scale estimation, we use the conservative scaling pool S={1 0.995, 1.005}, which is similar to <ref type="bibr" target="#b12">[13]</ref>.</p><p>In our algorithm, we implement the training and detection process in MATLAB while the feature extraction step in C++ for runtime performance as in the Multi-Expert Entropy Minimization (MEEM) method <ref type="bibr" target="#b35">[36]</ref>. It runs at 10 fps on a desktop computer with Intel i5-2400 CPU (3.10 GHz) and 6 GB memory.</p><p>Dataset. We evaluate the proposed DLSSVM algorithm on the TB50 <ref type="bibr" target="#b30">[31]</ref> and TB100 <ref type="bibr" target="#b31">[32]</ref> benchmark datasets. For detailed analysis, these sequences are annotated with 11 challenging attributes including illumination variation (IV), scale variation (SV), occlusion (OCC), deformation (DEF), motion blur (MB), fast motion (FM), in-plane rotation (IPR), out-of plane rotation (OPR), out-of-view (OV), background clutters (BC) and low resolution (LR).</p><p>Evaluation Protocol and Metrics. As suggested in <ref type="bibr" target="#b30">[31]</ref>, we evaluate the tracking algorithms using three protocols: one-pass evaluation (OPE), temporal robustness evaluation (TRE), and spatial robustness evaluation (SRE) using precision and success rates. We present the main findings in this manuscript and more results can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Analysis of Proposed DLSSVM and Related SSVM Trackers</head><p>We evaluate the DLSSVM method and the related trackers on the TB50 <ref type="bibr" target="#b30">[31]</ref> dataset. <ref type="table" target="#tab_0">Table 1</ref> summarizes the characteristics of those SSVM trackers. <ref type="table">Table 2</ref> shows the experimental results of those related SSVM trackers including the run-time performance. The mean FPS (frames per second) is estimated on a long sequence liquor with 1741 frames.</p><p>we denote the DLSSVM tracker without the unary representation as DLSSVM-NU, and the method using 50, 100 and 500 support vectors as DLSSVM-B50 ,DLSSVM-B100 and DLSSVM-B500, respectively. The DLSSVM with multi-scale estimation is denoted as Scale-DLSSVM.</p><p>Analysis of DLSSVM tracker. Based on the results of the DLSSVM-NU and DLSSVM-B100 methods using the OPE, TRE and SRE protocols, it is clear that the explicit feature map with the unary representation plays an important role in robust object tracking. Overall, the DLSSVM tracker is insensitive to different numbers of support vectors (e.g., from 50 to 500). Furthermore, the Scale-DLSSVM method obtain better accuracies than the DLSSVM scheme at the expense of lower processing speed. In the following, the DLSSVM tracker is referred to the one with 100 support vectors for evaluations against other state-of-the-art tracking methods, unless specified otherwise.     Comparisons with Other SSVM trackers. We first implement a linear SSVM tracker with the sub-gradient optimization method <ref type="bibr" target="#b24">[25]</ref>, and refer it as the SSG tracker (i.e., a baseline SSVM tracker). The learning rate to update clas-sifiers is manually selected without using the closed form solution via (7) (i.e.,the step size in the four methods from the bottom of <ref type="table">Table 2</ref> is manually set). As shown in <ref type="table">Table 2</ref>, although the SSG tracker uses the same high dimensional features as the DLSSVM-NU tracker at a higher processing rate, the tracking accuracy in all three indices is lower than that of the Struck <ref type="bibr" target="#b7">[8]</ref> method with a small margin.</p><p>Second, we implement the original Struck <ref type="bibr" target="#b7">[8]</ref> method and a linear Struck approach in MATLAB for fair comparisons. Note that Haar-like feature used by Struck <ref type="bibr" target="#b7">[8]</ref> is not proper for computing the explicit feature map of intersection kernel so we compare Struck and our method using our feature representations. In addition, we also evaluate the performance of the Struck method with a linear kernel with (Linear-Struck) and without (Linear-Struck-NU) using the explicit feature map.</p><p>For the Struck <ref type="bibr" target="#b7">[8]</ref> method, we note that the linear Struck method with high dimensional features (Linear-Struck-NU) outperforms the original non-linear kernel Struck in terms of both accuracy (all metrics) and speed, which suggests that linear Struck with high dimensional feature is more proper than Struck with Gaussian kernel for visual tracking. The DLSSVM tracker (i.e., DLSSVM-B100) performs favorably against the Struck <ref type="bibr" target="#b7">[8]</ref> and Linear-Struck methods in accuracy and speed. On the other hand, the experimental comparisons between the SSG, Linear-Struck and DLSSVM methods in <ref type="table">Table 2</ref> indicate that the linear SSVM classifier with the step size in closed form solution is crucial to robust object tracking. With simpler optimization process, the proposed DLSSVM tracker performs favorably against the Struck [8] method using non-linear and linear kernels in terms of accuracy and speed. It indicates that DCD optimization <ref type="bibr" target="#b19">[20]</ref> used by our DLSSVM is better than SMO <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b3">4]</ref> used by Struck <ref type="bibr" target="#b7">[8]</ref> for visual tracking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparisons with State-of-the-Art Trackers</head><p>We evaluate the DLSSVM and Scale-DLSSVM trackers against the state-of-the-art methods on the TB50 <ref type="bibr" target="#b30">[31]</ref> and TB100 <ref type="bibr" target="#b31">[32]</ref> datasets, where the results of 29 trackers are reported. In addition, we include 6 most recent trackers for performance evaluation. The HCFT <ref type="bibr" target="#b13">[14]</ref> and DLT <ref type="bibr" target="#b27">[28]</ref> methods are developed based on hierarchical features via deep learning. The STC <ref type="bibr" target="#b36">[37]</ref> and KCF <ref type="bibr" target="#b9">[10]</ref> schemes are based correlations filters. Furthermore, the TGPR <ref type="bibr" target="#b6">[7]</ref> and MEEM <ref type="bibr" target="#b35">[36]</ref> algorithms are developed based on regression and multiple trackers. The precision and success rates for the top ten trackers on the TB50 <ref type="bibr" target="#b30">[31]</ref> and TB100 <ref type="bibr" target="#b31">[32]</ref> datasets are presented in <ref type="figure" target="#fig_3">Figure 3</ref> and <ref type="figure" target="#fig_4">Figure 4</ref>.</p><p>The KCF tracker <ref type="bibr" target="#b9">[10]</ref> exploits circulant matrix computations and achieves high run-time speed. In addition, the recent method <ref type="bibr" target="#b12">[13]</ref> shows that the performance of the KCF method can be further improved by a more effective representation based on color name attributes <ref type="bibr" target="#b11">[12]</ref>. Overall, the proposed DLSSVM tracker with simple color and spatial features performs favorably over the KCF method in terms of accuracy using all metrics.</p><p>The MEEM <ref type="bibr" target="#b35">[36]</ref> tracking method uses a mixture of ex-perts based on entropy minimization where a linear SVM with twin prototypes <ref type="bibr" target="#b28">[29]</ref> is used as the base tracker. The proposed DLSSVM tracker performs well against the MEEM method in most metrics except the OPE precision. In addition, the Scale-DLSSVM method with multi-scale estimation outperforms the MEEM tracker <ref type="bibr" target="#b35">[36]</ref> in all metrics on both TB-50 and TB-100 datasets.</p><p>Compared to deep learning based methods, the proposed DLSSVM method performs favorably against the DLT <ref type="bibr" target="#b27">[28]</ref> tracker on the TB50 <ref type="bibr" target="#b30">[31]</ref> and TB100 <ref type="bibr" target="#b31">[32]</ref> datasets, and the Scale-DLSSVM algorithm performs comparably against the state-of-the-art HCFT <ref type="bibr" target="#b13">[14]</ref> method which is based on both correlation filters and hierarchical convolutional features. We note that the proposed DLSSVM and Scale-DLSSVM methods only use simple image features while the HCFT method takes advantage of complex hierarchical convolutional features that requires offline training on a large dataset. These experimental results show that the dual linear optimization scheme used by the proposed SSVM trackers is effective and efficient for robust object tracking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper, we propose an efficient and effective SSVM formulation for robust object tracking via a dual linear SSVM optimization method and an explicit feature map. By using linear kernels, we can easily update the primal classifier and speed up the algorithm. With the dual SSVM formulation, we derive a closed form update scheme for the primal classifier which is critical for robust object tracking. We approximate intersection kernel with the explicit feature map to make non-linear decision by our linear SSVM classifier for better performance. The DLSSVM tracking method is further improved with multi-scale estimation to account for large scale changes. Experimental results show that the proposed DLSSVM tracker performs favorably against the state-of-the-art methods on large benchmark datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Comparing optimization processes for the Struck<ref type="bibr" target="#b7">[8]</ref> and DLSSVM methods. (a) First, both SSVM trackers crop structured samples around the tracking result in each frame. Each structured output of each sample has a dual coefficient α. (b) Second, a selected sample is used to update its dual coefficients related to different structured outputs, i.e. support vectors. The Struck<ref type="bibr" target="#b7">[8]</ref> and DLSSVM methods use different optimization schemes to update it. (c) Third, a pair of dual variables need to be carefully chosen and optimized in the Struck<ref type="bibr" target="#b7">[8]</ref> method while only one dual variable is selected by a simple method and then updated in the proposed DLSSVM algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Main steps of the proposed DLSSVM tracker. (a) First, we crop structured samples around the tracking results of the previous frame. (b) Second, we update the discriminative classifier via dual linear SSVM optimization. Note that the explicitly discriminative classifier is very important for object tracking to rapidly train and detect. (c) We apply the updated classifier to detect the object in the current frame.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Average precision plot (top row) and success plot (bottom row) for the OPE, TRE and SRE on the TB50<ref type="bibr" target="#b30">[31]</ref> dataset. For presentation clarity, only the top ten trackers with respect to the ranking score are shown in each plot.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Average precision plot (top row) and success plot (bottom row) for the OPE, TRE and SRE on the TB100<ref type="bibr" target="#b31">[32]</ref> dataset. For presentation clarity, only the top ten trackers with respect to the ranking score are shown in each plot.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 .</head><label>1</label><figDesc>Characteristics of SSVM trackers. NU means no unary representation for the features</figDesc><table>SSVM trackers 
closed form 
kernel 
feature 
feature 
high dimension non-linear discriminative 
solution 
type 
type 
dimensions 
feature 
decesion 
classifier 
SSG 
no 
linear 
image feature 
1600 
yes 
no 
explicit 
Struck 
yes 
Gaussian 
Haar-like 
192 
no 
yes 
implicit 
Linear-Struck-NU 
yes 
linear 
image feature 
1600 
yes 
no 
explicit 
Linear-Struck 
yes 
linear 
image feature 
6400 
yes 
yes 
explicit 
DLSSVM-NU 
yes 
linear 
image feature 
1600 
yes 
no 
explicit 
DLSSVM 
yes 
linear 
image feature 
6400 
yes 
yes 
explicit 

Table 2. Experimental comparisons of the proposed DLSSVM and related trackers with different parameters settings: B50, B100 and B500 
mean the budgets of support vectors are 50, 100 and 500 respectively. The entries in Bold red indicate the best results and the ones in blue 
indicate the second best. 

SSVM trackers 

OPE 
TRE 
SRE 
Mean FPS 
precision 
success 
precision 
success 
precision 
success 
(20 pixels) (AUC) (20 pixels) (AUC) (20 pixels) (AUC) 
DLSSVM-NU 
0.794 
0.557 
0.810 
0.581 
0.724 
0.508 
28.88 
DLSSVM-B50 
0.828 
0.587 
0.846 
0.606 
0.780 
0.543 
10.10 
DLSSVM-B100 
0.829 
0.589 
0.856 
0.610 
0.783 
0.545 
10.22 
DLSSVM-B500 
0.826 
0.588 
0.852 
0.609 
0.787 
0.548 
10.37 
Scale-DLSSVM 
0.861 
0.608 
0.857 
0.615 
0.811 
0.565 
5.40 
SSG 
0.608 
0.443 
0.665 
0.486 
0.584 
0.424 
46.13 
Struck 
0.656 
0.474 
0.707 
0.514 
0.634 
0.449 
0.90 
Linear-Struck-NU 
0.703 
0.506 
0.751 
0.540 
0.655 
0.462 
1.46 
Linear-Struck 
0.792 
0.556 
0.824 
0.589 
0.736 
0.515 
1.20 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Support vector tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1064" to="1072" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ensemble tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="61" to="271" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Robust object tracking with online multiple instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Babenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1619" to="1632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Solving multiclass support vector machines with larank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gallinari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A review of visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cannons</surname></persName>
		</author>
		<idno>CSE-2008-07</idno>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci. Eng., York Univ</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mean-shift blob tracking through scale space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Transfer learning based visual tracking with gaussian processes regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Struck: Structured output tracking with kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Exploiting the circulant structure of tracking-by-detection with kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Highspeed tracking with kernelized correlation filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>PAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Tracking-learningdetection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1409" to="1422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Coloring action recognition in still images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Anwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bagdanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="205" to="221" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A scale adaptive kernel correlation filter tracker with feature integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV Worksohps</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hierarchical convolutional features for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Max-margin additive classifiers for detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Robust visual tracking using l1 minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Robust visual tracking and vehicle classification via sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2259" to="2272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Finding the best from the second bestsinhibiting subjective bias in evaluation of visual tracking algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Fast training of support vector machines using sequential minimal optimization. Advances in kernel methodssupport vector learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Dual coordinate solvers for large-scale structural svms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1312.1743" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">(online) subgradient methods for structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Ratliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Zinkevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICAIS</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Incremental learning for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="125" to="141" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On-line random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leistner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Santner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Godec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distribution fields for tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sevilla-Lara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Pegasos: Primal estimated sub-gradient solver for svm. Mathematical programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cotter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="3" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Visual tracking: An experimental survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Calderara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dehghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1442" to="1468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Efficient additive kernels via explicit feature maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="480" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning a deep compact image representation for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">online training on a budget of support vector machines using twin prototypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vucetic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SADM</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Online spatio-temporal structural context learning for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Online object tracking: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<title level="m">Object tracking benchmark. PAMI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1834" to="1848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Partbased visual tracking with online latent structural learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Object tracking: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Non-parametric local transforms for computing visual correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Woodfill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Meem: Robust tracking via multiple experts using entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fast tracking via dense spatio-temporal context learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Real-time compressive tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Accelerated training of max-margin markov networks with kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">519</biblScope>
			<biblScope unit="page" from="88" to="102" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
