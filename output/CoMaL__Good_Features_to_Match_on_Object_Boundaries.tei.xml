<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CoMaL: Good Features to Match on Object Boundaries</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swarna</forename><forename type="middle">K</forename><surname>Ravindran</surname></persName>
							<email>swarnakr@cs.duke.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Technology Madras Chennai INDIA</orgName>
								<address>
									<postCode>600036</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Mittal</surname></persName>
							<email>amittal@cse.iitm.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Technology Madras Chennai INDIA</orgName>
								<address>
									<postCode>600036</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CoMaL: Good Features to Match on Object Boundaries</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Traditional Feature Detectors and Trackers use information aggregation in 2D patches to detect and match discriminative patches. However, this information does not remain the same at object boundaries when there is object motion against a significantly varying background. In this paper, we propose a new approach for feature detection, tracking and re-detection that gives significantly improved results at the object boundaries. We utilize level lines or iso-intensity curves that often remain stable and can be reliably detected even at the object boundaries, which they often trace. Stable portions of long level lines are detected and points of high curvature are detected on such curves for corner detection. Further, this level line is used to separate the portions belonging to the two objects, which is then used for robust matching of such points. While such CoMaL (Corners on Maximally-stable Level Line Segments) points were found to be much more reliable at the object boundary regions, they perform comparably at the interior regions as well. This is illustrated in exhaustive experiments on realworld datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Feature points in an image are points that have a distinctive image structure around them and have been used in several applications such as point tracking <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b31">31]</ref>, Visual Odometry (for Automotive Applications, for instance) <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b43">43]</ref>, Optical Flow <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b1">2]</ref>, Stereo <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b41">41]</ref>, Structure from Motion (SfM) from video <ref type="bibr" target="#b41">[41,</ref><ref type="bibr" target="#b49">49]</ref>, and Simultaneous Localization and Mapping (SLAM) <ref type="bibr" target="#b20">[21]</ref> among others. Most of the popular feature detectors (Harris <ref type="bibr" target="#b15">[16]</ref>, Shi and Tomasi <ref type="bibr" target="#b42">[42]</ref> SURF <ref type="bibr" target="#b3">[4]</ref> and Hessian <ref type="bibr" target="#b28">[28]</ref>) utilize the whole information in a patch surrounding the point to find feature points. For instance, the Harris detects points that have significant aggregated gradients in orthogonal directions in a surrounding patch. Many recent detectors * The author is currently at Duke University (AGAST <ref type="bibr" target="#b26">[26]</ref>, FAST <ref type="bibr" target="#b38">[38]</ref> and FAST-ER <ref type="bibr" target="#b39">[39]</ref>) use intensity comparisons in different directions and use machine learning techniques to significantly speed up the computation. These features have been matched using a variety of techniques. The simple Sum-of-Squared-Distance(SSD), with some local optimization <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b25">25]</ref>, is still typically the method of choice when there are only small changes in the illumination or viewpoint (for e.g. point tracking, flow and stereo applications) while more complicated descriptors such as SIFT <ref type="bibr" target="#b24">[24]</ref> have been utilized where there are more such variations. Many modern variants output a binary descriptor for extremely efficient matching (BRIEF <ref type="bibr" target="#b5">[6]</ref>, ORB <ref type="bibr" target="#b40">[40]</ref>, Daisy <ref type="bibr" target="#b45">[45]</ref>, FREAK <ref type="bibr" target="#b0">[1]</ref> and NSD <ref type="bibr" target="#b4">[5]</ref>).</p><p>While these Feature Detection and Matching approaches perform reasonably in the interior of objects, they perform quite poorly on the object boundaries <ref type="bibr" target="#b49">[49]</ref>. This can be attributed to two reasons. First, the detectors rely on fixed (scalable) image patches which may straddle object boundaries and depth discontinuities and a change in these can lead to a change in the detected object. Second, even if a boundary point is detected at the same location w.r.t. one of the objects, matching is very difficult as the part in the patch belonging to the other object changes. <ref type="figure" target="#fig_0">(Fig. 1)</ref>.</p><p>In this paper, we try to address these problems by proposing an approach for Feature Detection and Matching that can detect points accurately even in the presence of a changing background. At the same time, the support region is automatically segmented into two parts which often correspond to the regions belonging to the two objects. This enables independent matching of these two parts and by considering only the matching part, the point can be matched accurately even in the presence of a changing background.</p><p>We utilize level lines (curves connecting points with the same intensity) for this purpose by noting that the boundaries of objects are typically traced by such level lines, which often move with the object <ref type="figure" target="#fig_1">(Fig 2)</ref>. By detecting turns/corners on level lines that do not change much with intensity variations (stability property), discriminative points can be found. We refer to such points as Corners on Maximally-stable Level Line Segments (CoMaL). Furthermore, this level line itself typically separates the two objects in the case of object boundaries and thus, we match the portions on either side of this curve separately and take the higher score of the two. This makes the matching method robust even in the boundary regions.</p><p>Several detectors have used level lines in the past <ref type="bibr" target="#b6">[7]</ref>, the most popular among them being the Maximally Stable Extremal Regions(MSER) detector <ref type="bibr" target="#b27">[27]</ref>. MSERs are stable, closed level lines that were shown to return high Repeatability and Matching scores in image matching experiments <ref type="bibr" target="#b29">[29]</ref>. They have also been used in hand and object tracking <ref type="bibr" target="#b8">[9]</ref>, where the object is typically homogeneous and has little interior texture, causing the other detectors to underperform. However, since MSER considers only small closed level lines and throws away the information in longer level lines in order to preserve the locality of a feature, it typically returns very few points and is not a popular choice for many other detection and matching applications where one needs to obtain a sufficient number of points ( <ref type="figure" target="#fig_1">Fig. 2(a)</ref>). In this work, we detect corners along long level lines ( <ref type="figure" target="#fig_1">Fig. 2(b)</ref>), which in fact are more stable than small level lines in many cases such as blur <ref type="bibr" target="#b34">[34,</ref><ref type="bibr" target="#b36">36]</ref>. Such long level lines have been used in the past by some detectors such as LAF <ref type="bibr" target="#b34">[34]</ref> and SAF <ref type="bibr" target="#b36">[36]</ref>, that build affine-invariant detectors using some key tangent points on the curve. However, they rely on very few particular key points on the curves to compute the features, which makes them quite noisy. Also, their affine-invariant property makes them less suitable for the basic task of feature detection, where such methods underperform <ref type="bibr" target="#b29">[29]</ref>. Edges, which are closely related to level lines, have been used to detect corners <ref type="bibr" target="#b47">[47]</ref>. However, edge-based feature detection is prone to a higher error as edges can often be fragmented. In this paper, we restrict ourselves to the problem of basic feature detection (without any scale or affine invariance) that also allows us to use much more robust measures for corner detection on such level lines.</p><p>Our detection and matching technique gave superior results compared to other state-of-the-art algorithms on the KITTI Vehicle dataset <ref type="bibr" target="#b13">[14]</ref> with real-world sequences, with significantly improved results on the object boundaries. Although our method is applicable in many scenarios, results are illustrated for two applications from this dataset: Point Tracking and Optical Flow. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Related Work on Handling Boundary Regions</head><p>Several algorithms have been tried to address varying backgrounds in boundary regions. The dominant edge is used to separate the two regions at the object boundary for the problem of Object Recognition in <ref type="bibr" target="#b30">[30]</ref>. In object tracking, SegTrack <ref type="bibr" target="#b2">[3]</ref>, Chen et al. <ref type="bibr" target="#b7">[8]</ref> and Oron et al. <ref type="bibr" target="#b35">[35]</ref> iteratively build probabilistic appearance models for the foreground and background in order to separate them for superior object tracking.In stereo, Kanade and Okutomi <ref type="bibr" target="#b19">[20]</ref> and DAISY (Tola et al.) <ref type="bibr" target="#b45">[45]</ref> adaptively determine the window/mask to use while matching each point. Almost all of the above approaches for different problems utilize smoothness constraints in a large region in an iterative manner to disambiguate the possible matches at the object boundaries. Thus, they have limitation when the object boundaries dominate the object appearance (for e.g. thin objects). Furthermore, they need a good initialization. Our algorithm can match points without such smoothness restrictions and on objects having very little internal texture and can also be used to provide some good matches as initializers for these algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Corners on Maximally Stable Level Lines</head><p>We define our corners on level lines, which are lines connecting points having the same intensity. If the intensity variation across the image is smooth or has been sufficiently smoothed by a smoothing operation, then such level lines form smooth curves in an image with nearby level lines having close intensities <ref type="figure" target="#fig_2">(Fig. 3)</ref>. Thus, by varying the intensity of the level line, one can move these curves in space. Portions on these level lines that do not move much when the intensity is varied are portions with good perpendicular gradients on the level line and are called stable in this work. When additionally, such level lines turn, then such corner points can be discriminated from other points in the neighborhood and detected as feature points. We first consider the stability of a level line segment extending on either side of a given candidate point p on a given level line, the extent of the segment being determined by the scale at which points are to being detected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Stability of a Level Line Segment</head><p>The first condition we desire for a corner point is that it should lie in a region of high gradients. A level line that has a high gradient on it is thus desirable. Although we can compute this directly, a more robust approach is to consider neighboring level lines and compute the distance between these. We define a level line that is a neighbor of LL(I) and is detected at an intensity of I + δ as LL N (LL(I), δ). A high value of the gradient on LL (which is always perpendicular to it) is characterized by close LL N 's for small δ's. The stability of a level line ρ(LL(I)) can then be defined by considering the distance between LL N (LL(I), +δ) and LL N (LL(I), −δ) for some given small value δ. This is illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>.</p><p>The Distance Measure The distance between neighboring level lines may be calculated using a variety of measures. A straightforward measure is to establish explicit correspondences between the two curves by considering the nearest points and then summing the distances between the corresponding points. While this can be speeded up using the Distance Transform, the corresponding points may not be unique and may not cover all the points, especially in the case of concave and convex curves, leading to noisy results.</p><p>Stable Affine Frames (SAF) <ref type="bibr" target="#b36">[36]</ref> uses the maximum of the distances between three particular pairs of corresponding points instead of all the corresponding points. These are two adjacent bi-tangent points on a level line and a central high-curvature point. However, the detection of these points, especially the bi-tangent, is known to be noisy. Further, relying on just 3 points is not very robust.</p><p>In this work, we use the area between the two level lines LL N (LL(I), +δ) and LL N (LL(I), −δ), normalized by the length of the level line, as the distance measure. This measure, based on the number of points between the two curves, is more robust to noise in the curves. It is inspired by MSER <ref type="bibr" target="#b27">[27]</ref>, which has been shown to be a robust detector in many evaluations <ref type="bibr" target="#b29">[29]</ref>.</p><p>Weighting the Points in the Patch We make a modification to this measure in order to make it more robust. Essentially, the points closer to the candidate corner p are more important than points far from p. To achieve this effect, while computing the area between the curves and the segment length of the level line, the points in the image patch centered at the point p are weighed using a 2D Gaussian G I (p, σ low I , σ high I , θ) centered at the candidate corner point p. The Gaussian is aligned along the direction θ of the tangent to the level line at the point p such that a high sigma σ high I is used in the direction perpendicular to θ and a low sigma σ low I is used in the direction of the tangent <ref type="figure" target="#fig_3">(Fig 4(a)</ref>). These σ's are multiplied by the scale s at which the point is to be detected. G I is truncated at 2 σ I for efficiency purposes.</p><p>Given such a weighting for the points in the surrounding patch, the weighted length len w is computed for the level line segment LL(I, p, s) at intensity I centered along the level line at the point p at scale s. Further, the weighted area ∆A w is calculated from the weighted points between LL N (LL(I, p, s), δ) and LL N (LL(I, p, s), −δ). Then, the stability ρ of the level line segment LL(I, p, s) using the variation parameter δ is defined as:</p><formula xml:id="formula_0">1 ρ(LL(I, p, s), δ) = ∆A w (LL(I, p, s)) len w (LL(I, p, s))<label>(1)</label></formula><p>Essentially, 1/ρ measures the average weighted motion of a point on LL(I, p, s) when the intensity I is varied. This stability measure is computationally simple, symmetric and more stable compared to many other alternatives since it relies on the characteristics of the entire curve and not just a few points on it which can be noisy. Given the stability of the level line segments, a nonmaximal suppression is finally done by picking only those segments LL(I, p, s) that have a higher ρ than their immediate neighbors: LL N (LL(I, p, s), 1) and LL N (LL(I, p, s), −1). Such maximally stable level line segments are denoted as MLL(I, p, s) in this work.</p><p>Such MLL's are distinctive in their neighborhoods from neighboring level lines. However, points on such level lines are distinctive from each other only where the curve turns. Such turns or corners on such level lines are detected using the following approach:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Corners on MLL's</head><p>The turn points or corners on maximally stable level line segments MLL are distinctive and can be differentiated from other points in the neighborhood. Thus, such points will be detected as corner points in this work.</p><p>A popular and straightforward approach to find corners on curves is by using the curvature <ref type="bibr" target="#b36">[36,</ref><ref type="bibr" target="#b6">7]</ref> which measures the rate of change in the curve direction at any given point of the curve (second derivative). Local maxima of such curvature along the curve can be used as corner points. However, this measure can be somewhat noisy due to the use of the second derivative. To make it less sensitive to noise, one must use a fairly high precision which increases the running time of the algorithm. We use a more robust and computationally much more efficient approach as it does not require a high precision while computation.</p><p>The distribution of points on the curve centered at the candidate corner point p is determined ( <ref type="figure" target="#fig_3">Fig. 4(b)</ref>). The Covariance matrix Σ s of such points at scale s is:</p><formula xml:id="formula_1">Σ s = G(p, σ s )⊗ (x −x) 2 (x −x)(y −ȳ) (x −x)(y −ȳ) (y −ȳ) 2<label>(2)</label></formula><p>wherex andȳ are the x and y means of points and a 1D Gaussian G(p, σ s ) is used to weigh the points on the level line such that σ s is proportional to the scale s.</p><p>The eigenvalues of Σ s reflect the distribution of the points along two principal orthogonal directions and high values of both indicate a corner. Shi and Tomasi <ref type="bibr" target="#b42">[42]</ref> and Tsai et al. <ref type="bibr" target="#b46">[46]</ref> use the minimum of the two eigenvalues as a measure for cornerness, arguing that it better represents the corner. However, computing the eigenvalues explicitly is slow, due to which the original Harris Corner detector <ref type="bibr" target="#b15">[16]</ref> works on the second moment matrix of the image gradients directly, defining cornerness as: det(Σ s ) − k · trace(Σ s ) 2 . Forstner et al <ref type="bibr" target="#b11">[12]</ref> and Lowe et al. <ref type="bibr" target="#b24">[24]</ref> use:</p><formula xml:id="formula_2">κ(s) = det(Σ s )/trace(Σ s ) 2 = (λ 1 · λ 2 ) (λ 1 + λ 2 ) 2<label>(3)</label></formula><p>Due to the normalization, it is scale invariant and since eigenvalues themselves are rotation invariant <ref type="bibr" target="#b15">[16]</ref>, this measure is also rotation invariant. This measure was found to be suitable for our purposes and can also be computed fast and is thus used in this work. A threshold is applied on the cornerness κ(s) in order to find points of high cornerness at scale s. Furthermore, a non-maximal suppression is employed along the MLL's to yield corners that are well localized along the level line.</p><p>Finally, corner points are defined as:</p><p>Definition: A point p is a feature point at scale s if LL(I(p), p, s) is maximally stable according to the stability measure ρ and the cornerness κ(s) of p is the local maxima along LL(I(p)) at scale s.</p><p>The important point to note here is that all the tests above have to be done by centering the curve and the patch at the point p. Calculation of such stability for every point on every level line is prohibitively slow. We next discuss an iterative approach to search for such corner points efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Algorithm: Iterative Feature Detection</head><p>In order to perform this search efficiently, we note that the maximally stable segments do not shift much when the scale is varied. This allows us to run an initialization step at a slightly higher scale (we use 2 times the scale of the final detection) in overlapping blocks for an initial estimate of the points. Furthermore, no weighting is used in this step which allows it to be fast. Each of such initial corners is passed through an iterative refinement step where the full constraints of patch centering at the detection point and point weighting are applied for stability and cornerness computations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Initialization</head><p>The first step in the Initialization is to divide the image into overlapping blocks of size 2Bs × 2Bs, where B is a multiplying factor specifying the support region to be used for corner detection and s is the scale at which we want to detect the final corners. Maximally stable level line segments at scale 2s, MLL(2s), are detected in each image block using a modified-MSER algorithm described next. No weight scaling as described in the previous section is applied. On such MLL ′ s, an initial set of corners C init s is determined using Eq 3. The cornerness threshold is also lowered a bit compared to the final detection threshold in order to not miss any final corners.</p><p>Efficient MLL Detection using a Modified MSER Algorithm: We modify the MSER algorithm to efficiently detect maximally stable level line segments since the MSER detector efficiently maintains the set of level lines and the area of the associated regions by the union-find algorithm. We replace the MSER's stability formulation with our formulation in Eq. 1, which involves a division by the weighted length of the level curve LL, which is an open curve, rather than a division by the area of the closed level line, which may not be the best thing to do in these blocks which often truncate such level lines and extremal regions. This modified MSER algorithm is run on each image block to get an initial set of stable level line segments MLL. Note that no point weighting as proposed in Section 2.1 is applied here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approximations in Corner Computation</head><p>Corner computation is run on such detected MLL's from each block. The time consuming step is the convolution with a Gaussian weight filter (Eq. 2) for the point contributions for each test point. This step can be made efficient by using the Central Limit Theorem to replace the Gaussian with an average filter that can be applied multiple times to approximate the effect of a Gaussian (The average filter is run 3 times for the results in this work). The averaging operation is extremely fast due to the applicability of Dynamic Programming. The idea is similar in spirit to the approximate 2D Gaussians implemented in SURF <ref type="bibr" target="#b3">[4]</ref>. Such an approximation is possible in our approach since our cornerness measure is quite robust to weight errors compared to other measures such as the curvature which require more precise computations. Note that there is no need to run this step at scale 2s and we run this corner detection step at scale s itself.</p><p>Running Time A maximum init window stride of 2Bs/2 ensures that each of the points is captured in at least one of the init windows. Since the MSER is a linear-time algorithm <ref type="bibr" target="#b33">[33]</ref>, the computation of the MLL's takes around 4 times the amount of time the MSER algorithm would take on the entire image. The computation of the corners on such MLL's is again linear in the number of pixels on the level lines, which is actually much lower than the number of pixels in the image and is thus extremely fast.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Iterative Point Refinement</head><p>Given an initial set of approximate corner locations obtained from the initialization stage, we run an iterative refinement algorithm for each point so that in the end, the level line is locally maximally stable with the detected point p as its center, and the stability measure is computed with the appropriate point weighting as specified in Section 2.1.</p><p>The first step in the refinement is to recompute the maximal level line MLL when the patch is centered at the current estimate of p. A block of size of Bs × Bs is used as the support region for point detection. The modified-MSER algorithm as described in the previous section is used. Among the many maximal level lines that may be found in this block, the one that is closest in terms of shape and distance to the current one is taken as the new MLL. Appropriate Gaussian weighting of the points is used, which also ensures that blocking causes minimal errors as the points near the block boundaries will have very low weights. Corners are re-detected on the new MLL at scale s and the one closest to the previous one is taken as the updated corner point.</p><p>This process is repeated till the point stops moving. At this stage, the point p satisfies both the conditions for our feature point and is output as a corner point at scale s.</p><p>Typically, the initial level line remains fixed or moves to only a nearby level line during the iterations and the maximum number of iterations was found to be only around 3 or 4 in our experiments. Each iteration is an order (Bs) 2 operation where most of the time is taken by the linear-time MSER algorithm running on the block of size Bs × Bs. It is also important to note that the algorithm is trivially parallelized, for example, by the use of GPUs. The whole iterative procedure is illustrated in <ref type="figure" target="#fig_4">Fig. 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Point Matching</head><p>While one can use simple strategies, such as the SSD for point tracking or descriptors such as SIFT to handle more variations, they don't work very well for the points on the boundary of two objects as the surrounding patch may contain regions from two relatively moving objects (an object vs. its background). To handle such cases, we propose to use the maximal level line on which the point was detected as a separation boundary between two regions of the patch and match the two regions separately <ref type="figure" target="#fig_5">(Fig. 6(b)</ref>). The basic idea is that the boundary between two objects is typically traced by a maximal level line which moves along with the object and thus an MLL is a good separation boundary between two moving objects. By using such an approach, one can correctly match boundary points on many objects, even if the objects themselves are homogenous and textureless and do not yield any corner points in the interior.</p><p>The SSD is used as the distance measure between the two patches in our work, although more complicated descriptors such as the SIFT can also be considered for many applications. A gradient descent is applied to the (half) patch before computing the SSD in order to deal with small shifts and errors in point localization. The SSD values are computed in the common(intersection) region of the masks of the two patches being matched and are normalized by the size of this region.</p><p>In case no external information is available, one can utilize the above two-region matching approach for all the points. However, if it is possible to classify the points as interior and boundary points, perhaps in an iterative way, then one can apply the two-region matching only to the boundary points as considering only a part of the patch for matching for the interior points does reduce the discriminability of the matcher due to utilization of lesser information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments and Results</head><p>While scale and affine-invariant features have been developed for many applications, in this work, we have developed a basic feature detector that does not handle scale or affine variations. Hence, we compare against basic feature detectors (Harris, Hessian, FAST) which are useful in applications such as point detection and tracking in videos. Thus, we evaluate for these applications only.</p><p>Harris, Hessian and FAST have been found to be the best basic detectors in many evaluations <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b48">48]</ref>. More recent ones such as FAST-ER and AGAST improve the speed of detection but their performance is quite similar to FAST <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b39">39]</ref> and thus only FAST was compared against. All the scale and affine-invariant detectors <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b29">29]</ref> including level line based methods such as SAF <ref type="bibr" target="#b36">[36]</ref> and LAF <ref type="bibr" target="#b34">[34]</ref> performed significantly worse than the basic point detectors for these applications and are not shown, due to lack of space.We include results for MSER since our method is closely related to theirs.</p><p>Dataset: The dataset that we choose for evaluation is the publicly available KITTI dataset <ref type="bibr" target="#b13">[14]</ref>. The dataset has realistic, challenging outdoor sequences with good groundtruths. We evaluate our method on 11 video sequences for Point Tracking and 194 image pairs for Optical Flow from this dataset. Each vehicle in the tracking sequence moves through roads against different backgrounds and the Optical Flow sequences consist of vehicles and other real-world structures with significant depth discontinuities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Vehicle tracking</head><p>We first consider a vehicle tracking application which uses interest point tracking <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b43">43,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b18">19]</ref>. The seminal KLT algorithm <ref type="bibr" target="#b25">[25]</ref> is still quite popular for such an application <ref type="bibr" target="#b43">[43,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b32">32]</ref> along with its variants <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b37">37]</ref>. In this application, interest points are detected and matched in subsequent frames. While simple tracking might work for a few frames, the tracks eventually get lost and have to be re-detected and matched to the original ones for longer term tracking. 11 challenging sequences from the KITTI dataset that have significant variations in the background were selected and we compare results for point matching at a gap of 1 and 5 frames to test the efficacy of the detectors and matchers for shorter and longer range point matching respectively. While matching, an appropriate neighborhood was set as the search region in order to restrict the amount of motion that each point can undergo.</p><p>Since the dataset contains only car tracking bounding boxes, the ground truth for point matches was generated from the annotated bounding boxes by assuming that the relative location of a point w.r.t. to the bounding box remains the same across frames. A small amount of error is allowed, as the object is not rigid in 2D and there might be some errors in the bounding box annotations. A 10-pixel allowance was found to be sufficient for this dataset.</p><p>For a fair comparison, we equalize the average number of detected features detected by a detector as far as possible. For detectors that return very few points (e.g MSER), the threshold is lowered as much as reasonably possible. For CoMaL, the threshold used to vary the number of points is     <ref type="table">Table 1</ref> shows the quantitative results. It is clear from the results that CoMaL yields a much higher number of correctly matched points compared to other approaches at a similar or higher accuracy. Generally, Hessian performs second, closely followed by FAST. The superior performance of our approach can be attributed to a much better performance and resilience in the boundary regions that are quite significant for these vehicle objects, while the interior points are correctly matched by most methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Optical Flow</head><p>Optical flow is a dense point tracking problem and many optical flow techniques use point feature tracking as an input to the computation of flow for the entire scene <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b1">2]</ref>. We evaluate our features for this application by matching points across pairs of images and verifying them using the ground-truth flow map provided with the dataset.</p><p>Since in this dataset, the full flow is available, one can determine the boundary regions by looking at motion discontinuities. This helps us evaluate the detectors separately at the boundary and non-boundary regions. The evaluation criteria is chosen to be same as the vehicle tracking application and <ref type="table">Table 2</ref> shows the average number of correctly matched points across the given flow pairs on the boundary and internal/non-boundary points separately.</p><p>In this test, it becomes clear that CoMaL + SSD outperforms the other approaches in the boundary regions while performing close to the best detector and matcher combinations in the non-boundary regions. Slightly lower performance for our method can be expected in the non-boundary portions as others use information from the whole patch for matching while we use only around half of it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Our Own Dataset</head><p>Finally, to evaluate the performance of the detectors at the boundary regions and under a varying background, since no suitable dataset exists in the literature, we have developed our own dataset. The background and the camera are kept static that allows the use of background subtraction to separate out the foreground from the background. This also enables detection of the boundary regions between the foreground and background for evaluation purposes.</p><p>Ground-truthing is done by extracting foreground blobs and assuming that the the relative location of a point with respect to the blob center does not change drastically over the frames. Matches obtained with CoMaL+SSD and Hes-sian+SIFT (which performs second-best) are shown visually for a homogeneous and textured object in <ref type="figure">Fig. 8</ref>. <ref type="table">Table 3</ref> presents quantitative results at the boundary regions. As can be seen, CoMaL beats all the competing methods by a large margin at the boundaries for both homogenous and textured objects, with an overall increase of 14.8 correctly matched points on an average over FAST + NSD which performs next best, closely followed by Hessian + NSD. Results at non-boundary regions are comparable to other detectors (shown in supplementary section).</p><p>Discussion For applications with significant boundary portions, our method can be used on its own. For other applications, one could use our method with others such as the Hessian, perhaps in an iterative framework, where the boundary and non-boundary portions are estimated iteratively in order to determine the best algorithm to use for different regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>We have presented an algorithm for corner detection and matching that was found to be much more robust in the boundary regions compared to existing approaches. This is accomplished by detecting corners on maximally stable level lines that often trace the object boundaries and by matching the two regions separated by such level lines separately. Results on point tracking on several datasets including the challenging real-world KITTI dataset show that our method is able to extract and correctly match much more points compared to existing approaches in the boundary regions. Future work includes application to other problems where our approach might be useful, such as SfM in video sequences and stereo.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>A car moving against a varying background. Nearly half of the patch centered on a Harris corner at the object boundary is part of the background.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>(a) A long level line that forms the boundary of an object. The information present along such level lines is discarded by MSER. (b) A few corners (marked in red) detected by us on locally stable portions of the level lines .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Stable and Unstable level lines in brown (top right) and blue (bottom right) boxes respectively. The Green level line LL is tested by considering LL N (LL, δ) and LL N (LL, −δ) level lines in red and purple respectively. Note that the lines are very close in the brown box due to which they mostly overlap in the illustration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>(a) The Gaussian weight centered on point p (yellow) on a level line LL. (b) The vectors connecting the points (in green) on the level line segment to their mean (x,ȳ) (in red). The distribution of these vectors is used to determine the cornerness of this level line segment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>(a) An Image divided into overlapping blocks of size 2Bs. Different blocks are shown in different colors for clarity purposes. (b) A sample MLL in one sample block (top) and a corner found on it (bottom). (c) The set of initial corners detected. (d &amp; e) The iterative procedure for point refinement. The MLL and the initial point (pink) detected in the initial stage with a block window of size 2Bs are used to center a block (yellow) of size Bs in the first step of the iteration. This point moves to the red point. When the window is now centered at this (red) point, it remains the same and is thus detected as the final corner.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>(a) +ve region (side with higher intensities) and (b)ve region (side with lower intensities) separated by the level line shown in yellow. They are matched separately for better matching.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>2 .</head><label>2</label><figDesc>Average number of correct matches Mcor for 194 pairs from the KITTI Flow dataset with the corresponding Matching accuracy Macc in the B (Boundary), and N-B (Non-Boundary Regions). The best is in bold and the second best is underlined.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Frame numbers 88 and 93 in the sequence Car-B from the KITTI dataset showing CoMaL + SSD matches in the first row followed by next performing combination: Hessian + SIFT and FAST + NSD in the 2nd and 3rd rows respectively. CoMaL points are matched more numerously and accurately at the object boundary regions in spite of a significant change in the background. the threshold on the stability value ρ. For a fair comparison, we use a typical scale value of 8.4 for all the detectors and all the other parameters for the detectors and descriptors are kept at their default values used in standard implementations. Comparative results for other scale settings were sim-ilar. While CoMaL is combined with only the SSD matcher, the other detectors are combined with SSD, NSD [5] and SIFT. CoMaL doesn't work very well with SIFT or NSD as the regions on either side of the level line are often homogeneous and not suitable for these descriptors. We define the matching accuracy or precision M acc as the ratio of the number of correct matches M cor to the total number of matches M found: M acc = M cor /M . Equalizing this for the different algorithms by varying the matching thresholds, one can compare the number of correct matches generated by the algorithm averaged over all frames. Fig 7 and videos in the supplementary section show some qualitative results of the approach, while</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>Table 3. Number of Correct Matches Mcor on the boundary regions for sequences in the CoMaL dataset averaged over all the frames in the sequence. The second number is the Matching accuracy Macc for the method. The best is in bold and the second best is underlined.Figure 8. Top Row: Matches on a Homogenous object -Box. Bottom Row: Matches on a Textured Object. CoMaL + SSD matches are shown in the first two images while Hessian + SIFT matches are shown in the last two.</figDesc><table>Type 

Seq 
CoMaL+SSD 
SSD 
NSD 
SIFT 
Harris 
Hessian MSER 
FAST 
Harris 
Hessian MSER 
FAST 
Harris 
Hessian MSER 
FAST 

Textured 

Pens 
27.6/0.9 
12.6/0.8 8.5/0.9 0.2/0.2 
3.2/0.8 
14.8/0.9 17.0/0.9 0.3/0.3 15.1/0.9 12.1/0.8 20.8/0.9 0.5/0.4 12.3/0.9 
Doll 
39.0/0.9 
14.8/0.8 11.7/0.8 0.6/0.3 
9.0/0.8 
21.4/0.9 29.4/0.9 0.4/0.5 31.1/0.9 16.2/0.8 22.3/0.9 0.7/0.6 24.7/0.9 
Toy 
31.2/0.8 
9.0/0.7 13.6/0.8 0.7/0.4 12.3/0.8 13.1/0.8 11.9/0.8 0.3/0.3 11.7/0.8 10.4/0.7 12.8/0.8 0.4/0.4 13.6/0.8 
Hero 
47.4/0.9 
16.4/0.9 17.8/0.9 1.2/0.5 16.7 /0.9 18.2/0.8 29.6/0.9 1.1/0.6 30.0/0.9 15.9/0.8 24.0/0.9 1.3/0.7 25.1/0.9 
Race-car 
52.5/0.9 
17.0/0.8 18.6/0.8 0.7/0.5 12.4/0.9 20.7/0.9 30.6/0.9 0.4/0.4 27.9/0.9 16.5/0.8 31.0/0.9 0.6/0.5 28.3/0.9 

Homogeneous 

Box 
37.5/0.9 
14.5/0.9 21.8/0.9 0.5/0.2 19.3/0.9 19.4/0.9 19.2/0.9 0.3/0.4 18.8/0.8 16.3/0.9 25.3/0.9 0.5/0.4 24.5/0.9 
Tape-Box 
39.1/0.9 
15.9/0.9 16.0/0.9 0.8/0.5 16.5/0.9 18.9/0.9 25.2/0.9 0.5/0.3 26.2/0.9 16.3/0.9 21.3/0.9 0.6/0.4 26.3/0.9 
House 
32.9/0.9 
13.2/0.9 21.0/0.9 0.6/0.4 22.4/0.9 17.7/0.8 25.0/0.9 0.5/0.5 27.5/0.9 13.9/0.8 25.7/0.9 0.7/0.6 28.8/0.9 
Average 
38.4 
14.2 
16.1 
0.7 
14.0 
18.0 
23.5 
0.5 
23.6 
14.7 
22.9 
0.7 
23.0 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Freak: Fast retina keypoint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2012</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="510" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Measuring flow complexity in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV 2013</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1097" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Segtrack: A novel tracking system with improved object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Almomani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIP 2013</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3939" to="3943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Surf: Speeded up robust features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Nested shape descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV 2013</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Brief: Binary robust independent elementary features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Calonder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Strecha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV 2010</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Extracting meaningful curves from images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Constructing adaptive complex cells for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV 2013</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1113" to="1120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient maximally stable extremal region (mser) tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Donoser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2006</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="553" to="560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Unscented feature tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Dorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Goldenstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="8" to="15" />
		</imprint>
		<respStmt>
			<orgName>CVIU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Svo: Fast semidirect monocular visual odometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Forster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pizzoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Scaramuzza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intl. Conf. on Robotics and Automation</title>
		<meeting>IEEE Intl. Conf. on Robotics and Automation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A framework for low level feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Förstner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV 1994</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="383" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Accurate, dense, and robust multiview stereopsis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Are we ready for autonomous driving? the kitti vision benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lenz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient online structured output learning for keypoint-based object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2012</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1894" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A combined corner and edge detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stephens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Alvey vision conference</title>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Disparity-space images and large occlusion stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Intille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Bobick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Large scale multi-view stereopsis evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vogiatzis</surname></persName>
		</author>
		<idno>CVPR 2014. 1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Urban tracker: Multiple object tracking in urban mixed traffic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Jodoin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-A</forename><surname>Bilodeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Saunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="885" to="892" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A stereo matching algorithm with an adaptive window: Theory and experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Okutomi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="920" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Improving the agility of keyframebased slam</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="802" to="815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sparse scene flow segmentation for moving object detection in urban environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium (IV)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="926" to="932" />
			<date type="published" when="2008" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Tracking feature points in uncalibrated images with radial distortion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lourenço</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Barreto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV 2012</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An iterative image registration technique with an application to stereo vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="1981" />
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adaptive and generic corner detection based on the accelerated segment test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burschka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Suppa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV 2010</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Robust wide baseline stereo from maximally stable extremal regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<title level="m">Scale &amp; affine invariant interest point detectors. IJCV</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A comparison of affine region detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schaffalitzky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Shape recognition with edge-based features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC 2003)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Consensus-based matching and tracking of keypoints for object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nebehay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pflugfelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV 2014</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="862" to="869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visual odometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nistér</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Naroditsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2004</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Linear time maximally stable extremal regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stewenius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV 2008</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">5303</biblScope>
			<biblScope unit="page" from="183" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Object recognition using local affine frames on maximally stable extremal regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Š</forename><surname>Obdržálek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Toward Category-Level Object Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Extended lucas-kanade tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bar-Hille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV 2014</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="142" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Stable affine frames on isophotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perdoch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Obdrzalek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV 2007</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Detailed real-time urban 3d reconstruction from video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nistér</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Akbarzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mordohai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="143" to="167" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fusing points and lines for high performance tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rosten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Drummond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV 2005</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Faster and better: A machine learning approach to corner detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rosten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Drummond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE PAMI</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Orb: an efficient alternative to sift or surf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rublee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rabaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Konolige</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bradski</surname></persName>
		</author>
		<idno>ICCV 2011. 1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Detecting changes in 3d structure of a scene from multi-view images captured by a vehicle-mounted camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sakurada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Okatani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2013</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Good features to track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 1994</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Vehicle behavior analysis using target motion trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vehicular Technology</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Translation-based klt tracker under severe camera rotation using gps/ins data. Geoscience and Remote Sensing Letters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tanathong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="68" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Daisy: An efficient dense descriptor applied to wide-baseline stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="815" to="830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Boundary-based corner detection using eigenvalues of covariance matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-M</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-T</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="40" />
			<date type="published" when="1999-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Matching widely separated views based on affine invariant regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="85" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Local invariant feature detectors: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FnT Comp. Graphics and Vision</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="177" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Efficient non-consecutive feature tracking for structure-from-motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-T</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV 2010</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
