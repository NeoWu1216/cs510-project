<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An efficient Exact-PGA algorithm for constant curvature manifolds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudrasis</forename><surname>Chakraborty</surname></persName>
							<email>1rudrasis@cise.ufl.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CISE</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<postCode>32611</postCode>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dohyung</forename><surname>Seo</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">U-Systems</orgName>
								<orgName type="institution" key="instit2">A GE Healthcare Company</orgName>
								<address>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baba</forename><forename type="middle">C</forename><surname>Vemuri</surname></persName>
							<email>vemuri@cise.ufl.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CISE</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<postCode>32611</postCode>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An efficient Exact-PGA algorithm for constant curvature manifolds</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Manifold-valued datasets are widely encountered in many computer vision tasks. A non-linear analog of the PCA algorithm, called the Principal Geodesic Analysis (PGA) algorithm suited for data lying on Riemannian manifolds was reported in literature a decade ago. Since the objective function in the PGA algorithm is highly non-linear and hard to solve efficiently in general, researchers have proposed a linear approximation. Though this linear approximation is easy to compute, it lacks accuracy especially when the data exhibits a large variance. Recently, an alternative called the exact PGA was proposed which tries to solve the optimization without any linearization. For general Riemannian manifolds, though it yields a better accuracy than the original (linearized) PGA, for data that exhibit large variance, the optimization is not computationally efficient. In this paper, we propose an efficient exact PGA algorithm for constant curvature Riemannian manifolds (CCM-EPGA). The CCM-EPGA algorithm differs significantly from existing PGA algorithms in two aspects, (i) the distance between a given manifold-valued data point and the principal submanifold is computed analytically and thus no optimization is required as in the existing methods. (ii) Unlike the existing PGA algorithms, the descent into codimension-1 submanifolds does not require any optimization but is accomplished through the use of the Rimeannian inverse Exponential map and the parallel transport operations. We present theoretical and experimental results for constant curvature Riemannian manifolds depicting favorable performance of the CCM-EPGA algorithm compared to existing PGA algorithms. We also present data reconstruction from the principal components which has not been reported in literature in this setting.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Principal Component Analysis (PCA) is a widely used dimensionality reduction technique in Science and Engineering. PCA however requires the input data to lie in a vector space. With the advent of new technologies and wide spread use of sophisticated feature extraction methods, manifold-valued data have become ubiquitous in many fields including but not limited to, Computer Vision, Medical Imaging and Machine Learning. A nonlinear version of PCA, called the Principal Geodesic Analysis (PGA), for data lying on Riemannian manifolds was introduced in <ref type="bibr" target="#b7">[8]</ref>.</p><p>Since the objective function of PGA is highly nonlinear and hard to solve in general, researchers proposed a linearized version of the PGA <ref type="bibr" target="#b7">[8]</ref>. Though this linearized PGA, hereafter referred to as PGA, is computationally efficient, it lacks accuracy for data with large spread/variance. In order to solve the objective function exactly, Sommer et al., <ref type="bibr" target="#b24">[25]</ref> proposed to solve the original objective function (not the approximation) and called it exact PGA . While exact PGA attempts to solve this complex nonlinear optimization problem, it is however computationally inefficient. Though it is not possible to efficiently and accurately solve this optimization problem for a general manifold, however, for manifolds with constant sectional curvature, we formulate an efficient and exact PGA algorithm, dubbed CCM-EPGA. It is well known in geometry, by virtue of the Killing-Hopf theorem <ref type="bibr" target="#b3">[4]</ref>, that any non-zero constant curvature manifold is isomorphic to either the hypersphere (S N ) or the hyperbolic space (H N ), hence in this work, we present the CCM-EPGA formulation for (S N ) and (H N ). Our formulation has several applications to Computer Vision and Statistics including directional data <ref type="bibr" target="#b20">[21]</ref> and color spaces <ref type="bibr" target="#b18">[19]</ref>. Several other applications of hyperbolic geometry are, shape analysis <ref type="bibr" target="#b29">[30]</ref>, Electrical Impedance Tomography, Geoscience Imaging <ref type="bibr" target="#b27">[28]</ref>, Brain Morphometry <ref type="bibr" target="#b28">[29]</ref>, Catadiaoptric Vision <ref type="bibr" target="#b2">[3]</ref> etc.</p><p>In order to depict the effectiveness of our proposed CCM-EPGA algorithm, we use the average projection error as defined in <ref type="bibr" target="#b24">[25]</ref>. We also report the computational time comparison of the CCM-EPGA with the PGA <ref type="bibr" target="#b7">[8]</ref> and the exact PGA <ref type="bibr" target="#b24">[25]</ref> algorithms respectively. Several variants of the PGA exist in literature and we briefly mention a few here. In <ref type="bibr" target="#b22">[23]</ref>, authors computed the principal geodesics (without approximation) only for a special Lie group, SO <ref type="bibr" target="#b2">(3)</ref>. Geodesic PCA (GPCA) <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b12">13]</ref> solves a different optimization function namely, optimizing the projection error along the geodesics. Authors in <ref type="bibr" target="#b12">[13]</ref>, minimize the projection error instead of maximizing variance in geodesic subspaces (defined later in the paper). GPCA does not use a linear approximation, but it is restricted to manifolds where a closed form expression for the geodesics exists. More recently, a probabilistic version of PGA called PPGA was presented in <ref type="bibr" target="#b30">[31]</ref>, which is a nonlinear version of PPCA <ref type="bibr" target="#b26">[27]</ref>. None of these methods attempt to compute the solution to the exact PGA problem defined in <ref type="bibr" target="#b24">[25]</ref>. Another recent work in <ref type="bibr" target="#b10">[11]</ref>, reports a non-linear generalization of PGA, namely the principal geodesic curves, and argues about its usefulness over PGA. The rest of the paper is organized as follows. In Section 2, we present the formulation of PGA. We also discuss the details of the linearized version of PGA <ref type="bibr" target="#b7">[8]</ref> and exact PGA <ref type="bibr" target="#b24">[25]</ref>. Our formulation of CCM-EPGA is presented in Section 2. Experimental results for the CCM-EPGA algorithm along with comparisons to exact PGA and PGA are presented in Section 3. In addition to synthetic data experiments, we present the comparative performance of CCM-EPGA on two real data applications. In Section 4, we present the formulation for the reconstruction of data from principal directions and components in this nonlinear setting. Finally, in section 5, we draw conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Principal Geodesic Analysis</head><p>Principal Component Analysis (PCA) <ref type="bibr" target="#b16">[17]</ref> is a well known and widely used statistical method for dimensionality reduction. Given a vector valued dataset, it returns a sequence of linear subspaces that maximize the variance of the projected data. The k th subspace is spanned by the principal vectors {v 1 , v 2 , · · · , v k } which are mutually orthogonal. PCA is well suited for vector-valued data sets but not for manifold-valued inputs. A decade ago, the nonlinear version called the Principal Geodesic Analysis (PGA) was developed to cope with manifold-valued inputs <ref type="bibr" target="#b7">[8]</ref>. In this section, first, we briefly describe this PGA algorithm, then, we show the key modification performed in <ref type="bibr" target="#b24">[25]</ref> to arrive at what they termed as the exact PGA algorithm. We then motivate and present our approach which leads to an efficient and novel algorithm for exact PGA on constant curvature manifolds (CCM-EPGA).</p><p>Let M be a Riemannian manifold. Let us suppose we are given a dataset, X = {x 1 , · · · , x n }, where x j ∈ M . Let us assume that the finite sample Fréchet mean <ref type="bibr" target="#b8">[9]</ref> of the data set exists and be denoted by µ. Let V k be the space spanned by mutually orthogonal vec-</p><formula xml:id="formula_0">tors (principal directions) {v 1 , · · · , v k }, v j ∈ T µ M, ∀j. Let S k be the k th geodesic subspace of T µ M , i.e., S k = Exp µ (V k ),</formula><p>where Exp is the Riemannian exponential map (see <ref type="bibr" target="#b3">[4]</ref> for definition). Then, the principal directions, v i are defined recursively by</p><formula xml:id="formula_1">v i = arg max v =1,v∈V ⊥ i−1 1 n n j=1 d 2 (µ, Π Si (x j ))<label>(1)</label></formula><formula xml:id="formula_2">S i = Exp µ (spanV i−1 , v i )<label>(2)</label></formula><p>where d(x, y) is the geodesic distance between x ∈ M and y ∈ M , Π S (x) is the point in S closest to x ∈ M . The PGA algorithm on M is summarized in Alg. 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1</head><p>The PGA algorithm on manifold M 1: Given a data set X = {x 1 , · · · , x n } ∈ M , and 1 ≤</p><formula xml:id="formula_3">L ≤ dim(M ) 2: Compute the FM, µ, of X [1] 3: Set k ← 1 4: Set {x 0 1 , · · · ,x 0 n } ← {x 1 , · · · , x n } 5: while k ≤ L do 6: Solve v k = arg max v =1,v∈TµM,v∈V ⊥ k−1 1 n n j=1 d 2 (µ, Π S k (x k−1 j ))</formula><p>as in Eq. (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>Project {x k−1 1 , · · · ,x k−1 n } to a k co-dimension one submanifold Z of M , which is orthogonal to the current geodesic subspace.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8:</head><p>Set the projected points to {x k 1 , · · · ,x k n } 9:</p><p>k ← k + 1 10: end while 2.1. PGA and exact PGA In Alg. 1 (lines 6 − 7), as the projection operator Π is hard to compute, hence a common alternative is to locally linearize the manifold. This approach <ref type="bibr" target="#b7">[8]</ref> maps all data points on to the tangent space at µ, and as the tangent plane is a vector space, one can use the PCA to compute the principal directions. This simple scheme is an approximation to the PGA and naturally raises the following question: Is it possible to do PGA (solve Eq. (1)) without any linearization? The answer is yes. But, computation of the projection operator, Π S (x), i.e., the closest point to x in S is computationally expensive. In <ref type="bibr" target="#b24">[25]</ref>, Sommer et al. give an alterna-tive formulation for the PGA by minimizing the average squared reconstruction error, i.e., d 2 (x j , Π Si (x j )) instead of d 2 (µ, Π Si (x j )) in eqns. <ref type="bibr" target="#b0">(1)</ref>. They use an optimization scheme to compute this projection. Further, they termed their algorithm, exact PGA, as it does not require any linearization. However, their optimization scheme is in general computationally expensive and for a data set with large variance, convergence is not guaranteed. Hence, for large variance data, their exact PGA is still an approximation as it might not converge. This motivated us to formulate an accurate and computationally efficient exact PGA, at least in cases where it is feasible to do so.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Efficient and accurate exact PGA</head><p>In this paper, we present an analytic expression for the projected point and design an effective way to project data points on to the co-dimension k submanifold (as in 1, line 7). An analytic expression is in general not possible to derive for arbitrary Riemannian manifolds. However, for constant curvature Riemannian manifolds, i.e., S N (positive constant curvature) and H N (negative constant curvature), we derive an analytic expression for the projected point and devise an efficient algorithm to project data points on to a co-dimension k submanifold. Both these manifolds are quite commonly encountered in Computer Vision <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref> as well as in many other fields of Science and Engineering. The former more so than the latter. Even though, there are applications that can be naturally posed in hyperbolic spaces (e.g., color spaces in Vision <ref type="bibr" target="#b18">[19]</ref>, catadiaoptric images <ref type="bibr" target="#b2">[3]</ref> etc.), their full potential has not yet been exploited in Computer Vision research as much as in the former case.</p><p>We first present some background material for the N -dimensional spherical and hyperbolic manifolds and then derive an analytical expression for the projected point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Basic Riemannian Geometry of S N</head><p>• Geodesic distance: The geodesic distance between ψ,ψ ∈ S N is given by, d(ψ,ψ) = arccos(ψ tψ ).</p><p>• Exponential Map: Given a vector v ∈ T ψ S N , the Riemannian Exponential map on S N is defined as Exp ψ (v) = cos(|v|)ψ + sin(|v|)v/|v|. The Exponential map gives the point which is located on the great circle along the direction defined by the tangent vector v at a distance |v| from ψ.</p><p>• Inverse Exponential Map: The tangent vector v ∈ T ψ S N directed from ψ toψ is given</p><formula xml:id="formula_4">by, Exp −1 ψ (ψ) = θ sin(θ) (ψ − ψ cos(θ)) where, θ = d(ψ,ψ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Basic Riemannian Geometry of H N</head><p>The hyperbolic N -dimensional manifold can be embedded in R N +1 using any of three different models. In this paper, we use the hyperboloid model <ref type="bibr" target="#b14">[15]</ref>. In this model, H N is defined as</p><formula xml:id="formula_5">H N = {x = (x 1 , · · · , x N +1 ) t ∈ R N +1 | &lt; x, x &gt; H = −1, x 1 &gt; 0}, where the inner product on H N , denoted by &lt; x, y &gt; H is defined as &lt; x, y &gt; H = −x 1 * y 1 + N +1 i=2 (x i * y i ). • Geodesic distance: The geodesic distance be- tween ψ,ψ ∈ H N is given by, d(ψ,ψ) = cosh −1 (− &lt; ψ,ψ &gt; H ). • Exponential Map: Given a vector v ∈ T ψ H N , the Riemannian Exponential map on H N is de- fined as, Exp ψ (v) = cosh(|v|)ψ + sinh(|v|)v/|v|. • Inverse Exponential Map: The tangent vec- tor v ∈ T ψ H N directed from ψ toψ is given by Exp −1 ψ (ψ) = θ sinh(θ) (ψ − ψ cosh(θ)) where, θ = d(ψ,ψ).</formula><p>For the rest of this paper, we consider the underlying manifold, M , as a constant curvature Riemannian manifold, i.e., M is diffeomorphic to either S N or H N , where N = dim(M ) <ref type="bibr" target="#b3">[4]</ref>. Let ψ,ψ ∈ M , v ∈ TψM . Further, let y(v, ψ) be defined as the projection of ψ on the geodesic submanifold defined byψ and v. Now, we will derive a closed form expression for y(v, ψ) in the case of S N and H N . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Analytic expression for</head><formula xml:id="formula_6">y(v, ψ) on S N Theorem 1. Let ψ ∈ S N and v ∈ TψS N .</formula><p>Then the projection of ψ on the geodesic submanifold defined bȳ ψ and v, i.e., y(v, ψ) is given by:</p><formula xml:id="formula_7">y(v, ψ) = cos(arctan (&lt; v, ψ &gt;)/(&lt; ψ,ψ &gt;) |v| )ψ + sin(arctan (&lt; v, ψ &gt;)/(&lt; ψ,ψ &gt;) |v| )v/|v| (3)</formula><p>Proof. Consider the spherical triangle shown in <ref type="figure" target="#fig_0">Fig.  1</ref>,</p><formula xml:id="formula_8">△ψψy ψ , where y ψ = y(v, ψ). Let, a = d(ψ, y ψ ), b = d(y ψ , ψ) and c = d(ψ,ψ). Also, let A = ∠ψψy ψ , B = ∠ψψy ψ , C = ∠ψy ψ ψ. Clearly, since y ψ is the projected point , C = π/2. So, cos B = &lt; c sin c (ψ −ψ cos c), v &gt; c|v| = &lt;v,ψ&gt; sin c − cot c &lt; v,ψ &gt; |v|<label>(4)</label></formula><p>Here, &lt; ., . &gt; denotes the Euclidean inner product, where both ψ and v are viewed as points in R N +1 , i.e., the ambient space. Note that, &lt; v,ψ &gt;= 0, as v ∈ TψS N . From spherical trigonometry, we know that tan a = cos B tan c.</p><formula xml:id="formula_9">∴ cos B tan c = &lt;v,ψ&gt; cos c |v| = (&lt; v, ψ &gt;)/(&lt; ψ,ψ &gt;) |v| ∴ a = arctan (&lt; v, ψ &gt;)/(&lt; ψ,ψ &gt;) |v|<label>(5)</label></formula><p>Hence, using the Exponential map, we can show that y ψ is given by,</p><formula xml:id="formula_10">y ψ = cos(a)ψ + sin(a)v/|v|<label>(6)</label></formula><p>Analogously, we can derive the formula for y(v, ψ) on H N , v ∈ TψH N . Theorem 2. Let ψ ∈ H N and v ∈ TψH N . Then the projection of ψ on the geodesic submanifold defined bȳ ψ and v, i.e., y(v, ψ) is given by:</p><formula xml:id="formula_11">y ψ = cosh(a)ψ + sinh(a)v/|v|<label>(7)</label></formula><p>where,</p><formula xml:id="formula_12">a = tanh −1 (&lt; v, ψ &gt; H )/(− &lt; ψ,ψ &gt; H ) |v| .</formula><p>Proof. As before, consider the hyperbolic triangle shown in, △ψψy ψ , where y ψ = <ref type="figure">y(v, ψ)</ref>. <ref type="figure">(y ψ , ψ) and c = d(ψ,ψ)</ref>. Also, let A = ∠ψψy ψ , B = ∠ψψy ψ , C = ∠ψy ψ ψ. Clearly, since y ψ is the projected point , C = π/2. Then, B is the angle between Logψ(ψ) and v. Hence,</p><formula xml:id="formula_13">Let, a = d(ψ, y ψ ), b = d</formula><formula xml:id="formula_14">cosh B = &lt;v,ψ&gt; H sinh c − coth c &lt; v,ψ &gt; H |v|<label>(8)</label></formula><p>Then, from hyperbolic trigonometry, as tanh a = cosh B tanh c, we get</p><formula xml:id="formula_15">a = tanh −1 (&lt; v, ψ &gt; H )/(− &lt; ψ,ψ &gt; H ) |v|<label>(9)</label></formula><p>Note that, since the arc length betweenψ and y ψ is a, hence, using the Exponential map, we can show that y ψ = cosh(a)ψ + sinh(a)v/|v|. Given the closed form expression for the projected point, now we are in a position to develop an efficient projection algorithm (for line 7 in Alg. 1), which is presented in Alg. 2. Note that, using Alg. 2, data points on the current submanifold are projected to a submanifold of dimension one less, which is needed by the PGA algorithm in line 6. Also note that, in order to ensure existence and uniqueness of FM on S N , we have restricted the data points to be within a geodesic ball of convexity radius &lt; π/2 <ref type="bibr" target="#b0">[1]</ref>. On H N , FM exists and is unique everywhere.</p><p>Note that in order to descend to the codimension-1 submanifolds, we use step-1 and step-2 instead of the optimization method used in the exact PGA algorithm of <ref type="bibr" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Results</head><p>In this section, we present experiments demonstrating the performance of CCM-EPGA compared to PGA <ref type="bibr" target="#b7">[8]</ref> and exact PGA <ref type="bibr" target="#b24">[25]</ref>. We used the average projection error, defined in <ref type="bibr" target="#b24">[25]</ref>, as a measure of performance in our experiments. The average projection error is defined as follows. Let {x i } n i=1 be data points on a manifold M . Let µ be the mean of the data points. Let, v Algorithm 2 Algorithm for projecting the data points to a co-dimension one submanifold 1: Input: a data point x i ∈ S N (H N ), a geodesic submanifold defined at µ and v ∈ T µ S N (T µ H N ), and y(v, x i ) which is the projection of ψ on to the geodesic submanifold. 2: Output:x i which is the projection of the data point</p><p>x i to a subspace, S N −1 <ref type="figure" target="#fig_0">(H N −1 )</ref>, that is orthogonal to the current geodesic submanifold. <ref type="bibr">3:</ref> Step 1.</p><p>Evaluate the tangent vector, v i ∈ T y(v,xi) S N (T y(v,xi) H N ) directed towards x i using the inverse Exponential map. It is clear that v i is orthogonal to v. <ref type="bibr">4:</ref> Step 2. Parallel transport v i to µ. Let v µ i denote the parallel transported vector. The geodesic submanifold defined by µ and v µ i is orthogonal to geodesic submanifolds obtained from the previous steps in Alg. 1.</p><formula xml:id="formula_16">5: Step 3. Setx i ← y(v µ i , x i )</formula><p>be the first principal direction and S = Exp µ (v). Then the error (E) is defined as follows:</p><formula xml:id="formula_17">E = 1 n n i=1 d 2 (x i , Π S (x i ))<label>(10)</label></formula><p>where d(., .) is the geodesic distance function on M . We also present the computation time for each of the three algorithms. All the experimental results reported here were obtained on a desktop with a single 3.33 GHz Intel-i7 CPU and 24 GB RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Comparative performance of CCM-EPGA on Synthetic data</head><p>In this section, we present the comparative performance of CCM-EPGA on several synthetic datasets. For each of the synthetic data, we have reported the average projection error and computation time for all three PGA algorithms in <ref type="table">Table 1</ref>. All the four datasets are on S 2 and the Fréchet mean is at the "north pole". For all the datasets, samples are in the northern hemisphere to ensure that the Fréchet mean is unique. Data 1 and Data 2 are generated by taking samples along a geodesic with a slight perturbation. The last two datasets are constructed by drawing random samples on the northern hemisphere. In addition, data points from Data 1 are depicted in <ref type="figure" target="#fig_1">Fig. 2</ref>. The first principal direction is also shown (black for CCM-EPGA, blue for PGA and red for exact PGA). Further, we also report the data variance for these synthetic datasets. By examining the results, it's evident that for data with low variance, the significance of CCM-EPGA in terms of projection error is marginal, while for high variance data, CCM-EPGA yields significantly better accuracy. Also, CCM-EPGA is computationally very fast in comparison to exact PGA. The results in <ref type="table">Table 1</ref> indicate that CCM-EPGA outperforms exact PGA in terms of efficiency and accuracy. Although, the required time for PGA is less than that of CCM-EPGA, in terms of accuracy, CCM-EPGA dominates PGA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Comparative performance on point-set data (S N example)</head><p>In this section, we depict the performance of the proposed CCM-EPGA algorithm on 2D point-set data. The database is called GatorBait-100 dataset <ref type="bibr" target="#b21">[22]</ref>. This dataset consists of 100 images of shapes of different fish. From each of these images of size 20 × 200, we first extract boundary points, then we apply the Schrödinger distance transform <ref type="bibr" target="#b6">[7]</ref> to map each of these point sets on a hypersphere (S 3999 ). Hence, this data consists of 100 point-sets each of which lie on S 3999 . As before, we have used the average projection error <ref type="bibr" target="#b24">[25]</ref>, to measure the performance of algorithms in the comparisons. Additionally, we report the computation time for each of these PGA algorithms. We used the code available online for exact PGA <ref type="bibr" target="#b23">[24]</ref>. This online implementation is not scalable to large (even moderate) number of data points, and further requires the computation of the Hessian matrix in the optimization step, which is computationally expensive. Hence, for this real data application on the high dimensional hyper-  sphere, we could not report the results for the exact PGA algorithm. Though one can use a Sparse matrix version of the exact PGA code, along with efficient parallelization to make the exact PGA algorithm suitable for moderately large data, we would like to point out that since our algorithm does not need such modifications, it clearly gives CCM-EPGA an advantage over exact PGA from a computational efficiency perspective. In terms of accuracy, it can be clearly seen that CCM-EPGA outperforms exact PGA from the results on synthetic datasets. Both average projection error and computational time on GatorBait-100 dataset are reported in <ref type="table" target="#tab_1">Table 2</ref>. This result demonstrates accuracy of CCM-EPGA over the PGA algorithm with a marginal sacrifice in efficiency but significant gains in accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">PGA on population of Gaussian distributions (H N example)</head><p>In this section, we propose a novel scheme to compute principal geodesic submanifolds for the manifold of Gaussian densities. Here, we use concepts from information geometry presented in <ref type="bibr" target="#b1">[2]</ref>, specifically, the Fisher information matrix <ref type="bibr" target="#b17">[18]</ref> to define a metric on this manifold <ref type="bibr" target="#b5">[6]</ref>. Consider a normal density f (.|θ) in an n−dimensional space, with parameters represented by θ. Then the ij th entry of the n × n Fisher matrix, denoted by g ij , is defined as follows:</p><formula xml:id="formula_18">g ij (θ) = R f (x|θ) ∂lnf (x|θ) ∂θ i ∂lnf (x|θ) ∂θ j dx<label>(11)</label></formula><p>For example, for a univariate normal density f (.|µ, σ), the fisher information matrix is</p><formula xml:id="formula_19">(g ij (µ, σ)) = 1 σ 2 0 0 2 σ 2<label>(12)</label></formula><p>So, the metric is defined as follows:</p><formula xml:id="formula_20">&lt; u, v &gt;= u t Gv<label>(13)</label></formula><p>where G = (g ij ) is the Fisher information matrix. Now, consider the parameter space for the univariate normal distributions. The parameter space is H F = (µ, σ) ∈ R 2 |σ &gt; 0, i.e., positive half space, which is the Hyperbolic space, modeled by the Poincaré halfplane, denoted by P 2 . We can define a bijection</p><formula xml:id="formula_21">F 1 : H F → P 2 as F (µ, σ) = ( µ √ 2 , σ).</formula><p>Hence, the univariate normal distributions can be parameterized by the 2−dimensional hyperbolic space. Moreover, there exists a diffeomorphsim between P 2 and H 2 (the mapping is analogous to stereographic projection for S N ), thus, we can readily use the formulation in Section 2 to compute principal geodesic submanifold on the manifold of univariate normal distributions.</p><p>Motivated by the above formulation, we ask the following question: Does there exist a similar relation for multivariate normal distributions? The answer is no in general. But if the multivariate distributions have diagonal covariance matrix, (i.e., independent uncorrelated variables in the multivariate case), the above relation between P 2 and H 2 can be generalized. Consider an N −dimensional normal distribution parameterized by (µ, Σ) where µ = (µ 1 , · · · , µ N ) t and Σ is a diagonal positive definite matrix (i.e., Σ ij = σ i , if i = j, else Σ ij = 0). Then, analogous to the univariate normal distribution case, we can define a bijection F N : H N F → P 2N as follows:</p><formula xml:id="formula_22">F N (µ, Σ) = ( µ 1 √ 2 , σ 1 , · · · , µ N √ 2 , σ N )<label>(14)</label></formula><p>Hence, we can use our formulation in Section 2 since there is a diffeomorphism between P 2N and H 2N . But, for general non-diagonal N −dimensional covariance matrix space, SP D(N ), the above formulation does not hold. This motivated us to go one step further to search for a parameterization of SP D(N ) where we can use the above formulation. In <ref type="bibr" target="#b15">[16]</ref>, authors have used the Iwasawa coordinates to parameterize SP D(N ). Using the Iwasawa coordinates <ref type="bibr" target="#b25">[26]</ref>, we can get a one-to-one mapping between SP D(N ) and the product manifold of P D(N ) and U (N − 1), where P D(N ) is manifold of N −dimensional diagonal positive definite matrix and U (N − 1) is the space of (N − 1)−dimensional upper triangular matrices, which is isomorphic to R N (N +1)/2 . We have used the formulation in <ref type="bibr" target="#b25">[26]</ref>, as discussed below.</p><p>Let Y = V N ∈ SP D(N ), then we can use Iwasawa decomposition to represent V N as a tuple <ref type="figure" target="#fig_0">(V N −1 , x N −1 , w N −1 )</ref>. And repeating the following partial Iwasawa decomposition:</p><formula xml:id="formula_23">V N = I x N −1 0 1 T V N −1 0 0 w N −1<label>(15)</label></formula><p>where w N −1 &gt; 0 and x N −1 ∈ R N −1 . We get the following vectorized expression:</p><formula xml:id="formula_24">V N → (((w 0 , x t 1 , w 1 ), x t 2 , w 2 ), · · · , x t N −1 , w N −1 )</formula><p>. Note that as each of w i is &gt; 0, we can construct a positive definite diagonal matrix with i th diagonal entry being w i . And as each x i is in R i , we will arrange them column-wise to form a upper triangular matrix. Thus, for P D(N ), we can use our formulation for the hyperboloid model of the hyperbolic space given in Section 2, and the standard PCA can be applied for R N (N +1)/2 .</p><p>We now use the above formulation to compute the principal geodesic submanifolds for a covariance descriptor representation of Brodatz texture dataset <ref type="bibr" target="#b4">[5]</ref>. Similar to our previous experiment on point-set data, in this experiment, we report the average projection error and the computation time. We adopt a similar procedure as in <ref type="bibr" target="#b11">[12]</ref> to derive the covariance descriptors for the texture images in the Brodatz database. Each 256×256 texture image is first partitioned into 64 non-overlapping 8 × 8 blocks. Then, for each block, the covariance matrix (F F T ) is summed over the blocks. Here, the covariance matrix is computed from the fea-</p><formula xml:id="formula_25">ture vector F = I, | ∂I ∂x |, | ∂I ∂y |, | ∂ 2 I ∂x 2 |, | ∂ 2 I ∂y 2 | t .</formula><p>We make the covariance matrix positive definite by adding a small positive diagonal matrix. Then, each image is represented as a normal distribution with zero mean and this computed covariance matrix. Then, we used the above formulation to map each normal distribution on to H 10 . The comparative results of CCM-EPGA with PGA and exact PGA are presented in <ref type="table" target="#tab_3">Table 3</ref>.</p><p>The results clearly demonstrate the efficiency and accuracy of CCM-EPGA over the PGA and the exact PGA algorithms.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Data Reconstruction from principal directions and coefficients</head><p>In this section, we present a recursive scheme to approximate an original data point with principal directions and coefficients. We present a reconstruction method for data on S N , the reconstruction for data points on H N can be done in an analogous manner. Let x j ∈ S N be the j th data point and v k the k th principal vector.x k j is the k th principal component of . We refer readers to <ref type="figure" target="#fig_2">Fig. 3</ref> for a geometric interpretation. Now, we will formulate a recursive scheme to reconstruct x j . Let us reconstruct the data using the first (k − 1) principal components. Then, the k th approximated point x k j is the intersection of two geodesics defined by x k−1 j ,v k andx k j ,w k−1 j . Let these two great circles be denoted by G 1 (t) = cos(t)x k−1 j + sin(t)v k <ref type="bibr" target="#b15">(16)</ref> G 2 (u) = cos(u)x k j + sin(u)w k−1 j <ref type="bibr" target="#b16">(17)</ref> At t = α 1 and u = α 2 , let G 1 (α 1 ) = G 2 (α 2 ) = x k j . Since,v k andw k−1 j are mutually orthogonal, we get, tan(α 1 ) tan(α 2 ) =&lt; x k−1 j ,w k−1 j &gt;&lt;x k j ,v k &gt; <ref type="bibr" target="#b17">(18)</ref> Note that, as our goal is to solve for α 1 or α 2 to get x k j , we need two equations. The second equation can be derived as follows: d(µ, G 1 (α 1 )) = d(µ, G 2 (α 2 )) This leads to, cos(α 2 ) = cos(α 1 ) &lt; µ, x k−1</p><formula xml:id="formula_26">j &gt; &lt; µ,x k j &gt;<label>(19)</label></formula><p>Then, by solving Eqs. <ref type="bibr" target="#b17">(18)</ref> and <ref type="formula" target="#formula_1">(19)</ref> we get, a cos 4 (α 1 ) + b cos 2 (α 1 ) + d = 0 <ref type="bibr" target="#b19">(20)</ref> where,</p><formula xml:id="formula_27">a =&lt; µ, x k−1 j &gt; 2 &lt; x k−1 j ,w k−1 j &gt; 2 &lt;x k j ,v k &gt; 2 − &lt; µ, x k−1 j &gt; 2 b =&lt; µ,x k j &gt; 2 + &lt; µ, x k−1 j &gt; 2</formula><p>and d = − &lt; µ,x k j &gt; 2 By solving the equation <ref type="formula" target="#formula_2">(20)</ref>, we get</p><formula xml:id="formula_28">α 1 = arccos −b + (b 2 − 4ad)sgn(a) 2a<label>(21)</label></formula><p>where, sgn(.) is the signum function. Hence, x k j = G 1 (α 1 ). This completes the reconstruction algorithm. Our future efforts will be focused on using this reconstruction algorithm in a variety of applications mentioned earlier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper, we presented an efficient and accurate exact-PGA algorithm for (non-zero) constant curvature manifolds, namely the hypersphere S n and the hyperbolic space H n . We presented an analytic expression for the projection of a data point on a geodesic submanifold, which is required in the PGA algorithm and in general involves solving a difficult optimization problem. Using these analytic expressions, we achieved a much more accurate and efficient solution for PGA on constant curvature manifolds, that are frequently encountered in Computer Vision, Medical Imaging and Machine Learning tasks. We presented comparison results on synthetic and real data sets demonstrating favorable performance of our algorithm in comparison to the state-of-the-art.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Projection of a data point on to a geodesic submanifold of the sphere.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Synthetic data (Data 1) on S 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Approximation of x j from the first k principal components.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>x j . Note that on S N , k th principal component of a data point is y(v k , x j ). Let x k j be the approximated x j from the first k principal components. Let w k−1 j be Log µ x µ tox k j . Let,v k be the parallel transported version of v k to x k−1 j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>proj. err. Time(s) avg. proj. err. Time(s) avg. proj. err.</figDesc><table>Data 

Var. 
CCM-EPGA 
PGA 
exact PGA 
avg. Time(s) 
Data 1 
2.16 
1.13e − 04 
0.70 
0.174 
0.46 
2.54e-02 
14853 
Data 2 
0.95 
5.87e − 02 
0.27 
0.59 
0.12 
0.59 
84.38 
Data 3 7.1e-03 
2.33e − 03 
0.19 
0.55 
0.05 
0.55 
16.87 
Data 4 5.9e-02 
0.27 
0.33 
0.37 
0.14 
0.37 
71.84 

Table 1: Comparison results on synthetic datasets 

Method 
avg. proj. error Time(s) 
CCM-EPGA 
2.83e − 10 
0.40 
PGA 
9.68e − 02 
0.28 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Comparison results on Gator-Bait database</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Comparison results on Brodatz database</figDesc><table></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This research was funded in part by the NSF IIS-1525431 to Prof. B. C. Vemuri. We thank Dr. Stefan Sommer of the University of Copenhagen, for providing us the code for his exact PGA algorithm.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Riemannian Lˆ{p} center of mass: Existence, uniqueness, and convexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Afsari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<publisher>American Mathematical Society</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="655" to="673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Methods of information geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>S.-I. Amari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nagaoka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>American Mathematical Soc</publisher>
			<biblScope unit="volume">191</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Scale space analysis and active contours for omnidirectional images. Image Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bogdanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Thiran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">An introduction to differentiable manifolds and Riemannian geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Boothby</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Academic press</publisher>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Textures: a photographic album for artists and designers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Brodatz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966" />
			<publisher>Dover Pubns</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fisher information distance: a geometrical reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Strapasson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Applied Mathematics</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A riemannian framework for matching point clouds represented by the schrödinger distance transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Eisenschenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3756" to="3761" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Principal geodesic analysis for the study of nonlinear statistics of shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Pizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="995" to="1005" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Leséléments aléatoires de nature quelconque dans un espace distancié</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fréchet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annales de l&apos;institut Henri Poincaré</title>
		<imprint>
			<publisher>Presses universitaires de France</publisher>
			<date type="published" when="1948" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="215" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Rotation averaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Trumpf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="305" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Principal curves on riemannian manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hauberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On a nonlinear generalization of sparse coding and dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 30th International Conference on Machine Learning</title>
		<meeting>The 30th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1480" to="1488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Intrinsic shape analysis: Geodesic pca for riemannian manifolds modulo isometric lie group actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huckemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Munk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistica Sinica</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Principal component analysis for riemannian manifolds, with an application to triangular shape spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huckemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ziezold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Applied Probability</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="299" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Hyperbolic geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Iversen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Metric learning using iwasawa decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 11th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>Computer Vision</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Jolliffe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Theory of point estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The hyperbolic geometry of illumination-induced chromaticity changes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Carmona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition, 2007. CVPR&apos;07. IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">If i had a fisheye i would not need so (1, n), or is hyperbolic geometry useful in image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Granlund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the SSAB Symposium</title>
		<meeting>of the SSAB Symposium<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="49" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Shape distributions for landmark data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mardia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dryden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Applied Probability</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="742" to="755" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
		<ptr target="https://www.cise.ufl.edu/˜anand/publications.html.5" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sangwine. Exact principal geodesic analysis for data on so (3)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Said</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Courty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">Le</forename><surname>Bihan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th European Signal Processing Conference (EUSIPCO-2007)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1700" to="1705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sommer</surname></persName>
		</author>
		<ptr target="https://github.com/nefan/smanifold" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Manifold valued statistics, exact principal geodesic analysis and the effect of linear approximations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lauze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hauberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2010</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="43" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Harmonic analysis on symmetric spaces and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Terras</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<publisher>Springer</publisher>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Probabilistic principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Tipping</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="611" to="622" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Inverse Problems and Applications: Inside Out II</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Uhlmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">60</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Teichmüller shape space theory and its application to brain morphometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-T</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Toga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Medical Image Computing and Computer-Assisted Intervention-MICCAI</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ricci flow for 3d shape analysis. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Samaras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">D</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Probabilistic principal geodesic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1178" to="1186" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
