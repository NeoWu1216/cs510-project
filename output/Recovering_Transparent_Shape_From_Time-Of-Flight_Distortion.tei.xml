<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Recovering Transparent Shape from Time-of-Flight Distortion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenichiro</forename><surname>Tanaka</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Osaka University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuhiro</forename><surname>Mukaigawa</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyuki</forename><surname>Kubo</surname></persName>
							<email>hkubo@is.naist.jp</email>
							<affiliation key="aff1">
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuyuki</forename><surname>Matsushita</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Osaka University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasushi</forename><surname>Yagi</surname></persName>
							<email>yagi@am.sanken</email>
							<affiliation key="aff0">
								<orgName type="institution">Osaka University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Recovering Transparent Shape from Time-of-Flight Distortion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a method for recovering shape and normal of a transparent object from a single viewpoint using a Time-of-Flight (ToF) camera. Our method is built upon the fact that the speed of light varies with the refractive index of the medium and therefore the depth measurement of a transparent object with a ToF camera may be distorted. We show that, from this ToF distortion, the refractive light path can be uniquely determined by estimating a single parameter. We estimate this parameter by introducing a surface normal consistency between the one determined by a light path candidate and the other computed from the corresponding shape. The proposed method is evaluated by both simulation and real-world experiments and shows faithful transparent shape recovery.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Transparent shape reconstruction is important for scientific imaging and applications in industrial manufacturing. It has been a difficult problem in computer vision because the appearance of a transparent object can only be indirectly observed by the distortion of background textures as illustrated in <ref type="figure" target="#fig_0">Fig. 1a</ref>. Several methods that uses the observations of the geometric distortion have been proposed, yet it is still an active research subject.</p><p>Recently, a Time-of-Flight (ToF) camera, which measures distance by correlation of its modulated light, is becoming a commodity device. When a scene containing a transparent object is recorded by a ToF camera, the ToF measurement also becomes distorted because the light slows down inside the transparent object due to its refractive index as illustrated in <ref type="figure" target="#fig_0">Fig. 1b</ref>. The distortion is different than the geometric distortion on the image coordinates, but still conveying rich information about the shape of transparent object. We call this distortion a Time-of-Flight distortion 1 in this paper and use it for recovering the shape of <ref type="bibr" target="#b0">1</ref> This is not ordinary depth distortions that are due to calibration or multi-path effects but the distortion of "time-of-flight." transparent object.</p><p>Our method records two ToF measurements of a transparent object from a single viewpoint but by moving the background reference surface which is calibrated. Assuming that the refractive index of the target object is known and the ToF camera is calibrated, the shape estimation problem can be viewed as the problem of searching the light path, which correspond to estimating front and back refraction points and its surface normal. We show that, using the ToF distortion, the light path has a simple expression that is governed by a single parameter. We develop a method for estimating this parameter using a surface normal consistency, that represents a consistency between the surface normal computed from the light path candidate and that obtained from the corresponding shape.</p><p>The proposed method estimates both front and back surfaces in a single viewpoint approach. Unlike previous single viewpoint approaches that are restricted to a scene with a single refraction, or requiring a number of light sources to illuminate the scene, the proposed method is able to recover a scene with two refraction surfaces from a single view point, with two observations obtained by moving the background reference surface. This new setting is enabled by the use of ToF distortion, which explicitly encodes the altered light speed in the transparent medium and its volume. Furthermore, we show a simple multi-path mitigation technique using a retroreflective sheet for this setting, which does not require any computational illumination devices, for recovering curved or multi-planar surfaces of transparent objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Early works of recovering the shape of transparent objects include <ref type="bibr" target="#b17">[17]</ref>, which recovers a single refraction water surface by observing the image placed under water. The setting of single refraction scenes has been further studied by several researchers. Morris and Kutulakos <ref type="bibr" target="#b16">[16]</ref> reconstruct the shape of a dynamic wavy surface by observing a reference pattern placed under water from stereo cameras. Alterman et al. <ref type="bibr" target="#b0">[1]</ref> estimate the position of the target object in the air from a camera placed in water using a stereo image sequence. Tian and Narasimhan <ref type="bibr" target="#b20">[20]</ref> simultaneously estimate the shape of water surface and planar underwater scene from an image sequence by water surface tracking based on the distortion model using the wave equation. Tian and Narasimhan <ref type="bibr" target="#b21">[21]</ref> also remove distortion of wavy surface in a data-driven approach and reconstruct wavy surface by spatially integrating the water distortion. Wetzstein et al. <ref type="bibr" target="#b22">[22]</ref> reconstruct thin transparent objects by assuming thin transparent objects as a single refraction surface using light-field probe, which converts the position and angle of the light source into color codes. In contrast to these approaches that assume a single refraction path, our method focuses on scenes with two refraction paths to estimate whole shape.</p><p>There are also methods that analyze solid transparent shapes that exhibit two or more refractions. Kutulakos and Steger <ref type="bibr" target="#b11">[12]</ref> show a general theory of tractability of shape recovery based on refractive paths characterized by the number of viewpoints, reference points, and refraction points. They also show reconstruction of a transparent shape from three viewpoints, two reference points, and two refraction points. Their problem setting is similar to ours but our method reconstructs from two observations from a single viewpoint using a ToF camera, with moving the background reference surface. There are also some single viewpoint approaches for transparent shape reconstruction. Morris and Kutulakos <ref type="bibr" target="#b15">[15]</ref> reconstruct inhomogeneous transparent objects by illuminating an object from various positions and analyzing the specular reflections. Similarly, Yeung et al. <ref type="bibr" target="#b23">[23]</ref> also propose a reconstruction method based on specular reflection analysis. While effective, these methods require a number of light positions for accurate recovery.</p><p>Some other methods take an approach of using special- ized devices for recovering transparent shape. Han et al. <ref type="bibr" target="#b5">[6]</ref> reconstruct a single side of transparent surface object by the crossing of two reference rays, one of which is measured in the air and the other is measured in liquid. There are also other unique methods for recovering transparent surfaces. Ihrke et al. <ref type="bibr" target="#b8">[9]</ref> reconstruct the shape of flowing water by dyeing water with a fluorescent chemical and observing from multiple video cameras. Ma et al. <ref type="bibr" target="#b12">[13]</ref> acquire the refractive index field based on the transport of intensity equations, which is a theory of phase imaging with coherent illumination, using collimated illumination, and reconstruct 3-d refractive volume based on tomography. Miyazaki and Ikeuchi <ref type="bibr" target="#b14">[14]</ref> propose an inverse polarization ray-tracing for estimating the front surface of a transparent object using polarized reflections. Eren et al. <ref type="bibr" target="#b3">[4]</ref> use thermal imaging for determining transparent shape by illuminating the target by laser beam. <ref type="table">Table 1</ref> summarizes the settings of transparent shape estimation methods, mainly single viewpoint approaches. Our method determines the shape of transparent objects from a single viewpoint with two reference points. We consider that a ToF camera is now a commodity device because it is available at a similar cost with ordinary RGB cameras.</p><p>Similar to our setting, there are works that use a ToF camera with scenes including transparent objects. Heide et al. <ref type="bibr" target="#b6">[7]</ref> recover light propagation sequences of a scene by sweeping the modulation frequency of their custom ToF camera. O'Toole et al. <ref type="bibr" target="#b18">[18]</ref> separate light-in-flight images into direct reflection, specular inter-reflection, and global components such as caustics based on spatial probing. Kadambi et al. <ref type="bibr" target="#b10">[11]</ref> reconstruct time sequential images of a scene including transparent objects by altering ToF measurement using coded light pulses. Gkioulekas et al. <ref type="bibr" target="#b4">[5]</ref> visualize propagation of light by an optical coherence tomography scheme using a Michelson interferometer. Because their method has pico-second time resolution, spectral dispersion in a glass slab can be visualized. While these works visualize light transport of the scene, our goal is reconstruct the shape of transparent objects. Similar to our work, Shim and Lee <ref type="bibr" target="#b19">[19]</ref> reconstruct the shape of thin translucent objects using a single ToF camera. They model the distortion of the depth by two layer (2-sparse) multipath model, and determined object and background layer's depth from multiple observations of different illumination phase delay. Unlike their method, our method is developed for recovering shape of transparent objects, which have two refraction points and considerable thickness, using the variation of speed of light inside the object and refractive paths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed method</head><p>In our setting, we measure a transparent object using a known reference board placed behind the object as illustrated in <ref type="figure" target="#fig_1">Fig. 2</ref>. The target scene is recorded by a ToF camera twice by moving the reference board at two distinct locations behind the object. A single ToF observation contains both intensity and depth measurements, and from the intensity measurement, we determine two reference points r 1 , r 2 ∈ R 3 . From these two reference point observations, the reference ray direction v 3 can be determined. With an assumption that the refractive index ν of the transparent object is known and that the camera is calibrated therefore the camera ray direction v 1 is known, our goal is to estimate the front surface point f and back surface point b at every camera pixel using the ToF depth measurement l ToF . This problem is equivalent to estimating two variable t and s, where t is the distance from the camera to the front surface point, and s is the distance from the back surface point to the reference point. Our method estimates these unknowns t and s from v 1 , v 3 , r 1 , and l ToF for determining the shape of transparent object. We begin with describing the ToF distortion model and develop the estimation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Time-of-Flight distortion model</head><p>A ToF sensor acquires the scene depth by observing the delay of returned light. When a transparent object is placed in the scene, a ToF sensor measures the optical length to the background object instead of the transparent object because light refracts and passes through the transparent object and reflects back from the background. In addition, the light speed slows down inside the transparent object according to its refractive index ν, hence the optical length measured by the ToF camera becomes different than the geometric length of the light path. The measured depth l ToF can, therefore, be expressed as</p><formula xml:id="formula_0">l ToF =t + ν |b − f | + s,<label>(1)</label></formula><p>where |·| represents the geometric length of the vector. We call this distortion the Time-of-Flight distortion in this paper, and use it for estimating the shape of transparent objects as it embeds the thickness of transparent object. This model is built upon the following two assumptions.</p><p>• Reflection on the transparent object surface is ignored. Specular reflection is only observed when the surface confronts with the ToF camera, which rarely happens in practice.</p><p>• We assume only a single path of ToF light rays and ignore multi-path interference. In practice, we avoid the multi-path effect using a retroreflective sheet, which is explained in an experiment section. Prior methods for multi-path separation in ToF sensing such as <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b10">11]</ref> can be alternatively used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Baseline method</head><p>By examining the equation of the ToF distortion (Eq. (1)) analytically, s can be expressed as a function of t as 2</p><formula xml:id="formula_1">s(t) = −h(t) − h 2 (t) − gi(t) g ,<label>(2)</label></formula><p>where g, h, and i are auxiliary variables defined as</p><formula xml:id="formula_2">     g = ν 2 − 1 h(t) = l ToF − t − ν 2 (r 1 − tv 1 ) T v 3 i(t) = ν 2 |r 1 − tv 1 | 2 − (l ToF − t) 2 .<label>(3)</label></formula><p>While this expression eliminates unknown vectors b and f , there still remains one degree of freedom to determine the unique shape s and t. For resolving the ambiguity, we use a surface normal consistency described in the following. When a hypothesized depth t is assumed, we can obtain a hypothesized front surface point f and back surface point b as functions of t:</p><formula xml:id="formula_3">f (t) = tv 1 , b(t) = r 1 − s(t)v 3 .<label>(4)</label></formula><p>Based on this, the refractive ray direction v 2 can be obtained from the hypothesized front surface point f to back surface point b as</p><formula xml:id="formula_4">v 2 (t) = b(t) − f (t) |b(t) − f (t)| .<label>(5)</label></formula><p>Since the refractive index ν is known, the surface normal n p (t) of the front surface point can be obtained from the refractive path using Snell's law as 3</p><formula xml:id="formula_5">n p (t) = νv 2 (t) − v 1 |νv 2 (t) − v 1 | = 1 N 2 (t) ν N 1 (t) (r 1 − s(t)v 3 − tv 1 ) − v 1 ,<label>(6)</label></formula><p>where</p><formula xml:id="formula_6">N 1 (t) = |b(t) − f (t)| and N 2 (t) = |νv 2 (t) − v 1 | are normalization coefficients.</formula><p>At the same time, we can obtain another surface normal n d (t) from the hypothesized shape as</p><formula xml:id="formula_7">n d (t) = ∂(tv1) ∂x × ∂(tv1) ∂y ∂(tv1) ∂x × ∂(tv1) ∂y ,<label>(7)</label></formula><p>where × and ∂ are cross product and partial differentiation operators, respectively. We assume that the neighbors around tv 1 correspond to those viewed in the camera pixel coordinates.</p><p>If the assumed front depth t is correct, two normals n p (t) and n d (t) should coincide; therefore, the estimation problem can be casted as an optimization problem as</p><formula xml:id="formula_8">argmin t c∈C n p,c (t c ) − n d,c (t c ) 2 2 ,<label>(8)</label></formula><p>where t is a vector listing t c for all pixels, C is a set of all pixels, t c is the hypothesized front depth of pixel c, n p,c and n d,c are the surface normal computed from the refractive path and that from hypothesized shape at pixel c, respectively. We call this method a baseline method, and in the next subsection, we introduce additional objectives for a more stable solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Robust estimation method</head><p>The objective function (Eq. <ref type="formula" target="#formula_8">(8)</ref>) directly uses the optical length measured by the ToF sensor (Eq. (1)) without considering uncertainty (or noise) in the measurement. To take into account observation noise, we introduce a new variable l c for each pixel c, which represents the noise-free ToF optical length. There are two objective terms; one of which is the normal consistency used for the baseline method described above, and the other is that the denoised signal l c should remain close enough to the measured signal l ToF . We additionally regularize the denoising part assuming the smoothness of both front and back surfaces. Hence, the <ref type="bibr" target="#b2">3</ref> Please refer to Appendix B in the supplementary material. discontinuity transparent object light paths backpoint <ref type="figure">Figure 3</ref>: Discontinuity of back surface points. Red and blue points are well ordered in each group, but generates discontinuity due to the edge on the front surface as emphasized by a black arrow. To take into account of this discontinuity, we use a Huber cost function for back surface smoothness.</p><p>overall objective function becomeŝ</p><formula xml:id="formula_9">t,l = argmin t,l c∈C n p,c (t c , l c ) − n d,c (t c ) 2 2 + λ 1 c∈C l c − l ToF (c) 2 2 + λ 2 j,k∈N t j v 1,j − t k v 1,k 2 2 + λ 3 c∈C ∂ ∂z b j (t c , l c ) H ,<label>(9)</label></formula><p>where l is a vector listing l c for all pixels, j and k are pixel indices chosen from a set of all neighborhood N , · H is the Huber penalty function <ref type="bibr" target="#b7">[8]</ref>  <ref type="bibr" target="#b3">4</ref> , v 1,c is a unit camera ray vector corresponding to pixel c, and l ToF (c) is the measured ToF depth at pixel c. The first term ensures the normal consistency, the second term represents denoising of measured signal l ToF , and the third and fourth terms regularize the denoising process by enforcing smoothness of front and back surfaces. If the front surface consists of multiple planes or is curved, continuity of back surface points could break as illustrated in <ref type="figure">Fig. 3</ref>. We therefore use a Huber cost function for the back surface smoothness because it allows occasional discontinuity (outliers) while retaining overall smoothness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Solution method</head><p>The optimization problem of Eq. (9) is unfortunately non-convex and difficult to directly solve. We therefore take an alternating minimization approach by splitting the original problem into two subproblems; one for estimating t with keeping l fixed (t-subproblem), and the other for determining l with given t (l-subproblem). This can be interpreted as alternating estimation of shape (t-subproblem) <ref type="bibr" target="#b3">4</ref> The Huber penalty function is an l 1 /l 2 hybrid norm hence it can be used as smoothness with discontinuity, and defined as</p><formula xml:id="formula_10">x H = i hǫ(x i ) , where hǫ(x) = |x| − ǫ/2 (|x| &gt; ǫ) x 2 /(2ǫ) otherwise</formula><p>and denoising of measurement (l-subproblem). Our method iteratively updates t and l with initialization of t = constant, which is chosen manually by setting the approximate distance to the object, and l = l ToF , which is a vectorized l ToF (c) for all pixels. We now discuss these two subproblems in detail.</p><p>t-subproblem By fixing l, Eq. (9) can be reduced to an optimization problem of t aŝ</p><formula xml:id="formula_11">t = argmin t c∈C n p,c (t c ,l c ) − n d,c (t c ) 2 2 + λ 2 j,k∈N t j v 1,j − t k v 1,k 2 2 ,<label>(10)</label></formula><p>wherel c represents the estimate of l c obtained from the previous iteration. This problem can be interpreted as estimation of the front surface shape because t c corresponds to the depth of front surface. Neglecting the back surface smoothness term is justified because of the fact that the length between f (t) and b(t) is almost fixed whenl c is unchanged. Due to the nested normalization terms as shown in Eq. <ref type="formula" target="#formula_5">(6)</ref>, it is difficult to analytically derive its first and second-order derivatives of the objective function. To avoid high computational complexity of calculating second derivatives, we use the L-BFGS method <ref type="bibr" target="#b24">[24]</ref> which only uses approximate Hessians rather than explicitly computing them. The t-subproblem is again non-convex; therefore, there is a chance of being trapped by a local minima. As we will see in Sec. 4.1, in practice, it yields good estimates with appropriate initialization.</p><p>l-subproblem By fixing t and neglecting the front surface normal consistency, we obtain an l optimization problem written asl</p><formula xml:id="formula_12">= argmin l c∈C l c − l ToF (c) 2 2 + λ ′ 3 c∈C ∂ ∂z b j (t c , l c ) H ,<label>(11)</label></formula><p>where λ ′ 3 = λ 3 /λ 1 . It can be viewed as a problem of denoising l regularized by the back surface smoothness (the second term) with a fixed front surfacet. Although this problem is not strictly convex, we observed that this problem is approximately convex 5 ; hence the optimal solution can be obtained. We again use the L-BFGS method as a minimizer for l-subproblem.</p><p>The solution method for the baseline method described in Sec. 3.2 corresponds to the t-subproblem. On the other <ref type="bibr" target="#b4">5</ref> Please refer to Appendix C in the supplementary material for the convexity of l-subproblem. In the implementation, we begin with the t-subproblem and iterate until convergence. We stop the iteration when the gap between estimates and former estimates for botht and l are small enough.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3-d view</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we first assess the accuracy, robustness, and convergence of the proposed method using simulation data, and apply the method to real-world transparent objects to evaluate its effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Simulation test</head><p>We generate simulation data of a scene with a transparent object that consist of the optical length and two reference points by ray tracing using Eq. (1) and Snell's law. To the data, we apply the proposed method to estimate front and back surface points and assess its accuracy by comparing with the ground-truth model. We use 0.005 for λ 2 and 20 for λ ′ 3 for all target objects in the simulation tests. Accuracy We first assess the effectiveness of the normal consistency objective (t-subproblem) using 48 types of transparent shapes generated by simulation. The data is noise-free in this experiment, and the solution is derived by solving the t-subproblem (baseline method with smoothness). The initial value of t is set to constant using an approximate depth to the object, which essentially corresponds to a planar surface located nearby the object. <ref type="figure" target="#fig_2">Figure 4a</ref> shows the result of a diamond shape scene. The result is close to the ground truth, whose root mean squared error (RMSE) is 0.524 mm (0.17 % of the optical length). As another example, <ref type="figure" target="#fig_2">Fig. 4b</ref> shows the result of a round torus-like object. The reconstruction accuracy is high in this case as well with RMSE 0.801 mm (0.26 % error), while there is visible artifacts at a few boundary regions. The average error of all 48 target objects is 0.45 %, and the result indicates the effectiveness of the normal consistency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of initialization</head><p>We assess the influence of different initializations to the solution of t-subproblem because the t-subproblem is non-convex as described in Sec. 3.4.</p><p>The transparent shape that we use for this test is placed at 200 mm from the camera, and its thickness is 50 mm; thus, the object spans in the range of 200 mm and 250 mm. We vary the initialization constant for t from 150 mm to  250 mm and assess the convergence and accuracy by solving the t-subproblem. <ref type="figure">Figure 5a</ref> shows the cost value at convergence, and <ref type="figure">Fig. 5b</ref> shows the reconstruction error. The reconstruction error is less than 1% in a wide range of initial values between 186 mm and 209 mm, which shows the tolerance of the method against inaccurate initial values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Convergence of alternating optimization</head><p>We also assess the convergence of the alternating optimization described in 3.4. In this simulation, we add Gaussian noise with its standard deviation of 0.5% of optical length to all the pixels of the depth data. <ref type="figure">Figure 6</ref> shows an example of the cost variations of two subproblems over iterations. The cost of both subproblems rapidly decreases at the beginning of iterations and remains stable after 3 iterations. With our test, most transparent shapes showed a similar convergence behavior and we consider that it is safe to say it reaches a local optimum.</p><p>Robustness against noise We further assess the effect of observation noise by adding noise to simulated ToF measurements. For comparison, we assess four approaches: (1) baseline method with smoothness (t-subproblem only), (2) t-subproblem with denoising, (3) alternating optimization (Sec. 3.4), and (4) alternating optimization with denoising. We use the Non-local Means Denoising <ref type="bibr" target="#b2">[3]</ref> for denoising ToF measurements. <ref type="figure" target="#fig_5">Figure 7</ref> summarizes the reconstruction errors of these four strategies with respect to the noise level. Without a proper noise handling (approach 1), results are significantly affected by observation noise hence the error increases together with the observation noise level. When denoising is applied prior to the optimization (approach 2), the error becomes stable regardless of the noise level. With the alternating optimization method (approach 3), the error is also suppressed while it shows degradation at higher noise levels. The highest accuracy is obtained by alternat- ing optimization with denoising (approach 4). The result indicates that denoising is effective, that alternating optimization is also effective in suppressing noise, and that the combination of these two is effective. For the real-world experiments in the next subsection, we use the alternating optimization with denoising approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Real-world experiment</head><p>For the real-world experiment, we use an off-the-shelf ToF camera (Kinect v2) and an LCD panel placed on a linear stage. Three distinct transparent objects are used for conducting the experiment. The parameters are set to λ 2 = 0.05 and λ ′ 3 = 10 for all target objects in this experiment.</p><p>Setup <ref type="figure" target="#fig_6">Figure 8</ref> shows our experimental setup. We use Microsoft Kinect v2 for a ToF camera, whose lens is changed to Edmund 35mm IR lens to narrower the field of view (FOV). To obtain reference points, we use an LCD panel, which is mounted on a motorized linear stage (OptoSigma SGSP26-150) that allows replication of positions in high precision. The LCD panel reflects the lights from Kinect with displayed patterns hence the back illumination of the display is turned off.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Calibration and measurements</head><p>The LCD-camera system is calibrated at two LCD locations before measurement. The 3-d position of every LCD's pixels at two depth locations are measured in the form of IR and depth images of calibrated Kinect. The pixel location of the LCD panel is determined by Gray code pattern projection method <ref type="bibr" target="#b9">[10]</ref>. For measurement, we place the target transparent object in between the camera and LCD panel. The target object is measured twice with distinct LCD panel locations. To obtain reference points in the measurement, we again use the Gray code pattern projection.</p><p>Result We conduct experiments using three transparent objects, which do not produce multi-path interferences. <ref type="figure">Figure 9</ref> shows target objects and the reconstruction results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cube</head><p>Wedge prism Schmidt prism  We can see that estimated point clouds well fit the groundtruth 3-d CAD model. To align the ground truth with the reconstruction, we use the Iterative Closest Point (ICP) <ref type="bibr" target="#b1">[2]</ref> algorithm. The quantitative reconstruction errors are summarized in <ref type="table" target="#tab_2">Table 2</ref>. The mean error in the Euclidean distance is small, and it shows the effectiveness of our method.</p><p>Multi-path avoidance If the target object is curved or has multiple planes, caustics appear on the background surface.</p><p>In such a case, there are multiple light paths sharing the same reflection point on the background; therefore the observed depth by a ToF camera does not satisfy the model of Eq. (1). To avoid this multi-path interference, we use a</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retro-reflection</head><p>Light rays <ref type="figure" target="#fig_0">Figure 10</ref>: Multi-path avoidance using a retroreflective sheet. Using a retroreflective sheet, two rays (colored yellow and red) can be observed separately even when their reflection point is overlapped.  retroreflective sheet placed on the background. The retroreflective sheet reflects the incident light ray to the incident direction; hence, multi-path interference can be avoided even when the reference points are overlapped as shown in <ref type="figure" target="#fig_0">Fig. 10</ref>.</p><p>To verify the effectiveness of the multi-path avoidance, we use a right angle prism shown in <ref type="figure" target="#fig_0">Fig. 11a</ref> measure it with and without a retroreflective sheet. <ref type="figure" target="#fig_0">Figure 11b</ref> shows a slice of the estimated points and the ground truth model. The result without a retroreflective sheet is distorted by multi-path interference while the result with the retroreflective sheet shows faithful recovery of the object. It is also verified quantitatively by the reconstruction errors of the experiment summarized in <ref type="table" target="#tab_3">Table 3</ref>. Finally, we recover the shape of a convex lens, which has curved surfaces. We again use a retroreflective sheet for avoiding the multi-path effect. <ref type="figure" target="#fig_0">Figure 12</ref> shows the estimated results. While it became somewhat noisy, the curved surface that exhibits multi-path refraction rays is recovered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussions</head><p>We developed a method for transparent shape recovery using the time-of-flight distortion. One of the issues of our method for a practical use is that it is currently limited to low-resolution, because it is bounded by the resolution of the ToF image sensor. Another issue is that our method breaks down when the light path refracts more than twice, e.g., due to total reflections inside the transparent object, which could occur at the edge of the object. To avoid this problem, the region near such edges should be treated differently by developing a suitable technique.</p><p>The normal consistency objective appeared in <ref type="formula" target="#formula_8">(8)</ref> and <ref type="formula" target="#formula_9">(9)</ref> is defined as the Euclidean distance of unit normal vectors. Theoretically, it should be better written by because of its directional nature. We have tested the above expression; however, the result did not change much while the computational cost increased significantly. Therefore, we decided to keep using the Euclidean distance of normals. While we assume the neighbors of front surface points correspond to those viewed in the camera pixel coordinate, we cannot use the same assumption for the back surface because of refractions (depicted in <ref type="figure">Fig. 3)</ref>, and a less restrictive smoothness term is defined for the back surface using a Huber cost function. We consider this design tends to make the front surface smoother than the back surface. This behavior can be balanced by adjusting weight parameters λs. Also, our solution is somehow heuristic approach for solving non-convex problem hence it is not guaranteed to reach a good estimate for any shapes.</p><p>In the future work, we are interested in exploring the direction of combining a computational illumination approach, such as <ref type="bibr" target="#b10">[11]</ref>, for not only mitigating the multi-path interference but also explicitly handling the multi-path effect for transparent shape recovery.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Two distortions caused by transparent objects. (a) Background texture is geometrically distorted by refraction. (b) Measured depth is distorted by slower light speed in the medium.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Transparent shape recovery problem. The front surface point f is on the camera ray at distance t, and the back surface point b is on the ray of 2 reference points at distance s.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Simulation examples: Diamond and torus-like objects. The top row shows the ground truth of 3-d view, pseudo-colored height map, and normal map of both front and back surfaces. The bottom row shows the reconstruction result. The reconstruction error is 0.17% and 0.26%, respectively.. hand, for the robust estimation method in Sec. 3.3, tand lsubproblems are repeatedly solved in an alternating manner.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Assessment result about local minimum depending on the initial value. (a) Terminated cost value. (b) Error of estimated shape compared to the ground-truth. All initial values between 186 mm and 209 mm result in accurate shapes. Convergence of our alternating minimization. (a) Cost of t-subproblem. (b) Cost of l-subproblem. They decrease over iterations and converge after 3 iterations in this example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Reconstruction error of four approaches with respect to varying noise level. The reconstruction error generally becomes higher with a greater noise level. Errors are suppressed by proper noise handling. The combination of denoising and alternating optimization yields stable and the lowest error among these four approaches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Experimental setup. IR lens of Kinect v2 is changed to obtain narrower field of view. Reference points are obtained using the LCD panel on a linear stage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 11 :</head><label>11</label><figDesc>Reconstruction result of a right angle prism. (a) The target object. (b) a slice view of the estimated surface points and the ground truth. Blue and red points are the result with and without retroreflective sheet, respectively. The retroreflective sheet mitigates multi-path interference for more faithful recovery. Object Mean Std. dev. without retroreflection 0.745 mm 1.115 mm with retroreflection 0.448 mm 0.828 mm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 12 :</head><label>12</label><figDesc>Reconstruction of a transparent curved object (convex lens)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>,c (t c ) T n d,c (t c ) − 1 2 ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>Experimental result of simple objects that consist of two planer surfaces. Top: Target objects. Front and back surfaces are single plane, hence no multi-path interferences are occurred. Middle: Estimated front points (yellow) and back points (cyan) with fit model by ICP (semitransparent). Bottom: Estimated height map (upper) and normal map (lower) of front surface (left) and back surface (right).</figDesc><table>Target objects 

Estimated point clouds and fit model 

front 
back 

Pseudo colored height and normal maps 

front 
back 
front 
back 
height 

normal 

Figure 9: Object 
Mean 
Std. dev. 
Cube (parallel surfaces) 0.188 mm 0.458 mm 
Wedge prism (18.8 • ) 
0.226 mm 1.137 mm 
Schmidt prism (45 • ) 
0.381 mm 1.398 mm 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Quantitative evaluation of reconstruction errors. We evaluate the mean and standard deviation of the Euclidean distance between recovered points and the ground truth CAD model. The estimated points are registered to the model by ICP algorithm prior to the evaluation.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Numerical evaluation of right angle prism. The result with retroreflective sheet is more accurate than that without it.</figDesc><table></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Please refer to Appendix A in the supplementary material for the derivation.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Triangulation in Random Refractive Distortions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alterman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Schechner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Swirski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computational Photography</title>
		<meeting>International Conference on Computational Photography</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Method for Registration of 3-D Shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Besl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Mckay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="239" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Non-Local Algorithm for Image Denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scanning from Heating: 3D Shape Estimation of Transparent Objects from Local Surface Heating</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Eren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Aubreton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Meriaudeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Sanchez Secades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fofi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Naskali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Truchetet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ercil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optics express</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="11457" to="11468" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Micronscale Light Transport Decomposition Using Interferometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gkioulekas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zickler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (ToG)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Fixed Viewpoint Approach for Dense Reconstruction of Transparent Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-Y</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4001" to="4008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lowbudget Transient Imaging using Photonic Mixer Devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Heide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Hullin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gregson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (ToG)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Robust Regression: Asymptotics, Conjectures and Monte Carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="799" to="821" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reconstructing the Geometry of Flowing Water</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ihrke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goidluecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Magnor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1055" to="1060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Range Imaging System for 3-d Object Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Inokuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Matsuda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Pattern Recognition</title>
		<meeting>International Conference on Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1984" />
			<biblScope unit="page" from="806" to="808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Coded Time of Flight Cameras: Sparse Deconvolution to Address Multipath Interference and Recover Time Profiles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kadambi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Whyte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhandari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Streeter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dorrington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (ToG)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Theory of Refractive and Specular 3D Shape by Light-path Triangulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kutulakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1448" to="1455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Transparent Object Reconstruction via Coded Transport of Intensity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wetzstein</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
			</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3238" to="3245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Inverse Polarization Raytracing: Estimating Surface Shapes of Transparent Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="910" to="917" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reconstructing the Surface of Inhomogeneous Transparent Scenes by Scatter-Trace Photography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J W</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Kutulakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dynamic Refraction Stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J W</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Kutulakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1518" to="1531" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Surface Shape Reconstruction of an Undulating Transparent Object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Murase</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="313" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Temporal Frequency Probing for 5D Transient Analysis of Global Light Transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>O&amp;apos;toole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Heide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Hullin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Kutulakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (ToG)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2014-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Recovering Translucent Object using a Single Time-of-Flight Depth Camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Seeing through Water: Image Restoration using Model-based Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Narasimhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2303" to="2310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Globally Optimal Datadriven Approach for Image Distortion Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Narasimhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1277" to="1284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Refractive Shape from Light Field Distortion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wetzstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roodnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1180" to="1186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adequate Reconstruction of Transparent Objects on a Shoestring Budget</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-K</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2513" to="2520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">L-BFGS-B: Algorithm 778: L-BFGS-B, FORTRAN Routines for Large Scale Bound Constrained Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="550" to="560" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
