<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Local Background Enclosure for RGB-D Salient Object Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Feng</surname></persName>
							<email>david.feng@nicta.com.au</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Australian National University</orgName>
								<orgName type="institution" key="instit2">Swinburne University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Barnes</surname></persName>
							<email>nick.barnes@nicta.com.au</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Australian National University</orgName>
								<orgName type="institution" key="instit2">Swinburne University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaodi</forename><surname>You</surname></persName>
							<email>shaodi.you@nicta.com.au</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Australian National University</orgName>
								<orgName type="institution" key="instit2">Swinburne University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicta</forename><forename type="middle">;</forename><surname>Rse</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Australian National University</orgName>
								<orgName type="institution" key="instit2">Swinburne University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Mccarthy</surname></persName>
							<email>cdmccarthy@swin.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Australian National University</orgName>
								<orgName type="institution" key="instit2">Swinburne University of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Local Background Enclosure for RGB-D Salient Object Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent work in salient object detection has considered the incorporation of depth cues from RGB-D images. In most cases, depth contrast is used as the main feature. However, areas of high contrast in background regions cause false positives for such methods, as the background frequently contains regions that are highly variable in depth.</p><p>Here, we propose a novel RGB-D saliency feature. Local Background Enclosure (LBE) captures the spread of angular directions which are background with respect to the candidate region and the object that it is part of. We show that our feature improves over state-of-the-art RGB-D saliency approaches as well as RGB methods on the RGBD1000 and NJUDS2000 datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Visual attention refers to the ability of the human visual system to rapidly identify scene components that stand out, or are salient, with respect to their surroundings. Early work on computing saliency aimed to model and predict human gaze on images <ref type="bibr" target="#b11">[12]</ref>. Recently the field has expanded to include the detection of entire salient regions or objects <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3]</ref>. These techniques have many computer vision applications, including compression <ref type="bibr" target="#b9">[10]</ref>, visual tracking <ref type="bibr" target="#b18">[19]</ref>, and image retargeting <ref type="bibr" target="#b17">[18]</ref>.</p><p>The saliency of a region is usually obtained by measuring contrast at a local <ref type="bibr" target="#b11">[12]</ref> and/or global scale <ref type="bibr" target="#b6">[7]</ref>. The majority of previous approaches compute contrast with respect to appearance-based features such as colour, texture, and intensity edges <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13]</ref>. However, recent advances in 3D data acquisition techniques have motivated the adoption of structural features, improving discrimination between different objects with similar appearance.</p><p>RGB-D saliency methods typically incorporate depth directly, or use depth in a contrast measurement framework <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref>, where contrast is computed as the difference between the means or distributions of foreground and background depth. Use of depth contrast in conjunction with colour contrast, various priors, and refinement schemes pro- (f) ACSD <ref type="bibr" target="#b14">[15]</ref> (g) LMH <ref type="bibr" target="#b21">[22]</ref> Figure 1. Saliency output on a depth image where foreground depth contrast is relatively low. Our method measures background enclosure of the object to overcome this problem.</p><p>duces state-of-the-art results <ref type="bibr" target="#b22">[23]</ref>. However, depth contrast is prone to false positives from background regions with large depth difference. <ref type="figure">Figure 1</ref> shows an example in which the foreground has relatively low contrast, making it challenging to detect using existing depth features. Contrast in background regions is unavoidable, and in general contrast in depth scenes can be dependent on random factors such as object placement and viewpoint. Although Ju et al. <ref type="bibr" target="#b14">[15]</ref> has started to investigate depth contrast for whole object structures, false positives still appear due to nearby regions with large depth difference as shown in <ref type="figure">Figure 1f</ref>. Aiming to address this issue, we propose the Local Background Enclosure (LBE) feature, which directly measures salient structure from depth. We note that salient objects tend to be characterised by being locally in front of surrounding regions, and the distance between an object and the background is not as important as the fact that the background surrounds the object for a large proportion of its boundary. The existence of background in a large spread of angular directions around the object implies pop-out structure and thus high saliency. Conversely, background regions are less likely to exhibit pop-out structure. Thus we pro-pose a depth saliency feature that incorporates two components. The first, which is proportional to saliency, is the angular density of background around a region, encoding the idea that a salient object is in front of most of its surroundings. The second feature component, which is inversely proportional to saliency, is the size of the largest angular region containing only foreground, since a large value implies significant foreground structure surrounding the object. This is the first time angular distributions of background directions have been explicitly incorporated for depth saliency. This feature is shown to be more robust than existing depth contrast-based measures. Further, we validate the proposed depth feature in a saliency system. We demonstrate that our depth feature out-performs state-ofthe-art methods when combined with a depth prior, spatial prior, background prior, and Grabcut refinement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>RGB-D saliency computation is a rapidly growing field, offering object detection and attention prediction in a manner that is robust to appearance. Early works use depth as a prior to reweight 2D saliency maps <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b26">27]</ref>. These approaches do not consider relative depth, and work best when the range of salient objects is closer than the background.</p><p>More recently, the effectiveness of global contrast for RGB salient object detection <ref type="bibr" target="#b6">[7]</ref> has inspired similar approaches for RGB-D saliency. Many existing methods measure global depth contrast, usually combined with colour and other modalities, to compute saliency <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref> . While the majority of previous work computes depth contrast using absolute depth difference between regions, some methods instead use signed depth difference, improving results for salient objects in front of background <ref type="bibr" target="#b7">[8]</ref>. Ju et al. <ref type="bibr" target="#b14">[15]</ref> observe that while a salient object should be in front of its surrounds, patches on that object may be at a similar depth. However, as with other depth contrast methods, the primary feature of <ref type="bibr" target="#b14">[15]</ref> is the depth difference between the foreground and background. Depth contrast methods are unlikely to produce good results when a salient object has low depth contrast compared to the rest of the scene (see <ref type="figure">Figure 1</ref>). While depth contrast measurement forms the foundation of many approaches, it is common practice to enhance the resulting saliency maps by applying various priors and other refinement steps. The use of spatial and depth priors is widespread in existing work <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24]</ref>. Ren et al. <ref type="bibr" target="#b22">[23]</ref> explore orientation and background priors for detecting salient objects, and use PageRank and MRFs to optimize their saliency map. Peng et al. <ref type="bibr" target="#b21">[22]</ref> incorporate object bias, and optimize their saliency map using a region growing approach. Ju et al. <ref type="bibr" target="#b14">[15]</ref> apply Grabcut segmentation to refine the boundaries of the generated saliency map. <ref type="figure">Figure 2</ref>. Illustration of the local background sets (blue) for four different candidate regions (green). In this example the neighbourhood radius is r = 200 pixels, and the depth cutoff is t = σ/2. Note that patches lying on salient objects tend to be enclosed by the local background set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Local Background Enclosure</head><p>In this section we introduce the Local Background Enclosure feature, which quantifies the proportion of the object boundary that is in front of the background. The salient object detection system will be described in Section 4. Given an RGB-D image with pixel grid I(x, y), we aim to segment the pixels into salient and non-salient pixels. For computational efficiency and to reduce noise from the depth image, instead of directly working on pixels, we oversegment the the image into a set of patches according to their RGB value. We denote the patches as P ⊂ I. We use SLIC <ref type="bibr" target="#b1">[2]</ref> to obtain the superpixel segmentation, although our method is flexible to the type of segmentation method used.</p><p>Salient objects tend to be locally in front of their surroundings, and consequently will be mostly enclosed by a region of greater depth, as shown in <ref type="figure">Figure 2</ref>. We propose the Local Background Enclosure feature denoted by S based on depth. This feature employs an angular density component, F , and an angular gap component, G, to measure the proportion of the object boundary in front of the background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Angular Density Component</head><p>We wish to measure the angular density of the regions surrounding P with greater depth than P , referred to as the local background. We consider a local neighbourhood N P of P , consisting of all patches within radius r of P . That is,</p><formula xml:id="formula_0">N P = {Q | c P − c Q 2 &lt; r}, where c P and c Q are patch centroids.</formula><p>We define the local background B (P, t) of P as the union of all patches within a neighbourhood N P that have a mean depth above a threshold t from P .</p><formula xml:id="formula_1">B (P, t) = {P ′ ∈ N P |D (P ′ ) &gt; D (P ) + t} ,<label>(1)</label></formula><p>where D (P ) denotes the mean depth of pixels in P .</p><p>We define a function f (P, B (P, t)) that computes the normalised ratio of the degree to which B (P, t) encloses   </p><formula xml:id="formula_2">0 σ 0 σ t t F = 0.05 G = 0.06 S = 0.03 P1: 1 0 σ 0 t F = 0.66 G = 0.78 S = 0.51 P2: 0 σ t f g</formula><formula xml:id="formula_3">P . f (P, B (P, t)) = 1 2π 2π 0 I (θ, P, B (P, t)) dθ,<label>(2)</label></formula><p>where I (θ, P, B (P, t))) is an indicator function that equals 1 if the line passing through the centroid of patch P with angle θ intersects B (P, t), and 0 otherwise. Note that we assume that P has a high compactness <ref type="bibr" target="#b1">[2]</ref>. A visualisation of f is shown in <ref type="figure" target="#fig_2">Figure 3</ref>. Thus f (P, B (P, t)) computes the angular density of the background directions. Note that the threshold t for background is an undetermined function. In order to address this, as frequently used in probability theory, we employ the distribution function, denoted as F (P ), instead of the density function f , to give a more robust measure. We define F (P ) as:</p><formula xml:id="formula_4">F (P ) = σ 0 f (P, B (P, t)) dt,<label>(3)</label></formula><p>where σ is the standard deviation of the mean patch depths within the local neighbourhood of P . This is given by</p><formula xml:id="formula_5">σ 2 = 1 |B(P,0)| Q∈B(P,0) D(Q) − D 2 , where D = 1 |B(P,0)| Q∈B(P,0) D(Q)</formula><p>. This implicitly incorporates information about the distribution of depth differences between P and its local background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Angular Gap Component</head><p>In addition to the angular density F (P ), we introduce the angular gap statistic G(P ). As shown in <ref type="figure" target="#fig_2">Figure 3</ref>, even though P2 and P3 have similar angular densities, we would expect P2 to have a significantly higher saliency since the background directions are more spread out. To capture this structure, we define the function g (P, Q) to find the largest angular gap of Q around P and incorporate this into the saliency score.</p><formula xml:id="formula_6">g (P, Q) = 1 2π · max (θ1,θ2)∈Θ {|θ 1 − θ 2 |} ,<label>(4)</label></formula><p>where Θ denotes the set of boundaries (θ 1 , θ 2 ) of angular regions that do not contain background:</p><formula xml:id="formula_7">Θ = {(θ 1 , θ 2 ) | I (θ, P, Q) = 0 ∀θ ∈ [θ 1 , θ 2 ]}.<label>(5)</label></formula><p>A visualisation of g is shown in <ref type="figure" target="#fig_2">Figure 3</ref>. We define the angular gap statistic as the distribution function of 1 − g:</p><formula xml:id="formula_8">G(P ) = σ 0 1 − g (P, B (P, t)) dt.<label>(6)</label></formula><p>The final Local Background Enclosure value is given by: <ref type="figure">Figure 8</ref> shows the generated saliency map on some example images. Note that the pop-out structure corresponding to salient objects is correctly identified. Depth contrast features fail to detect the objects, or exhibit high false positives.</p><formula xml:id="formula_9">S(P ) = F (P ) · G(P ).<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Saliency Detection System</head><p>We construct a system for salient object detection using the proposed feature. Specifically, we reweight the Local Background Enclosure feature saliency using depth and spatial priors, and then refine the result using Grabcut segmentation. An overview of our system is given in <ref type="figure" target="#fig_5">Figure 4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Depth, Spatial, and Background Prior</head><p>Studies report that absolute depth is an important component of pre-attentive visual attention, with closer objects more likely to appear salient to the human visual system <ref type="bibr" target="#b15">[16]</ref>. Accordingly, scaling saliency by depth is a common refinement step in previous work <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b24">25</ref>,  27]. We perform absolute depth reweighting using a depth prior D(x, y) to modulate the saliency of pixels with depth greater than the median depth of the image <ref type="bibr" target="#b14">[15]</ref>. Another widely used prior is spatial bias, based on the tendency of the human visual system to fixate on objects near the center of an image <ref type="bibr" target="#b25">[26]</ref>. Existing saliency methods commonly incorporate a center bias term to model this effect <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24]</ref>. We incorporate this idea into our system, applying a Gaussian G(x, y) to re-weight patch saliency based on the distance between the pixel (x, y) and the image center.</p><p>Recent works also incorporate a background prior based on some measure of boundary connectedness to improve detector precision <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>. We use the background prior map B(x, y) described in <ref type="bibr" target="#b27">[28]</ref> to reweight saliency.</p><p>The low-level saliency map with priors applied is thus given by:</p><formula xml:id="formula_10">S b = S · D · G · B<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Grabcut Segmentation</head><p>The saliency map S b may contain inaccurate foreground boundaries for parts of the object that do not exhibit strong pop-out structure. Boundary refinement is a common postprocessing step employed in existing salient object detection systems (e.g. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref>). Similar to <ref type="bibr" target="#b19">[20]</ref>, we use Grabcut based boundary refinement to improve object boundaries using appearance information. The foreground model is initialized with a binary mask obtained by applying a threshold α 0 to S b . The output Grabcut segmentation mask A is used to prune non-foreground areas from S b . The refined saliency map is thus given by</p><formula xml:id="formula_11">S g = A · S b .<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Implementation Details</head><p>The discrete version of the angular density function f is implemented using a histogram-based approximation, denoted asf . Let h (i, P, B (P, t)) be an n bin polar occupancy histogram, where bin i is 1 if the corresponding angular range contains an angle between the centroids of P and a patch in B (P, t), and 0 otherwise. We setf to be equal to the fill ratio of h.</p><formula xml:id="formula_12">f = 1 n n i=1</formula><p>h (i, P, B (P, t)) .</p><p>The distribution function F is computed numerically us-ingF by samplingf at m equally spaced points across the integration range such that:</p><formula xml:id="formula_14">F (P ) = 1 m m i=1f P, B P, i · σ m .<label>(11)</label></formula><p>Similarly, we defineG to evaluate G:</p><formula xml:id="formula_15">G(P ) = 1 m m i=1 1 − 1 2π · g P, i · σ m .<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>The performance of our saliency system is evaluated on two datasets for RGB-D salient object detection. RGBD1000 <ref type="bibr" target="#b21">[22]</ref> contains 1000 RGB and structured light depth images. NJUDS2000 <ref type="bibr" target="#b14">[15]</ref> contains 2000 RGB and disparity images computed from stereo image pairs.</p><p>The proposed Local Background Enclosure feature is compared against the following state-of-the art contrastbased depth features: multi-scale depth-contrast (LMH-D) <ref type="bibr" target="#b21">[22]</ref>; global depth contrast (GP-D) <ref type="bibr" target="#b22">[23]</ref>; and ACSD <ref type="bibr" target="#b12">[13]</ref>. We also include versions of LMH-D and GP-D with signed depth, denoted LMH-SD and GP-SD respectively, where neighbouring patches with a lower average depth do not contribute to the contrast measure of a patch. Additionally, in order to verify the contribution of using the distribution functions, we compute the product of the density functions f (P, t) · g(P, t) with fixed threshold t = σ/2.</p><p>We then evaluate the contribution of prior application and Grabcut refinement on our salient object detection system on both datasets. Finally, we compare our salient object detection system with three state-of-the-art RGB-D salient object detection systems: LMH <ref type="bibr" target="#b21">[22]</ref>, ACSD <ref type="bibr" target="#b14">[15]</ref>, and a recently proposed method that exploits global priors, which we refer to as GP <ref type="bibr" target="#b22">[23]</ref>. We also include comparisons with the state-of-the-art 2D saliency algorithms DRFI <ref type="bibr" target="#b13">[14]</ref> and DSR <ref type="bibr" target="#b16">[17]</ref>, which were found to be top ranking methods by a recent study <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Evaluation Metrics</head><p>We present the precision-recall curve and mean F-score to evaluate algorithm performance. The F-score is computed from the saliency output using an adaptive threshold equal to twice the mean of the image <ref type="bibr" target="#b0">[1]</ref>. Note that the Fscore is calculated as:</p><formula xml:id="formula_16">F β = (1 + β 2 ) × P recision × Recall β 2 × P recision + Recall<label>(13)</label></formula><p>where β = 0.3 to weigh precision more than recall <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Experimental Setup</head><p>We set n = 32 histogram bins and m = 10 evaluation steps in our implementation of F and G respectively. These two values were found to provide a good trade-off between accuracy and efficiency for general use. The radius of the neighbourhood N P should be set to equal the expected radius of the largest object to detect, thus we set it to half the image diagonal for general use. We use SLIC <ref type="bibr" target="#b1">[2]</ref> on the colour image to generate the set of patches, with the num-ber of patches set to the length of the diagonal of the image in pixels.</p><p>Our saliency method has one parameter -the threshold α 0 used to generate the foreground mask for Grabcut initialisation. We empirically set this to α 0 = 0.8 in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Results</head><p>The LBE feature outperforms the contrast-based depth features used in state-of-the-art systems <ref type="figure">(Figures 5a and 5b)</ref>. The performance of the depth features of GP and LMH is significantly improved when excluding patches with lower depth than the candidate patch during contrast computation. It can also be seen that using the distribution function gives improved results compared to using the density functions evaluated at a fixed threshold t. <ref type="figure">Figures 5c and 5d</ref> show the increase in performance from applying priors and Grabcut segmentation to the LBE feature.</p><p>Compared to contrast-based depth features, the LBE feature reduces false negatives when the foreground has relatively low depth contrast <ref type="figure">(Figure 7 rows 1-2)</ref>, and decreases false positives from high background contrast <ref type="figure">(Figure 7</ref> rows 3-5). <ref type="figure">Figure 6</ref> shows that our saliency system outperforms all  <ref type="figure">Figure 7</ref>. Comparison of the raw LBE feature with depth contrast-based features ACSD <ref type="bibr" target="#b14">[15]</ref>, GP-D and GP-SD <ref type="bibr" target="#b22">[23]</ref>, and LMH-D and LMH-SD <ref type="bibr" target="#b21">[22]</ref>. The last row displays a failure case.</p><p>other state-of-the-art RGB-D salient object detection systems. Our saliency system achieves the highest F-score on both datasets, with GP obtaining the second best performance. In addition to the highest F-score, our method exhibits the highest recall among the depth based methods on both datasets, reflecting the fact that our depth feature correctly identifies a greater portion of the foreground compared to contrast-based methods. From <ref type="figure">Figure 6a</ref> we see that our method has the highest PR curve on RGBD1000. <ref type="figure">Figure 6b</ref> shows that our system has high precision up to around 0.65 recall, with superior performance in the region of high precision. This demonstrates that our feature is able to identify salient structure from depth more effectively than existing contrast-based methods. With the exception of DRFI on RGBD1000, the RGB methods perform worse than most depth-aware methods. <ref type="figure">Figure 8</ref> shows the output of our salient detection system compared with state-of-the-art methods. Note that the other methods tend to have a high number of false positives due to depth contrast in background regions, for example depth change across a flat table is registered as salient by ACSD in the second row. The angular statistics employed by our depth feature provide a more robust measure of salient structure.</p><p>Failure Cases Since our method measures pop-out structure, it does not produce good results when the salient object is surrounded in all directions by background with lower depth. An example is shown in <ref type="figure">Figure 7</ref> row 6. This is a rare occurrence, and the other depth saliency methods with the exception of GP-D also produce poor results in this case. In these situations, it is questionable whether the object can be considered to be salient. Note that GP-D produces the best results in this image because it does not assume that salient objects are in front of the background, however this leads to poor performance on the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we have proposed a novel depth feature that exploits depth background enclosure to detect salient objects in RGB-D images. We incorporate this feature into a salient object detection system using depth prior, spatial prior, and Grabcut refinement. Our approach out-performs existing methods on two publicly available RGB-D salient object detection datasets. (f) ACSD <ref type="bibr" target="#b14">[15]</ref> (g) LMH <ref type="bibr" target="#b21">[22]</ref> Figure 8. Comparison of output saliency maps produced by our salient object detection system against the output of GP <ref type="bibr" target="#b22">[23]</ref>, ACSD <ref type="bibr" target="#b14">[15]</ref>, and LMH <ref type="bibr" target="#b21">[22]</ref>. Our LBE depth feature allows for a more accurate final saliency map compared to methods using contrast-based depth features. Note that G. T. denotes Ground Truth.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Illustration of the background enclosure feature evaluated on the depth image from Figure 1. (a) The density functions computed at image locations marked by the green points with neighbourhood boundaries marked by dotted lines. The blue fill denotes angular regions containing points with greater depth than t = σ/2 from the center depth, with the maximum gap between these regions marked in red. The values of the angular density component f , the angular gap component g, and saliency s = f · (1 − g) for t = σ/2 are marked. (b) The distribution functions F , G, and final LBE saliency S = F · G at each point.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Overview of our saliency detection system. Given an RGB-D image and superpixel segmentation, we first compute our Local Background Enclosure feature, then apply depth, spatial, and background priors, and finally refine the result using Grabcut segmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .Figure 6 .</head><label>56</label><figDesc>PR curves showing performance of LBE feature against contrast-based depth features on (a) RGBD1000 and (b) NJUDS2000. PR curves showing the effect of each component of the saliency system on (c) RGBD1000 and (d) NJUDS2000. P and GC refer to prior application and Grabcut refinement respectively. Quantitative comparisons of performance over NJUDS2000 dataset. PR curve of our saliency system against state-of-theart RGB-D saliency systems on (a) RGBD1000 and (b) NJUDS2000. F-measure of the different systems on (c) RGBD1000 and (d) NJUDS2000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Truth (d) LBE (Ours) (e) ACSD<ref type="bibr" target="#b14">[15]</ref> (f) GP-D<ref type="bibr" target="#b22">[23]</ref> (g) GP-SD<ref type="bibr" target="#b22">[23]</ref> (h) LMH-D<ref type="bibr" target="#b21">[22]</ref> (i) LMH-SD<ref type="bibr" target="#b21">[22]</ref> </figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Frequency-tuned salient region detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hemami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Estrada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Susstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1597" to="1604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">SLIC superpixels compared to state-of-the-art superpixel methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Susstrunk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2274" to="2282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Salient object detection: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5706" to="5722" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adaptive 3d rendering based on region-of-interest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chamaret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Godeffroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">Le</forename><surname>Meur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IS&amp;T/SPIE Electronic Imaging, pages 75240V-75240V. International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Depth information fused salient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIMCS</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="66" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Efficient salient region detection with soft image abstraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Warrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Crook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1529" to="1536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Global contrast based salient region detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-M</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="409" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Depth enhanced saliency detection method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIMCS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Depth really matters: Improving visual salient region detection with depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Desingh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jawahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A novel multiresolution spatiotemporal saliency detection model and its applications in image and video compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="185" to="198" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Salient object detection in RGB-D image based on saliency fusion and propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIMCS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="1" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A model of saliency-based visual attention for rapid scene analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Niebur</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1254" to="1259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Saliency detection via absorbing markov chain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1665" to="1672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Salient object detection: A discriminative regional feature integration approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2083" to="2090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Depth saliency based on anisotropic center-surround difference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Depth matters: Influence of depth cues on visual saliency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Katti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yadati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kankanhalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="101" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Saliency detection via dense and sparse reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Image retargeting using depth enhanced saliency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-R</forename><surname>Chen</surname></persName>
		</author>
		<idno>3DSA2013</idno>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Saliency-based discriminant tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1007" to="1013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Saliency segmentation based on learning and graph cut refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mehrani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Leveraging stereopsis for saliency analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="454" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Rgbd salient object detection: a benchmark and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="92" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploiting global priors for RGB-D saliency detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPRW</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Saliency detection for rgbd images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIMCS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">72</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Depth incorporating with color improves salient object detection. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Quantifying center bias of observers in free viewing of dynamic natural scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-H</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Carmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">G</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Munoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Stereoscopic visual attention model for 3d video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Multimedia Modeling</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="314" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Saliency optimization from robust background detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2814" to="2821" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
