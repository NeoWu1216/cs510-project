<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ReD-SFA: Relation Discovery Based Slow Feature Analysis for Trajectory Clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Zhang</surname></persName>
							<email>zzhang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CRIPAC &amp; NLPR</orgName>
								<orgName type="department" key="dep2">Institute of Automation</orgName>
								<orgName type="laboratory">Centre for Quantum Computation and Intelligent Systems</orgName>
								<orgName type="institution" key="instit1">Chinese Academy of Sciences</orgName>
								<orgName type="institution" key="instit2">University of Technology Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiqi</forename><surname>Huang</surname></persName>
							<email>kqhuang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CRIPAC &amp; NLPR</orgName>
								<orgName type="department" key="dep2">Institute of Automation</orgName>
								<orgName type="laboratory">Centre for Quantum Computation and Intelligent Systems</orgName>
								<orgName type="institution" key="instit1">Chinese Academy of Sciences</orgName>
								<orgName type="institution" key="instit2">University of Technology Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CRIPAC &amp; NLPR</orgName>
								<orgName type="department" key="dep2">Institute of Automation</orgName>
								<orgName type="laboratory">Centre for Quantum Computation and Intelligent Systems</orgName>
								<orgName type="institution" key="instit1">Chinese Academy of Sciences</orgName>
								<orgName type="institution" key="instit2">University of Technology Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peipei</forename><surname>Yang</surname></persName>
							<email>ppyang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CRIPAC &amp; NLPR</orgName>
								<orgName type="department" key="dep2">Institute of Automation</orgName>
								<orgName type="laboratory">Centre for Quantum Computation and Intelligent Systems</orgName>
								<orgName type="institution" key="instit1">Chinese Academy of Sciences</orgName>
								<orgName type="institution" key="instit2">University of Technology Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Li</surname></persName>
							<email>jun.li@uts.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CRIPAC &amp; NLPR</orgName>
								<orgName type="department" key="dep2">Institute of Automation</orgName>
								<orgName type="laboratory">Centre for Quantum Computation and Intelligent Systems</orgName>
								<orgName type="institution" key="instit1">Chinese Academy of Sciences</orgName>
								<orgName type="institution" key="instit2">University of Technology Sydney</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ReD-SFA: Relation Discovery Based Slow Feature Analysis for Trajectory Clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For spectral embedding/clustering, it is still an open problem on how to construct an relation graph to reflect the intrinsic structures in data. In this paper, we proposed an approach, named Relation Discovery based Slow Feature Analysis (ReD-SFA), for feature learning and graph construction simultaneously. Given an initial graph with only a few nearest but most reliable pairwise relations, new reliable relations are discovered by an assumption of reliability preservation, i.e., the reliable relations will preserve their reliabilities in the learnt projection subspace. We formulate the idea as a cross entropy (CE) minimization problem to reduce the discrepancy between two Bernoulli distributions parameterized by the updated distances and the existing relation graph respectively. Furthermore, to overcome the imbalanced distribution of samples, a Boosting-like strategy is proposed to balance the discovered relations over all clusters. To evaluate the proposed method, extensive experiments are performed with various trajectory clustering tasks, including motion segmentation, time series clustering and crowd detection. The results demonstrate that ReD-SFA can discover reliable intra-cluster relations with high precision, and competitive clustering performance can be achieved in comparison with state-of-the-art.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Trajectory clustering provides benefits for many vision tasks, such as motion segmentation <ref type="bibr" target="#b23">[24]</ref>, object detection <ref type="bibr" target="#b3">[4]</ref>, action recognition <ref type="bibr" target="#b30">[31]</ref> and scene modeling <ref type="bibr" target="#b31">[32]</ref>. As trajectories often lie in a low dimensional subspace, spectral methods have been widely used, where trajectories will be firstly embedded into a low dimensional feature space before clustering. However, it is still an open problem to construct an appropriate relation graph by which the intrinsic structures in data can be well encoded.</p><p>With original (x, y) sequence representation of trajectories, the most straightforward way to construct relation graph is to calculate the distance (e.g., Euclidian distance) between all pairs of samples, and remain a number of pairwise relations with the smallest distances through K nearest neighbor (K-NN) criterion or ε-ball neighbor criterion. However, it is difficult to capture the true reliable relations by setting a constant k or ε for all samples and different datasets. A large k or ε may induce wrong relations due to the high dimensionality and variant distribution densities of samples, while a small one may miss true relations.</p><p>From another aspect, if efficient features can be extracted in advance, it will be much easier to construct reliable relation graph. For trajectory clustering, some hand-crafted features, such as velocity <ref type="bibr" target="#b7">[8]</ref> and high-order derivatives <ref type="bibr" target="#b13">[14]</ref>, have been adopted before graph construction. Thus, it may be better to do feature learning and relation discovery jointly, instead of the one-step graph construction.</p><p>In this paper, given a small number of initial reliable relations which can be obtained by selecting the nearest neighborhood relations in original space X, we will discover new relations with ε-ball neighbor criterion in the low dimensional feature space Y , where the ε can be estimated by an assumption of reliability preservation, i.e., the reliable relations will preserve their reliabilities in the feature space.</p><p>The process is illustrated in <ref type="figure" target="#fig_0">Fig.1</ref>. The left two figures show the data samples of two clusters (denoted by blue and green stars) in original space X, and the dash line indicates the projection direction learnt by the current relations (red links). In projection space Y (right figures), some pairwise relations are enhanced greatly, as their distances in feature space Y are even smaller than the distances of some initial reliable relations. Thus, the enhanced relations can be discovered as new reliable relations based on which the projection direction can be further corrected (left bottom). With such progress, the samples of intra-cluster will be concen- In this work, we proposed ReD-SFA to jointly construct relation graphs and learn features, where Slow Feature Analysis (SFA) <ref type="bibr" target="#b33">[34]</ref> is chosen as the basic feature learning algorithm. In summary, the efforts of this paper include:</p><p>• The idea of joint graph construction and feature learning is formulated as a problem of cross entropy minimization, which aims to reduce the discrepancy between two Bernoulli distributions parameterized by the updated distances and the relation graph respectively.</p><p>• For efficient optimization, the original objective function is relaxed to its upper bound, so that the solution is well compatible with the GSFA. Furthermore, all parameters can be selected automatically.</p><p>• Furthermore, to overcome the problem of imbalance distribution of data samples, a Boosting-like strategy is proposed to improve the balance of discovered relations over different clusters.</p><p>• Extensive experiments are performed with various clustering tasks, e.g., motion segmentation, time series clustering and crowd detection. The competitive performance demonstrates the effectiveness of ReD-SFA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>For spectral based trajectory clustering, the primary problem is how to construct the affinity graph to measure the pairwise relations between trajectories. In previous work, there are mainly two kinds of methods on the problem: similarity based methods and learning based methods.</p><p>For similarity based methods <ref type="bibr" target="#b3">[4]</ref> [21], the similarities between all pairs of trajectories need to be calculated based on original trajectories or other trajectory features. Various hand-crafted features, e.g., velocity <ref type="bibr" target="#b3">[4]</ref> [8] <ref type="bibr" target="#b37">[38]</ref>, high order motion models <ref type="bibr" target="#b13">[14]</ref>  <ref type="bibr" target="#b20">[21]</ref>, and Principle Components Analysis (PCA) coefficients <ref type="bibr" target="#b0">[1]</ref>, are proposed. Another impor-tant issue is to design a good similarity metric, especially to overcome the problem of trajectories with varying lengths and misalignment. The commonly used similarity metrics include Euclidean distance <ref type="bibr" target="#b0">[1]</ref>, Hausdorff distance <ref type="bibr" target="#b14">[15]</ref>, Dynamic Time Warping (DTW) <ref type="bibr" target="#b17">[18]</ref>, and Edit Distance on Real sequence (EDR) <ref type="bibr" target="#b6">[7]</ref>, etc. A comparison on different similarity metrics can be found in <ref type="bibr" target="#b35">[36]</ref>.</p><p>For learning based methods, the subspace segmentation (clustering) <ref type="bibr" target="#b34">[35]</ref>  <ref type="bibr" target="#b10">[11]</ref> [20] <ref type="bibr" target="#b23">[24]</ref> have achieved impressive performance for point trajectory clustering. In their work, one step of subspace recovery is performed firstly, where each trajectory is reconstructed by other samples based on self-expressiveness property <ref type="bibr" target="#b10">[11]</ref>. Then, the sparse coefficients are used to build the affinity matrix for subsequent spectral clustering. The main challenge is how to handle the noises in trajectories <ref type="bibr" target="#b19">[20]</ref>. For this problem, variant algebraic regularization terms, such as affine projection <ref type="bibr" target="#b34">[35]</ref>, agglomerative lossy compression (ALC) <ref type="bibr" target="#b23">[24]</ref>, low rank <ref type="bibr" target="#b19">[20]</ref>, sparse <ref type="bibr" target="#b10">[11]</ref>, and epipolar constraint <ref type="bibr" target="#b16">[17]</ref>,has been proposed. Recently, Wang et.al, <ref type="bibr" target="#b32">[33]</ref> combined sparse and low rank constraint to promote the robustness of subspace clustering.</p><p>Our work is close to the manifold clustering methods, such as LLMC <ref type="bibr" target="#b15">[16]</ref> and SMCE <ref type="bibr" target="#b9">[10]</ref>, which try to find relations and a projection to a lower-dimensional space of data. Different with the work which adopted local linear assumption to learn neighbor weights in original space, we discover reliable relations in feature space iteratively. Our work is also related to information theoretic based subspace models <ref type="bibr" target="#b8">[9]</ref>[27] which adopted mutual information metric to measure the divergence between class labels and transformed features. While, this work focuses on unsupervised learning with a problem of cross entropy minimization.</p><p>In this work, SFA is adopted to learn trajectory features. SFA has been used for unsupervised invariance learning in visual neural cell modeling <ref type="bibr" target="#b33">[34]</ref>  <ref type="bibr" target="#b2">[3]</ref> and feature extraction in pattern recognition, e.g., digit recognition <ref type="bibr" target="#b1">[2]</ref>, scene classification <ref type="bibr" target="#b25">[26]</ref>, behavior recognition <ref type="bibr" target="#b36">[37]</ref>  <ref type="bibr" target="#b24">[25]</ref>. In <ref type="bibr" target="#b11">[12]</ref> the SFA is generalized from temporal sequences to relation graphs for supervised dimensionality reduction. Here, we will extend the GSFA to unsupervised clustering based on joint relation discovery and feature learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ReD-SFA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem definition and initialization</head><p>Given a collection of data points X = [x 1 , ..., x n ] for x i ∈ R d , ReD-SFA will learn a projection matrix P = [p 1 , ..., p c ] and construct a relation graph composed of a Boolean matrix ∆ = δ i j and a real value matrix W = w i j simultaneously, so that P ⊤ x i (∈ R c ) is the intrinsic low-dim representation of x i , δ i j ∈ {1, 0} indicates whether the relation of the ith sample and the jth one can be measured by l i j = ||P ⊤ x i − P ⊤ x j || 2 reliably or not, and w i j ∈ [0, 1] denotes the confidence degree of δ i j .</p><p>At initialization, only the first m nearest relations in original space are set to 1 in ∆ 0 , otherwise 0. W 0 is set as follows, while the superscript 0 denotes the initial stage,</p><formula xml:id="formula_0">w 0 i j =    e −l 0 i j 2 /t , δ 0 i j = 1, 1 − e −l 0 i j 2 /t , δ 0 i j = 0.<label>(1)</label></formula><p>where l 0 i j = ||x i − x j || 2 and t is a scale factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Objective function</head><p>Assuming a Boolean variable r i j ∈ {1, 0} indicates the intra-cluster relation or not between x i and x j , which can be modeled with a Bernoulli distribution described by l i j in feature space as well as another Bernoulli distribution based on w i j in relation graph, the ReD-SFA aims to reduce the discrepancy between the two distributions. Thus a cross entropy (CE) based objective function is adopted as follows.</p><formula xml:id="formula_1">min n ∑ i, j,i = j H f w i j , f l i j (2)</formula><p>The cross entropy H f w i j , f l i j (abbreviated by H i j ) is calculated <ref type="bibr" target="#b18">[19]</ref>:</p><formula xml:id="formula_2">H i j = − ∑ r i j ∈{1,0} f w i j (r i j ) ln f l i j (r i j ),<label>(3)</label></formula><p>where the Bernoulli distribution f l i j (r i j ) is defined as:</p><formula xml:id="formula_3">f l i j (r i j ) = B l i j r i j (1 − B l i j ) 1−r i j = δ i j Pr(r i j = 1; l i j , δ i j = 1) + (1 − δ i j )Pr(r i j = 1; l i j , δ i j = 0) r i j δ i j Pr(r i j = 0; l i j , δ i j = 1) + (1 − δ i j )Pr(r i j = 0; l i j , δ i j = 0) 1−r i j (4) We define Pr(r i j = 1; l i j , δ i j = 1) = 1 2 + 1 2 e −l 2</formula><p>i j to be larger than <ref type="bibr" target="#b0">1</ref> 2 with the assumption of local consistency <ref type="bibr" target="#b38">[39]</ref>, i.e.,nearby points are likely to have the same cluster label. Otherwise, δ i j = 0 means the distance l i j is too far to measure the reliability, thus Pr(</p><formula xml:id="formula_4">r i j = 1; l i j , δ i j = 0) is decided by a threshold ε as 1 2 − 1 2 e −ε 2 which is smaller than 1 2 . Similarly, we can define f w i j (r i j ) with the type of E- q.4, where Pr(r i j = 1; w i j , δ i j = 1) = 1 2 + 1 2 w i j and Pr(r i j = 1; w i j , δ i j = 0) = 1 2 − 1 2 w i j .</formula><p>With the above definitions, Eq.2 can be summarized as a function of P, ∆ and W. In the optimization, however, it is very complex to compute the derivative of P directly, due to the logarithmic term. For efficiency, an auxiliary variable η &lt; 1 2 is introduced, so that 1 2 + 1 2 e −x 2 is approximated by <ref type="bibr" target="#b0">1</ref> </p><formula xml:id="formula_5">2 + 1 2 − η e −x 2 and 1 2 − 1 2 e −x 2 is replaced by 1 2 − 1 2 − η e −x 2 . S- ince − ln 1 2 + 1 2 − η e −x 2 ≤ − ln (1 − η) e −x 2 and − ln 1 2 − 1 2 − η e −x 2 ≤ − ln ηe −x 2 , H i j in Eq.3 can be relaxed to the upper bound function J i j , J i j =δ i j w i j ||P ⊤ x i − P ⊤ x j || 2 2 + (1 − δ i j w i j )ε 2 + w i j ln η 1 − η − ln η(1 − η).<label>(5)</label></formula><p>Detailed derivations are shown in supplemental materials. Additionally, one regularization term is added to avoid</p><formula xml:id="formula_6">the divergence from initial W 0 , i.e., J W i j = w i j − w 0 i j 2 .</formula><p>Thus, the final objective function is as follows:</p><formula xml:id="formula_7">min P,∆,W n ∑ i, j,i = j λ J i j + (1 − λ )J W i j (6) where λ is a trade-off parameter in [0, 1].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Optimization</head><p>Step 1: Given ∆ and W, Eq.6 can be transformed into</p><formula xml:id="formula_8">min n ∑ i, j,i = j λ δ i j w i j Tr P ⊤ x i − P ⊤ x j P ⊤ x i − P ⊤ x j ⊤ . (7)</formula><p>As presented in GSFA <ref type="bibr" target="#b11">[12]</ref>, P can be optimized by solving the generalized eigenvalue problem,</p><formula xml:id="formula_9">AP = τBP<label>(8)</label></formula><p>where the derivative covariance matrix A is calculated as:</p><formula xml:id="formula_10">A = 1 R n ∑ i, j,i = j λ δ i j w i j (x i − x j ) (x i − x j ) ⊤ (9) with R = ∑ n i, j,i = j λ δ i j w i j .</formula><p>And the matrix B is as:</p><formula xml:id="formula_11">B = 1 V n ∑ i=1 λ v i (x i −x) (x i −x) ⊤ (10) where V = ∑ n i=1 v i with v i = ∑ n j=1 λ δ i j w i j ,</formula><p>andx is the mean value of all data samples.</p><p>Step 2: Given P and W, δ i j can be simply updated with the following rule:</p><formula xml:id="formula_12">δ i j = 1, l i j ≤ ε, 0, Otherwise.<label>(11)</label></formula><p>where the ε should remain most initial relations δ 0 i j = 1 still reliable in the feature space. Meanwhile, it should be tight enough to avoid noise relations. The selection of ε will be discussed in the next section.</p><p>Step 3: Given ∆ and P, the optimization of w i j can be obtained by calculating the first derivative for each w i j , then let it equal to zero.</p><formula xml:id="formula_13">w i j =    w 0 i j + λ 2(1−λ ) ε 2 − l 2 i j + ln 1−η η , δ i j = 1; w 0 i j + λ 2(1−λ ) ln 1−η η , δ i j = 0. (12) Note, w i j should be limited in the range of [0, 1].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Selection of parameters 3.4.1 Selection of ε</head><p>In this work, ε indicates the threshold of reliable distances in feature space. As shown in Eq.11, a pairwise relation will be considered to be reliable, if the distance is smaller than ε. According to the assumption of reliability preservation, ε is estimated as the percentile of a very high percentage (e.g. 98th percentile), given the distribution of reliable relations.</p><p>Here, we find the reliable relation set L = l i j |δ i j = 1 can be well modeled by alpha-stable distribution. <ref type="figure" target="#fig_1">Figure  2</ref>(a) shows one example of the histogram of distances on a trajectory set in Hopkins 155 dataset <ref type="bibr" target="#b27">[28]</ref>. The distribution has a typical heavy right tail which cannot be modeled by common normal distribution.</p><p>Thus, we firstly estimate the alpha-stable distribution with the set L, after the optimization of P at each round. Then, ε is calculate as the percentile value of a given very high percentage q, i.e.,</p><formula xml:id="formula_14">ε = Percentile (q|α, β , γ, µ)<label>(13)</label></formula><p>where, α, β , γ and µ are the four parameters in alpha-stable distribution. α ∈ (0, 2] describes the tail of the distribution. β ∈ [−1, 1] is the skewness. The last two parameters are the scale γ &gt; 0, and the location µ ∈ R, which are similar to the variance and mean in normal distribution. Here, a toolbox <ref type="bibr" target="#b28">[29]</ref> is used for the estimation of alpha-stable distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Selection of λ and η</head><p>In Eq.6, λ controls the balance between J i j and J W i j . And η controls the increment speed of w i j in Eq.12. Here, instead of setting a constant value λ and η over all relations empirically, the two parameters are set for each relation individually. The priors come from the contextual information of a given sample pair. For the ith sample and the jth </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 ReD-SFA Algorithm</head><p>Require: ∆ 0 , W 0 , X Ensure: P, ∆, W 1: ∆ = ∆ 0 , W = W 0 and Calculate λ , η with Eq.14 and Eq.15 2: Calculate J with Eq.6 3: while 1 do 4:</p><p>Update P with GSFA <ref type="bibr" target="#b32">[33]</ref> to solve the problem in Eq. 7 <ref type="bibr">5:</ref> Estimate ε with Eq.13 <ref type="bibr">6:</ref> Update δ i j , where δ i j ∈ ∆ with Eq.11 <ref type="bibr">7:</ref> Update W with Eq. 12 <ref type="bibr">8:</ref> Calculate new J ′ with Eq.6 9:</p><p>if J &lt; J ′ then sample, as the increasing of the number of shared reliable neighborhoods, the relation r i j is more likely to be reliable, so that it should favor more weight to J i j and a higher increment speed of w i j . Based on the above idea, λ i j and η i j are determined as follows.</p><formula xml:id="formula_15">λ i j = z s i j z t i j e − z t z t i j<label>(14)</label></formula><formula xml:id="formula_16">η i j = 1 2 1 − z s i j z t i j e − z t z t i j<label>(15)</label></formula><p>where z s i j is the number of shared neighborhoods, i.e., z s i j = ∑ k,k =i, j δ 0 ik ∧ δ 0 k j , and z t i j is the total number of reliable neighborhoods, i.e., z t i j = ∑ k,k =i, j δ 0 ik ∨ δ 0 k j , and z t is the mean value over all pairs of samples. As z t i j = 0, a small value is set to λ i j and η i j , e.g., <ref type="bibr" target="#b0">1</ref> n . Finally, the ReD-SFA is summarized in Alg.1. <ref type="figure" target="#fig_1">Figure 2(b)</ref> shows an instance on how the objective function changes with respect to the number of iterations. In our experiments, the ReD-SFA usually halts within 5 iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Boosting ReD-SFA</head><p>As presented above, ReD-SFA discovers reliable relations based on a few nearest neighborhoods. However, due to the imbalanced distribution of densities among different clusters, the initial reliable relations may be from only highdensity clusters. In such case, the relations discovered by ReD-SFA will not cover all clusters.</p><p>To address this problem, we adopt the idea of boosting learning to run the ReD-SFA in several rounds to discover relations from all clusters. At each new round of ReD-SFA, the data samples uncovered in previous rounds are selected out to form a candidate set Φ. Then, the ReD-SFA is implemented only over the pairwise relations in Φ. Finally, all the discovered relations are gathered to form the final relation graph and the GSFA is performed again to obtain the final feature representation. <ref type="figure" target="#fig_3">Figure 3</ref> shows an example of the implementation process of boosting ReD-SFA, where the trajectories covered by the discovered relations in each run of ReD-SFA (the last three sub-figures) are labeled as red color. Besides, the statistics of the discovered relations in each round are presented in the table. The high precisions (Prec. = True/Total) indicate that most discovered relations are intra-cluster relations. The imbalance distributions of the relation discovery over the three clusters are also shown in the last row (Ground Truth), where the cluster "C1" has a much small proportion (only 2%) over the total intra-cluster relations, while the cluster "C3" is the most prevalent one. As shown in the figure, the first run of ReD-SFA concentrates on the cluster "C3", because the initial relations are mainly on this cluster (the second sub-figure from left), the second round is mainly for the cluster "C2", and so on. The multiple runs of ReD-SFA improve the balance of the discovered relations. The right bottom figure shows the final feature representation, where the well-separated clusters can be easily grouped by simple clustering algorithms, e.g., K-means.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Motion segmentation on Hopkins 155 dataset</head><p>The Hopkins 155 dataset <ref type="bibr" target="#b27">[28]</ref> has become a standard benchmark to evaluate trajectory clustering algorithms. The dataset provides 155 trajectories sets with 2 or 3 motion categories as well as the ground truth of all trajectories.</p><p>Both parameters of ReD-SFA are percentage type. One is m which denotes the first m nearest relations are selected in initial graph, the other is q indicating the percentile threshold ε for relation discovery. In this work, m ranges from 1% to 10%, q ranges from 92% to 99%. Furthermore, PCA is performed as preprocessing, like in SFA <ref type="bibr" target="#b33">[34]</ref> and GSFA <ref type="bibr" target="#b11">[12]</ref>. For all sets, the dimensionality of PCA is set to 9, and the final is further reduced to 3 after ReD-SFA.</p><p>To better understand the properties of the ReD-SFA on relation discovery and feature learning, we pick out 20 trajectory sets with three motions for a set of controlled tests. On this set, GSFA and ReD-SFA are performed with the same initial relation graph in terms of the first m nearest pairwise relations. <ref type="figure" target="#fig_4">Fig.4</ref> shows the clustering errors of GS-FA and ReD-SFA over the 20 sets along with different m values, where q is fixed to 95%. From the two figures, it is not surprised that the overall errors of ReD-SFA are much lower than that of GSFA, where the blue colors denote low errors (it is better shown in color). Furthermore, for GSFA, the necessary percentages of initial relations to obtain low errors are also variant. For example, the 7th set needs at least 8% to obtain a low error rate, and the 16th set needs above 10%. Thus, the sensitivity to m makes GSFA difficult to set a constant value over all sets. While for ReD-SFA, it achieves lower errors only using small m values with the helps of relation discovery.</p><p>We find on the 18th set, the clustering errors of GSFA over all m values are very high (around 40% displayed by orange color), while for ReD-SFA, the errors are very low (below 10%) with only small number of initial relations. Thus, we further analyze the discovered relations on the set. Based on the ground truth (labels) of trajectories, we check whether each relation discovered by the ReD-SFA is intra-   cluster relation or not. The statistical results are presented in <ref type="table">Table 1</ref>, where the precision (Prec.) and recall (Rec.) are defined as</p><formula xml:id="formula_17">Prec. = T P.Num. Total.D.Num ,<label>(16)</label></formula><formula xml:id="formula_18">Rec. = T P.Num. GroundTruth ,<label>(17)</label></formula><p>where T P.Num means the number of true positives, Total.D.Num is the total number of discovered relations. Besides the overall recall values, the recall values on the three clusters are also reported indivally. Since we do not distinguish the cluster labels of discovered relations, we only show the overall precisions. From <ref type="table">Table 1</ref>, we find that all initial relations are reliable intra-cluster relations in the three initial settings with m = 1%, 3%, 5% (Precision is 100%). However, the distribution of initial relations is very imbalance on the three clusters. The very little amount of relations in the 1st cluster (the recall is only 2.09% with m = 3%) will make the features of this cluster disperse in a large scale after the GSFA learning, shown with red points in the left of <ref type="figure" target="#fig_5">Figure 5</ref>. It explains the high errors of GSFA While since the Boostinglike relation discovery, the recall values of all clusters can be improved greatly, especially on the 1st cluster (from 2.09% to 67.31% as m = 3%), so that the features learnt by ReD-SFA are more centralized according to individual clusters (right in <ref type="figure" target="#fig_5">Fig. 5</ref>). <ref type="figure" target="#fig_6">Figure 6</ref> presents the average errors of GSFA and ReD-SFA over all 155 sets with different m and q values. Besides ε-ball initialization, denoted by 1, we also test k-NN initialization denoted by 2. From the figure, the performance of the GSFA with k-NN initialization is clearly better than εball initialization, because the k-NN initialization provides more balanced distribution of initial relations. However, k-NN initialization trends to introduce noise relations (intercluster relations) as the increasing of m. The initial noise relations will lead to a larger ε in relation discovery, which may introduce more noise relations in later stage. Thus, the performance of ReD-SFA with k-NN initialization (black circle) is worse than that of ε-ball initialization (red star).</p><p>Compared to state-of-the-art methods, <ref type="table">Table 2</ref> shows the average errors over the entire dataset. The compared methods include GPCA <ref type="bibr" target="#b29">[30]</ref>, ALC <ref type="bibr" target="#b23">[24]</ref>, SSC <ref type="bibr" target="#b10">[11]</ref>, SCC <ref type="bibr" target="#b5">[6]</ref>, L-RR <ref type="bibr" target="#b19">[20]</ref>, RV <ref type="bibr" target="#b16">[17]</ref>, LLMC <ref type="bibr" target="#b15">[16]</ref> and SMCE <ref type="bibr" target="#b9">[10]</ref>. From the table, the recent work on the dataset has achieved very low errors (below to 1%). However, these results are achieved with specifical designs for 3D affine motion models or some additional pre/post-processing. Overall, ReD-SFA is still competitive with previous methods.</p><p>We also test the computational times on the Hopkins 155 dataset. On average, there are 296 trajectory samples per set. The average number of frames per trajectory is 29. The average time costs per trajectory of ReD-SFA as well as several classical approaches are shown in <ref type="table">Table 1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Time series clustering on CC Dataset</head><p>In this section, we will test ReD-SFA with a more general time series clustering task. The synthetic control charts (CC) dataset contains 600 1D samples <ref type="bibr" target="#b21">[22]</ref> for time series classification and indexing. There are six classes: normal, cyclic, increasing trend, decreasing trend, upward shift, and downward shift. Each class has 100 samples, and the dimensionality of each sample is 60. Some samples are illustrated in <ref type="figure">Figure 7</ref>, where misalignment widely occurs in intra-class trajectories. We use the first 2, 3, 4, 5 and all 6 classes data to do clustering 5 times. For comparison, we implement a DTW based spectral clustering method <ref type="bibr" target="#b35">[36]</ref>, two subspace clustering algorithms, i.e., LRR <ref type="bibr" target="#b19">[20]</ref> and SS-C <ref type="bibr" target="#b10">[11]</ref>, and a manifold clustering algorithm, SMCE <ref type="bibr" target="#b9">[10]</ref>. For ReD-SFA, LRR and SSC, PCA is firstly performed and the first 9 principle components are remained. For SMCE, we run the algorithm with the parameter setting of k = 10 (maximum neighbor size), λ = 10 (trade-off parameter). <ref type="table" target="#tab_2">Table 4</ref> presents the errors of different clustering methods. The two subspace clustering methods cannot achieve satisfying results. LRR fails to recover correct subspaces in all clustering tasks. SSC is much better than LRR in 2 and 3 classes, however it still cannot achieve good performance, as more classes are involved. That is mainly because the assumption of global linear relationship among data, i.e., "self-expressiveness" property, widely adopted in subspace clustering is restrictive to the large misalignment. While, the SMCE and the ReD-SFA based on local neighbor relationships are more reliable in general case and thus obtain better performance. As more classes (5 and 6 classes), ReD-SFA achieves lower errors than SCME due to the high precision of relation discovery. DTW shows impressive clustering results, due to its superior capability to correct the misalignment. Compared to these methods, ReD-SFA achieves much better results than subspace learning based methods, and similar with DTW, which demonstrates the effectiveness of ReD-SFA on the general time series clustering task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Crowd detection on CUHK Crowd Dataset</head><p>In this section, we test ReD-SFA with crow detection task in numerous and varied scenes. The CUHK crowd dataset <ref type="bibr" target="#b22">[23]</ref> includes 474 crowd videos with various densities and perspective scales from many different surveillance environments. In <ref type="bibr" target="#b37">[38]</ref>  <ref type="bibr" target="#b22">[23]</ref>, coherent crowd motion patterns are detected by tracklets clustering, where tracklets from 300 video clips are manually annotated into groups for evaluation. Some samples are illustrated in the last column of <ref type="figure">Fig.9</ref>, where the tracklets indicated by the same color and marker form one crowd group and the outliers that do not belong to any groups are indicated by red plus.</p><p>For each frame, a set of tracklets with the same length is selected by a sliding window. Then, ReD-SFA is performed to discover the reliable intra-cluster relations among tracklets. Finally, a number of crowd groups are identified as the connected components in the relation matrix ∆, where the groups with size of less than 3 are deemed as outliers.</p><p>Here, to reduce the serious effects of outliers often occurring in real world scenes, we adopt a priori on crowd motion, coherent neighbor invariance (CNI) in <ref type="bibr" target="#b37">[38]</ref>, and restrict the relation discovery of ReD-SFA only from the coherent neighbors. With the prior, coherent neighbors a- mong tracklets are those spatial neighborhood relationships persevered in several consecutive frames. The details on CNI can refer to <ref type="bibr" target="#b37">[38]</ref>. In their work, crowd groups are determined through coherent filtering (CF) which removes the unreliable relations with low velocity correlations in coherent neighbors. Different from CF <ref type="bibr" target="#b37">[38]</ref> which explicitly calculates the velocity correlation distance with strong priors on crowd groups, ReD-SFA learns tracklet features automatically based on original x-y coordinates. As the number of crowd groups is assumed unknown in <ref type="bibr" target="#b37">[38]</ref>  <ref type="bibr" target="#b22">[23]</ref>, Normalized Mutual Information (NMI) is adopted to measure the results quantitatively. The left of <ref type="figure">Fig.8</ref> shows the comparison results of ReD-SFA (q = 96% and c = 4) and CF with varying thresholds of velocity correlations for CF, which are also used for the initialization of ReD-SFA. Additionally, the results of ReD-SFA without using CNI priori (blue square marker) are also presented. From the results, the ReD-SFA with CNI priori (red circle marker) achieves higher clustering results than the CF consistently at all settings. Compared to other methods, including mixture of dynamic texture (DTM) <ref type="bibr" target="#b4">[5]</ref>, hierarchical clustering (HC) <ref type="bibr" target="#b14">[15]</ref>, coherent filtering(CF) <ref type="bibr" target="#b37">[38]</ref> and collective transition (CT) <ref type="bibr" target="#b22">[23]</ref>, the results reported in <ref type="bibr" target="#b22">[23]</ref> are also presented at the right of <ref type="figure">Fig.8</ref>. The result of ReD-SFA is better than other methods except for the CT method which adopts an additional Markov chain model to refine the clustering results of CF with more dynamic information.</p><p>Some examples on the crowd detection results of CF and ReD-SFA are presented in <ref type="figure">Fig. 9</ref>. As shown in the figure, ReD-SFA obtain more accurate motion boundaries than CF. It is worthy noting: Firstly, in the ground truth, the members in the same group only need have a common goal and coherent motion direction, even they are moving at different locations with far spatial distance. However, the relations discovered by ReD-SFA encodes the spatial affinity based on original tracklet representation. Thus, ReD-SFA tends to obtain smaller crowd groups as spatial gaps exist between group members. In some cases, e.g., the 3rd row and the 4th row, such detection results are more consistent with common perception. Secondly, some outliers in ground truth (red plus) are not well labeled. In the last row, the tracklets located at the lady with white coat are mixed with her back person, and labeled as outliers. In such cases, ReD-SFA ob-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CF</head><p>ReD-SFA Ground Truth <ref type="figure">Figure 9</ref>. Some crowd detection results on CUHK Dataset. Note, the groups with the same color can be further distinguished by the markers. This graphic should be seen in color for complete clarity.</p><p>tains more accurate segmentation results. In the first and second row of <ref type="figure">Fig.9</ref>, ReD-SFA merges some outlier points (red plus in ground truth) with its around group. However, it seems more coherent than the ground truth.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Illustration of the learning process of ReD-SFA. trated more closely in the new space Y ′ (right bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>(a) An example to show the heavy-tailed distribution of L. (b)Objective function vs. the number of learning iterations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>J</head><label></label><figDesc>= J ′ 13: end while</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Illustration of Boosting-like ReD-SFA. The table shows the distributions of the discovered relations over different clusters in the three runs of ReD-SFA. The "ground truth" denotes the number of true intra-cluster relations in each clusters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>The error rates with variant initial parameters m over the 20 sets in Hopkins Dataset. This graphic should be seen in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>The features learnt by GSFA and ReD-SFA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>The average errors of the GSFA and the ReD-SFA over all 155 sets with different m values, when q is fixed to 95%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Total D. Num.</figDesc><table>Prec./Rec.(TP Num.) 
Rec. C1 (TP Num.) Rec. C2 (TP Num.) Rec. C3 (TP Num.) 
Per. of Nearest Neighbors in Initial Graph: 1% 
Initial 
1232 
100% / 2.6% (1232) 
0.27% (8) 
2.79% (2490) 
2.73% (3562) 
ReD-SFA 
9478 
99.68% / 19.91% (9448) 
89.36% (2654) 
11.78% (1855) 
17.19% (4939) 
Per. of Nearest Neighbors in Initial Graph: 3% 
Initial 
3696 
100% / 7.79% (3696) 
2.09% (62) 
8.93% (1406) 
7.75% (2228) 
ReD-SFA 
16946 
95.82% / 34.22% (16238) 
67.31% (1999) 
43.71% (6885) 
25.6% (7354) 
Per. of Nearest Neighbors in Initial Graph: 5% 
Initial 
6160 
100% / 12.98% (6160) 
3.64% (108) 
15.81% (2490) 
12.4% (3562) 
ReD-SFA 
21473 
94.74% / 42.87% (20344) 
65.56% (1947) 
56.37% (8879) 
33.13% (9518) 
Ground Truth 
47450 
2970 
15750 
28730 

Table 1. Results of Statistical Analysis on Pairwise Relation Discovery in the 18th set "2RT3RCT A". 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>. The results of other approaches are taken from the work<ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b12">[13]</ref>. ReD-</figDesc><table>GPCA'05 ALC'10 SCC'09 SSC'13 LRR'13 RV'14 LLMC'07 SMCE'11 ReD-SFA 
total 
10.02% 
3.37% 
2.70% 
2.41% 
1.59% 
0.77% 
4.80% 
3.25% 
2.19% 
three 
28.66% 
6.69% 
5.89% 
4.40% 
-
1.88% 
8.85% 
7.03% 
3.98% 
two 
4.59% 
2.4% 
1.77% 
1.83% 
-
0.44% 
3.62% 
2.15% 
1.67% 

Table 2. Clustering errors (%) on the entire Hopkins 155 dataset. 

Figure 7. Some samples from the CC Dataset. 

SFA is implemented on a PC with Intel i7 2.1GHz. We can 
see that the ReD-SFA achieves the lowest time cost because 
of the close form solution in ReD-SFA, while other methods 
needs more computing iterations in optimization. 

Algorithm 
SSC [11] LRR [20] ICLM[13] ReD-SFA 
Avg. time (s) 
94 
1.9 
1.4 
1.2 

Table 3. Average time cost (seconds) for the Hopkins 155 dataset. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 4 .</head><label>4</label><figDesc>Clustering errors on the CC dataset.</figDesc><table>Num. C 
LRR 
SSC 
SMCE DTW ReD-SFA 
2 
41.5% 
1.5% 
0% 
0% 
0% 
3 
49.7% 2.33% 
0% 
0% 
0% 
4 
48.5% 
38% 
0% 
0.3% 
0% 
5 
51.6% 34.8% 28.4% 
4% 
6.6% 
6 
60.5% 
44% 
43.2% 24.7% 
22.8% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>Figure 8. Quantitative comparison on CUHK Dataset. The left figure shows the NMI with varying parameter settings. The right is the comparison results with other state-of-the-art methods.</figDesc><table>Methods 

NMI 

DTM [5] 
0.30 

HC [14] 
0.27 

CF [37] 
0.42 

CT [22] 
0.48 

ReD-SFA 
0.45 

Threshold 

NMI 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we proposed ReD-SFA for joint feature learning and relations discovery for trajectory clustering. Here, ReD-SFA is formulated as an problem of cross entropy minimization which continuously reduces the discrepancy between the updated pairwise similarities and the existing affinity graph, so that more reliable relations can be discovered. Furthermore, a Boosting-like strategy is proposed to tackle the imbalance of the discovered relations. Benefitting from the relation discovery, competitive results on different trajectory clustering tasks validate the proposed method. In future, we will extend the ReD-SFA to other data sources, e.g., images or videos. And a scalable ReD-SFA will be designed for large scale feature learning. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgement</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Real-time motion trajectory-based indexing and retrieval of video sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bashir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khokhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schonfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="65" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Handwritten digit recognition with nonlinear fisher discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Berkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks: Formal Models and Their Applications ICANN 2005</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="285" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Slow feature analysis yields a rich repertoire of complex cell properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Berkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wiskott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="page" from="579" to="602" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Object segmentation by long term analysis of point trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">6315</biblScope>
			<biblScope unit="page" from="282" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Modeling, clustering, and segmenting video with mixtures of dynamic textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Motion segmentation by scc on the hopkins 155 database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV Workshops</title>
		<meeting>ICCV Workshops</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Robust and fast similarity search for moving object trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Tamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Oria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGMOD International Conference on Management of Data</title>
		<meeting>ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="491" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Non-negative matrix factorization of partial track data for motion segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cheriyadat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Radke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="865" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Visual words assignment via information-theoretic manifold embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">44</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Sparse modeling for high-dimensional multimanifold data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">Thesis</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sparse subspace clustering: Algorithm, theory, and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2765" to="2781" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">How to solve classification and regression problems on high-dimensional data with a supervised extension of slow feature analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Escalante-B</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wiskott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="3683" to="3719" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Fast rigid motion segmentation via incrementally-complex local model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Flores-Mangas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jepson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fradet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perez</surname></persName>
		</author>
		<title level="m">Clustering point trajectories with various lifespans. European Conference on Visual Media Production</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Vision-based analysis of small groups in pedestrian crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Ruback</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Segmenting motions of different types by unsupervised manifold clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rigid motion segmentation using randomized voting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Scaling up dynamic time warping for datamining application</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGKDD Conf. on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>ACM SIGKDD Conf. on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="285" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kevin</surname></persName>
		</author>
		<title level="m">Machine Learning: A Probabilistic Perspective</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Robust recovery of subspace structures by low-rank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="171" to="184" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Higher order motion models and spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ochs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="614" to="621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Time-series similarity queries employing a feature-based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Alcock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Hellenic Conference on Informatics</title>
		<meeting>Hellenic Conference on Informatics</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Scene-independent group profiling in crowd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Motion segmentation in the presence of outlying, incomplete, or corrupted trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE. T-PAMI</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1832" to="1845" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dlsfa: Deeply-learned slow feature analysis for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2625" to="2632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dynamic scene classification: Learning motion descriptors with slow features analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Theriault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2603" to="2610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Feature extraction by non parametric mutual information maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Torkkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1415" to="1438" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A benchmark for the comparison of 3d motion segmentation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Alpha-stable distributions in matlab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Veillette</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Generalized principal component analysis (gpca)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1945" to="1959" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Matching mixtures of trajectories for human action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vrigkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Karavasilis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Nikou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kakadiaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Image Understanding (CVIU)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="27" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Trajectory analysis and semantic region modeling using nonparametric bayesian models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="287" to="321" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Provable subspace clustering:whe n lrr meets ssc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Slow feature analysis: Unsupervised learning of invariances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wiskott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="715" to="770" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A general framework for motion segmentation: Independent, articulated, rigid, non-rigid, degenerate and non-degenerate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">3954</biblScope>
			<biblScope unit="page" from="94" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Comparison of similarity measures for trajectory clustering in outdoor surveillance scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICPR</title>
		<meeting>ICPR</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Slow feature analysis for human action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="436" to="450" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Coherent filtering: Detecting coherent motions from crowd clutters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning with local and global consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
