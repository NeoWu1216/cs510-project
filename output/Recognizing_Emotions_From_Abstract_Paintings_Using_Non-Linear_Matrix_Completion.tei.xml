<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Recognizing Emotions from Abstract Paintings using Non-Linear Matrix Completion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Alameda-Pineda</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Trento</orgName>
								<address>
									<addrLine>Via Sommarive 9</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
							<email>eliricci@fbk.eu</email>
							<affiliation key="aff1">
								<orgName type="institution">Fondazione Bruno Kessler</orgName>
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Perugia</orgName>
								<address>
									<addrLine>Via Duranti 93</addrLine>
									<postCode>06123</postCode>
									<settlement>Perugia</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Trento</orgName>
								<address>
									<addrLine>Via Sommarive 9</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
							<email>niculae.sebe@unitn.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Trento</orgName>
								<address>
									<addrLine>Via Sommarive 9</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Recognizing Emotions from Abstract Paintings using Non-Linear Matrix Completion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Advanced computer vision and machine learning techniques tried to automatically categorize the emotions elicited by abstract paintings with limited success. Since the annotation of the emotional content is highly resourceconsuming, datasets of abstract paintings are either constrained in size or partially annotated. Consequently, it is natural to address the targeted task within a transductive framework. Intuitively, the use of multi-label classification techniques is desirable so to synergically exploit the relations between multiple latent variables, such as emotional content, technique, author, etc. A very popular approach for transductive multi-label recognition under linear classification settings is matrix completion. In this study we introduce non-linear matrix completion (NLMC), thus extending classical linear matrix completion techniques to the non-linear case. Together with the theory grounding the model, we propose an efficient optimization solver. As shown by our extensive experimental validation on two publicly available datasets, NLMC outperforms state-of-the-art methods when recognizing emotions from abstract paintings.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Beyond the automatic recognition of objective properties of images, in the past few years the computer vision research community successfully invested large efforts in the systematic characterization of subjective properties from visual cues. Image aesthetics <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b25">26]</ref>, portrait beauty assessment <ref type="bibr" target="#b30">[31]</ref>, meaningful texture selection <ref type="bibr" target="#b6">[7]</ref>, memorability gaugement <ref type="bibr" target="#b12">[13]</ref>, emotion recognition <ref type="bibr" target="#b27">[28]</ref> and creativity <ref type="bibr" target="#b29">[30]</ref> are examples of such subjective vision-based recognition tasks. Remarkably, researchers made a tremendous progress in the automatic analysis of artworks targeting a diverse range of tasks, such as inferring paintings styles <ref type="bibr" target="#b22">[23]</ref>, studying the influences between artists and art movements <ref type="bibr" target="#b36">[37]</ref>, distinguishing authentic drawings from imitations <ref type="bibr" target="#b11">[12]</ref>, automatically generating artworks <ref type="bibr" target="#b33">[34]</ref> and assessing evoked emotions <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b45">46]</ref>. <ref type="figure" target="#fig_0">Figure 1</ref> shows examples of abstract paintings from the MART dataset eliciting positive and negative emotions: which one does what? <ref type="bibr" target="#b0">1</ref> The particular case of the automatic analysis of modern art is exciting and challenging for the research community, since the artist aims to convey strong and deep emotional content to the observer. Indeed, artists immersed into the abstract art movement tend to enhance the non-figurative component and to express "only internal truths, renouncing in consequence all consideration of external form" <ref type="bibr" target="#b17">[18]</ref>. Subsequently, when analysing modern art paintings, it is of utmost importance to study the relationship between visual features (e.g. colour, shapes, textures) and evoked emotions. In other words, it is crucial, and even more intriguing, to design vision-based learning models able to exploit this link and to predict the emotion evoked by a particular painting. It is therefore unsurprising that there exist several attempts to develop computational approaches for analysing people's emotional experience in reaction to modern artworks <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b31">32]</ref>. Most of these studies rely on advanced computer vision and machine learning approaches for emotionally categorising artworks <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b31">32]</ref> and for inferring the parts of the paintings responsible for evoking specific feelings <ref type="bibr" target="#b43">[44]</ref>. Other studies investigate how the tex- <ref type="bibr" target="#b0">1</ref> The answer is . Filled boxes correspond to negative emotions. tual component (the title and the description of a painting) influences the observer's perceptual experience <ref type="bibr" target="#b32">[33]</ref>.</p><p>Importantly, the automatic analysis of modern artworks is challenging for different reasons. First of all, annotating artworks with perceptual attributes is extremely time consuming and requires the development of ad-hoc crowdsourcing platforms together with further post-processing to account for inter-subject and painting variability. Even if conducted under controlled settings, the outcome of this process may lead to noisy and/or missing labels. Second, while the textual component has shown to influence the observer's perception, the title and the description of paintings are very heterogeneous, pithy and not always available. Third, the emotional content is strongly related to other characteristics of the painting, such as the painting technique, the artist or even the creation year. Consequently, we believe that the automatic analysis of modern artworks should be done (i) in a transductive setting so all the visual features, including those of the unlabeled samples, are used for learning and (ii) using multi-label methods able to exploit the relations between different latent variables.</p><p>Up to the authors' knowledge one of the most successful transductive multi-label learning frameworks is matrix completion (MC) <ref type="bibr" target="#b8">[9]</ref>. Previous works have proven MC to be an effective approach for different computer vision tasks such as multi-label image classification with noisy labels <ref type="bibr" target="#b4">[5]</ref>, image retrieval and tagging <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b5">6]</ref>, manifold correspondence finding <ref type="bibr" target="#b19">[20]</ref> and head/body pose estimation <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1]</ref>. Until now, matrix completion approaches were tied to assume a linear classification model. In this paper we introduce the first method for non-linear classification with matrix completion and name it non-linear matrix comple-tion (NLMC). <ref type="figure" target="#fig_1">Figure 2</ref> shows an overview of the proposed NLMC approach: multiple and possible noisy training labels are used together with the full (training and testing) kernel matrix to estimate the testing labels. Intuitively, we extend the linear MC to non-linear kernels, where the implicit kernel features may be of infinite dimension, providing all the necessary theoretical background. We show that the problem can be cast into a finite-dimension optimization problem, for which we only need the kernel matrices (and not the features themselves). Finally, we report the method's performance with an extensive set of experiments conducted on two publicly available datasets for emotion recognition from abstract paintings.</p><p>Contributions. This paper has several contributions:</p><p>• Introducing the very first non-linear learning approach within the well-known matrix completion philosophy and its application to the emotion recognition problem from abstract paintings (we provide all the necessary theoretical background to support the formalization of the method).</p><p>• Casting the learning problem using the implicit (potentially infinite-dimensional) features into a nonlinear optimization problem for which only the (finitedimensional) kernel matrix is required, and not the implicit features.</p><p>• Reporting an extensive experimental campaign on the only two publicly available datasets for emotion recognition from abstract paintings. <ref type="bibr" target="#b1">2</ref> In this regard, we compare the accuracy in two tasks: emotion recognition and joint painting technique and emotion recognition, showing the advantage of the proposed approach over state-of-the-art methods on transductive learning and on emotion recognition from abstract paintings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In this section we discuss previous works related to (i) visual learning models for emotional analysis of abstract paintings and (ii) matrix completion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Painting Emotion Recognition</head><p>Nowadays, there is an increasing research interest on developing computational models for emotion analysis of modern art paintings. Previous works investigated the role of several visual features (e.g. color, shape and texture) when predicting the emotion conveyed by the artworks to the observers. Yanulevskaya et al. <ref type="bibr" target="#b42">[43]</ref> proposed an emotion categorization approach based on the aggregation of local image statistics and Support Vector Machines (SVM).</p><p>Machajdik et al. <ref type="bibr" target="#b24">[25]</ref> introduced a unified framework to classify artworks emotionally combining low-level visual features and high-level concepts from psychology and art theory. In <ref type="bibr" target="#b43">[44]</ref> a bag-of-visual-words model combined with SVM was proposed to classify abstract paintings into those eliciting positive or negative emotions. Moreover, a backprojection technique was introduced to identify which parts of the paintings evoke positive or negative emotions. Zhao et al. <ref type="bibr" target="#b45">[46]</ref> proposed an approach for emotional classification of images where specific visual features were designed according to art principles, trying to capture information about balance, harmony, variety and movement. Amirshani et al. <ref type="bibr" target="#b2">[3]</ref> documented the research effort towards collecting datasets of paintings with annotations based on human perceptual scores. Sartori et al. <ref type="bibr" target="#b32">[33]</ref> introduced a joint learning framework for abstract painting emotion recognition which integrates both visual and text information. To our knowledge, no previous works have tackled the problem of emotional categorization of modern art paintings considering a multi-label transductive classification framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Matrix Completion</head><p>As discussed in the introduction, the recognition of emotions elicited by abstract paintings would definitely benefit from a transductive multi-label learning framework. While several multi-label classification methods under a supervised setting with lots of training data have been developed, for instance <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b20">21]</ref>, research on transductive multilabel classification has received much less attention. Indeed, Kong et al. <ref type="bibr" target="#b18">[19]</ref> proposed a method based on label set propagation for small datasets, Hariharan et al. <ref type="bibr" target="#b9">[10]</ref> introduced a max-margin formulation for zero-shot learning applications, Hueber et al. <ref type="bibr" target="#b10">[11]</ref> derived a generative regressor with missing data, and Goldberg et al. <ref type="bibr" target="#b8">[9]</ref> studied the matrix completion framework in depth. This is the technical scope of the present paper, since matrix completion is particularly advantageous when data and labels are noisy or in the case of missing data. Previous research studies in computer vision exploited matrix completion for several applications, such as multi-label image classification <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b23">24]</ref>, image retrieval <ref type="bibr" target="#b40">[41]</ref>, facial analysis <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b34">35]</ref> and joint head and body pose estimation <ref type="bibr" target="#b1">[2]</ref>. Other works focused on developing algorithms to efficiently solve the MC optimization problem <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b41">42]</ref>. A recent study <ref type="bibr" target="#b16">[17]</ref> extended matrix completion to incorporate an underlying graph structure inducing a weighted relationship between the columns and the rows of the matrix. Importantly, previous works considered matrix completion only for linear classification. The proposed non-linear matrix completion is, up to our knowledge, the first approach for non-linear multi-label classification in a transductive setting able to deal with noisy or missing labels/features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Emotion Analysis using NLMC</head><p>The main goal of this study is to analyse the emotional experience of people looking at modern art. Intuitively, the emotional experience is linked to other characteristics of the paintings, such as the painting technique or the style. Therefore, for the sake of completeness, we chose to address this problem within a multi-label framework. Furthermore, given that the annotation cost of the perceived emotion is considerably high, a transductive scenario seems to be the most appropriate. Thus, we extract visual features from m training paintings X 0 = [x 1 , . . . , x m ] and from n testing paintings</p><formula xml:id="formula_0">X 1 = [x m+1 , . . . , x p=m+n ], x i ∈ R l ∀i ∈ {1, . . . , p},</formula><p>where l is the dimension of the feature space. The multi-labels are denoted by y i ∈ R k , and for the sake of clarity we assume they are available for the training set Y 0 = [y 1 , . . . , y m ] while unknown for the testing set Y 1 = [y m+1 , . . . , y p ], although (non-linear) matrix completion can naturally handle partially available labels. In practice, being in a transductive setting means that visual features of all (training and testing) samples are used at training time. In the following, we first describe the features extracted from the abstract paintings, to later on state the non-linear matrix completion model and the optimisation problem, and finally propose an efficient solver that leads to the optimum labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Visual features for abstract paintings</head><p>We use the state-of-the-art color-based visual features recently proposed in <ref type="bibr" target="#b31">[32]</ref>. These color-based image features are inspired from Itten's understanding of the relevance of colors and their combinations <ref type="bibr" target="#b13">[14]</ref>. The complete description of the features can be found in <ref type="bibr" target="#b31">[32]</ref>, but we sketch the three-stage pipeline used to extract them.</p><p>Firstly, we use the Color Naming Method (CNM) of <ref type="bibr" target="#b38">[39]</ref> to create a visual vocabulary inspired from 11 linguistic labels, considered to be the ones human beings use to express colors. This color nomenclature has shown to be more robust to photometric changes than previous approaches. CNM allows us to map each of the pixels in a painting to a new color value taking into account a small neighborhood of the pixel. Once this has been done independently per each artwork, the new pixel values of all paintings are jointly clustered in the maximum number of possible colors in Itten's model (i.e. 180 <ref type="bibr" target="#b13">[14]</ref>). After that all pixels are quantized to the centroids obtained from the clustering algorithm. In a second stage, the images quantized accordingly to Itten's color model are segmented using <ref type="bibr" target="#b7">[8]</ref>. The two main parameters of this method are the standard deviation of the Gaussian filter and the observation scale. We used the same values as in <ref type="bibr" target="#b31">[32]</ref> for both parameters, without observing significant performance variations around this working point. In a third stage, we use two color-based features, namely: color co-occurrence features and patch-based color-combination features. These features are desgined to capture different relations between colors: twocolor combinations, the amount of colors, the position of colors and the distance between colors. A fully detailed description of the Itten-inspired features can be found in <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Non-Linear Matrix Completion</head><p>Recently, the computer vision community developed interesting methods for classification in the framework of matrix completion <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b1">2]</ref>. In all MC approaches, the joint label-feature matrix is considered:</p><formula xml:id="formula_1">� Y 0 Y 1 X 0 X 1 � ∈ R (k+l)×(m+n) .<label>(1)</label></formula><p>In previous MC studies the classifier taken under consideration was linear, and the following assumption held:</p><formula xml:id="formula_2">[Y 0 Y 1 ] = W [X 0 X 1 ],<label>(2)</label></formula><p>with W ∈ R k×l being the classifier's parameters. One of the promiment features of this formulation is that the classifier's parameters are not explicitly computed and the unknown labels are directly estimated. The classifier imposes a linear dependency between the rows of the matrix. Therefore, the matrix completion problem is usually cast into a rank-minimization problem.</p><p>Up to the present, nobody considered non-linear classification under the MC framework. In this study we present a formal methodology together with an optimization method so to combine the classification capabilities of the matrix completion framework with the representation power of non-linear kernels applied to the visual features so to efficiently estimate the evoked emotion of abstract paintings.</p><p>To this aim, we assume the data is mapped into a hdimensional space through an unknown feature mapping φ. For this we define φ i = φ(x i ), and from them Φ 0 , and Φ 1 analogously to X 0 and X 1 . Importantly, (i) the dimension of the new feature space is possibly infinite (h ≤ ∞), (ii) the new features are unknown and (iii) only the kernel matrices,</p><formula xml:id="formula_3">that is K 00 = Φ � 0 Φ 0 ∈ R m×m , K 01 = Φ � 0 Φ 1 ∈ R m×n and K 11 = Φ � 1 Φ 1 ∈ R n×n , are available.</formula><p>The new labelfeature matrix is defined as:</p><formula xml:id="formula_4">� Z = � Y 0 Y 1 Φ 0 Φ 1 � .<label>(3)</label></formula><p>Given the linear relationship between the labels and the new features</p><formula xml:id="formula_5">[Y 0 Y 1 ] = � W [Φ 0 Φ 1 ],</formula><p>we seek for a low-rank approximation of the matrix � Z:</p><formula xml:id="formula_6">Z * = arg min Z rank(Z) s.t. P Ω (Z − � Z) = 0,<label>(4)</label></formula><p>where P Ω has the effect of a binary mask over the set of all features and training labels, ensuring that the testing visual features Φ 1 are also used at training time.</p><p>While the optimization problem in <ref type="formula" target="#formula_6">(4)</ref> is well-defined for finite matrices, defining the rank of a matrix with an infinite number of rows is not immediate. Lemma 1 in the supplementary material proves that the rank operator is defined for such matrices (under mild conditions), and subsequently <ref type="formula" target="#formula_6">(4)</ref> is well-defined with at least one feasible solution: Z = � Z. Since minimizing the rank is an NP problem, classical studies on matrix completion used the nuclear norm, that is the sum of the singular values. Again Lemma 1 provides the background to define the singular values (and therefore the nuclear norm) of a matrix with infinite number of rows. Very importantly, and this is the main theoretical result of this study, Theorem 1 proves that the nuclear norm is the tighest convex envelope of the rank (as with finite matrices) and that the following problem is equivalent to <ref type="formula" target="#formula_6">(4)</ref>:</p><formula xml:id="formula_7">Z * = arg min Z �Z� * s.t. P Ω (Z − � Z) = 0.<label>(5)</label></formula><p>Furthermore, also inspired by <ref type="bibr" target="#b28">[29]</ref>, we impose the decomposition Z = LQ � , where L ∈ R (k+h)×r and Q ∈ R p×r , and therefore the optimization problem rewrites:</p><formula xml:id="formula_8">(L * , Q * ) = arg min L,Q �L� 2 F + �Q� 2 F s.t. P Ω (LQ � − � Z) = 0.<label>(6)</label></formula><p>Importantly, as noted in <ref type="bibr" target="#b28">[29]</ref>-Lemma 5.1, the problems <ref type="formula" target="#formula_7">(5)</ref> and <ref type="formula" target="#formula_8">(6)</ref> are equivalent for a sufficiently large value of r. Finally, we impose an additional constraint in order to avoid a persistent issue of matrix decomposition techniques (non-negative matrix factorization is another example): the scale ambiguity problem. Indeed, if the j-th column of L and Q is multiplied/divided by the same scalar, the final approximation does not change. This ambiguity induces many identical local minima in the objective function, thus confusing any optimization solver. Typically, one imposes some kind of normalization on one of the matrices of the decomposition. Without loss of generality, we chose to impose that Q is orthogonal: 3 Q � Q = I r , where I r is the r × r identity matrix. The optimization problem rewrites:</p><formula xml:id="formula_9">(L * , Q * ) = arg min L,Q �L� 2 F + �Q� 2 F s.t. P Ω (LQ � − � Z) = 0 and Q � Q = I r . (7)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Recognizing evoked emotions</head><p>In order to recognize the emotions evoked from the abstract paintings, we need to solve the previous optimization problem. For clarity purposes, we transfer the label-feature (resp. the training-testing) structure into L (resp. Q):</p><formula xml:id="formula_10">L = � L 0 L 1 � ∈ R k×r ∈ R h×r , Q = � Q 0 Q 1 � ∈ R m×r ∈ R n×r . (8)</formula><p>Once the optimal solution is found, the unknown labels (emotion and painting technique) are estimated using:</p><formula xml:id="formula_11">Y * 1 = L * 0 (Q * 1 ) � ,<label>(9)</label></formula><p>where * denotes optimality.</p><p>In an ideal scenario, where the visual features and the label annotations were noiseless and fully trustworthy, the equality constrain P Ω (LQ � − � Z) = 0 would be appropriate. In the current scenario, where annotations as well as the extracted visual features may be noisy, relaxing the original problem by means of a measure of how close are estimations to the available observations is intuitively more appropriate. Hence, the objective function rewrites:</p><formula xml:id="formula_12">F (Q 0 , Q 1 , L 0 , L 1 ) := �Y 0 − L 0 Q � 0 � 2 F + �Φ 0 − L 1 Q � 0 � 2 F + �Φ 1 − L 1 Q � 1 � 2 F + λ(�L 0 � 2 F + �L 1 � 2 F ),<label>(10)</label></formula><p>being λ a regularization parameter (we used �Q� 2 F = r). As it is often the case in kernel approaches, the features cannot be explicitly computed. Consequently, the explicit computation of L 1 is also unfeasible. We solve this issue by taking the derivative of the cost function with respect to L 1 and replace its optimal value into the cost function. After this step, the feature matrices are not needed any more, but only the kernel matrices. Since L 1 can potentially have an infinte number of rows, we cannot reason on the rules of finite-dimensional calculus. The theoretical foundations allowing us to take the derivative of a function with respect to a matrix with an infinite number of rows lie in the field of functional analysis and are detailed in the supplementary material. We obtain the following result:</p><formula xml:id="formula_13">∂F ∂L 1 = −2Φ 0 Q 0 +2L 1 Q � 0 Q 0 −2Φ 1 Q 1 +2L 1 Q � 1 Q 1 +2λL 1 ,</formula><p>and by canceling this derivative we obtain:</p><formula xml:id="formula_14">L * 1 = (Φ 0 Q 0 + Φ 1 Q 1 )(λI r + Q � 0 Q 0 + Q � 1 Q 1 ) −1 = 1 λ + 1 (Φ 0 Q 0 + Φ 1 Q 1 ),<label>(11)</label></formula><p>where we used the normalization of Q. By replacing L 1 with its optimal value in the objective function we obtain:</p><formula xml:id="formula_15">F (Q 0 , Q 1 , L 0 ) = −2Tr(Y � 0 L 0 Q � 0 ) + Tr(L � 0 L 0 Q � 0 Q 0 ) + λTr(L � 0 L 0 ) − 1 λ + 1</formula><p>Tr(Q � KQ), <ref type="bibr" target="#b11">(12)</ref> where K = [K ij ] ij is the kernel matrix constructed from the visual features, i.e. K ij = Φ � i Φ j . We can also take the (regular) derivative with respect to L 0 :</p><formula xml:id="formula_16">∂F ∂L 0 = −2Y 0 Q 0 + 2L 0 Q � 0 Q 0 + 2λL 0<label>(13)</label></formula><p>which cancels out when:</p><formula xml:id="formula_17">L * 0 = Y 0 Q 0 (Q � 0 Q 0 + λI r ) −1 .<label>(14)</label></formula><p>By plugging back this value into F we obtain:</p><formula xml:id="formula_18">F (Q 0 , Q 1 ) = −Tr(Q � 0 Y � 0 Y 0 Q 0 (Q � 0 Q 0 + λI r ) −1 ) − 1 λ + 1 Tr(Q � KQ).<label>(15)</label></formula><p>We reduced the original optimisation problem to:</p><formula xml:id="formula_19">(Q * 0 , Q * 1 ) = arg min Q0,Q1 F (Q 0 , Q 1 ) s.t. Q � 0 Q 0 + Q � 1 Q 1 = I r ,<label>(16)</label></formula><p>that can be solved with an interior-point algorithm <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b3">4]</ref> where the estimation of the Hessian is done with finite differences and the iteration step is computed using conjugate gradient. In that case, the precision of such solver increases drastically if the gradient of the objective function is provided:</p><formula xml:id="formula_20">∂F ∂Q 1 = − 2 1 + λ (K 01 Q 0 + K 11 Q 1 ),<label>(17)</label></formula><formula xml:id="formula_21">∂F ∂Q 0 = 2Q 0 � Q λ 0 � −1 Q � 0 Y � 0 Y 0 Q 0 � Q λ 0 � −1 −2Y � 0 Y 0 Q 0 � Q λ 0 � −1 − 2 1 + λ (K 00 Q 0 + K 01 Q 1 ),<label>(18)</label></formula><p>where Q λ 0 = Q � 0 Q 0 + λI r . Once the optimal solution (Q * 0 , Q * 1 ) is found, we can compute L * 0 with <ref type="bibr" target="#b13">(14)</ref> and estimate the emotions and painting style using (9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Validation</head><p>We validate the proposed non-linear matrix completion approach on single-label and multi-label classification. The complete experimental validation consists on five different tests: (i) the evaluation of the color-based features using a standard classification method, (ii) the recognition of the emotional experience of people observing abstract paintings (as in <ref type="bibr" target="#b31">[32]</ref> we aim to recognize if an abstract painting elicits a positive or a negative feeling), (iii) the parameter sensitivity analysis of the proposed NLMC method on this task, (iv) the ability of NLMC to jointly estimate the emotion elicited and the painting technique (among Acrylic, Oil, Tempera and Lithography) and (v) the ability of NLMC to do that from only one example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>In our experiments we used two publicly available 4 datasets: MART and devArt. The main difference is the artists' background, since MART contains paintings by professional artists and devArt consists on paintings by amateur artists. Each dataset is composed by 500 images. The annotation of the emotional perception was done using the relative score method in <ref type="bibr" target="#b31">[32]</ref>, which provides positive/negative labels from partial order relations that are answers to the question: "Which painting in the pair looks more positive to you?".</p><p>The MART dataset <ref type="bibr" target="#b43">[44]</ref> is a collection from the electronic archive of the Museum of Modern and Contemporary Art of Trento and Rovereto (MART). The abstract paintings were produced by almost 80 different professional artists since the beginning of the 20th century until now. Among the painters, there are famous artists like Kandinsky, Albers or Veronesi. Importantly, these artists are known, not only by their exceptional artworks, but also by their theoretical studies on abstract art in terms of color, shapes or texture. An extract of paintings from MART is shown in <ref type="figure" target="#fig_2">Figure 3</ref> (top). The painting technique was annotated by an expert.</p><p>The devArt dataset is a collection of amateur abstract paintings obtained from the "DeviantArt" online social network <ref type="bibr" target="#b4">5</ref> . DeviantArt is one of the largest online art communities with more than 280 million artworks and 30 million registered users. We selected the 500 most favored artworks that were under the category Traditional Art/Paintings/Abstract, from 406 different authors. A sample of the devArt dataset is shown in <ref type="figure" target="#fig_2">Figure 3</ref> (bottom).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head><p>The features. Abstract art theorists state that color is the most important aspect for abstract painting emotion recognition <ref type="bibr" target="#b13">[14]</ref>. Our first experiment serves to find out weather this is also true from a computational point of view. <ref type="figure">Figure 4</ref> shows the 5-fold cross-validation average emotion recognition accuracy when a SVM classifier is fed with the color combination features <ref type="bibr" target="#b31">[32]</ref>, the LAB visual words <ref type="bibr" target="#b43">[44]</ref> and CNN features <ref type="bibr" target="#b14">[15]</ref>. Experimental results shows that the 5 www.deviantart.com LAB <ref type="bibr" target="#b41">[42]</ref> Color Combination <ref type="bibr" target="#b30">[31]</ref> CNN <ref type="bibr" target="#b13">[14]</ref> fine-tuning</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Average Emotion</head><p>Recognition Accuracy (%) <ref type="figure">Figure 4</ref>. Evaluation of abstract painting emotion recognition for different features. color combination feature outperforms the two other alternative features. CNN seem not to be effective enough to extract emotion information from the images. Therefore, we only perform experiments with the color-based features. Emotion Recognition. We compare the average emotion recognition accuracy of the proposed non-linear matrix completion (NLMC) method to four different baselines. On the one hand, to two traditional transductive learning approaches namely: kernel transductive SVM (TSVM <ref type="bibr" target="#b15">[16]</ref>) and linear matrix completion (LMC e.g. <ref type="bibr" target="#b5">[6]</ref>). On the other hand, to two state-of-the-art methods for emotion recognition from abstract paintings: Lasso and Group Lasso, both evaluated in <ref type="bibr" target="#b31">[32]</ref>. The decomposition size of NLMC and LMC was cross-validated on r ∈ {2, 3, 4, 5}, since no increase of performance was observed for higher values of r. Similarly, for NLMC, LMC and TSVM, the regularization parameter was cross-validated on the set {10 −5 , . . . , 10 −1 }, and the radial basis function kernel (variance) parameter was cross-validated on the set {0.01, 0.0316, 0.1, 0.316, 1.0, 3.16}. The regularization parameters of Lasso and Group Lasso were crossvalidated in the range {0.1, 0.316, 1, 3.16, 10, 31.6, 100} and {0.0001, 0.001, 0.01, 0.1, 1} respectively (since for Group Lasso, the regularization parameter represents a proportion of its estimated maximum value 6 ). Results in <ref type="table" target="#tab_0">Table 1</ref> are a 12-realization average with a 10-fold cross-validation strategy. The entire software is available at https://github.com/xavirema/nlmc. First of all we observe that the proposed NLMC approach systematically outperforms all baselines in both datasets. Very importantly, this behaviour is observed also another set of experiments aiming to evaluate the performance of the methods when reducing the size of the training set. Since the MART dataset is the most challenging among the two, <ref type="figure">Figure 5</ref> shows the average recognition accuracy of the methods for different training set sizes. Summarizing, NLMC outperforms, both the state-of-the-art on the emotion recognition task and traditional transductive approaches widely used in the computer vision community. This suggests that NLMC could be beneficial for other computer vision tasks. Finally, <ref type="figure" target="#fig_5">Figure 7</ref> shows some qualitative results of the NLMC method on both datasets.</p><p>Parameter Sensitivity &amp; Complexity Analysis. We also report (see <ref type="figure">Figure 6</ref>) the parameter sensitivity analysis of the proposed NLMC method. The optimal working point of the method is at λ = 0.01, γ = 0.1 for the MART dataset and at λ = 0.1, γ = 0.316 for the devArt dataset. We notice from the two graphs that the two working points are in a fairly flat part of the surface, meaning that the NLMC method is not very sensitive to variations of the parameters around the optimal working point. In ad- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Training Testing TSVM <ref type="bibr" target="#b15">[16]</ref> 0.79 LMC <ref type="bibr" target="#b5">[6]</ref> 2.82 Lasso <ref type="bibr" target="#b31">[32]</ref> 0.03 0.001 Group Lasso <ref type="bibr" target="#b31">[32]</ref> 4.21 0.002 NLMC 1.71 dition to evaluate the performance variation of the method with the parameter values, we also compared its computational complexity. <ref type="table" target="#tab_1">Table 2</ref> shows elapsed time of the training and testing phases (joint in transductive approaches) on the MART dataset with 400 training/100 testing paintings. Experiments ran on a regular laptop with an Intel-i5 processor at 2.67 GHz. We remark that, even if NLMC is not the fastest method, it is much faster than the two closest competitors in terms of performance, namely: Group Lasso and LMC. Regarding the convergence, we have experimentally observed that the relative variation of the objective function goe below 10 −5 after 20 iterations of the algorithm. Joint Emotion and Technique Recognition. One of the prominent features of MC in general and NLMC in particular is that the model is naturally able to deal with multiple label at once. Hence, we evaluate the performance of the proposed method within a multi-label classification setting addressing two tasks simultaneously: the recognition of the emotion and of the painting technique. Since the painting technique is not annotated in the devArt dataset, this experiment is only conducted on the MART dataset. Moreover, given that TSVM, Lasso and Group Lasso are not multi-label classification techniques, we here compare with the state-of-the-art transductive multi-label approach in <ref type="bibr" target="#b18">[19]</ref>, called label set propagation (LSP). The neighborhood size parameter of LSP was cross-validated in the range {5, . . . , 12}. Finally, in order to guarantee a fair comparison with <ref type="bibr" target="#b18">[19]</ref>, we rebalanced the dataset, leading to a dataset with 8 samples per combination of emotion and technique label (eight combinations in total). Consequently, the results we report here are not directly comparable to the ones in <ref type="table" target="#tab_0">Table 1</ref>. Average accuracy results on both tasks are reported in <ref type="table" target="#tab_2">Table 3</ref>. Consistently with the findings in <ref type="table" target="#tab_0">Table 1</ref>, the proposed NLMC approach outperforms all baselines. Importantly, up to the authors' knowledge this is the first study addressing the task of joint recognition of emotion and painting technique from abstract paintings, thus setting the baseline for future research.</p><p>One-shot Emotion and Technique Recognition. Naturally, transductive learning approaches can be used in a one-shot learning setting, meaning that the training set consists on one sample per class. Hence, we explored the use of NLMC in such application, thus trying to jointly estimate the emotion and the painting technique from only one annotated sample per label combination (eight samples in total). <ref type="table" target="#tab_3">Table 4</ref> shows the results of our experiments comparing NLMC with LMC and LSP. Even if all methods experience an expected small drop in performance, it is clear that NLMC outperforms LMC and LSP both for emotion and technique recognition, consistently with the previous experiments (i.e. Tables 1 and 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper we address the task of recognizing the emotion elicited by abstract paintings. Since annotating the emotion of a painting is a highly resource-consuming task, it is desirable to perform the learning in a transductive setting. Intuitively, the emotion has complex interdependencies with other characteristics of the painting, such as the painting technique. Therefore we propose to address the task with a new multi-label transductive classifier, named non-linear matrix completion. This is the first work addressing matrix completion, which is inherently transductive and multi-label, under the assumption of a non-linear classifier. We derive the theoretical foundation required to set the optimization problem and propose a solver that performs the learning. In order to validate the approach, we conducted experiments on two publicly available dataset and addressed two tasks: emotion recognition and joint emotion and painting technique recognition. Results show systematic improvement over state-of-the-art on transductive single-and multi-label approaches as well as other supervised approaches previously used in emotion recognition of abstract paintings. Future works will focus on extending the proposed framework to handle missing features in order to integrate other sources of information (e.g. text) useful for emotional abstract painting analysis. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Sample abstract paintings of the MART dataset: which one does elicite in you a positive or a negative emotion?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Overview of the proposed non-linear matrix completion framework for abstract painting analysis. Multiple and possibly noisy labels (i.e. emotion and painting technique) are estimated from the kernel matrix within a transductive setting, where both the training and testing features (and thus the full kernel matrix) are available at training time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Sample paintings from the MART dataset (top row) and from the devArt dataset (bottom row).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .Figure 6 .</head><label>56</label><figDesc>Average emotion recognition accuracy with varying training set size on the MART dataset. Sensitivity study of parameters of the proposed NLMC method on the MART (left) and devArt (right) datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Sample results for abstract painting analysis. Top two groups come from the MART dataset, while bottom two groups from the devArt dataset. Left column corresponds to paintings with positive feelings, while the right column corresponds to negative feelings. Paintings framed in purple corresponds to misclassifications of the proposed NLMC method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table>Average emotion recognition accuracy (in %) of all base-
line methods in both MART and devArt datasets. 

Method 
MART devArt 

TSVM [16] 
69.2 
70.0 
LMC [6] 
71.8 
72.5 
Lasso [32] 
68.2 
70.4 
Group Lasso [32] 
70.5 
72.1 

NLMC 
72.8 
76.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 .</head><label>2</label><figDesc>Computational complexity (in s) of different methods on the MART dataset (i.e. 400 training/100 testing paintings).</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 .</head><label>3</label><figDesc>Average multi-label recognition accuracy on the MART dataset: emotion and painting technique.</figDesc><table>Method Emotion Technique 

LSP [19] 
67.19 
40.63 
LMC [6] 
68.75 
34.69 

NLMC 
69.38 
41.87 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 4 .</head><label>4</label><figDesc>Average multi-label one-shot recognition accuracy on the MART dataset: emotion and painting technique.</figDesc><table>Method Emotion Technique 

LSP [19] 
53.13 
24.54 
LMC [6] 
60.27 
32.81 

NLMC 
64.51 
33.48 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We are in private communication with the authors of<ref type="bibr" target="#b2">[3]</ref>, but the dataset is still unavailable due to copyright issues.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">If Q = UDV is the SVD of Q we defineL = LV � D andQ = U, so that LQ � =LQ � andQ is orthogonal.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">http://disi.unitn.it/˜sartori/datasets/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">See the documentation of the publicly available software used for the experiments: http://www.yelab.net/software/SLEP/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SALSA: A novel dataset for multimodal group behaviour analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Alameda-Pineda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Staiano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Batrinca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lepri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Lanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Analyzing free-standing conversational groups: A multimodal approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Alameda-Pineda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Lanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Jenaesthetics subjective dataset: Analyzing paintings by subjective scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Amirshahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">U</forename><surname>Hayn-Leichsenring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Denzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Redies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV Workshops</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A trust region method based on interior point techniques for nonlinear programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Prog</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="149" to="185" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Matrix completion for weakly-supervised multi-label image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Matrix completion for resolving label ambiguity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Describing textures in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cimpoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Efficient graphbased image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="181" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Transduction with matrix completion: Three birds with one stone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient max-margin multi-label classification with applications to zero-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="127" to="155" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Speaker-adaptive acoustic-articulatory inversion using cascaded gaussian mixture regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hueber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Girin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Alameda-Pineda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bailly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM TASLP</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2246" to="2259" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Quantification of artistic style through sparse coding analysis in the drawings of pieter bruegel the elder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Rockmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">What makes a photograph memorable?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>TPAMI</publisher>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1469" to="1482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The art of color: The subjective experience and objective rationale of color</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Itten</surname></persName>
		</author>
		<editor>Wiley</editor>
		<imprint>
			<date type="published" when="1974" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Caffe: An open source convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Transductive inference for text classification using support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Matrix completion on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kalofolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Concerning the spiritual in art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kandinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Art History Series</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1914" />
			<publisher>Dover Books on</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Transductive multi-label learning via label set propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="704" to="719" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Functional correspondence by matrix completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kovnatsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Active learning with multi-label svm classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multi-label classification via feature-aware implicit label space encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Inferring painting style with multi-task dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Low-rank multi-view learning in matrix completion for multi-label image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Affective image classification using features inspired by psychology and art theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Machajdik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Discovering beautiful attributes for aesthetic image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marchesotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="246" to="266" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ava: A largescale database for aesthetic visual analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marchesotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A mixed bag of emotions: Model, predict, and transfer emotion distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gallagher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Guaranteed minimumrank solutions of linear matrix equations via nuclear norm minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fazel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Parrilo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM review</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">6 seconds of sound and vision: Creativity in micro-videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Redi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>O&amp;apos;hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schifanella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Trevisiol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jaimes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The beauty of capturing faces: Rating the quality of digital portraits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Redi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rasiwasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jaimes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FG</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Who&apos;s afraid of itten: Using the art theory of color combination to analyze emotions in abstract paintings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sartori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Culibrk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Looking at Mondrian&apos;s Victory Boogie-Woogie: What do i feel?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sartori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ozbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Salah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Salah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI, 2015. 1</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Self-adaptive matrix completion for heart rate estimation from face videos under realistic conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tulyakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Alameda-Pineda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An interior algorithm for nonlinear optimization that combines line search and trust region steps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Waltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Orban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Prog</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="391" to="408" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">SOM based artistic styles visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Takatsuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICME</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Practical matrix completion and corruption recovery using proximal alternating robust subspace minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-F</forename><surname>Cheong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-C</forename><surname>Toh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="315" to="344" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Affective analysis of professional and amateur abstract paintings using statistical analysis and art theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Larlus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1512" to="1523" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multi-label learning with missing labels for image annotation and facial action unit recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-G</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Tag completion for image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Speedup matrix completion with side information: Application to multi-label learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Emotional valence categorization using holistic image features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Yanulevskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Gemert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Herbold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Geusebroek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIP</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">In the eye of the beholder: employing statistical analysis and eye tracking for analyzing abstract paintings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Yanulevskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sartori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zamboni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bacci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Melcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Fusion of multichannel local and global structural cues for photo aesthetics evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1419" to="1429" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Exploring principles-of-art features for image emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
