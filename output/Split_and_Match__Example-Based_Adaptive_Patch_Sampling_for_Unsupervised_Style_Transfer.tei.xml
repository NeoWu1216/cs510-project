<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Split and Match: Example-based Adaptive Patch Sampling for Unsupervised Style Transfer</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriel</forename><surname>Frigo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Technicolor</orgName>
								<address>
									<settlement>Research&amp;Innovation</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Université Paris Descartes</orgName>
								<address>
									<postCode>MAP5</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neus</forename><surname>Sabater</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Technicolor</orgName>
								<address>
									<settlement>Research&amp;Innovation</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Delon</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Université Paris Descartes</orgName>
								<address>
									<postCode>MAP5</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Hellier</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Technicolor</orgName>
								<address>
									<settlement>Research&amp;Innovation</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Split and Match: Example-based Adaptive Patch Sampling for Unsupervised Style Transfer</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a novel unsupervised method to transfer the style of an example image to a source image. The complex notion of image style is here considered as a local texture transfer, eventually coupled with a global color transfer. For the local texture transfer, we propose a new method based on an adaptive patch partition that captures the style of the example image and preserves the structure of the source image. More precisely, this example-based partition predicts how well a source patch matches an example patch. Results on various images show that our method outperforms the most recent techniques.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Style transfer is the task of transforming an image in such a way that it mimics the style of a given example. This class of computational methods are of special interest in film post-production and graphics, where one could generate different renditions of the same scene under different "style parameters" <ref type="bibr" target="#b17">[17]</ref>  <ref type="bibr" target="#b6">[6]</ref>. The difficulty of this task is bound to the complexity of defining the style as a composition of different visual attributes such as color, shading, texture, lines, strokes and regions.</p><p>Example-based methods have been widely employed to solve problems such as texture synthesis <ref type="bibr" target="#b7">[7]</ref>, inpainting <ref type="bibr" target="#b5">[5]</ref>, and super-resolution <ref type="bibr" target="#b10">[10]</ref> with state-of-the-art performance. These non-local and non-parametric approaches draw on the principle of self-similarity in natural images: similar patches (sub-images) are expected to be found at different locations of a single image.</p><p>Despite the practical success of patch-based methods for inverse problems, the patch dimensionality remains a sensitive parameter to tune in these algorithms. For instance, to obtain a coherent patch-based texture synthesis, patches should have approximately the same dimensionality of the dominant pattern in the example texture. The problem of patch dimensionality is equally crucial for example-based style transfer. In this case, we are given as example an image containing a mixture of style and content. Hence, patch dimensions should be large enough to represent the patterns that characterize the example style, while small enough to forbid the synthesis of content structures present in the example image. We propose a style transfer method that is able to meet these requirements by means of an adaptive patch partition. <ref type="figure" target="#fig_0">Fig. 1</ref> illustrates our method. This paper makes the following contributions:</p><p>• We suggest that a correct style transfer can be thought as a local transfer of texture and a global transfer of color. A robust method for local texture transfer must capture the style while preserving the image structure, and this can be achieved with a spatially adaptive image partition.</p><p>• We show that a relevant partition must incorporate a prediction of how well an image portion of the source image will be matched to the example style image. That naturally leads to an example-based partition, where the partition is bound to the coupling between the source image and the example image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Style transfer can be related to texture <ref type="bibr" target="#b7">[7]</ref> and color transfer <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b12">12]</ref>. Texture transfer can be seen as a special case of texture synthesis, where example-based texture generation is constrained by the geometry of an original image. Style transfer, for this part, can be seen as a composition of texture and color transfer, where style is transferred from an example to an original image, being modeled as a combination of texture and color. Recent methods modeling style transfer in a color context include <ref type="bibr" target="#b23">[23]</ref>, where the style of head shots is mimicked through local image statistics and <ref type="bibr" target="#b24">[24]</ref> where the daytime of an image is transformed relying on examples. In this work, we approach style mainly from the textural rather than the color aspect.</p><p>Texture synthesis by non-parametric sampling is inspired by the Markov model of natural language <ref type="bibr" target="#b22">[22]</ref>, where text Original Example</p><p>Adaptive partition Stylization with our method generation is posed as sampling from a statistical model of letter sequences (n-grams) taken from an example text. In an analogous manner, non-parametric texture synthesis relies on sampling pixels directly from an example texture. It became a popular approach for texture synthesis <ref type="bibr" target="#b8">[8]</ref> and for texture transfer <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b27">27]</ref> due to convincing representation of either non-structural and structural textures.</p><p>In the literature of texture synthesis and transfer, we find two main approaches to compute non-parametric sampling from an image based Markov Random Field (MRF), which we call here respectively as the greedy and the iterative strategies. The first strategy considers texture synthesis as the minimization of a greedy heuristic cost function, performing sampling by neighborhood matching to obtain a local solution. The non-parametric texture synthesis method of <ref type="bibr" target="#b8">[8]</ref> takes a pixel to be synthesized by random sampling from a pool of candidate pixels selected from an example texture. A similar approach was extended to patch-based texture synthesis and also for texture transfer in <ref type="bibr" target="#b7">[7]</ref>. We follow in this work an iterative strategy, inspired by <ref type="bibr" target="#b11">[11]</ref> and <ref type="bibr" target="#b25">[25]</ref>, which considers an explicit probability density modeling of the problem and computes an approximate Maximum a Posteriori (MAP) solution through an iterative optimization based on Loopy Belief Propagation or Graph cuts.</p><p>Style transfer can be computed in a supervised or unsupervised fashion. One of the first methods to propose supervised style transfer posed the problem as computing an "image analogy" given by A : A ′ :: B : B ′ <ref type="bibr" target="#b15">[15]</ref>, implying that an input image B should be related to a stylized image B ′ the same way as image A is related to A ′ , with A and A ′ known. In this method, inspired by the texture transfer of <ref type="bibr" target="#b0">[1]</ref>, a pixel to be synthesized in image B ′ is directly selected from an example stylized image A ′ , by minimizing a cost function that takes into account the similarity between B and A and the preservation of local neighborhoods in A ′ . The image analogies approach was extended to video in the work of <ref type="bibr" target="#b3">[3]</ref>, where the problem of temporal coherence is investigated, and recently it was accelerated with hash ta-bles in <ref type="bibr" target="#b2">[2]</ref>. We note that the supervised approach needs a registered pair of example images A and A ′ from which it is possible to learn a style transformation, however this pair of images is hardly available in practice. In this work we rather consider an unsupervised approach.</p><p>There are few works dealing with unsupervised style transfer in the literature, the closest to our method being <ref type="bibr" target="#b21">[21]</ref>, <ref type="bibr" target="#b4">[4]</ref> and <ref type="bibr" target="#b27">[27]</ref>. Still borrowing from the image analogies notation, we can consider that the unsupervised scenario assumes that only an example image A ′ and an original image B are given. In <ref type="bibr" target="#b21">[21]</ref> the authors describe a Bayesian technique for inferring the most likely output image from the input image and the exemplar image. The prior on the output image P (B ′ ) is a patch-based MRF obtained from the input image. The authors in <ref type="bibr" target="#b27">[27]</ref> decompose original and example images into three additive components: draft, paint and edge. In our approach, the input image is not decomposed into additive parts, as we rather consider a spatial decomposition. Moreover, we note that in both <ref type="bibr" target="#b21">[21]</ref> and <ref type="bibr" target="#b27">[27]</ref>, a MRF is defined for image patches disposed over a regular grid, which is not the case in our approach, where we consider an example-based adaptive image partition.</p><p>Finally, the recent work of <ref type="bibr" target="#b13">[13]</ref> proposed a style transfer technique using Convolutional Neural Networks (CNN) to separate and recombine the content and the style of two images. Their method differs considerably from our approach, assuming a pre-trained neural network architecture and solving gradient descent for style reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Split and Match Style Transfer</head><p>According to the primal sketch theory of visual perception <ref type="bibr" target="#b18">[18]</ref>, an image may be seen as a composition of structures: an ensemble of noticeable primitives or tokens; and textures: an ensemble with no distinct primitives in preattentive vision. Inspired by this principle, <ref type="bibr" target="#b9">[9]</ref> presented a generative model for natural images that operates guided by these two different image components, that they called as sketchable and non-sketchable parts.</p><p>In this work, we adopt a similar view for example-based style synthesis. Our main motivation comes from the observation that the visual elements accounting for distinctive painting styles in fine arts are often anisotropic with respect to scale. In other words, details corresponding to the geometry (or the sketchable part) of a scene are often painted carefully with fine brushwork, while the scene nonsketchable part is sometimes painted with rougher brushes, where brushwork style is usually more distinct. Obviously, this observation holds more importantly for some particular artistic styles such as impressionism and postimpressionism than other painting styles such as realism.</p><p>We remind that in texture transfer, pixel-based models have assumed neighborhoods with regular size, and patchbased methods similarly assume an image decomposition into patches in a regular grid. As we illustrate in <ref type="figure">Fig. 2</ref>, a regular grid assumption is problematic for style transfer. In general, if the patches in a regular grid are small (for instance of size 8 × 8), we achieve a realistic reconstruction of the original image, but the style of the example image is hardly noticeable. On the other hand, for larger patch size, the style from the example can be noticed in the reconstructed image, however the fine geometry of the original image is not correctly reconstructed.</p><p>In order to overcome this limitation, we propose a method that takes into account the scale problem in stylization. In the following subsections, we give a formal definition for unsupervised style transfer and our proposed solution to the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem definition</head><p>Let u : Ω u → R 3 be an input image and v : Ω v → R 3 an example style image. Style transfer can be posed as finding a correspondence map ϕ : Ω u → Ω v which assigns to each point x ∈ Ω u in the original image domain a corresponding point ϕ(x) ∈ Ω v in the example image domain. The output image can then be defined asû = v(ϕ).</p><p>In order to capture the style of v while preserving the structures of u, the correspondence map ϕ should ideally be a piecewise constant translation map on a partition</p><formula xml:id="formula_0">R = {R i } n i=1</formula><p>of Ω u . In practice, the partition R should depend on the geometrical content of u, while ensuring the existence of good correspondences between u and v over each region R i . To achieve a convincing style transfer, regularity is also required at the boundary between neighboring correspondent regions.</p><p>All these requirements could be expressed in a unique non convex energy depending on both R and ϕ and requiring an alternating optimization strategy. For the sake of simplicity, our approach rather considers these sub-problems independently, following the four steps below:</p><p>1. Split and match: compute an adaptive partition R of In the split and match step, we split Ω u into a quadtree R which takes into account both the geometry of u and the ability for these regions to have good matches in v. At the same time, we compute for each region R i a reduced set of candidate regions in v. The search of the optimal map ϕ is then seen as a graph labeling problem, where the nodes of the graph are the regions R i . We denote L i = {l i k } K k=1 the set of K candidate labels for the region R i , the label l i k ∈ Ω v being a patch coordinate in image v. This probabilistic labeling problem is solved by belief propagation, followed by bilinear blending for the final reconstruction. We note thatû is reconstructed by texture transfer only in luminance (Y channel in YUV color space).</p><p>Finally, we suggest applying a global color transfer method <ref type="bibr" target="#b12">[12]</ref> in chrominance channel to capture the color style, and a contrast transformation to match the global contrast of the example image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Split and Match adaptive partition</head><p>As we claim throughout this paper, decomposing an image into a suitable partition has a considerable impact in the quality of patch-based style synthesis. We propose a simple yet effective approach based on a modified version of the classic Split and Merge decomposition <ref type="bibr" target="#b16">[16]</ref>. In the classic algorithm, the local variance of a quadtree cell decides whether a cell will be split into four cells. Here we propose a "Split and Match" example-guided decomposition, where the stopping criteria for quadtree splitting depends also on the patch similarity between the input and example images.</p><p>In our representation, a region R i is a square of Ω u , of size τ i × τ i . We denote by x i its center and we denote indifferently by u(R i ) or p u xi the patch of size τ 2 i centered at</p><formula xml:id="formula_1">x i .</formula><p>The decomposition starts with one single region R 1 := Ω u . Each region R i of the partition is split into four equal squares, each one of size ( τi 2 ) 2 , until a patch in the example image v matches u(R i ) with some degree of accuracy.</p><p>Since quadtree patches can have arbitrary size, we use normalized distances for patch comparison. More precisely, the distance between two patches p u xi and p v y of the same size τ 2 i is defined as</p><formula xml:id="formula_2">d[p u xi , p v y ] = ||p u xi − p v y || 2 τ 2 i .<label>(1)</label></formula><p>Now, if y i is the best correspondence of x i in v at this scale τ i :</p><formula xml:id="formula_3">y i := arg min y d[p u xi , p v y ],<label>(2)</label></formula><p>the region R i is split in four regions if the following condition is satisfied</p><formula xml:id="formula_4">ζ(p u xi , p v yi ) = σ i + d[p u xi , p v yi ] &gt; ω and τ i &gt; Υ 0 or τ i &gt; Υ 1 ,<label>(3)</label></formula><p>where σ i = V ar(p u xi ) is the standard deviation of p u xi , ω is a similarity threshold (fixed to ω := 15 in practice), Υ 0 is the minimum patch size and Υ 1 the maximum patch size allowed in the quadtree (respectively fixed to 8 2 and 256 2 ).</p><p>Observe that R i is not encouraged to be split if there is at least one patch p v y which is similar enough to p u xi , unless the standard deviation of the patch σ i is large.</p><p>Eventually, for every "leaf node" of the quadtree (nodes for which the splitting condition in Eq. <ref type="formula" target="#formula_4">(3)</ref> is not satisfied), a set of K candidate labels L i = {l i k } K k=1 is selected for R i by computing a spatially constrained K-nearest neighbors</p><formula xml:id="formula_5">(k-NN) {p v li k } K k=1 of p u xi in v. A spatial constraint |l i k − l i k+1 | &gt; χ (with χ := τi 2 in practice)</formula><p>, requires that two candidate patch labels l i k and l i k+1 are sufficiently distant from each other and encourages label variety. The whole split and match step is summarized in Algorithm 1. Compute spatially constrained k-NN: <ref type="bibr" target="#b12">12</ref>:</p><formula xml:id="formula_6">L i ← {l i k } K k=1 with |l i k − l i k+1 | &gt; χ 13:</formula><p>end if 14: end for In <ref type="figure">Fig. 2</ref>, we show the interest of adopting an examplebased adaptive image partition. Note that for 8 2 patch dimensionality, the pointillist texture feature is not captured, while for 32 2 patch dimensionality the style is better captured at the cost of having poor reconstruction of structures present in the original image. When a classic adaptive partition is used (based on the variance of the original image), style transfer is reasonably achieved, but entire structures are also copied from the example image (the woman's face in the painting). On the other hand, when the "Split and Match" adaptive partition is used, it leads to a convincing synthesis of the example style, while structures in the original image are well preserved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Markov Random Fields modeling</head><p>Markov Random Fields (MRF) are a well known inference model for computer vision problems <ref type="bibr" target="#b14">[14]</ref>, widely a) Regular grid b) Adaptive quadtree used to model texture synthesis <ref type="bibr" target="#b28">[28]</ref> and texture transfer <ref type="bibr" target="#b7">[7]</ref>. Within this framework, the problem of example-based style transfer can be solved by computing the Maximum a Posteriori from a well chosen joint probability distribution on all image units (quadtree patch labels in our model).</p><p>Usually, patch-based MRF models such as in <ref type="bibr" target="#b11">[11]</ref> are computed over a graph in a regular grid, as illustrated in <ref type="figure" target="#fig_3">Fig. 3a</ref>. In this work, we rather propose a MRF model over an adaptive partition, as shown in <ref type="figure" target="#fig_3">Fig. 3b</ref>. Nevertheless, the neighborhood definition in the proposed quadtree MRF is analogous to a 4-neighborhood in a regular grid.</p><p>As discussed in Sec. 3.2, for a quadtree patch p u xi , we first compute a set of K candidate labels L i = {l i k } K k=1 as a strategy to reduce the dimensionality of the labeling problem. We consider now an inference model to compute the most likely set of label assignments for all the patches in R, where labels represent patch correspondences between u and v. More precisely, we search for the set of label as-signmentsL = {l i } n i=1 maximizing the probability density</p><formula xml:id="formula_7">P (L) = 1 Z i φ(l i ) (i,j)∈N ψ(l i , l j ),<label>(4)</label></formula><p>where Z is a normalization constant, φ is the data fidelity term</p><formula xml:id="formula_8">φ(l i ) = exp(−d[p u xi , p v li ]λ d )<label>(5)</label></formula><p>and ψ(l i , l j ) is a pairwise compatibility term between neighboring nodes i and j ((i, j) ∈ N means that R i and R j are neighbors in Ω u )</p><formula xml:id="formula_9">ψ(l i , l j ) = exp(−d[p v li ,p v lj ]λ s + |l i − l j | 2 λ r ),<label>(6)</label></formula><p>with λ d , λ s and λ r three positive weights (respectively fixed to 2, 2 and 1 in all experiments). This function ψ is composed of a smoothness term and a term penalizing label repetitions.</p><p>In patch-based MRFs, the compatibility term ensures that neighbor candidate patches are similar in their overlapping region. To define this properly, we first extend each region R i of the partition R by τ i θ in each direction (θ is an overlapping ratio set to 0.5 in practice). This permits to define an overlap between two neighboring extended regions R i and R j . The term d[p v li ,p v lj ] in ψ(l i , l j ) is the distance between the corresponding extended patches in v over this intersection R i ∩ R j . While we search for smooth intensity transitions in the overlapping part of neighbor candidate patches, we also aim to penalize two neighbor nodes to have exactly the same label, thus we encourage |l i − l j | 2 to be large as a strategy to boost local synthesis variety.</p><p>Note that computing an exact MAP inference to solve directly Eq. (4) is an intractable combinatorial problem due to the high dimensionality of image based graphical models, but approximate solutions can be found by iterative algorithms. We adopt in this work the Loopy Belief Propagation method <ref type="bibr" target="#b26">[26]</ref>  <ref type="bibr" target="#b19">[19]</ref>. Basically, neighboring variables update their likelihoods by message passing and usually after a small number of iterations, the approximate marginal probabilities (beliefs) of all the variables in a MRF are computed <ref type="bibr" target="#b11">[11]</ref>. In practice, we do not maximize the density (4) but rather minimize its negative logarithm for computational convenience.</p><p>Finally, a patch in the reconstructed imageû with estimated labell i is given by pû xi = p v li .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Bilinear blending</head><p>Although we compute label correspondences that are likely to be coherent across overlapping regions, seams can still be noted in the reconstructed imageû across the quadtree patch boundaries. In order to remove visible seams we apply an effective method inspired on linear alpha blending. Note that in an overlapping quadtree, a variable number of patches may overlap. Then, a pixel x in the final reconstructed imageũ(x) is defined as a linear combination of the S overlapping patch intensities at x:</p><formula xml:id="formula_10">u(x) = S s=1 α s (x)pû xs (x) , where α s (x) = δ(x, ∂pû xs ) S s=1 δ(x, ∂pû xs )<label>(7)</label></formula><p>is the weighting factor and δ(x, ∂pû xs ) is the normalized closest distance between pixel x and the patch border ∂pû xs :</p><formula xml:id="formula_11">δ(x, ∂pû xs ) = |x − ∂pû xs | 2 τ 2 s .<label>(8)</label></formula><p>This blending strategy ensures smooth transitions between neighbor patches at a very low computational cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Global color and contrast transfer</head><p>We have described in the previous subsections our strategy for texture transfer through an adaptive patch-based ap-proach. Now, we consider that color and contrast are two features in style that may be consistently modeled as global transformations.</p><p>That said, we apply the color transfer method proposed in our previous work <ref type="bibr" target="#b12">[12]</ref> to match consistently the color palettes of the original and example images. This color transformation is combined with a global contrast transformation achieved by a parametric histogram specification. In particular, classical histogram specification between images may lead to visual artifacts, thus we approximate the histogram specification curve to a power law model through least squares fitting. That ensures that the contrast is transferred globally without creating artifacts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We present here a number of experiments performed with our method. In <ref type="figure">Fig. 4</ref>, we present a comparison of our algorithm and two state-of-the-art style transfer methods. The first method, called PatchTable <ref type="bibr" target="#b2">[2]</ref>, is originally applied for supervised style transfer, but since we do not have a pair of example unfiltered and filtered images (as used in <ref type="bibr" target="#b15">[15]</ref>), we apply their method 1 in an unsupervised setting by assuming that the unfiltered and filtered images are the same. In their result, Van Gogh's typical brushwork is transferred at some point, but the complete painting style is poorly recreated. Also the overall structures of the original image are lost. The second method is the Neural Artistic Style <ref type="bibr" target="#b13">[13]</ref>, based on CNN. While the color palette of the example image is well preserved, the texture is not well recreated in their results. For example, the texture in the sky differs considerably from the snail shapes in Van Gogh's painting. Our result outperforms state-of-the-art methods, capturing the local image texture, color and contrast.</p><p>In <ref type="figure" target="#fig_5">Fig. 5</ref>, we present an illustration of style transfer from two different styles of sketches. Both results show the good performance of our algorithm in transferring the drawing style.</p><p>Finally, in <ref type="figure" target="#fig_6">Fig. 6</ref>, we show style transfer with our method for two different painting styles. With our adaptive quadtree partition each original image has a different partition particularly adapted to the given example. Thanks to this strategy, our algorithm accomplishes to transfer the appearance independently of the scale texture of the example or the geometry of the original image. We believe that a good style transfer implies to reproduce the texture and the color palette of the example image, as we have already mentioned. However, other artistic choices are possible depending on the desired results. For example, some application may request to only transfer texture and keep the colors of the original image. <ref type="figure" target="#fig_4">Fig. 7</ref> shows our results when transferring or not the global color. <ref type="bibr" target="#b0">1</ref> We use the code provided in the author's page</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source image</head><p>Example image</p><p>Only texture transfer Texture + color transfer </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we have proposed a new style transfer method that, differently to previous patch-based approaches, is able to synthesize textures independently of their scale. Our results suggest that the decomposition of content and style in artistic images can be achieved with a simple yet efficient adaptive image partition.</p><p>Moreover, we have shown that a local texture modeling and a global color transfer strategy leads to a convincing and structure-preserving stylization. On the other hand, stateof-the-art style transfer methods are likely to destroy structures at the cost of synthesizing style.</p><p>We note that our method is naturally not guaranteed to transfer textures that belong to the same semantic category in the input and example images. The incorporation of additional semantic constraints or user scribbles could be beneficial to enforce, for instance, that the style in the sky of an example image is mimicked in the sky of the stylized image.</p><p>Transferring edge styles is also not guaranteed by our method, since the euclidean norm between image patches is not well adapted to match edges of different thickness and styles. On the other hand, a norm computed in a transformed feature space (for example, the filter responses from the convolutional layers of a CNN) could be more adapted to match edges of different styles.</p><p>At the moment, our implementation takes approximately 3 min. for a 512 × 512 image. Future work will concentrate on the acceleration of the patch search, and the adaptation of our method for videos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original and Example</head><p>Our method Unsupervised Patch table <ref type="bibr" target="#b2">[2]</ref> Neural Artistic Style <ref type="bibr" target="#b13">[13]</ref> Figure 4. Comparison with state-of-the-art. It can be observed that our method captures the prominent texture and color features from Van Gogh's painting, with an overall accurate reconstruction of buildings. The method of <ref type="bibr" target="#b2">[2]</ref> captures partially the brushwork texture from the painting, but the buildings are not well reconstructed. The method of <ref type="bibr" target="#b13">[13]</ref> captures accurately the painting colors, however it does not reconstruct all main structures in the original image (buildings in bottom left), and the brushwork textures are not noticeable in the result image, which has a rather blurry effect in the sky.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Illustration of the proposed unsupervised style transfer. From left to right: the source image, the example image, the adaptive example-based partition, and the result of the style transfer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Global color and contrast matching (Sec. 3.5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1 "R</head><label>1</label><figDesc>Split and Match" patch decomposition Input: Images: u, v; parameters:Υ 0 , Υ 1 , ω Output: Set of regions R = {R i } n i=1 , set of candidate labels L = {L i } n i=1 1: Initialization: R 1 ← {Ω u } 2: for every region R i ∈ R do ← {R \ R i } ∪ {R m+1 , ..., R m+4 }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>a) MRF for low-level vision problems over a regular grid. Nodes in the bottom layer represent image units from the observed scene, while nodes in the top layer represent hidden image units that we search to estimate through inference. The vertical edges represent data fidelity terms, while the horizontal edges represent pairwise compatibility terms. b) MRF over an adaptive image partition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 .</head><label>7</label><figDesc>Illustration of only texture versus texture and color transfer. Both results are interesting depending on the artistic choice.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Illustration of example-based style transfer for sketches. From left to right: original image from Magritte and the result of our algorithm using as example the smaller sketches at the right. In this example texture as well as color are very important to reproduce the style.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Illustration of our example-based style transfer for different painting styles. Example images from van Gogh's and Seurat's are on the top and original images are on the left. Our algorithm transfers successfully the style for different texture scales and it preserves the image geometry of the original images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Figure 2. Comparison of partitioning strategies for style transfer. Top row: original and example. Middle row: style transfer using regular patches. Small patches do not manage to capture the style, while large patches do not preserve the image structures. Bottom row: style transfer using adaptive patches. The left adaptive partition based on image variance exhibits an artifact due to a large image portion that cannot be correctly matched. On the contrary, the example-based partition finds good matches for all parts.</figDesc><table>Original 
Example 

Regular grid, patch size: 8 2 Regular grid, patch size: 32 2 

Variance-based quadtree 
Our method 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Synthesizing natural textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ashikhmin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 Symposium on Interactive 3D</title>
		<meeting>the 2001 Symposium on Interactive 3D</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<title level="m">Graphics, I3D &apos;01</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="217" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Patchtable: Efficient patch queries for large datasets and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-M</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Stylizing animation by example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bénard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mordatch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hegarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Senn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fleischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pesare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Breeden</surname></persName>
		</author>
		<idno>119:1-119:12</idno>
	</analytic>
	<monogr>
		<title level="j">ACM TOG</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2013-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Consistent image analogies using semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Region filling and object removal by exemplar-based image inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-IP</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1200" to="1212" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An invitation to discuss computer depiction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NPAR</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="111" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image quilting for texture synthesis and transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="341" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Texture synthesis by non-parametric sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page">1033</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Towards a mathematical theory of primal sketch and sketchability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Examplebased super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pasztor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Graph. Appl</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="56" to="65" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning low-level vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pasztor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Carmichael</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Optimal transportation for example-guided color transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Frigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sabater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Demoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hellier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A neural algorithm of artistic style</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
		<idno>abs/1508.06576</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Stochastic relaxation, gibbs distributions, and the bayesian restoration of images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Image analogies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Salesin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Picture segmentation by a directed split and merge procedure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pavlidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="1974" />
			<biblScope unit="page" from="424" to="433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">State of the art: A taxonomy of artistic stylization techniques for images and video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kyprianidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Collomosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Isenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="866" to="885" />
			<date type="published" when="2013-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Vision: A Computational Investigation into the Human Representation and Processing of Visual Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<publisher>Henry Holt and Co., Inc</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Color transfer between images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Reinhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ashikhmin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gooch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Graph. Appl</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="34" to="41" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Unsupervised image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rosales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Achan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="472" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A mathematical theory of communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell System Technical Journal</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="379" to="423" />
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Style transfer for headshot portraits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOG</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">148</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Datadriven hallucination of different times of day from a single outdoor photo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>ACM TOG</publisher>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">200</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Face photo-sketch synthesis and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1955" to="1967" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Belief propagation and revision in networks with loops</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Style transfer via image component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1594" to="1601" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Filters, random fields and maximum entropy (frame): Towards a unified theory for texture modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="107" to="126" />
			<date type="published" when="1998-04" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
