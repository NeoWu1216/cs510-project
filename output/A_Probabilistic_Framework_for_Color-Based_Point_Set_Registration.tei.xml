<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Probabilistic Framework for Color-Based Point Set Registration</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
							<email>martin.danelljan@liu.se</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="laboratory">Computer Vision Laboratory</orgName>
								<orgName type="institution">Linköping University</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fahad</roleName><forename type="first">Giulia</forename><surname>Meneghetti</surname></persName>
							<email>giulia.meneghetti@liu.se</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="laboratory">Computer Vision Laboratory</orgName>
								<orgName type="institution">Linköping University</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahbaz</forename><surname>Khan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="laboratory">Computer Vision Laboratory</orgName>
								<orgName type="institution">Linköping University</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Felsberg</surname></persName>
							<email>michael.felsberg@liu.se</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="laboratory">Computer Vision Laboratory</orgName>
								<orgName type="institution">Linköping University</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Probabilistic Framework for Color-Based Point Set Registration</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In recent years, sensors capable of measuring both color and depth information have become increasingly popular. Despite the abundance of colored point set data, stateof-the-art probabilistic registration techniques ignore the available color information. In this paper, we propose a probabilistic point set registration framework that exploits available color information associated with the points. Our method is based on a model of the joint distribution of 3D-point observations and their color information. The proposed model captures discriminative color information, while being computationally efficient. We derive an EM algorithm for jointly estimating the model parameters and the relative transformations.</p><p>Comprehensive experiments are performed on the Stanford Lounge dataset, captured by an RGB-D camera, and two point sets captured by a Lidar sensor. Our results demonstrate a significant gain in robustness and accuracy when incorporating color information. On the Stanford Lounge dataset, our approach achieves a relative reduction of the failure rate by 78% compared to the baseline. Furthermore, our proposed model outperforms standard strategies for combining color and 3D-point information, leading to state-of-the-art results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>3D-point set registration is a classical computer vision problem with important applications. Generally, the points originate from measurements of sensors, such as time-offlight cameras and laser range scanners. The problem is to register observed point sets from the same scene by finding their relative geometric transformations. One class of approaches <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">16]</ref>, based on the Iterative Closest Point (ICP) <ref type="bibr" target="#b0">[1]</ref>, iteratively assumes pairwise correspondences and then finds the transformation by distance minimization. Alternatively, probabilistic methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b13">14]</ref> model the distribution of points using e.g. Gaussian Mixture Models (GMMs).</p><p>Recently, probabilistic approaches demonstrated promising results for point set registration <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7]</ref>. The im-(a) First set.</p><p>(b) Second set.</p><p>(c) Baseline registration <ref type="bibr" target="#b4">[5]</ref>.</p><p>(d) Our color-based registration. proved performance in probabilistic methods is achieved by modeling the distribution of points as a density function. The probabilistic approaches can be further categorized into correlation-based and Expectation Maximization (EM) based methods. The correlation-based approaches <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b16">17]</ref> estimate the transformation parameters by maximizing a similarity measure between the density models of the two point sets. Instead, the EM-based methods simultaneously estimate the density model and the transformation parameters <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">14]</ref>. In this paper, we explore probabilistic models for EM-based colored point set registration. State-of-the-art probabilistic techniques <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">14]</ref> rely on the distribution of points in 3D-space, while ignoring additional information, such as color, for point set registration. On the other hand, the increased availability of cheap RGB-D cameras has triggered the use of colored 3D-point sets in many computer vision applications, including 3D object recognition <ref type="bibr" target="#b3">[4]</ref>, scene reconstruction <ref type="bibr" target="#b2">[3]</ref> and robotics <ref type="bibr" target="#b5">[6]</ref>. Besides RGB-D cameras, many laser range scanners also capture RGB or intensity information. Additionally, col-ored point sets are produced by stereo cameras and ordinary cameras by using structure from motion. In this paper, we investigate the problem of incorporating color information for probabilistic point set registration, regardless of the sensor used for capturing the data.</p><p>When incorporating color information in probabilistic point set registration, the main objective is to find a suitable probability density model of the joint observation space. The joint space consists of the 3D-point observations and their associated color information. Color information can be incorporated into a probabilistic point set model in two standard ways. (i) A first approach is to directly introduce joint mixture components in the complete observation space. This model requires large amounts of data due to the high dimensionality of the joint space, leading to a high computational cost. (ii) A second approach is to assume stochastic independence between points and color, which enables separable modeling of both spaces. However, this assumption ignores the crucial information about the spatial dependence of color. The aforementioned shortcomings of both fusion approaches motivate us to investigate alternative probabilistic models for incorporating color information. Contributions: In this paper, we propose a color-based probabilistic framework for point set registration. Our model combines the advantages of (i) and (ii), by assuming conditional independence between the location of a point and its color value, given the spatial mixture component. In our model, each spatial component also contains a nonparametric density estimator of the local color distribution. We derive an efficient EM algorithm for joint estimation of the mixture and the transformation parameters. Our approach is generic and can be used to integrate other invariant features, such as curvature and local shape.</p><p>Comprehensive experiments are performed on the Stanford Lounge dataset <ref type="bibr" target="#b18">[19]</ref> containing 3000 RGB-D frames with ground-truth poses. We also perform experiments on two colored point sets captured by a Lidar: one indoor scene and one outdoor scene <ref type="bibr" target="#b17">[18]</ref>. The results clearly demonstrate that our color-based registration significantly improves the baseline method. We further show that the proposed colorbased registration method outperforms standard color extensions, leading to state-of-the-art performance. <ref type="figure" target="#fig_0">Figure 1</ref> shows registration results on the indoor Lidar dataset, using the baseline <ref type="bibr" target="#b4">[5]</ref> and our color-based registration model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Initially, most point set registration methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">16]</ref> were based on the classical ICP <ref type="bibr" target="#b0">[1]</ref> algorithm. The ICP-based approaches alternate between assuming point-to-point correspondences between the two sets and finding the optimal transformation parameters. The standard ICP <ref type="bibr" target="#b0">[1]</ref> is known to require a good initialization, since it is prone to get stuck in local minima. Several methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref> have been pro-posed to tackle this robustness issue.</p><p>Probabilistic registration techniques employ, e.g., Gaussian mixtures to model the distribution of points. In correlation based probabilistic approaches <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b16">17]</ref>, the two point sets are modeled separately in a first step. A similarity measure between the density models, e.g. the KL divergence, is then maximized with respect to the transformation parameters. However, these methods lead to nonlinear optimization problems with non-convex constraints. To avoid complex optimization problems, several recent methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">14]</ref> simultaneously estimate the density model and the registration parameters in an EM-based framework. Among these methods, the recent Joint Registration of Multiple Point Sets (JRMPS) <ref type="bibr" target="#b4">[5]</ref> models all involved point sets as transformed realizations of a single common GMM. Compared to previous EM-based methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14]</ref>, JRMPS does not constrain the GMM centroids to the points in a particular set. This further enables a joint registration of multiple point sets.</p><p>The use of color information for point set registration has been investigated in previous works <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b11">12]</ref>. Huhle et al. <ref type="bibr" target="#b7">[8]</ref> propose a kernel-based extension to the normal distributions transform, for aligning colored point sets. Most approaches <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref> aim at augmenting ICP-based methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b15">16]</ref> with color. In these approaches, a metric is introduced in a joint point-color space, to find correspondences in each iteration. A drawback of these ICP variants is that the metric relies on a data dependent parameter that controls the trade-off between spatial distance and color difference. Different to these methods, we incorporate color information in a probabilistic registration framework. The registration is performed using an EM-based maximum likelihood estimation. Next, we describe the baseline probabilistic registration framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Joint Registration of Point Sets</head><p>We base our registration framework on the JRMPS <ref type="bibr" target="#b4">[5]</ref> method, since it has shown to provide improved performance compared to previous GMM based approaches <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14]</ref>. Contrary to these methods, JRMPS assumes both sets to be transformed realizations of one reference GMM. This avoids the underlying asymmetric assumption of using one of the sets as a reference model in the registration <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14]</ref>. Further, the JRMPS has the advantage of naturally generalizing to joint registration of multiple sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Point Set Observation Model</head><p>In the problem of joint registration of multiple point sets, the observations consist of 3D-points in M different views of the same scene. The aim is then to find the transformation of each set to a common reference coordinate system, called the reference frame. All observations of 3D-points are assumed to originate from the same spatial distribution V ∼ p V , representing the entire scene. Here, V ∈ R 3 is a random variable (r.v.) of a point in the reference frame, and p V is the probability density function (p.d.f.) of V.</p><p>Let X ij ∈ R 3 be the r.v. of the j:th observed point in view i ∈ {1, . . . , M } and let x ij be its observed value. Observations in view i are related to the reference frame by the unknown rigid transformation</p><formula xml:id="formula_0">φ i (x) = R i x + t i , such that φ i (X ij ) ∼ p V . The transformed observations φ i (X ij )</formula><p>thus have the distribution p V in the reference frame. Consequently, the p.d.f. of the observation X ij is given by p Xij (x ij ) = p V (φ i (x ij )). To simplify notation, we often write p Xij (x ij ) = p(x ij ).</p><p>As described above, the observed points are assumed to be transformed samples of the distribution p V . The point distribution p V is modeled as a mixture of Gaussian distributions. Let K be the number of Gaussian components. We then introduce the discrete latent r.v. Z ∈ {0, . . . , K} that assigns the point V to the mixture component Z = k. The extra 0th component is a uniform distribution that models the occurrence of outlier points. The joint p.d.f. of V and Z factorizes as p(v, z) = p(v|z)p(z). For discrete variables, we use the notation p(Z = k) = p Z (k). The mixture component weights π k are defined as the prior probabilities π k = p(Z = k) of the latent variable Z. The conditional distribution of V given Z = k is then defined as,</p><formula xml:id="formula_1">p(v|Z = k) = U U (v), k = 0 N (v; µ k , Σ k ), k = 0.<label>(1)</label></formula><p>Here, U U denotes a uniform distribution in the convex hull U ⊂ R 3 of the observations <ref type="bibr" target="#b6">[7]</ref>. The multivariate normal distribution with expectation µ and covariance Σ is denoted by N (· ; µ, Σ). The point density function p V is obtained by marginalizing over the latent variable Z,</p><formula xml:id="formula_2">p V (v) = K k=1 π k N (v; µ k , Σ k ) + π 0 U U (v).<label>(2)</label></formula><p>Next, we describe how the above described observation model is used for point set registration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Point Set Registration</head><p>The registration is performed by jointly estimating the transformation and the GMM parameters, in (2), using the EM algorithm. We denote the set of all observations by X = {x ij } Ni,M j=1,i=1 and the collection of corresponding latent variables by</p><formula xml:id="formula_3">Z = {Z ij } Ni,M j=1,i=1 .</formula><p>Here, N i denotes the number of observations in point set i. All observations are assumed to be independent. As in <ref type="bibr" target="#b4">[5]</ref>, a fix outlier weight π 0 is assumed. The model parameters are summarized as,</p><formula xml:id="formula_4">Θ = {π k , µ k , Σ k } K k=1 , {R i , t i } M i=1 .<label>(3)</label></formula><p>The point registration is performed by jointly estimating the parameters Θ from the observed data X . In <ref type="bibr" target="#b4">[5]</ref>, a Maximum Likelihood (ML) estimate of Θ is obtained using the Expectation Maximization (EM) framework. The E-step evaluates the conditional expectation of the complete data loglikelihood log p(X , Z|Θ). The expectation is taken with respect to the latent variables Z given the observed data X and the current estimate of the parameters Θ (n) ,</p><formula xml:id="formula_5">Q(Θ; Θ (n) ) = E Z|X ,Θ (n) [log p(X , Z|Θ)] = Z p(Z|X , Θ (n) ) log p(X , Z|Θ)<label>(4)</label></formula><p>In the M-step, the aim is to find the optimizer of (4) as</p><formula xml:id="formula_6">Θ (n+1) = arg max Θ Q(Θ; Θ (n) ).</formula><p>To obtain a closed form solution, the M-step is divided into two conditional maximization (CM) steps <ref type="bibr" target="#b12">[13]</ref>, where the transformation and GMM parameters are updated separately <ref type="bibr" target="#b6">[7]</ref>. Using the definitions in section 3.1 and the independent observations assumption, the complete data likelihood is ex-</p><formula xml:id="formula_7">pressed as p(X , Z|Θ) = ij p(x ij , z ij |Θ), where p(x ij , Z ij = k|Θ) = π k N (φ i (x ij ); µ k , Σ k ) , k = 0. (5)</formula><p>The posterior density of the latent variables factorizes as p(Z|X , Θ (n) ) = ij p(z ij |x ij , Θ (n) ). The E-step then reduces to computing the posterior probabilities of the latent variables α</p><formula xml:id="formula_8">(n) ijk := p(Z ij = k|x ij , Θ (n) ) [5]. Eq. 4 now simplifies to, Q(Θ; Θ (n) ) = ijk α (n) ijk log p(x ij , Z ij = k|Θ). (6)</formula><p>By applying (5) and ignoring constant terms, <ref type="bibr" target="#b5">(6)</ref> can be rewritten to the equivalent minimization problem,</p><formula xml:id="formula_9">f (Θ; Θ (n) ) = ij K k=1 α (n) ijk 1 2 log |Σ k | + 1 2 R i x ij + t i − µ k 2 Σ −1 k − log π k . (7)</formula><p>Here, |Σ k | denotes the determinant of Σ k and we have defined x 2</p><formula xml:id="formula_10">Σ −1 k = x T Σ −1 k x.</formula><p>For simplicity, isotropic covariances are assumed Σ k = σ 2 k I, as in <ref type="bibr" target="#b4">[5]</ref>. The parameters Θ are updated in the two CM-steps of the algorithm. The first CM-step minimizes <ref type="formula">(7)</ref> with respect to the transformation parameters</p><formula xml:id="formula_11">{R i , t i } M i=1 , given the cur- rent GMM parameters {π (n−1) k , µ (n−1) k , Σ (n−1) k } K k=1 .</formula><p>The second CM-step minimizes (7) with respect to the GMM parameters given the new {R</p><formula xml:id="formula_12">(n) i , t (n) i } M i=1</formula><p>. We refer to <ref type="bibr" target="#b4">[5]</ref> for the closed form solutions of the two CM-steps. Next we introduce our color based registration technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Feature Based Point Set Registration</head><p>We reformulate the registration problem from section 3 to incorporate feature information associated with each 3Dpoint. In this work, we investigate the incorporation of color information for point set registration. However, our framework is not restricted to color features. It also enables the use of, e.g., structural features that describe the local shape or curvature of the point set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Feature Based Observation Model</head><p>Our framework assumes the observations to consist of a 3D-point and its associated feature value, e.g. color. Let Y ∈ Ω denote the r.v. of the feature value associated with the 3D-point V. Here, Ω is the set of all possible feature values, called the feature space. For example, if Y is the color of the 3D-point in normalized HSV coordinates, then the feature space is the unit cube Ω = [0, 1] 3 . We assume observations of points and features to originate from a common joint distribution (V, Y ) ∼ p V,Y . The aim of this paper is to propose an efficient yet distinctive mixture model of the joint point-feature density p V,Y . Next, we investigate three different strategies to construct a mixture model of the joint point-feature space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">The Direct Approach</head><p>A direct generalization of the GMM based registration technique (section 3), is to introduce joint mixture components in the point-feature space R 3 ×Ω. In general, let F (v, y; θ k ) denote the density function of a mixture component in the joint space (v, y) ∈ R 3 × Ω. Here, θ k denote the parameters of the k:th component. A mixture model in the joint point-feature space is expressed as</p><formula xml:id="formula_13">p V,Y (v, y) = K k=1 π k F (v, y; θ k ).<label>(8)</label></formula><p>However, this strategy of directly introducing joint components F (v, y; θ k ) requires a large amount of data, due to the exponential growth of volume with the number of dimensions (i.e. the curse of dimensionality). This leads to a higher computational cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">The Independent Approach</head><p>To alleviate the problems induced by the direct strategy <ref type="formula" target="#formula_13">(8)</ref>, a simple approach is to assume stochastic independence between 3D-points and feature values. The joint distribution p V,Y then factorizes as the product of the marginal distributions for the 3D-points p V and feature values p Y , such that p V,Y = p V p Y . This assumption enables the spatial distribution of points p V and the distribution of features p Y to be modeled separately. LetF ,θ l andπ l denote the components, parameters and weights respectively for the mixture model of the feature density p Y . We denote the number of feature components by L. The joint distribution can then be expressed as</p><formula xml:id="formula_14">p V,Y (v, y) = K k=1 L l=1 π kπl N (v; µ k , Σ k )F (y;θ l ). (9)</formula><p>Here, we have used the GMM presented in section 3.1 for the spatial distribution p V and ignore the uniform component for simplicity. While the independence assumption allows for a separation of the mixture models, it completely removes information regarding the spatial dependence of feature values. Such information is crucial for aiding the registration process.</p><p>The aforementioned approaches have major limitations when incorporating feature information for point set registration. Next, we describe an approach that combines the discriminative power of the direct approach with the efficiency of the independent approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Our Approach</head><p>We propose a mixture model of the joint point-feature space R 3 × Ω that tackles the drawbacks of the aforementioned approaches. Contrary to the direct strategy (section 4.1.1), our method does not require an increased amount of points to infer the model parameters. We thereby avoid the problems induced by the higher dimensionality of the observation space. Additionally, our model accurately captures the local characteristics in the distribution of features, e.g., how colors are distributed in the scene. This enables our framework to exploit the underlying discriminative feature information associated with each 3D-point. The proposed mixture model contains a separate feature distribution for each spatial mixture component (illustrated in <ref type="figure" target="#fig_1">figure 2</ref>). In addition to the spatial latent variable Z, we introduce a second latent r.v. C ∈ {1, . . . , L}. This variable assigns a point-feature pair (V, Y ) to one of the L mixture components in the feature space Ω. Our model is based on the conditional independence assumption between the point V and the feature variables Y, C given the spatial mixture component Z. This is symbolically expressed as V ⊥ Y, C | Z. Our model assumption enables the following factorization of the joint p.d.f. of (V, Y, C, Z), p(v, y, c, z) = p(v, y, c|z)p(z) = p(v|z)p(y, c|z)p(z) = p(v|z)p(y|c, z)p(c|z)p(z).</p><p>The first and fourth factor of (10) do not depend on the feature information, and are defined in section 3.1 (see <ref type="formula" target="#formula_1">(1)</ref>). Each spatial component is given a separate feature distribution that characterizes the occurrences of feature values in the vicinity of the component. These distributions are defined by the feature component weights, determined by the conditional probability of a feature component C = l given a spatial component Z = k,</p><formula xml:id="formula_16">p(C = l|Z = k) = ρ kl , k = 0.<label>(11)</label></formula><p>This expression defines the third factor in <ref type="bibr" target="#b9">(10)</ref>. The feature mixture weights must satisfy ρ kl ≥ 0 and l ρ kl = 1 for each spatial component k. For the outlier component k = 0, we assume uniform weights p(C = l|Z = 0) = 1 /L. The second factor p(y|c, z) in <ref type="formula" target="#formula_1">(10)</ref> is determined by the mixture components in the feature space. Since the feature space Ω can be compact or discrete, we do not restrict our choice to Gaussian distributions. Instead, we consider arbitrary non-negative functions B l : Ω → R satisfying Ω B l = 1. We define, p(y|C = l, Z = k) =</p><p>U Ω (y), k = 0 B l (y), k = 0.</p><p>As for the spatial mixture components (1), we also use a uniform component in the feature space for Z = 0 to model outliers. The integration feature information into the registration process comes at an increased computational cost. In order to minimize this cost, we use non-parametric feature components B l in our model. This allows the probabilities B l (y ij ) to be precomputed and avoids additional costly maximizations of in the M-step. The proposed mixture model of the joint space is computed by marginalizing over the latent variables Z, C in (10) and using the definitions (1), <ref type="bibr" target="#b10">(11)</ref> and <ref type="formula" target="#formula_1">(12)</ref>,</p><formula xml:id="formula_18">p V,Y (v, y) = K k=1 L l=1 π k ρ kl B l (y)N (v; µ k , Σ k ) + π 0 U U (v)U Ω (y).<label>(13)</label></formula><p>Our model (13) differs from the direct approach <ref type="bibr" target="#b7">(8)</ref> in that it enables a separation between the point and feature components. It also differs from the independent approach <ref type="bibr" target="#b8">(9)</ref> in that the feature component weights ρ kl depend on the spatial component k. Our model thus shares distinctiveness with the direct approach (8) and efficiency with the independent approach (9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Registration</head><p>Different from the standard GMM based registration (section 3), our model includes the feature observations y ij and the corresponding latent feature variables C ij . In our framework, the set of all observations is X = {(x ij , y ij )} Ni,M j=1,i=1 and the collection of corresponding latent variables is Z = {(Z ij , C ij )} Ni,M j=1,i=1 . The model parameters have been extended with the feature distribution weights ρ kl in <ref type="bibr" target="#b10">(11)</ref>, and are given as</p><formula xml:id="formula_19">Θ = {π k , µ k , Σ k , ρ k1 , . . . , ρ kL } K k=1 , {R i , t i } M i=1 .<label>(14)</label></formula><p>We apply an EM procedure, as described in section 3.2, to estimate the parameters (14) of our model. The model assumptions in section 4.1.3 imply the complete data likelihood p(X , Z|Θ) = ij p(x ij , y ij , c ij , z ij |Θ), where the joint probability of an observation and its latent variables is</p><formula xml:id="formula_20">p(x ij , y ij , C ij = l, Z ij = k|Θ) = = π k ρ kl B l (y ij )N (φ i (x ij ); µ k , Σ k ) , k = 0. (15)</formula><p>The independence of observations imply the factorization p(Z|X , Θ (n) ) = ij p(z ij , c ij |x ij , y ij , Θ (n) ). By applying (15), the latent posteriors are expressed as, 1</p><formula xml:id="formula_21">α (n) ijkl := p(Z ij = k, C ij = l|x ij , y ij , Θ (n) ) = (16) π (n) k ρ (n) kl B l (y ij )N φ (n) i (x ij ); µ (n) k , Σ (n) k K q=1 L r=1 π (n) q ρ (n) qr B r (y ij )N φ (n) i (x ij ); µ (n) q , Σ (n) q + λ .</formula><p>Here, the constant in the denominator, originating from the outlier component is given by λ = For our mixture model, the expected complete data loglikelihood (4) reduces to,</p><formula xml:id="formula_22">Q(Θ; Θ (n) ) = ijkl α (n)</formula><p>ijkl log p(x ij , y ij , C ij = l, Z ij = k|Θ).</p><p>(17) As in section 3.2, maximization of the expected complete data log-likelihood <ref type="bibr" target="#b16">(17)</ref> can be reformulated as an equivalent minimization problem by applying (15), 1</p><formula xml:id="formula_23">g(Θ; Θ (n) ) = ij K k=1 L l=1 α (n) ijkl 1 2 log |Σ k | + 1 2 R i x ij + t i − µ k 2 Σ −1 k − log π k − log ρ kl . (18)</formula><p>To simplify the expression (17), we first define the marginal latent posteriors by summing over the latent feature variable α</p><formula xml:id="formula_24">(n) ijk = l α (n)</formula><p>ijkl . This enables our loss <ref type="bibr" target="#b17">(18)</ref> to be rewritten as, </p><formula xml:id="formula_25">g(Θ; Θ (n) ) = f (Θ; Θ (n) )− ij K k=1 L l=1 α (n) ijkl log ρ kl . (19)</formula><p>Here, f (Θ; Θ (n) ) is the corresponding loss <ref type="formula">(7)</ref> in the standard GMM-based registration. This implies that the transformation parameters (R i , t i ) and the spatial mixture parameters (π k , µ k , Σ k ) can be obtained as in section 3.2. However, in our method, the latent posteriors given by <ref type="bibr" target="#b15">(16)</ref> are used in the M-step. Different from section 3, our marginal latent posteriors α (n) ijk thus also integrate feature information into the EM-procedure. Finally, the feature distribution weights are obtained by minimizing the second term in <ref type="bibr" target="#b18">(19)</ref> using Lagrangian multipliers, 1</p><formula xml:id="formula_26">ρ (n) kl = ij α (n) ijkl ij α (n) ijk , k = 1, . . . , K.<label>(20)</label></formula><p>We incorporate the estimation of the feature distribution parameters (20) in the second CM-step (see section 3.2), along with the estimation of the other mixture parameters. <ref type="figure" target="#fig_3">Figure 3</ref> shows an overview of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Feature Description</head><p>Here, we provide a detailed description of how the distribution of features is modeled, by the selection of feature mixture components B l . We restrict our discussion to color features. In our model, the feature observations are represented by an HSV triplet y = (y H , y S , y V ) ∈ Ω = [0, 1] 3 . In this work, we use second order B-splines to construct the feature components B l . However, other functions with similar characteristics can also be used. Each component B l is a separable function B l (y) = a l B 1 l (y H )B 2 l (y S )B 3 l (y V ). In each dimension, the component is given by a scaled and shifted second order B-spline function B i l . The constant a l is a normalization factor given by the condition Ω B l = 1. The components B l are placed in a regular grid inside the unit cube Ω = [0, 1] 3 . The spacing between the components is set to 1/L d along feature dimension d, where L d denotes the number of components in dimension d. The total number of components is hence L = d L d .</p><p>Similar to GMMs, our method is able to model multimodal color distributions. However, our choice of nonparametric mixture components B l is computationally beneficial. In contrast, employing a standard GMM in the color space requires computation of the color means and covariances in the EM-procedure. Our approach further allows the probabilities B l (y ij ) to be precomputed for all points. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We perform a comprehensive quantitative and qualitative evaluations on one RGB-D and two Lidar datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Details and Parameters</head><p>We use the same number of spatial components K = 500, the same outlier ratio π 0 = 0.005 and 100 EMiterations for both the standard JRMPS and our color-based versions. We also initialize all methods with the same parameters for the spatial GMM. The initial means µ (0) k are uniformly sampled on a sphere with the radius equal to the standard deviation of the point distribution. As in <ref type="bibr" target="#b4">[5]</ref>, we fix the spatial component weights π k to uniform, since we did not observe any improvement in updating them. The feature component weights ρ kl are initialized by uniformly sampling the L − 1 simplex for each k. Our approach is implemented in Matlab. Compared to the baseline JRMPS, our approach marginally increases the computation time (25 to 27 sec. on a single core), for 2000 points per set.</p><p>For the direct approach, presented in section 4.1.1, the joint components are constructed as products of a spatial Gaussian and a feature component F (v, y; θ k ) = N (v; µ k , Σ k )B l k (y). Here, B l k is constructed as in section 4.3, and the index l k ∈ {1, . . . , L} is selected randomly for each component k. For the independent approach (section 4.1.2), we also set the feature components based on the B-splines presented in section 4.3. That is, we set F (y;θ l ) = B l (y) in <ref type="bibr" target="#b8">(9)</ref>. For all methods, we use L d = 4 feature components in each dimension of the HSV space, which gives L = 64 feature components in total. For both the direct and independent approaches, we also employ the additional uniform outlier component (see section 3.1). Evaluation Criteria: We compute the rotation errors compared to the ground truth by measuring the Frobenius distance between rotation matrices <ref type="bibr" target="#b4">[5]</ref>. The rotation error is defined as R − R F , whereR and R are the estimated and ground-truth relative rotations between two point sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Stanford Lounge Dataset</head><p>We perform experiments on the Stanford Lounge Dataset <ref type="bibr" target="#b18">[19]</ref>, consisting of 3000 RGB-D frames taken by a Kinect. <ref type="figure" target="#fig_4">Figure 4</ref> contains an example frame. We use the estimated poses, provided by the authors, as ground truth.  <ref type="table">Table 1</ref>. A comparison with other registration methods on the Stanford Lounge dataset. We report the failure rate along with the average and standard deviation of the inlier rotation errors. Compared to the baseline JRMPS <ref type="bibr" target="#b4">[5]</ref>, our approach achieves significantly better robustness with a relative reduction in the failure rate by 78%. Further, our approach outperforms other color based methods, including Color GICP <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Pairwise Registration</head><p>We compare our approach with several state-of-the-art methods with publicly available code, namely ICP 2 <ref type="bibr" target="#b0">[1]</ref>, GMMReg <ref type="bibr" target="#b8">[9]</ref>, Color GICP 3 <ref type="bibr" target="#b10">[11]</ref>, and the baseline JRMPS <ref type="bibr" target="#b4">[5]</ref>. To ensure a significant initial transformation, we perform registration between frame number n and n + 5, for all frames n in the dataset. We randomly downsample the frames to 10000 points. As a measure of robustness, we report the failure rate defined as the percentage of rotation errors larger than 0.1 (approximately 4 degrees). We further define a registration to be an inlier if the error is smaller than 0.1. We compute the average and standard deviation of the inlier rotation errors, as measures of accuracy.</p><p>The results are reported in <ref type="table">Table 1</ref>. The standard ICP obtains inferior performance with a failure rate of 15.7%. The baseline JRMPS achieves a failure rate of 3.41%. The Color GICP provides competitive results with a failure rate of 1.27%. The two standard color extensions, using the independent and direct approaches, provides the failure rates 3.41% and 2.14% respectively. Our approach achieves the best results on this dataset, with a failure rate of 0.74%. Additionally, our method obtains a significant reduction of the    average rotation error by 12.5% compared to JRMPS. In <ref type="figure" target="#fig_5">figure 5</ref> we investigate the impact of varying the number of feature components L on the Stanford Lounge dataset, when using 2000 points per set. <ref type="bibr" target="#b3">4</ref> The left plot shows the average frame-to-frame rotation error for inliers, when increasing the number of components per HSV-dimension from 2 to 7. As a reference, we also include the baseline JRMPS. The independent approach (section 4.1.2) provides similar results to JRMPS. The direct approach (section 4.1.1), requires a larger amount of data points when increasing the number of feature components. The performance therefore rapidly degrades as the number of feature components is increased. Contrary to this, our model benefits from increasing the number of feature components, leading to improved results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Joint Multi-view Registration</head><p>Here, we investigate the performance of our approach for joint registration of multiple point sets. Alignment of multiple point sets is important in many applications. Most registration methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b10">11]</ref> are however limited to pairwise registration. In these cases, multi-view registration must be performed either by sequential pair-wise alignment or by performing a one-versus-all strategy, leading to drift or biased solutions. Similar to JRMPS <ref type="bibr" target="#b4">[5]</ref>, our method is able to jointly register an arbitrary number of point sets. We perform joint registration of every 10 consecutive frames, with <ref type="bibr" target="#b1">2</ref> We use the built-in MATLAB implementation of ICP. <ref type="bibr" target="#b2">3</ref> We use the Color GICP implemented in Point Cloud Library. <ref type="bibr" target="#b3">4</ref> Analysis of K and π 0 is provided in the supplementary material. an interval of 9 frames, on the Stanford Lounge dataset. This implies that joint multi-view registration is performed on frame 1-10, 10-19, etc. <ref type="table" target="#tab_2">Table 2</ref> contains the results, by measuring the frame-to-frame rotation errors. Our color based model reduces the relative failure rate by 86% compared to the baseline JRMPS. In case of average rotation error, our approach provides a significant reduction of 15.9%. <ref type="figure" target="#fig_6">Figure 6</ref> shows the recall and convergence rate plots. Recall is computed as the fraction of frame-to-frame rotation errors smaller than a threshold. In <ref type="figure" target="#fig_6">figure 6</ref>, the recall is plotted over a range of error thresholds. To compare the convergence rate of our method with the baseline JRMPS, we plot the average frame-to-frame inlier rotation error after each EM iteration. Our method converges in significantly fewer iterations, enabling a more efficient registration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Lidar Datasets</head><p>We experimented with two Lidar datasets, acquired by a FARO Focus3D. Both consist of more than a million colored 3D points in a single 360 degree view. The Indoor dataset is visualized in <ref type="figure" target="#fig_0">figure 1</ref> and the Outdoor dataset is visualized in <ref type="figure">figure 8</ref>. We compare with state-of-the-art methods by evaluating the robustness to initial rotation errors. Registration is performed using initial rotation errors between 0 and 180 degrees with an interval of 5 degrees. For every angle, we uniformly sample 100 random rotation (a) Color GICP.</p><p>(b) Ours. <ref type="figure">Figure 8</ref>. Registration of an outdoor scene captured by a Lidar. Color GICP (a) fails to register the point sets due to a large initial transformation. Our approach (b) accurately register the point sets.</p><p>axes. The point sets are constructed by randomly sampling points from the single Lidar scan. For each transformation, we sample two sets with 2000 points each. One of the sets is then transformed with the rotation defined by its corresponding axis and angle. We plot the recall at a rotation error threshold of 0.025 (approximately 1 degree) with respect to the initial angle. We also compare the total recall over all registrations. Lidar Indoor Dataset: <ref type="figure" target="#fig_7">Figure 7a</ref> shows the angle robustness comparison in terms of angle recall and total recall. ICP, GMMreg and Color GICP struggle for initial angles larger than 60 degrees. The robustness of JRMSP starts to degrade at an initial angle of 90 degrees. Our approach provides consistent registrations for angles up to 180 degrees. Lidar Outdoor Dataset: <ref type="figure" target="#fig_7">Figure 7b</ref> shows the initial angle robustness comparison on the Lidar Outdoor dataset. As in the Indoor dataset, the ICP and Color GICP provides inferior results due to large initial transformations. Our approach provides consistent improvements compared to the JRMPS. <ref type="figure">Figure 8</ref> shows a qualitative comparison between Color GICP and our approach on this dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this work, we propose a novel probabilistic approach to incorporate color information for point set registration. Our method is based on constructing an efficient mixture model for the joint point-color observation space. An EM algorithm is then derived to estimate the parameters of the mixture model and the relative transformations.</p><p>Experiments are performed on three challenging datasets. Our results clearly demonstrate that color information improves accuracy and robustness for point set registration. We show that a careful integration of spatial and color information is crucial to obtain optimal performance. Our approach exploits the discriminative color information associated with each point, while preserving efficiency.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Registration of the two colored point sets (a) and (b), of an indoor scene captured by a Lidar. The baseline GMM-based method (c) fails to register the two point sets due to the large initial rotation error of 90 degrees. Our method accurately registers the two sets (d), by exploiting the available color information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>An illustration of our mixture model of the joint pointcolor space. The ellipses represent spatial mixture components p(v|Z = k) in our model. Each spatial component k is associated with a mixture model in the color space, given by the weights ρ kl (visualized as histograms). This mixture model encodes the color distribution of points associated with the spatial component k.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>)m(Ω) , where m denotes the reference measure of the space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Overview of our EM-based registration. The parameters updated after each step are indicated on the arrow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>An RGB-D frame from the Stanford Lounge dataset, containing the RGB image (left) and the depth (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>An analysis of the number of feature mixture components L, on the Stanford Lounge dataset. We compare our approach with the baseline JRMPS and the two standard colorextensions. We show the average inlier rotation error (left) and failure rate (right) for different numbers of components per feature dimension L d in the HSV space. Our approach provides consistent improvements compared to the other probabilistic approaches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>A joint multi-view registration comparison of our method with JRMPS<ref type="bibr" target="#b4">[5]</ref> on the Stanford Lounge dataset. The recall plot (left) shows the fraction of correct registrations over a range of rotation-error thresholds. The convergence plot (right) shows the average frame-to-frame inlier rotation error after each EM iteration. Our method demonstrates superior accuracy and robustness, while achieving faster convergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Initialization robustness comparison on the Lidar Indoor (a) and Outdoor (b) datasets. The left plots show the recall at a threshold of 0.025. The recall is computed over 100 randomly sampled rotation axes for each angle. The right plots contain the total recall over all registrations, plotted with respect to the error threshold. Compared to previous methods, our approach provides superior robustness, while maintaining the accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table>A comparison of joint multi-view registration on the Stan-
ford Lounge dataset, in terms of average inlier error, standard de-
viation and failure rate. Our approach significantly reduces the 
relative failure rate with 86% compared to JRMPS. 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">See the supplementary material for a detailed derivation.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments: This work has been supported by SSF (VPS), VR (EMC 2 ), Vinnova (iQMatic), EU's Horizon 2020 R&amp;I program grant No 644839, the Wallenberg Autonomous Systems Program, the NSC and Nvidia.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A method for registration of 3-d shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Besl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Mckay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="239" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust euclidean alignment of 3d point sets: the trimmed iterative closest point algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chetverikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stepanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krsek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IMAVIS</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="299" to="309" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robust reconstruction of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Model globally, match locally: Efficient and robust 3d object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Drost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ulrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ilic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A generative model for the joint registration of multiple point sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Evangelidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kounades-Bastian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">Z</forename><surname>Psarakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Real-time onboard 6dof localization of an indoor mav in degraded visual environments using a rgb-d camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rigid and articulated point registration with expectation conditional maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yguel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dewaele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="587" to="602" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Registration of colored 3d point clouds with a kernel-based extension to the normal distributions transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Huhle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Straßer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Robust point set registration using gaussian mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Vemuri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1633" to="1645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Registration and integration of textured 3d data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IMAVIS</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="147" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Color supported generalized-icp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Korn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Holzkothen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pauli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VISAPP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Color point cloud registration with 4d ICP algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Men</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gebre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pochiraju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Maximum Likelihood Estimation via the ECM Algorithm: A General Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">L</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="278" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Point set registration: Coherent point drift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Myronenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">B</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="2262" to="2275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The softassign procrustes matching algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">L</forename><surname>Bookstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPMI</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generalized-icp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hähnel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RSS</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A correlation-based approach to robust point set registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Capturing reality for computer graphics applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Banterle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph Asia Course</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dense scene reconstruction with points of interest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="112" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
