<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast ConvNets Using Group-wise Brain Damage</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vadim</forename><surname>Lebedev</surname></persName>
							<email>vadim.lebedev@skoltech.ru</email>
							<affiliation key="aff0">
								<orgName type="department">Skolkovo Institute of Science and Technology (Skoltech) 2 Yandex</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
							<email>lempitsky@skoltech.ru</email>
							<affiliation key="aff0">
								<orgName type="department">Skolkovo Institute of Science and Technology (Skoltech) 2 Yandex</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Fast ConvNets Using Group-wise Brain Damage</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:40+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We revisit the idea of brain damage, i.e. the pruning of the coefficients of a neural network, and suggest how brain damage can be modified and used to speedup convolutional layers in ConvNets. The approach uses the fact that many efficient implementations reduce generalized convolutions to matrix multiplications. The suggested brain damage process prunes the convolutional kernel tensor in a group-wise fashion. After such pruning, convolutions can be reduced to multiplications of thinned dense matrices, which leads to speedup. We investigate different ways to add group-wise prunning to the learning process, and show that severalfold speedups of convolutional layers can be attained using group-sparsity regularizers. Our approach can adjust the shapes of the receptive fields in the convolutional layers, and even prune excessive feature maps from ConvNets, all in data-driven way.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the original Optimal Brain Damage work <ref type="bibr" target="#b31">[32]</ref> of 25 years ago, LeCun et al. observed that a carefully designed "brain-damage" process can sparsify the coefficients of a multi-layer neural network very significantly while incurring minimal or no loss of the prediction accuracy. Such process resembles the biological learning processes in mammals, in whose brains the number of synapses peak during early childhood and is then reduced substantially in the process of synaptic pruning <ref type="bibr" target="#b7">[8]</ref>. The optimal brain damage algorithm and its variants, however, impose sparsity in an unstructured way. As a result, while a large number of parameters can be pruned, the attained level of sparsity in the network is usually insufficient to achieve substantial computational speedup on modern architectures. These days, due to the overwhelming success of very big convolutional neural networks (ConvNets) <ref type="bibr" target="#b29">[30]</ref> on a variety of machine learning problems, the task of speeding up Con-vNets has become a topic of active research and engineering. Generalized convolution, i.e. the operation of convolving a 4D kernel tensor with the stack of input maps in order to produce the stack of output maps, is at the core of Con-vNets and also represents their speed bottleneck. Here, we present a simple approach that modifies the standard generalized convolution process by imposing structured "braindamage" on the kernel tensor. We demonstrate that considerable speed-up of ConvNets can be obtained for a certain structure.</p><p>This structure is motivated by the observation that the majority of current implementations of generalized convolutions (including the most efficient one at the time of submission) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b36">37]</ref> compute generalized convolutions by reducing them to matrix multiplications (this reduction is also referred to as lowering, unrolling, or the im2col operation). While unstructured brain damage in a convolutional layer, i.e. shrinking some of the coefficients of the convolutional kernel tensor to zero, will make one of the factor matrices (the filter matrix) sparse, it will not make the overall multiplication run faster. Our idea therefore is to group together the entries of the convolutional tensor in a certain fashion and to shrink such groups to zero in a coordinated way. By doing this, we can eliminate rows and columns from both factor matrices that are multiplied when convolution is reduced to matrix multiplication. Repeated elimination of rows and columns makes both factor matrices thinner (but still dense) and results in faster matrix multiplication.</p><p>We demonstrate that conventional group sparsity regularizer <ref type="bibr" target="#b47">[48]</ref> embedded into stochastic gradient descent minimization is able to accomplish group-wise brain damage efficiently. The use of group sparsity thus allows us to optimize receptive fields in the convolutional network. Our approach therefore makes the case for the natural idea of using structured sparsity as a simple way to optimize connectivity in deep architectures. In the experiments, our speed-up factors exceed those obtained by recent tensorfactorization based methods. For example, we show that group-wise brain damage can accelerate the bottleneck layers of AlexNet ('conv2' and 'conv3') by a factor of 8.5x simultaneously, while incurring only modest ( 1%) loss of the prediction accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>As ConvNets are growing in size and are spreading towards real-time and large-scale computer vision systems, a lot of attention is attracted to the problem of speeding up convolutional layers (e.g. through the use of Fourier transforms <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b44">45]</ref>). Several recent works investigate various kinds of tensor factorization in order to break generalized convolution into a sequence of smaller convolutions with fewer parameters <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b28">29]</ref>. Using inexact low-rank factorizations within such approaches allows to obtain considerable speedup when low enough decomposition rank is used. Our approach is related to tensorfactorization approaches as we also seek to replace full convolution tensor with a tensor that has fewer parameters. Our approach however does not perform any sort of decomposition/factorization for the kernel tensor.</p><p>Another more distantly related approach is represented by a group of methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b40">41]</ref> that compress the initial large ConvNet into a smaller network with different architecture while trying to match the outputs of the two networks. Our approach is also related to methods that use structured sparsity <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b23">24]</ref> to discover optimal architectures of certain machine learners, e.g. to discover the optimal structure of a graphical model <ref type="bibr" target="#b21">[22]</ref> or the optimal receptive fields in the two-layered image classifier <ref type="bibr" target="#b24">[25]</ref>. On the other hand, since our approach effectively learns receptive fields within a ConvNet, it can be related to other receptive field learning approaches, e.g. <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b34">35]</ref>.</p><p>The combination of sparsity and deep learning has been investigated within several unsupervised approaches such as sparse autoencoders <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7]</ref> and sparse deep belief networks <ref type="bibr" target="#b32">[33]</ref>. We also note two reports that use some form of sparsification of deep feedforward networks and appeared in the recent months as we were developing our approach. Similarly to <ref type="bibr" target="#b31">[32]</ref>, the work <ref type="bibr" target="#b13">[14]</ref> uses sparsification to reduce the number of parameters in the memory-bound scenario. Their goal is thus to save memory rather than to attain acceleration. In the report of <ref type="bibr" target="#b16">[17]</ref>, the output of the convolution is computed at a sparsified set of locations with the gaps being filled by interpolation. This approach does not sparsify the convolutional kernel and is therefore different from the group-wise brain damage approach we suggest here.</p><p>Our work focuses on the task of speeding up convolutional layers (as they represent the speed bottleneck) and is therefore complementary to approaches that focus on the reduction of size/memory footprint of fully-connected lay-ers <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b46">47]</ref>.</p><p>Finally, we note that the use of sparse matrices in order to speed-up convolutional neural networks was vrey recently explored in <ref type="bibr" target="#b33">[34]</ref>. Learning with regularizations (including group lasso) was used there to obtain sparse weights, which were applied to data via efficiently implemented sparse matrix multiplication. In contrast to their work, we aim to keep matrix multiplication dense (by imposig structure during sparsification), as such operation is much more efficient on modern architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Group-Sparse Convolutions</head><p>Below, we discuss the reduction from generalized convolution to matrix multiplication <ref type="bibr" target="#b8">[9]</ref> and introduce the notation along the way. We then explain the group-sparse convolution idea. Generalized convolution within a convolutional layer transforms an input stack of S maps of size W ′ ×H ′ , which can be treated as a three-dimensional tensor (array) U whs , into an output stack of T maps of size W ′′ ×H ′′ which form a three-dimensional tensor V wht . The exact relation between W ′ , H ′ and W ′′ , H ′′ depends on the padding and stride settings within the layer, and our approach can handle any padding/striding settings seamlessly. The transformation is defined by the following formula:</p><formula xml:id="formula_0">V (x, y, t) = S s=1 i=1..d j=1..d K(i, j, s, t) · (1) U (x+i− d+1 2 , y+j− d+1 2 , s)</formula><p>Here, K is a four-dimensional kernel tensor of size d×d×S×T with the first two dimensions corresponding to the spatial dimensions, the third dimension corresponding to input maps, the fourth dimension corresponding to output maps. The spatial width and height of the kernel are denoted as d (for simplicity, we assume square shaped kernels and odd d).</p><p>The implementation of (1) constitutes the speed bottleneck for ConvNets. In <ref type="bibr" target="#b9">[10]</ref>, it was suggested to reduce the computation of all entries of V to the multiplication of two large and dense matrices. The reduction allows to use highly optimized implementations of dense matrix multiplications (e.g. variants of BLAS <ref type="bibr" target="#b5">[6]</ref> libraries) that have been developed over many years for all possible computing architectures. The reduction proceeds as follows:</p><p>• The kernel tensor K is reshaped into the filter matrix F of size T × d 2 S, where the t-th row corresponds to a sequence of S 2D filters K(:, :, s, t) reshaped in a row-wise fashion into row vectors.</p><p>• The input map stack U is reshaped into the patch matrix P of size d 2 S × W ′′ H ′′ , where the l-th column * * <ref type="figure">Figure</ref>  In both cases, we show the diagram for two input maps (S = 2, blue-green color coding). We highlight three output maps t 1 , t 2 , t 3 color-coded red-orange-yellow, and we also highlight two spatial locations l 1 and l 2 . In both cases, the output map stack is obtained by reshaping the product of the filter matrix and the patch matrix. In the standard case, the filters and the patches sampled during the formation of the patch matrix are dense. After group-wise brain damage, both the filters and the patch sampling patterns are group-sparse (one sparsity pattern per input map), which results in much thinner filter and patch matrices and thus leads to much faster matrix multiplication/convolution. corresponds to a certain output location l = (x, y) and is stacked from the S patches extracted from S input maps, all centered at this location and reshaped in a row-wise fashion into column vectors.</p><p>• The filter matrix F is multiplied by the patch matrix P resulting in a matrixṼ of size T × W ′′ H ′′ that contains all the elements of V (each column corresponds to a certain location and contains the values of this location in the T output maps). The multiplication implements (1) exactly, as each row-by-column product within the multiplication corresponds to one instance of the computation (1) for certain (x, y, t). The output tensor (map stack) V can be obtained from˜V by reshaping.</p><p>The construction discussed above has proven to be highly successful and is used in the majority of modern ConvNets "backends", e.g. <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b36">37]</ref>. Our key idea is to train ConvNets with sparse convolutional kernels that are consistent with this construction.</p><p>Such consistency can be achieved if the sparsity patterns are aligned in a certain way. Formally, group-wise brain damage introduces a sparsity pattern Q s for every input map s ∈ 1 . . . S. The sparsity pattern is defined as a subset of the full spatial d-by-d grid, i.e. Q s ⊂ {1 . . . d} ⊗ {1 . . . d}. The convolutional operation then becomes a slight modification of (1):</p><formula xml:id="formula_1">V (x, y, t) = S s=1 (i,j)∈Qs K(i, j, s, t) · (2) U (x+i− d+1 2 , y+j− d+1 2 ,</formula><p>s) The reduction of (2) is an almost straightforward replication of the procedure <ref type="bibr" target="#b9">[10]</ref>. The only modifications are ( <ref type="figure" target="#fig_0">Figure 1</ref>):</p><p>• When the filter matrix is assembled, each 2D filter K(: , :, s, t) is reshaped into a row-vector of length |Q s | by including only non-zero elements. The filter matrix thus becomes of size T × S s=1 |Q s |. • When the patch matrix is assembled, each 2D patch at Importantly, the observed speedup is almost linear in the sparsity level (diagonal). Green curve shows the 'im2col' layer speedup on a GPU. While a certain constant overhead can be seen, we believe that (part of) it can be eliminated via more elaborated GPU implementation.</p><formula xml:id="formula_2">location l = (x, y) in map S is reshaped into a col- umn vector of size |Q s | by sampling the input map U (:, :, s) sparsely at locations (x+i− d+1 2 , y+j− d+1 2 ), where (i, j) ∈ Q s . The patch matrix thus becomes of size S s=1 |Q s | × W ′′ H ′′ .</formula><p>As a result of this modification, the multiplication of two dense matrices of sizes T × d 2 S and d 2 S × W ′′ H ′′ is replaced by the multiplication of two dense matrices of sizes T × S s=1 |Q s | and S s=1 |Q s | × W ′′ H ′′ , which results in the d 2 S/ S s=1 |Q s |-times reduction in the number of scalar operations. In our experiments with the reference implementation of <ref type="bibr" target="#b26">[27]</ref> the wall-clock reduction in the convolution time between the original implementation and the group-sparse convolution was almost matching the "theoretical" speed-up factor ( <ref type="figure" target="#fig_1">Figure 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Fast ConvNets with Group-sparse convolutions</head><p>We consider two different scenarios that obtain fast Con-vNets with group-sparse convolutions. First, we consider training such networks from scratch, and secondly we consider obtaining such networks by modification of pretrained architectures (i.e. performing "brain damage").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Training from scratch</head><p>Predefined group-sparsity pattern. The simplest solution that we consider is to choose the sparsity patterns Ω S in advance in a data-independent manner, and enforce these patterns during the learning of the network. One particular case of this approach is simply reducing the spatial size of filters to a minimum, e.g. three-by-three, or even smaller rectangular pattern all the way to one-by-one (this is in line with a recent work of <ref type="bibr" target="#b18">[19]</ref> where they consider 2 × 2 filters for some of their architectures). Note, that with our approach we are free to choose non-rectangular filters, and in the experiments we found this very useful.</p><p>One of the downsides of this approach is that when designing an architecture with multiple convolution layers, there are no clear design principles that can guide the choice of the filter shapes. In contrast, the methods discussed below can start with larger filters and then shrink their sizes towards optimally-shaped small filters.</p><p>Training with group-sparsity regularizer. Rather than fixing the group-sparsity pattern in advance, it is possible to find it as a part of learning process while the network is trained. A classical way to achieve this is through the use of group-sparsity regularization <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b23">24]</ref>. Thus, we consider a regularizer based on l 2,1 -norm:</p><formula xml:id="formula_3">Ω 2,1 (K) = λ i,j,s Γ ijs = λ i,j,s T t=1 K(i, j, s, t) 2 ,<label>(3)</label></formula><p>where the vector Γ ijs denotes the group of kernel tensor entries K(i, j, s, :). The effect of the regularizer (3) is in shrinking some of such groups to zero in a coordinated fashion. When an entire group Γ ijs is set to zero, one can set the pixel (i, j) in the sparsity pattern Ω s to zero, thus increasing the group-sparsity.</p><p>For a convolutional layer that is being sparsified, the gradient of (3), i.e.:</p><formula xml:id="formula_4">∂Ω 2,1 (K) ∂K(i, j, s, t) = λ K(i, j, s, t) T z=1 K(i, j, s, z) 2<label>(4)</label></formula><p>can simply be added to the gradient of the learning loss while performing stochastic gradient updates in the course of learning. The coefficient λ in <ref type="formula" target="#formula_3">(3)</ref> and <ref type="formula" target="#formula_4">(4)</ref> controls the strength of the regularization w.r.t. the main learning loss. Generally, using the regularizer (3) will result in a groupsparsified kernel tensor with some of Γ ijs having only nearzero entries. Because of the stochastic nature of SGD and non-differentiability of l 12 norm near zero, the entries in these groups will not be exactly zero, and further postprocessing is needed to nullify the near zero groups and to set the sparsity patterns Ω S accordingly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Sparsifying with Group-wise Brain Damage</head><p>While it is possible to train ConvNets with group-sparse convolutions from scratch, the main focus of our paper is developing algorithms that can speed-up existing pretrained networks that often take excessive time for training. Towards this end, we have developed two approaches that can accelerate pretrained networks by inflicting group-wise brain damage in a way that the drop in the prediction accuracy is kept small. In both cases, we assume that we have access to the training dataset D, the model was trained on.</p><p>Group-wise sparsification with fine-tuning. Our first implementation is also based on the group-sparse regularizer (3). We start with the input ConvNet and run the learning process on the dataset D with the added regularizer (3). After a certain amount of iterations, a predefined number of groups Γ ijs with the smallest l2-norm is set to zero. For a desired density level τ ∈ [0, 1] and respective speedup 1/τ , we set d 2 S (1 − τ ) groups to zero, making the respective Q S sparse.</p><p>We have found two complications with this approach. Firstly, for a given density τ it was generally hard to set appropriate regularization strength λ in advance without trying several values. Secondly, for small τ (large speedup) the appropriate regularization strength λ typically leads to an excessive regularization, as many groups end up being biased towards zero but not close to zero. Because of that, the prediction accuracy for such λ experienced significant drop in the process of learning as compared to the input ConvNet.</p><p>Fortunately, one can recover from most of this drop by the subsequent fine-tuning of the network, that follows after the brain-damage process. For the fine-tuning, we fix the sparsity patterns Q S and restart learning without groupsparse regularization. We then train for an excessive number of epochs. As a result of such fine-tuning, the network adapts to the imposed sparsity patterns, while the prediction accuracy goes up and recovers most of the drop.</p><p>Gradual group-wise sparsification. To avoid the two complications discussed above we developed an alternative approach that essentially combines the brain-damage and the fine-tuning processes, and furthermore avoids most of the need for manual search for good meta-parameter values. The approach also often leads to considerably better results.</p><p>In this approach, we consider the truncated l 12 regularizer:</p><formula xml:id="formula_5">Ω T 2,1 (K) = λ i,j,s min( Γ ijs , θ)<label>(5)</label></formula><p>The gradient of (5) equals (4) when Γ ijs &lt; θ and is zero otherwise. Informally speaking, the value of θ controls which groups are considered "promising" and are being shrinked towards zero, and which groups are considered to be too far from zero and therefore stay unaffected by the regularizer (5).</p><p>To perform brain-damage, we then create a validation set on which we monitor the performance of the network. We choose the maximum drop δ of the prediction accuracy on the validation set that we are willing to tolerate. We then start with an input ConvNet and perform learning with the regularizer (5) while varying θ. Specifically, after each epoch we monitor the performance of the network on We compare the results obtained by training with l 2,1 and l 1 regularizations followed by sparsifications, as well as training with predefined sparsity patterns Ω S (black dots). Overall, training with l 2,1 regularizer obtains the best result that can be further improved by finetuning without regularization.</p><p>a hold-out set and increase θ (intensifying brain damage) if the accuracy drop is less than δ and decrease θ, thus relieving certain groups from the effect of the regularizer, if the drop is greater than δ.</p><p>To perform the actual sparsification, we also introduce an additional threshold ǫ≪δ. In the process of learning, when the norm of a certain group falls below the threshold (i.e. |Γ ijs &lt; ǫ) the group is greedily fixed to zero and eliminated from the tensor. The sparsity thus monotonically increases through the process, and we carry on training until the sparsification process stalls, i.e. the system keeps training with Γ and performance drop oscillating, while no new groups have their lengths fall under ǫ for a number of epochs. In our experiments, all increments and decrements of θ was based on five-percent quantiles of the groups. I.e. every time θ is adjusted, we set θ to bring 5% of groups Γ ijs in or out of the Γ ijs &lt;θ "territory".</p><p>Overall, we found the whole procedure to be rather insensitive to the choices of λ and ǫ, and overall to be more practical and lead to higher group-sparsity and speed-ups than those attainable by the sparsification with fine-tuning approach. Most importantly, we could use same λ and ǫ, as well as same shared value of θ when sparsifiying multiple layers simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>Implementation details. Our implementation is based on Caffe <ref type="bibr" target="#b26">[27]</ref> and modifies their original convolution, which is implemented as two subsequent transformations method density speed-up accuracy drop Accelerating the second convolutional layer of AlexNet Denton et al. <ref type="bibr" target="#b14">[15]</ref>: Tensor decomposition + Fine-tuning 2.7x ∼ 1% Lebedev et al. <ref type="bibr" target="#b28">[29]</ref>: CP-decomposition + Fine-tuning 4.5x ∼ 1% Jaderberg et al. <ref type="bibr" target="#b20">[21]</ref>: Tensor decomposition + Fine-tuning <ref type="bibr" target="#b5">6</ref>  <ref type="table">Table 1</ref>: Accelerating convolutional layers of the pretrained AlexNet architecture: results of the two variants of our method for various sparsity levels alongside tensor-decomposition based methods (note: the results for <ref type="bibr" target="#b20">[21]</ref> are reproduced from <ref type="bibr" target="#b28">[29]</ref>).</p><p>(im2col and matrix multiplication). To implement the group-sparse convolution we focused on the forward propagation step and CPU computation. Most of our methods can be extended for backprop step and for GPUs, however making such extensions efficient is non-trivial. For our purpose, we only needed to modify the im2col function, so that it can fill in the patch matrix while following certain sparsity patterns.</p><p>Datasets. We perform the following experiments. Firstly, we consider a small-scale setting, and compare training ConvNets with group-wise brain damage from scratch with baselines. We use MNIST dataset <ref type="bibr" target="#b30">[31]</ref> for these small-scale experiments. We then consider a largescale problem, namely ImageNet (ILSVRC) image classification and the task of accelerating of a pretrained architecture, namely the Caffe version of AlexNet <ref type="bibr" target="#b27">[28]</ref>. We also give preliminary results for one of the VGGNet networks <ref type="bibr" target="#b43">[44]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">MNIST experiments</head><p>We trained the LeNet architecture on the MNIST dataset from random initialization while adding the group-sparse regularization (section 4.1) while varying the regularization strength λ and picking the optimal one for each sparsity level. The sparsification affects both convolutional layers of LeNet, and the same density level τ is enforced in both layers. We also consider a number of baselines:</p><p>• A simple baseline that trains the network without regularization and then simply eliminates (sets to zero) a certain number of groups Γ ijs with the smallest l2norms. The performance of this baseline was clearly below all other methods and it is not reported.</p><p>• Picking sparsity patterns Q S in advance. We consider filters with only one central non-zero entry and filters with two adjacent central non-zero elements. These options correspond to the density of 4% and 8% respectively. The former is essentially equivalent to a non-convolutional network, where almost all processing happens in the fully-connected layers.</p><p>• We also consider a simpler non-group-wise sparsification by training with l1-norm regularizer (with varying λ) but then nullifying groups |Γ ijs based on their norms.</p><p>The results of the proposed method and the baselines are shown in <ref type="figure" target="#fig_2">Figure 3</ref>. The rightmost plot shows the comparison of the l 1 -envelope, l 2,1 -envelope, and the performance of the group-wise brain damage applied to the network trained without sparsity-inducing regularizer. The use of group-sparsity regularization boosts the performance of group-wise brain damage very considerably. Twenty-fold acceleration of convolutional layers can be obtained while keeping the error low (2.1%, reduced to 1.71% after finetuning). Using l 1 -regularizer followed by optimal brain damage works worse than l 2,1 -regularizer. Pre-fixing sparsity patterns achieves good results, which are still worse than training with group-sparsity regularizer. Note also that all methods except the baseline with the pre-fixed patterns can be improved via fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">ILSVRC experiments</head><p>We first consider the AlexNet (Caffe reimplementation) architecture that has five convolutional layers. We consider the following subtasks: (i) accelerating the second convolutional layer (which is the slowest of all layers), (ii) accelerating the second and the third layers (which are the two slowest layers), (iii) accelerating all five convolutional layers (which together take the vast majority of the forwardpropagation time). When reporting the final density in subtasks (ii) and (iii), we weigh the densities in different layers by the forward propagation times.</p><p>We focused on accelerating the existing network from Caffe zoo ( <ref type="table">Table 1)</ref>. As an additional baseline, we evaluate the variant of our method that trims the network according to some predefined sparsity pattern, and then learns the network while keeping the same fixed pattern. Namely we consider the following symmetric centered patterns: vertical or horizontal block 1×3, the 3×3 cross pattern, 3×3 square or diamond shape inside 5×5 filter.</p><p>For the first two subtasks, we evaluated the variant of our method with sparsity-inducing regularizer for various sparsity levels. For several desired density levels τ we searched for optimal λ through a large range with ten-fold increments. For each τ we pick λ that results in the minimal accuracy drop after sparsification before fine-tuning. After picking the optimal λ, we perform fine-tuning (with fixed sparsity patterns). <ref type="figure">Figure 4</ref> demonstrate sparsity patterns Ω S obtained for different sparsity levels.</p><p>Finally, for all three subtasks we evaluated the most advanced of our methods, namely gradual group-wise sparsification. We set the parameters λ and ǫ to 0.01 and 0.1 respectively. We split the test set of ILSVRC randomly into two halves and use one of the halves solely to estimate the drop of the classification accuracy in the dynamical adjustment of θ. We then report the performance drop on the other half of the test set. We set the acceptable performance drop to be 1% of top-1 accuracy. <ref type="table">Table 1</ref>, the results of gradual sparsification outperform the tensor factorization methods as well as sparsification with fine-tuning considerably, achieving higher group-sparsification/speed-up for similar prediction accuracy drop. Notably, the proposed approach is more successful in speeding-up AlexNet than a number of approaches based on tensor decomposition. <ref type="figure" target="#fig_3">Figure 5</ref> further visualizes the process of the simultaneous gradual brain damage inflicted on all five layers of AlexNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>As shown in</head><p>"External" computer vision task. Convolutional layers of large networks pretrained on large annotated training sets such as ILSVRC can be used as universal spatially localized features in a variety of ways <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b0">1]</ref>, which is particularly valuable for problems with considerably smaller training sets. Recently, <ref type="bibr" target="#b2">[3]</ref> showed that descriptors obtained by sum-pooling of the features that emerge in the last convolutional layer of a pretrained network can be used as stateof-the-art holistic descriptors for image retrieval. We followed their approach (that includes PCA whitening and normalization as postprocessing) to assess the effect of groupsparsification on an external task. Comparing AlexNet as a base model, and the network with the simultaneous groupsparisfication of all convolutional layers from <ref type="table">Table 1</ref>  VGGNet results. We have also applied the gradual group-wise sparsification to the slowest convolutional layer of VGGNet (the deeper 19 layer version of <ref type="bibr" target="#b43">[44]</ref>, starting from its Caffe Zoo version. The sparsification obtained the density τ = 0.13 with only 0.2% top-1 accuracy drop. Interestingly, unlike the experiments with AlexNet where we rarely observed empty sparsity patterns Ω S ("dead feature maps"), in this example such all-zero patterns were present (29 out of 64), suggesting that this manually designed architecture contains excessive number of feature maps in this layer. This result also suggest that our approach is suitable even for networks with very small initial filter sizes in convolutional layers (3 × 3 for VGGNet). When applied to all convolutional layers of the VGG network, our method obtains different densities for different layer. It can pose a problem if some layers are reaching density close to zero while others are mostly dense, which proved to be the case with VGGNet. We've implemented rescaling described in <ref type="bibr" target="#b37">[38]</ref> to level group norms of different layers and reached density τ = 0.45 with this approach, which corresponds to more than 2× speedup with 0.7% accuracy drop</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>We have presented an approach to speeding up ConvNets that uses the group-wise brain damage process that sparsifies convolution operations. The approach takes into ac-(a) sparsity 1 − τ = 0.9 (b) sparsity 1 − τ = 0.8 (c) sparsity 1 − τ = 0.6 <ref type="figure">Figure 4</ref>: The sparsity patterns obtained by group-wise brain damage on the second convolutional layer of AlexNet for different sparsity levels. Nonzero weights are shown in white. In general, group-wise brain damage shrinks the receptive fields towards the center and tends to make them circular. The left plot shows the monotonic growth of the sparsity levels of the five convolutional layers as the iterations progress. The middle plot shows the relative prediction accuracy drop for the current system for the validation part and for the hold-out test set. Finally, the right part visualizes the process of the adjustment of θ threshold in the truncated l 2,1 regularization. This plot shows the percentile of groups Γ ijs with the l 2 -norm less than θ. θ is increased or decreased dependent on whether the performance drop on the validation set is greater or smaller than 1.2%. count the way generalized convolutions are reduced to matrix multiplications, and prune the entries of the convolution kernel in a groupwise fashion. The exact sparsity patterns can be learned from data using group-sparsity regularization. When applied after learning with such regularization and followed by fine-tuning, group-wise brain damage obtains state-of-the-art performance for speeding up Con-vNets.</p><p>Aside from the practical value, the proposed approach also makes the case for the use of sparse learning for automated discovery of optimal network architectures, which is arguably one of the main unsolved problems in deep learning. In our case, group-sparse regularizer allows the model to discover optimal receptive fields ( <ref type="figure">Figure 4</ref>). It is inter-esting to see that the optimization process decided to shrink the receptive fields towards the center compared to the full version (which is consistent with the findings in <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b18">19]</ref>). Perhaps, even more interesting is to see that in general, the learning process decided to make the receptive fields roughly circular. Also, the process treated AlexNet and VGGNet differently, eliminating entire feature maps by assigning their sparsity patterns Ω S to zero maps in the latter case. Note that such elimination brings additional speedup (since the entire map needs not be computed in the previous layer). Such elimination can be explicitly encouraged within our approach using hierarchical group-sparsity regularizers <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b23">24]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 :</head><label>1</label><figDesc>Standard Generalized Convolution (top) vs. Generalized Convolution after Group-wise Brain Damage (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The blue curve shows relative speed-up versus density level τ , measured for forward propagation in the second convolutional layer of AlexNet on CPU and GPU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Accuracy vs. density level on MNIST dataset (LeNet architecture) for various ConvNets with groupsparse convolutions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>The process of sparsification of all five layers in AlexNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>with 3.2x speedup, we have found a negligible drop in performance for the INRIA holidays dataset [23] from 0.783 mAP to 0.780 mAP, and a reasonably small drop for the Oxford Building dataset [40] from 0.45 to 0.41.</figDesc><table></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">From generic to specific deep representations for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Azizpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops</title>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06-07" />
			<biblScope unit="page" from="36" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Do deep nets really need to be deep?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2654" to="2662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Aggregating local deep features for image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Babenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploring large feature spaces with hierarchical multiple kernel learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">153</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An updated set of basic linear algebra subprograms (BLAS)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Blackford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Petitet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pozo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Remington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Whaley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Duff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hammarling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Henry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="151" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sparse feature learning for deep belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1185" to="1192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Synaptic pruning in development: a computational account</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chechik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Meilijson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ruppin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1759" to="1777" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">High performance convolutional neural networks for document processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chellapilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tenth International Workshop on Frontiers in Handwriting Recognition</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">High Performance Convolutional Neural Networks for Document Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chellapilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
		<ptr target="http://www.suvisoft.com" />
	</analytic>
	<monogr>
		<title level="m">Tenth International Workshop on Frontiers in Handwriting Recognition</title>
		<editor>G. Lorette</editor>
		<meeting><address><addrLine>La Baule (France)</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Compressing neural networks with the hashing trick</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tyree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="2285" to="2294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chetlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Woolley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandermersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.0759</idno>
		<title level="m">Efficient primitives for deep learning</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Selecting receptive fields in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<editor>J. Shawe-Taylor, R. Zemel, P. Bartlett, F. Pereira, and K. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2528" to="2536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<idno>abs/1412.1442</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploiting linear structure within convolutional networks for efficient evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ernational Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">DeCAF: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 31st International Conference on Machine Learning</title>
		<meeting>The 31st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="647" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Perforated CNNs: Acceleration through elimination of redundant convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Figurnov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<idno>abs/1504.08362</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep learning with limited numerical precision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="1737" to="1746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Convolutional neural networks at constrained time cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2014 Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Speeding up convolutional neural networks with low rank expansions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC)</title>
		<meeting>the British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On learning discrete graphical models using groupsparse regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jalali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sanghavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="378" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hamming embedding and weak geometric consistency for large scale image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Structured variable selection with sparsity-inducing norms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jenatton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Audibert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2777" to="2824" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Beyond spatial pyramids: Receptive field learning for pooled image features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3370" to="3377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Multimedia</title>
		<meeting>the ACM International Conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Caffe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5093</idno>
		<title level="m">Convolutional architecture for fast feature embedding</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Speeding-up convolutional neural networks using fine-tuned cp-decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lebedev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rakhuba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">V</forename><surname>Oseledets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ernational Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Backpropagation applied to handwritten zip code recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="541" to="551" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Optimal brain damage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Solla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="598" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sparse deep belief net model for visual area v2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ekanadham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<editor>J. Platt, D. Koller, Y. Singer, and S. Roweis</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="873" to="880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The treasure beneath convolutional layers: Cross-convolutionallayer pooling for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Learning smooth pooling regions for visual recognition. 24th British Machine Vision Conference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>BMVA Press</publisher>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5851</idno>
		<title level="m">Fast training of convolutional networks through FFTs</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nervanasystems</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nervanagpu</surname></persName>
		</author>
		<ptr target="https://github.com/NervanaSystems/nervanagpu" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Data-dependent path normalization in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tomioka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<idno>abs/1511.06747</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Tensorizing neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Novikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Podoprikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Osokin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vetrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Object retrieval with large vocabularies and fast spatial matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Fitnets: Hints for thin deep nets. Inernational Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The group-lasso for generalized linear models: uniqueness of solutions and efficient algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="848" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Low-rank matrix factorization for deep neural network training with highdimensional output targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kingsbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arisoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ramabhadran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-05-26" />
			<biblScope unit="page" from="6655" to="6659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inernational Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Fast convolutional nets with fbfft: A GPU performance evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasilache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Piantino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ernational Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">MatConvNet -convolutional neural networks for matlab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lenc</surname></persName>
		</author>
		<idno>abs/1412.4564</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Restructuring of deep neural network acoustic models with singular value decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th Annual Conference of the International Speech Communication Association</title>
		<meeting><address><addrLine>Lyon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08-25" />
			<biblScope unit="page" from="2365" to="2369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Model selection and estimation in regression with grouped variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="67" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
