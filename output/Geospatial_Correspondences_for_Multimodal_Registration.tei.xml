<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Geospatial Correspondences for Multimodal Registration</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcos</surname></persName>
							<email>diego.marcos@geo.uzh.ch</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Zurich</orgName>
								<orgName type="institution" key="instit2">Raffay Hamid DigitalGlobe Inc</orgName>
								<orgName type="institution" key="instit3">University of Zurich</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devis</forename><surname>Tuia</surname></persName>
							<email>devis.tuia@geo.uzh.ch</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Zurich</orgName>
								<orgName type="institution" key="instit2">Raffay Hamid DigitalGlobe Inc</orgName>
								<orgName type="institution" key="instit3">University of Zurich</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Geospatial Correspondences for Multimodal Registration</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:40+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The growing availability of very high resolution (&lt;1 m/pixel) satellite and aerial images has opened up unprecedented opportunities to monitor and analyze the evolution of land-cover and land-use across the world. To do so, images of the same geographical areas acquired at different times and, potentially, with different sensors must be efficiently parsed to update maps and detect land-cover changes. However, a naïve transfer of ground truth labels from one location in the source image to the corresponding location in the target image is generally not feasible, as these images are often only loosely registered (with up to ± 50m of non-uniform errors). Furthermore, land-cover changes in an area over time must be taken into account for an accurate ground truth transfer. To tackle these challenges, we propose a mid-level sensor-invariant representation that encodes image regions in terms of the spatial distribution of their spectral neighbors. We incorporate this representation in a Markov Random Field to simultaneously account for nonlinear mis-registrations and enforce locality priors to find matches between multi-sensor images. We show how our approach can be used to assist in several multimodal land-cover update and change detection problems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, there has been a tremendous increase in the amount and resolution of commercially available satellite imagery <ref type="bibr" target="#b13">[14]</ref>. This growth has opened numerous avenues to monitor and analyze the land-cover and land-use around the world, resulting in many novel applications including precision agriculture <ref type="bibr" target="#b44">[45]</ref>, population density estimation <ref type="bibr" target="#b22">[23]</ref>, and location based services <ref type="bibr" target="#b31">[32]</ref>.</p><p>A key challenge common to these applications is the efficient generation of land-cover maps, i.e. segmenting remotely sensed images into semantic classes such as forests, roads, buildings etc. This problem is exacerbated by the need to frequently update these maps by accounting for the constant natural and man-made changes on the Earth's surface. The growing number of available air and space-borne sensors, together with their short revisit time makes the au- tomatic updating of such maps with remote sensing data an important and challenging research direction <ref type="bibr" target="#b27">[28]</ref>. Traditional mapping approaches cannot be directly applied to solve this problem, as the appearance-consistency assumption they make does not generally hold true for multi-sensor multi-temporal (heterogeneous) images. This is due to the large variation in acquisition conditions e.g. frequency bands, resolution, acquisition times and geometry. It is therefore common to view multi-sensor land-cover update from the perspective of domain adaptation <ref type="bibr" target="#b1">[2]</ref> where correspondences between the source and target domains are defined using a shared feature-space.</p><p>In this work, we propose a novel mid-level representation that assists in performing domain adaptation by extracting a domain-invariant feature for every image region (a super-pixel, <ref type="figure" target="#fig_0">Figure 1b</ref>) in each image in terms of the spatial distribution of its spectral neighbors (SDSN). Our representation is particularly geared towards image series acquired over the same geographical area at different times and using different sensors. In order to obtain domain invariance we exploit the fact that satellite images are loosely geo-registered, usually up to a non-uniform registration error of ±50 m. We can therefore divide the images into a relatively coarse set of patches ( <ref type="figure" target="#fig_0">Figure 1c</ref>) in order to obtain an approximately registered shared coordinate system. By encoding image regions in terms of their spectral distances from the mean value of each patch in their respective domains <ref type="figure" target="#fig_0">(Figure 1d</ref>), SDSN is able to provide a simple yet effective way to map information across different satellite sensors. This sensor invariance allows to use these features for multimodal image registration. We incorporate our SDSN representation in a Markov Random Field ( <ref type="figure" target="#fig_1">Figure 2</ref>) where intra-domain edges are used to encourage smoothness and favor matches over short distances, while interdomain edges encourage matching superpixels with similar domain-invariant features <ref type="figure" target="#fig_1">(Figure 2d</ref>). We show how this can be used for domain adaptation using two different strategies: direct transfer of land-cover ground truth (GT) ( § 4.1) and finding super-pixel pairs for unsupervised manifold alignment ( § 4.2). We also show how this approach can be used effectively for detecting land-cover changes in an unsupervised manner ( § 4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The problem of land-cover segmentation in multi-sensor and multi-temporal scenarios can be formulated as an instance of the more general problem of domain adaptation, which addresses the transfer of available domain-specific knowledge to a different but related domain. Both semisupervised <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b42">43]</ref> and unsupervised <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> approaches have been proposed to perform domain adaptation.</p><p>For semi-supervised approaches, techniques involving co-training <ref type="bibr" target="#b37">[38]</ref>, label propagation <ref type="bibr" target="#b43">[44]</ref>, variants of expectation maximization <ref type="bibr" target="#b8">[9]</ref> and SVM <ref type="bibr" target="#b15">[16]</ref> have been successfully proposed. More recently, approaches involving coregularization <ref type="bibr" target="#b25">[26]</ref> and data rotation <ref type="bibr" target="#b30">[31]</ref> have also been put forth. These approaches still require some labeled examples in the target domain, which prevents their application to problems where such labels are not available.</p><p>Unsupervised domain adaptation is generally considered a harder problem since we do not have any labeled correspondence between the domains. In this regard, ap-proaches relying on source-target partial distribution similarity <ref type="bibr" target="#b18">[19]</ref>, clustering <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b6">7]</ref>, structural correspondence learning <ref type="bibr" target="#b5">[6]</ref>, domain divergence minimization <ref type="bibr" target="#b4">[5]</ref>, manifold alignment <ref type="bibr" target="#b41">[42]</ref> and deep learning <ref type="bibr" target="#b16">[17]</ref> have been proposed. However, these methods require a certain level of correlation between the distributions of both domains. In this work, we put forth a strategy that is able to deal with distributions from different domains without requiring them to be correlated by exploiting the fact that for our setting the images are loosely spatially geo-registered.</p><p>A third approach, not always explicitly referred to as domain adaptation, consists of using engineered domain invariant features. It has been successfully applied in both remotely sensed <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b21">22]</ref> and natural images <ref type="bibr" target="#b26">[27]</ref>. Some of these features (e.g. SIFT <ref type="bibr" target="#b26">[27]</ref> or shape descriptors <ref type="bibr" target="#b21">[22]</ref>) achieve domain-invariance at the cost of discarding relevant information, e.g. color in R-G-B imagery, while focusing only on geometrical information. In contrast, we propose to fully take into account spectral information while also offering the possibility to include task-specific appearance descriptors in the process. SDSN is related to the local selfsimilarity (LSS) <ref type="bibr" target="#b32">[33]</ref> and global self-similarity (GSS) <ref type="bibr" target="#b10">[11]</ref> features. However, unlike these approaches, SDSN uses approximate geographical correspondences to allow for crossdomain comparisons, hence offering both the expressiveness of GSS and the simplicity of LSS.</p><p>In remote sensing, domain adaptation has been traditionally used for land-cover map update tasks <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b2">3]</ref>. Most of these pipelines assume a perfect pixel-to-pixel registration between multi-temporal images, which is a serious limiting factor for high resolution and multi-sensor data. An object-based variant resides in the semantic tie points strategy proposed in <ref type="bibr" target="#b29">[30]</ref> and used in <ref type="bibr" target="#b28">[29]</ref> for remote sensing domain adaptation. An MRF-based approach <ref type="bibr" target="#b26">[27]</ref> significantly relaxing the co-registration constraint is presented in <ref type="bibr" target="#b38">[39]</ref>, where registration and change detection are simultaneously performed. They use several correlation similarity measures that imply using the same number of spectral bands in both domains. Our approach extends this work to the multi-sensor setting where feature spaces are usually composed by different types and number of spectral channels, making it more general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>We use super-pixels as our basic computational unit since they reduce the size of the problem while offering a meaningful spatial support. In this work we use the SLIC segmentation method presented in <ref type="bibr" target="#b0">[1]</ref>. Given an image I D of size m × n in domain D, and a SLIC segment size parameter s, we build a super-pixel image H D of size roughly (m/s × n/s).</p><p>We formulate our problem as an object matching problem by using a Markov Random Field (MRF), similar to <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b26">27]</ref>. An important feature of this model is that the contribution to the MRF energy associated to each matched pair can be used as an estimate of matching confidence. Ev-</p><formula xml:id="formula_0">ery super-pixel H j B ∈ H B in domain B (target) is matched to super-pixel H i A ∈ H A in the domain A (source)</formula><p>with a certain confidence relative to rest of the matches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Spatial Distribution of Spectral Neighbors</head><p>Our main hypothesis is that objects that are spectrally similar in one domain tend to be spectrally similar in other domains, except when they have undergone a land cover change. For instance, a patch of vegetation in an RGB image is likely to have a similar color to other areas of vegetation in that image. At the same time, a patch of vegetation in a near infrared (NIR) image is likely to look very similar to other vegetated areas in the same NIR image. This withinimage similarity is independent to how similar or dissimilar a particular patch of vegetation might look across the two images. We use this observation to encode each super-pixel H i D in domain D in terms of its similarity to other regions of the image (see <ref type="figure" target="#fig_0">Figure 1</ref>).</p><p>To do so, we start by computing a downscaled version J D of the original image I D as the average spectral signature of every non-overlaping d × d patch in I D . Here J D is of size (m/d × n/d) and contains Q = (mn)/d 2 elements. We then compute the SDSN feature f i SDSN for H i D as:</p><formula xml:id="formula_1">f i SDSN = [f i1 SDSN · · · f iq SDSN · · · f iQ SDSN ],<label>(1)</label></formula><p>where</p><formula xml:id="formula_2">f iq SDSN = e −σ S(J q D )−S(H i D ) 2 .<label>(2)</label></formula><p>Here, S(J q D ) and S(H i D ) are the spectrum (e.g. RGB color) associated to J q D and the mean spectrum of H i D respectively. Note that f i SDSN has Q dimensions. Each element f iq SDSN of f i SDSN encodes the similarity of the spectrum of H i D to the average spectrum of a particular patch of the image, J q D . Downscaling allows for robustness against registration noise between the images in the different domains. For example, a 15 pixel shift in the original image becomes a sub-pixel shift of 0.15 pixels using downscaling factor of 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Matching Formulation</head><p>We build on previous matching approaches relying on MRF such as <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b38">39]</ref>. We define a graph G = (V, E) where every edge ǫ ij ∈ E connects two nodes i, j ∈ V with a weight c(ǫ ij ). Every node i corresponds to a super-pixel H i B in the target domain. Since we expect the misregistration shifts to be consistent within a region of the image, possibly with shift larger than the superpixel size, we consider mid-range connections for node i, N i , beyond first order neighborhoods. In our experiments (Section 4) we use a 25 × 25 super-pixel neighborhood. We make use of the SLIC grid initialization to define the neighborhood systems efficiently. We set weights c(ǫ ij ) inversely proportional to the geographical distance between node i and its neighbors and we normalize them such that ǫij ∈Ni c(ǫ ij ) = 1. Each node is defined by its geographical coordinates p i = (x, y) and is assigned to a matching vector w i = (u, v) towards a super-pixel M i = H k A in the source domain, defined by its coordinates q k = p i + w i . M is a look-up table storing the currently selected matches. The matching process is formulated as an energy minimization over the graph G as:</p><formula xml:id="formula_3">E(M ) = i Θ data (H i B , H k A ) + λ small i Φ small (w i ) + λ smooth i Φ smooth (N i ). (3)</formula><p>The data term Θ data measures the dissimilarity between H i B and its match H k A , defined by:</p><formula xml:id="formula_4">Θ data = f ∈F α f Θ f (4)</formula><p>where α f is the weight given to each dissimilarity measure Θ f , computed using the feature f , e.g. SDSN, SIFT, color, etc. Here F defines the set of all features considered. The dissimilarity between a pair of superpixels H k A and H j B in feature f ∈ F is computed as:</p><formula xml:id="formula_5">Θ f (H k A , H i B ) = −log f (H k A ) ⊤ · f (H i B )<label>(5)</label></formula><p>We normalize each feature to have unit ℓ 2 -norm. To further spread the samples over the unit ball, we center every vector to zero mean. Note that the matrix version of this formulation can use optimized BLAS Level-3 <ref type="bibr" target="#b17">[18]</ref> and therefore can be computed efficiently by optimally using all the resources of modern computing architecture. In Equation <ref type="formula">(3)</ref>, the term Φ small penalizes big matching displacements and depends only on the matching vector:</p><formula xml:id="formula_6">Φ small (i) = w i 2<label>(6)</label></formula><p>Similarly, Φ smooth penalizes matching vectors deviating too much from the average matching vector in a neighborhood:</p><formula xml:id="formula_7">Φ smooth (N i ) = w i − j∈Ni c(ǫ ij )w j 2<label>(7)</label></formula><p>where all j ∈ N i are the neighbors of i and each ǫ ij the corresponding edge, with c(ǫ ij ) being the edge weight. The confidence of the match of node i in the target domain B is then defined as −E(M i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Optimization</head><p>Since satellite images are loosely pre-aligned, the optimal solution does not have large w. Therefore, we limit the search for a match for i ∈ B to a window of size w × w around the initial match. In practice, we initialize the system on the geographically nearest super-pixel in A. Note that we can see the matching problem as a classification problem with w 2 classes, corresponding to every possible match for each super-pixel in B <ref type="bibr" target="#b14">[15]</ref>. To find a set of matches M that minimize Equation <ref type="formula">(3)</ref>, we employ the Iterated Conditional Modes (ICM) algorithm <ref type="bibr" target="#b3">[4]</ref>. Thanks to the grid structure of the graph we can use Fast Fourier Transform (FFT) to compute the energy in the form of a convolution, which significantly improves the efficiency of the algorithm. The fact that the initialization is never very far from the solution <ref type="bibr" target="#b36">[37]</ref>, the use of super-pixels and the FFT means that, for image pairs used in this work, the presented method typically converges in less than 10 seconds using ICM on a standard personal computer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head><p>We apply our proposed representation to three different problems within the context of multimodal registration. In all the experiments the SDSN feature is compared to a multi-scale SIFT feature over the average color channel with patch sizes of 9, 17 and 33 pixels <ref type="bibr" target="#b39">[40]</ref> and a feature consisting of the common spectral bands, thereafter referred to as "color". In all the experiments using a set of two features, the values of α f have been set to 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Ground Truth Transfer</head><p>We aim to transfer the available ground truth (GT) from the source image to the target image, while simultaneously avoiding the regions that have likely undergone some land cover change. This transferred GT is then used to train a kNN classifier in the target domain to generate an updated land cover map. The choice of kNN classifier is due to its simplicity and distribution independence. We use a hand labeled GT of the target domain to validate the map obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Dataset and Setup</head><p>The source domain consists of five QuickBird <ref type="bibr" target="#b11">[12]</ref> satellite images of Zurich Switzerland taken in August 2002. They have four channels: near infrared, red, green and blue (NIR-R-G-B), and a resolution of about 0.62 cm/pixel. These image are a subset of the Zurich Summer dataset presented in <ref type="bibr" target="#b40">[41]</ref>. The target domain is a corresponding set of five NIR-R-G aerial images of the same area, with nearly the same footprint, captured during the campaign of summer 2013 and provided by the Swiss Federal Office of Topography <ref type="bibr" target="#b35">[36]</ref>. We refer to this dataset as NIR-R-G Orthophoto data. The resolution of the target images is 25 cm/pixel. To test our approach in the case where source and target only share the R and G bands, we discard the NIR band of the QuickBird images and use exclusively the R-G-B bands throughout the experiments. <ref type="figure" target="#fig_2">Figure 3</ref> shows an example image pair and the corresponding GT maps. In this dataset, the geo-registration error of the image pairs ranges from 5 m to 15 m. Each image in the source domain has a quite dense GT land-cover map consisting of between four and six classes among Roads, Buildings, Trees, Grass, Bare Soil, Water, Railways and Swimming Pools. We treat each of the five image pairs as an independent GT transfer problem. For each image pair, we first re-scale them to the size of the smaller image in the pair. Note that this step is not required but it results in obtaining a similar number of superpixels, which helps getting a good matching. The images are then segmented with SLIC <ref type="bibr" target="#b0">[1]</ref>, with the superpixel size of 10 pixels and the regularization parameter values set to 10. The SDSN features are computed using a downsampling factor d of 20 and a σ of 0.5. For the MRF matching we used λ smooth = 0.05 and λ small = 0.05.</p><p>After matching, 90% most confident matches are used for transferring the GT to the target image. We then used all the transferred GT to train a pixel-wise kNN classifier with k = 5. The classified land cover map is compared to the hand labeled target GT for validation. We report results from QuickBird <ref type="bibr" target="#b11">[12]</ref> to Orthophoto <ref type="bibr" target="#b35">[36]</ref> and vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Results</head><p>The classification results are shown in in <ref type="table" target="#tab_0">Table 1</ref>. Using SIFT or color features alone produces results that are significantly worse than the results obtained using the proposed SDSN features. Using SDSN in conjunction with SIFT produces the best results on average. This is because SDSN and SIFT encode very different properties of the super-pixels, i.e. the former encodes spectral information in terms of global interactions across the whole image, while the latter encodes the local geometry. These two forms of information complement each other in describing land-cover changes, resulting in better GT transfer. We also compare our results with those obtained using a multi-modal mutual information-based registration method <ref type="bibr" target="#b24">[25]</ref>  <ref type="table">(Table 2)</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Parameter Sensitivity and Circular Validation</head><p>We now focus on the sensitivity of our method to the choice of parameter values used when transferring the GT from source to target A → B. In the left column of <ref type="figure" target="#fig_5">Figure 4</ref> we see the result of applying this concept to the values of λ small and λ smooth , the SDSN's σ, and the down-scaling factor d. It can be observed that most image-pairs are not very sensitive to variations in the tested parameters showing the robustness of our framework to its various parameters. We also study how a circular validation strategy <ref type="bibr" target="#b6">[7]</ref> can help with estimating a good set of parameters for our framework. In the case of GT transfer, this can be done by transferring the GT from source to target A → B, and then from target back to source A → B → A, where it is compared to the original GT for evaluation. This setting corresponds to the right column of <ref type="figure" target="#fig_5">Figure 4</ref>. It can be observed that the optimal values obtained during validation A → B → A are similar to the optimal values required for our original problem A → B. This result shows that we can employ this circular validation strategy <ref type="bibr" target="#b6">[7]</ref> in practice to select the optimal parameter values required by our framework. Note that  the downsampling factor d determines the number of operations required to compute the SDSN feature and affects the computation time in a quadratic manner (see <ref type="table" target="#tab_1">Table 3</ref>). However, the results in <ref type="figure" target="#fig_5">Figure 4</ref> suggest that this time can be greatly reduced at a small cost in accuracy.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Sensitivity to Perturbations in the Input</head><p>We use the image shown in <ref type="figure" target="#fig_2">Figure 3a</ref> in order to explore how sensitive our method is to three types of perturbations: 1) amount of change, 2) displacement and 3) rotation between the images. To do so, we match the image in <ref type="figure" target="#fig_2">Figure 3a</ref> with a perturbed version of itself. The land-cover changes were added by substituting vegetation superpixels with bare soil ones. Performance was measured as the percentage of changed superpixels recalled, assuming that the amount of change had been correctly estimated. When considering displacement and rotation, the amount of change is fixed at 20%. Results in <ref type="table">Table 4</ref> show high robustness even for the most extreme amounts of change and displacement, which are the main sources of perturbation to be expected in remotely sensed images.</p><p>Change amount (%) <ref type="bibr" target="#b5">6</ref>   <ref type="table">Table 4</ref>. Sensitivity to changes, displacements and rotations in the target (B). Domains A and B consist of the RBG and NIR-R-G bands of <ref type="figure" target="#fig_2">Figure 3a</ref> respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Unsupervised Manifold Alignment</head><p>We now explore the problem where the source and target images have a partial overlap, but there is no GT available in the overlap area. To perform domain adaptation, we cannot simply register the labeled super-pixels directly. However, we can project both domains in a common latent space where both domains are similarly distributed. We use the same settings presented in <ref type="bibr" target="#b28">[29]</ref>, where a hand-labeled set of super-pixel pairs in the overlapping area are used to perform manifold alignment between the two domains. Instead of manual selection, we use the proposed method to automatically find a set of these super-pixel pairs.</p><p>We use the manifold alignment algorithm in <ref type="bibr" target="#b42">[43]</ref>, where the local geometrical structure of the domain is preserved while enforcing weak class consistency using the matched super-pixel pairs. Once the domains are aligned, one can then directly train and test in the aligned domain.</p><p>To find a set of confident super-pixel matches that are also representative of the different land covers in the image, we partition the super-pixel spectra in the target domain using k-means clustering and select the most confident matches in each cluster. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Dataset and Setup</head><p>For these experiments, we use the dataset presented in <ref type="bibr" target="#b28">[29]</ref>. The images cover an area of Lausanne, Switzerland. The source domain is a WorldView 2 <ref type="bibr" target="#b12">[13]</ref> image, with 8 spectral bands in the visible and infrared region, taken in 2011 and the target domain is a 25 cm/pixel resolution NIR-R-G Orthophoto <ref type="bibr" target="#b35">[36]</ref>. <ref type="figure" target="#fig_7">Figure 5b</ref> shows the areas of interest, with their corresponding GT, and <ref type="figure" target="#fig_7">Figure 5c</ref> the area common to both domains. The land-cover classification includes 5 classes, as shown in <ref type="figure" target="#fig_7">Figure 5b</ref>. The parameters for SLIC were set to segment size of 20 pixels and regularization parameter of 10. The σ value for the SDSN was set to 0.5 and the downsampling factor for the low resolution image was set to 100. For the MRF matching, we used λ smooth = 10 −2 and λ small = 10 −2 . We then partitioned the superpixels in the target domain into 26 clusters and randomly took 10 confident matches from each of the 20 most populated clusters.</p><p>For manifold alignment, we used the same settings as in <ref type="bibr" target="#b28">[29]</ref>. After projecting the data onto the latent feature space, we tested the performance of the alignment by classifying in the test image using only the labeled pixels from the source image. We report results using kNN with k = 5 training with 400 labeled pixels per class. We also tried other classifiers, such as Random Forest and SVM (not shown in this paper), obtaining comparable trends. For each type of feature (color, SIFT, SDSN and SDSN+SIFT) we generated 5 instances of the super-pixel pair set. For each instance, as well as for the hand labeled super-pixel pairs, we computed 10 realizations of the manifold alignment and classification training set.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Results</head><p>An example of an automatically generated super-pixel pair set with SDNS feature matching is shown in <ref type="figure" target="#fig_8">Figure 6</ref>. Notice how the high-confidence super-pixels pairs are distributed across the whole image evenly. In <ref type="figure" target="#fig_10">Figure 7</ref> we see the average classification results. We see how the automatically generated super-pixel pair sets using SDSN, SIFT or SDSN+SIFT perform substantially better than the hand labeled map in the vast majority of cases. Moreover, in this experiment, using SDSN+SIFT does not seem to have an advantage over SDSN alone. This is possibly due to the presence of higher rise buildings, compared to the Zurich dataset, and the acquisition angle difference between domains. This has a big impact on the local geometry, to which SIFT is highly sensitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Change Detection</head><p>The main assumption underlying the SDSN feature is that spectral neighborhood relations are domain invariant and can be used to match with high confidence the areas that remain unchanged between domains. Considering the other end of the confidence spectrum, we can build a map of low confidence areas that can be used for change detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Datasets and Setup</head><p>To test our framework on change detection, we use an image-pair from the dataset in § 4.1.1, shown in <ref type="figure" target="#fig_11">Figure 8a</ref> and 8b, with change GT in green. We also apply our method to an RGB image-pair from Google Earth of an agricultural area near Melbourne, Australia taken on 10/17/2014 and 01/03/2015, <ref type="figure" target="#fig_0">Figure 10a</ref>-b. We chose this location as it represents a case where the three similarity measures, using SDSN, SIFT and color, provide different notions of change. Our pre-processing for this experiment is the same as in § 4.1. The MRF parameters λ smooth and λ small are set to 0.2. We set them higher in this case compared to the GT transfer setting because here we want to penalize non-smooth high-confidence matches more. The matching is done in both directions, i.e., A → B and B → A. The two resulting confidence maps are then combined by taking, for each location, the minimum value among the two maps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Results</head><p>Figures 8c-f show as heat-maps the low confidence matches, in yellow. We calculated the confidence using 4 different invariant features within our MRF framework: the common bands (color), SIFT, SDSN and SDSN+SIFT. In the case of SIFT, <ref type="figure" target="#fig_11">Figure 8e</ref>, the algorithm detects the illumination changes in the forest (lower right corner of the image) as the dominant changes. Using the common bands R and B, <ref type="figure" target="#fig_11">Figure 8c</ref>, highlights mostly illumination changes on the roads and rooftops, with only changes #3, 6, 12 and 14 being clearly detected. SDSN, <ref type="figure" target="#fig_11">Figure 8d</ref>, shows a better correlation with the labeled changes, while detecting also changes in building's shadows. This undesired effect is reduced by using SDSN+SIFT. SDSN clearly detects changes #2, 3, 4, 5, 6, 8, 9, 10, 11, 12 and 14 while maintaining a false positive ratio comparable to or even lower than the color feature. We present the ROC curves for change detection in <ref type="figure" target="#fig_12">Figure 9</ref>. It can be observed that results incorporating the SDSN feature are significantly better than those  obtained using either color or SIFT features. Once more, using SDSN+SIFT results in a slightly better performance than SDSN alone. <ref type="figure" target="#fig_0">Figure 10c</ref>-e show the non confident areas on the Google Earth image pair using the common bands, SIFT and SDSN features respectively. We can clearly see how each map corresponds to a different notion of change. Using the common bands, in this case all R, G and B, highlights the ar- eas in which the color change is stronger, such as the dark green vegetation turning into bright bare soil. SIFT is correlated with geometrical changes in the image, such as the cloud shadow in the center top of <ref type="figure" target="#fig_0">Figure 10a</ref>. On the other hand, SDSN highlights the the areas that undergo an uncommon transformation compared to the predominant set of transformations. Given that most areas have either changed from vegetation to bare-soil or vice versa, these uncommon transformations include vegetation that continues to be vegetation (e.g. the field near top left corner) and bare soil that stays bare soil (e.g. roads). While the former transformation is an anomaly we would like to detect, the latter is an artifact due to the spectral similarity between roads and bare-soil classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We proposed the spatial distributions of spectral neighbors (SDSN) as a cross-domain feature for multi-sensor, multi-temporal image pairs of sub-meter resolution. We showed that SDSN can help to match the super-pixels between two images from overlapping areas while distinguishing between the spectral changes that are the artifacts of different acquisition conditions from those due to real land-cover changes. We showed the usefulness of SDSN for land-cover map update and for change detection.</p><p>We incorporate the SDSN representation into a Markov Random Field to account for nonlinear misregistrations and to enforce a locality prior in order to find matches between multi-sensor, multi-temporal images. Furthermore, we compare SDSN with other features commonly used in remote sensing image registration. Our results demonstrate that SDSN performs significantly better than the alternatives considered, maximizing domain invariance and resulting in better classification and change detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Illustration of Spatial Distribution of Spectral Neighbors (SDSN). (a): Remotely sensed image IA in domain A. (b): Superpixels computed for IA. (c): Downsampled version of IA. (d): The SDSN features are computed as similarities of a superpixel in (b) with every value in (c). The same procedure is applied to the image in domain B. Superpixels belonging to the same land-cover class tend have similar SDSN values across domains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>(a): Remotely sensed images. (b): Superpixel segmentation of the images. (c): Stack of domain invariant features computed for each superpixel maintaining the neighborhoods. (d): Graphical model used to match superpixels from both domains. (e): Contribution of each match to MRF cost function is used as confidence map of the matching, enabling the detection of areas with higher probability of having undergone a land cover change.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>One of the 5 image pairs from the Zurich dataset. (a): Quickbird<ref type="bibr" target="#b11">[12]</ref> image, the source domain, and the corresponding GT. (b): False color Representation of the 3 band NIR-R-G Orthophoto data<ref type="bibr" target="#b35">[36]</ref> (2013) and its GT: Roads, buildings, trees, grass, water and bare soil. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Classification accuracy in the five Zurich image pairs for different values of (a): λsmall and λsmooth (both take the same value in this experiment), (b): σ value for the SDSN feature, (c): the downscaling parameter d for the SDSN feature.On the left, we transfer the GT from source to target. On the right is from source to target and back to source.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>(a): Layout of the used images in the area of Lausanne, Switzerland. (b): Representation of the 2 images used (left) and the respective GTs (right). From top to bottom: Prilly 2011 (WorldView 2 [13]) and Renens 2012 (NIR-R-G Orthophoto). Color legend: buildings, roads, grass, trees and shadows. (c): Hand labeled super-pixel pairs (in yellow). Figure best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 .</head><label>6</label><figDesc>Automatically generated super-pixel pair map using the proposed SDSN features. (a): Grayscale version of the World-View 2 [13] image used as source. (b): Grayscale version of the NIR-R-G Orthophoto [36] image used as target. Matched segment pairs are within the neighborhood of each other and are marked with same color in order to imply correspondence. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 .</head><label>7</label><figDesc>Classification results (as overall accuracy) on the manifold alignment experiment using kNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 8 .</head><label>8</label><figDesc>(a) Image in domain A and (b) B. Change GT marked in green. (c-f) The low confidence areas, those contributing the most to the MRF energy, are shown in yellow. The matching has been performed with the same parameters using the following features: (a) common spectral bands, (b) SIFT , (c) SDSN and (d) SDSN+SIFT. Best viwed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 9 .</head><label>9</label><figDesc>Correctly detected change pixels versus false positives for all different values of the detection threshold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 10 .</head><label>10</label><figDesc>(a, b): Google Earth images taken in 10/2014 and 01/2015 respectively. (c-e): Low matching confidence areas are shown in yellow, (c) using color, (d) SIFT, (e) SDSN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 .</head><label>1</label><figDesc>Average classification accuracy for ground truth transfer. The first column correspond to image pairs. A and B correspond to QuickBird<ref type="bibr" target="#b11">[12]</ref> Orthophoto<ref type="bibr" target="#b35">[36]</ref> domains.</figDesc><table>Method SDSN+SIFT Affine[25] Non-rigid[25] 
AA 
66.0% 
63.7% 
64.0% 

Table 2. Numerical comparison with [25], Average Accuracy. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 .</head><label>3</label><figDesc>Time (images 700 × 1000 pixels on a single CPU) to compute SDSN features wrt. downsampling, d.</figDesc><table></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Slic superpixels compared to state-of-the-art superpixel methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Susstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2012-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Change detection in optical aerial images by a multilayer conditional mixed Markov model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Benedek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Szirányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3416" to="3430" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the statistical analysis of dirty pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Besag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="259" to="302" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning bounds for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wortman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="440" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Domain adaptation problems: A DASVM classification technique and a circular validation strategy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marconcini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An iterative technique for the detection of land-cover transitions in multitemporal remotesensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Serpico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="858" to="867" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Transferring naive bayes classifiers for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-R</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Conference on Artificial Intelligence</title>
		<meeting>the National Conference on Artificial Intelligence<address><addrLine>Menlo Park, CA; Cambridge, MA; London</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">540</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Domain adaptation for statistical classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="126" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Global and efficient selfsimilarity for object classification and detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1633" to="1640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Digitalglobe</forename><surname>Quickbird</surname></persName>
		</author>
		<ptr target="http://global.digitalglobe.com/sites/default/files/QuickBird-DS-QB-Prod.pdf/" />
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Digitalglobe</surname></persName>
		</author>
		<ptr target="http://global.digitalglobe.com/sites/default/files/DG_WorldView2_DS_PROD.pdf/" />
	</analytic>
	<monogr>
		<title level="j">WorldView</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Commercial satellite imaging market -global industry analysis, size, share, growth, trends, and forecast</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Doe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transparency Market Research</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2013" to="2019" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The correlated correspondence algorithm for unsupervised registration of nonrigid surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Dragomir Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Sebastian Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings of the 2004 Conference</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Domain adaptation from multiple sources via auxiliary classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting>the 26th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="289" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.7495</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Van Loan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Matrix computations</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2012" />
			<publisher>JHU Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 30th International Conference on Machine Learning</title>
		<meeting>The 30th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="222" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Geodesic flow kernel for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2066" to="2073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Domain adaptation for object recognition: An unsupervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2011 IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="999" to="1006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Large-scale damage detection using satellite imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gueguen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hamid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1321" to="1328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Estimating census district populations from satellite imagery: some approaches and limitations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harvey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2071" to="2095" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The class imbalance problem: A systematic study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Stephen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="429" to="449" />
		</imprint>
	</monogr>
	<note>Intelligent data analysis</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">MRI modality transformation in demon registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-J</forename><surname>Kroon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Slump</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ISBI</title>
		<meeting>ISBI</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="963" to="966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Co-regularization based semi-supervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daume</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="478" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">SIFT flow: Dense correspondence across scenes and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Current situation and needs of change detection techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Moran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Image and Data Fusion</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="38" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Weakly supervised alignment of multisensor images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marcos-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Geoscience and Remote Sensing Symposium (IGARSS)</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Semantic tie points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Montoya-Zegarra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leistner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of Computer Vision (WACV), 2013 IEEE Workshop on</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="377" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Domain adaptation via transfer component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="199" to="210" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Location-based services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Voisard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Matching local self-similarities across images and videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition, 2007. CVPR&apos;07. IEEE Conference on</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Efficient mrf deformation model for non-rigid image matching. Computer Vision and Image Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shekhovtsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kovtun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hlaváč</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Improving predictive inference under covariate shift by weighting the log-likelihood function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shimodaira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of statistical planning and inference</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="244" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Swisstopo</surname></persName>
		</author>
		<ptr target="http://www.swisstopo.admin.ch/internet/swisstopo/en/home/products/images/ortho/swissimage/SWISSIMAGE_FCIR.html.4" />
		<title level="m">Swiss Federal Office of Topography SWIS-SIMAGE FCIR</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A comparative study of energy minimization methods for Markov Random Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tappen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2006</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="16" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Co-adaptation: Adaptive co-training for semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="3721" to="3724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Simultaneous registration and change detection in multitemporal, very high resolution remote sensing data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vakalopoulou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Karantzalos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">VLFeat: An open and portable library of computer vision algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fulkerson</surname></persName>
		</author>
		<ptr target="http://www.vlfeat.org/" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Semantic segmentation of urban scenes by learning local class interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Manifold alignment without correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Heterogeneous domain adaptation using manifold alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI Proceedings-International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">1541</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Bridged refinement for transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-R</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Discovery in Databases: PKDD 2007</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="324" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Using high-resolution airborne and satellite imagery to assess crop growth and yield variability for precision agriculture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Everitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="582" to="592" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
