<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multiple Models Fitting as a Set Coverage Problem</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Magri</surname></persName>
							<email>magri.luca.l@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Dept</orgName>
								<orgName type="institution">University of Verona Strada Le Grazie</orgName>
								<address>
									<postCode>15 -37134</postCode>
									<settlement>Verona</settlement>
									<region>IT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Fusiello</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">DPIA -University of Udine</orgName>
								<address>
									<addrLine>Via delle Scienze, 208</addrLine>
									<postCode>-33100</postCode>
									<settlement>Udine</settlement>
									<region>IT</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multiple Models Fitting as a Set Coverage Problem</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper deals with the extraction of multiple models from noisy or outlier-contaminated data. We cast the multi-model fitting problem in terms of set coverage, deriving a simple and effective method that generalizes Ransac to multiple models and deals with intersecting structures and outliers in a straightforward and principled manner, while avoiding the typical shortcomings of sequential approaches and those of clustering. The method compares favorably against the state-of-the-art on simulated and publicly available real data-sets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Finding a model (or structure) that fits data corrupted by noise and outliers is an omnipresent problem in empirical sciences, including Computer Vision. When multiple instances of the same structure are present in the data, the problem has a chicken-and-egg pattern: in order to estimate models one needs to first segment the data, and in order to segment the data it is necessary to know which model points belong to. Moreover, the presence of multiple structures strains robust estimation, because, in addition to rogue points, the outliers to a structure of interest are all the inliers to the other structures.</p><p>Among the wide range of methods proposed in Computer Vision to address the challenge of multiple models geometric fitting, the analysis of consensus together with its counterpart, the analysis of preferences, can be recognized as leitmotifs recurring throughout the extensive literature on the subject. The consensus set of a model is simply defined as the set of points that are inliers to that model. Dually, the preference set of a point is the set of models to which that point is inlier. Most of the multi-model fitting techniques proposed in the literature can be ascribed to one of these two concepts, according to which horn of the chicken-eggdilemma is addressed first.</p><p>Consensus-based algorithms put the emphasis on the estimation part and focus on models that describe as many points as possible. On the other hand, preference approaches concentrate on the segmentation side of the problem, and aim at finding a proper partition of the data, from which model estimation follows.</p><p>Both approaches conceptually work on the consensus/preference matrix P defined as</p><formula xml:id="formula_0">P (i, j) = 1 if err(x i , θ j ) &lt; ǫ 0 otherwise<label>(1)</label></formula><p>where x i ∈ X are data points, θ j ∈ H tentative structures, err a suitable error function and ǫ the inlier threshold. The binary matrix P can be interpreted in several ways. It can be regarded as the incidence matrix of an hyper-graph where rows correspond to vertices and columns represent hyperedges; alternatively its rows, identified with preference sets, can be interpreted as representations of data in high dimensional spaces. In both cases multi-model fitting boils down to cluster analysis. Changing the perspective, columns of P can be interpreted as consensus sets, whose cardinality is to be maximized.</p><p>In the remaining of this section we shall track down the path that, starting from consensus throughout preference analysis, have been followed in the literature to address the challenges of multiple structures recovery. For a review of multi-model fitting from the perspective of the optimization of a global energy functional the reader is referred to <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Consensus analysis</head><p>Consensus analysis stands out as one of the first efforts to address robust model estimation. The methods belonging to this category follow a common paradigm. At first the space Θ of all the feasible structures is approximated as a suitable finite hypothesis space H in different ways. Then a voting procedure elects the structures in H that best explain the data in terms of consensus.</p><p>The idea of exploiting consensus is at the core of the celebrated Ransac (Random Sample Consensus) and its variants (see <ref type="bibr" target="#b18">[20]</ref> and references therein). A straightforward generalization to multiple models is Sequential Ransac <ref type="bibr" target="#b24">[29,</ref><ref type="bibr" target="#b28">33]</ref>, an iterative, greedy algorithm that executes Ransac many times and removes the found inliers from the data as each structure is detected. As a consequence, inaccurate detections at early stages of the algorithm can heavily deteriorate the results; in addition, points in the intersections do not contribute to the sampling of subsequent structures. As such, this strategy is inherently prone to achieve suboptimal segmentation. A parallel scheme, dubbed Multi-Ransac, has been proposed in <ref type="bibr" target="#b34">[39]</ref> in the endeavor to mitigate its greediness. This method, however, falls short of dealing with intersecting models.</p><p>The popular Hough transform and its randomized version <ref type="bibr" target="#b30">[35]</ref> can be regarded as consensus-oriented algorithms too. A more general approach consists in finding modes directly in Θ (e.g. <ref type="bibr" target="#b21">[25]</ref>). In this way the difficulties of the quantization step are alleviated by mapping the data into the parameter space through random sampling and then by seeking the modes (e.g. with with mean-shift <ref type="bibr" target="#b2">[3]</ref>).</p><p>In all these consensus based methods, alongside the voting phase, the approximation of Θ is a recurring and tricky issue. The crucial point is that, when multiple structures are hidden in the data, consensus oriented algorithms have to disambiguate between genuine structures and redundant ones, i.e. instances of the same model with slightly different parameter. This issue is addressed by enforcing several disjointedness criteria, either explicitly or implicitly by different approximations of the solution space.</p><p>For instance, Hough transform handles redundancy by capturing similar structures in the same equivalence class via the quantization of Θ. Along the same line, the bandwidth used in mean shift can be thought as a softer way to localize and aggregate redundant models. Also Sequential Ransac and Multi-Ransac enforce disjointedness by avoiding to sample similar models <ref type="bibr" target="#b6">[7]</ref>. As regards Sequential Ransac, this idea can be identified in the iterative removal of the discovered inliers and in the subsequent sampling of the hypotheses on the remaining data. In Multi-Ransac this is more evident, since this algorithm explicitly search for the best collection of k disjoint models. In practice, however, using consensus as the only criterion seems short-sighted, for true models can have mutual intersections greater than redundant ones, hence the algorithm would fail in discerning authentic structures.</p><p>In order to overcome the drawbacks inherent to consensus methods, the problem has been tackled from a different point of view, where the role of data and models are reverted: rather than representing models and inspecting which points support them, points are described by the preference they grant to models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Preference analysis</head><p>The idea of describing point by their residuals can be traced back to <ref type="bibr" target="#b33">[38]</ref> where the residuals distributions of in-dividual points, with respect to a set of putative structures randomly sampled, is analyzed. In particular, the most significant structures are revealed as peaks in the histograms of the residuals. In addition, the number of models is automatically determined by the median number of modes found over all data points. In practice, the mode-finding step of this strategy suffers of low accuracy and depends critically on the bin size adopted.</p><p>Building on this idea, J-Linkage algorithm <ref type="bibr" target="#b23">[28]</ref> was the first successful application of a preference-based representation of data. A two steps first-represent-then-cluster scheme is implemented: data are represented by the votes they grant to a set of model hypotheses, then a greedy agglomerative clustering is performed to obtain a partition of the data.</p><p>Several elements in common with previous methods can be recognized: an inlier threshold ǫ is used as in Ransac and the idea of casting points' votes echoes Randomize Hough Transform. Despite that, J-Linkage does not rely on a quantized space, which causes the shortcoming of Hough Transform, nor on the residual space, which leads to the difficulties of modes estimation, but explicitly introduces a conceptual space where points are portrayed by the preferences they have accorded to random provisional models. The changes of perspective entailed by preference analysis results in a different approach to the chicken-&amp;-egg dilemma. Structures are recognized as groups of neighboring points in the conceptual space therefore the emphasis is shifted from the estimation to the segmentation part of the problem. T-Linkage <ref type="bibr" target="#b14">[15]</ref> extends this idea by relaxing the notion of binary preference set allowing the use of soft votes to depict points preference more accurately.</p><p>Along the same line of J-Linkage, Kernel Fitting (KF) <ref type="bibr" target="#b1">[2]</ref>, Robust Preference Analysis <ref type="bibr" target="#b15">[16]</ref> (RPA) and Random Cluster Model Simulated Annealing (RCMSA) <ref type="bibr" target="#b17">[19]</ref> exploits points preferences.</p><p>KF and RPA first derive a kernel matrix to measure agreement between preferences, then a (different) transformation is applied in order to detect and remove outliers. Then the cleaned kernel matrix is used by KF to oversegment the remaining inliers and reassemble the structures with a merging scheme. RPA performs symmetric non negative factorization on the cleaned kernel matrix in order to extract the most representative sampled models. Robust statistic is then employed to assign the data to the recovered structures. RCMSA <ref type="bibr" target="#b17">[19]</ref> organizes point preferences in a weighted graph and the multi-model fitting task is stated as a graph cut problem which is solved efficiently in an annealing framework.</p><p>Finally, we can ascribe to preference analysis also all the approaches based on higher order clustering <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b32">37]</ref>, where higher order similarity tensors are defined between n-tuple of points as the probability of points to be clustered together measured in terms of residual errors with respect to provisional models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Shortcoming of preference approaches</head><p>Indubitably, a preference-based approach has the great advantage of casting specific multi-model fitting problems in a very general clustering framework. Nevertheless it has been largely recognized by the research community that the segmentation/clustering problem is ill-posed, and that a "no free lunch theorem" <ref type="bibr" target="#b29">[34]</ref> holds, which states that a given clustering method can be optimal only with respect to some specific type of data-set.</p><p>Moreover, Kleinberg <ref type="bibr" target="#b11">[12]</ref> confirms that clustering techniques are inherently fraught with ambiguities: he conceives an axiomatic theory in which he defines three desirable properties that a clustering scheme ought to satisfy, namely scale-invariance, a "richness" condition that all partitions are achievable, and a consistency requirement on the shrinking and stretching of distances. In that setting an "impossibility theorem" is derived, demonstrating that there is no clustering function satisfying simultaneously all the three properties.</p><p>In addition, two other main issues are not satisfactorily handled by clustering techniques. In first instance, classical clustering approaches are designed to yield a partition of the data, hence they are not suitable for dealing explicitly with intersecting structures. As a result, intersections are either ignored or dealt indirectly with ad hoc post processing on the output.</p><p>In second place, the treatment reserved to outliers is not completely sound. For estimation purposes, gross outliers ought to fall in a special group of points, but clustering treats all the segments in the same way. This is the reason why partitional clustering schemes are not able to enforce robustness by simply throwing-in one additional model with the hope that outliers will be clustered together. Hierarchical methods in practice are more resilient to outliers, still they do not have a specific treatment during the clustering phase: for example T-Linkage relies on a posteriori specific heuristics to ensure robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Multi-model fitting as a coverage problem</head><p>For all the reasons described in the previous section, in this work we sidestep the pitfalls of clustering and focus on the objective of maximizing consensus. However, in doing this, we shall counteract the shortcomings of Sequential Ransac and its relatives, namely greediness and poor handling of intersecting models. These requirements will naturally lead to a coverage formulation, which will be referred to as "Random sample Coverage", or RansaCov.</p><p>Let us start by assuming that all the points x i ∈ X are inliers (the case of outliers will be dealt with later on). This is equivalent to state that all the points are explained by some structures, in other words, the true structures determine, by means of their consensus sets, a cover of the data, i.e. a collection of sets whose union contains X:</p><formula xml:id="formula_1">F = {S j : j ∈ J} such that X ⊆ j∈J S j ,<label>(2)</label></formula><p>Note that we are not requiring that these sets are disjoint, so we are not limited to partitions and we can properly handle the case of intersecting models. By invoking the Occam's principle, a straightforward formulation is therefore to ask for a cover consisting of a minimal number of consensus sets. In this way we are implicitly discouraging redundant models. Thus we are naturally led to the following SET COVER problem.</p><p>Definition 2.1 (SET COVER). Given a ground set X and F = {S 1 , . . . , S m } a cover of X, select the minimum number of subsets from F that covers X.</p><p>In this formulation, X = {x 1 , . . . , x n } contains the data points and the collection F = {S 1 , . . . , S m } is composed by the consensus sets of the sampled models θ 1 , . . . , θ m ∈ H: i.e. S j = {x ∈ X : err(x, θ j ) &lt; ǫ} instantiated on minimal sample sets as in Ransac. The property that F is a cover of X can be easily enforced by requiring that every points of X is sampled at least once. SET COVER can be rephrased rigorously using the matrix P in the constraints formulation and introducing m binary variables z j ∈ {0, 1} for each subset S j . If S j is selected in the solution then z j = 1, otherwise z j = 0. In this way SET COVER can be shown to be equivalent to an Integer Linear Programming (ILP) problem: minimize m j=1 z j subject to P z ≥ 1.</p><p>(</p><p>The constraint can be expanded as</p><formula xml:id="formula_3">j:Sj ∋xi z j ≥ 1 ∀x i ∈ X<label>(4)</label></formula><p>where it becomes clear that it is meant to ensures that the solution {S j } j:zj =1 is a cover of X. If X is corrupted by rogue points we can integrate them in the formulation of the problem at the cost of introducing an additional parameter k equal to the desired number of structures. Requiring some extra information to deal with outliers seems to be unavoidable. In this respect, k is a more guessable parameter than others.</p><p>Instead of trying to find the smallest number of sets that cover all elements, we search for the largest number of points that can be covered by k sets, possibly leaving some points (the outliers) uncovered. This leads to the so called MAXIMUM COVERAGE problem. Definition 2.2 (MAXIMUM COVERAGE). Given a ground set X, F = {S 1 , . . . , S m } a collection of subsets of X and an integer k, select from F at most k subsets that cover the maximum number of points in X.</p><p>This problem is translated in an ILP one thanks to a collection of n auxiliary variables y i , such that y i = 1 if x i belongs to the returned subsets, 0 otherwise:</p><formula xml:id="formula_4">maximize n i=1 y i subject to m j=1 z j ≤ k j:Sj ∋xi z j ≥ y i ∀x i ∈ X 0 ≤ y i ≤ 1, z j ∈ {0, 1}.<label>(5)</label></formula><p>The first condition enforces that no more than k sets are picked and the second constraint ensures that if y i ≥ 0 then at least one set S j ∋ x i is selected.</p><p>The following preprocessing is applied to the input collection of sets. First of all, keeping in mind that our aim is to maximize consensus, we refit a structure to each consensus set via least squares, and, if the consensus has increased, we update the structure and its supporting points. The remaining sets are hence ordered by cardinality |S 1 | ≥ |S 2 | ≥ . . . ≥ |S k | and a set S j is discarded if</p><formula xml:id="formula_5">S j ⊆ j−1 i=1 S i .<label>(6)</label></formula><p>The rationale of this choice is to keep only those structures that cover at least a point that otherwise would be uncovered by the union of larger ones. Please note that in particular we are deleting subsets that are contained in one larger set. SET COVER and MAXIMUM COVERAGE are long known to be NP-hard <ref type="bibr" target="#b10">[11]</ref>: not surprisingly, since the inherent complexity of multi-model fitting does not disappear by simply rephrasing it in different terms. Nevertheless, these optimization problems are among the oldest, most studied and widespread ones in the mathematical programming literature. Therefore we can reap the outcomes of the efforts made by the scientific community in addressing this issues, and enjoy the fruits of several studies focused on approximating the solutions of these problems.</p><p>For example, the greedy strategy -hereinafter Greedy-RansaCov -which keeps choosing the set that covers most uncovered points until they all are covered, embodies the spirit of Sequential Ransac with the only differences that the hypothesis space is not sampled iteratively 1 and, instead of returning a partition, intersecting segments are allowed. It has been demonstrated by Feige <ref type="bibr" target="#b5">[6]</ref> that this greedy strategy is the best possible in terms of approximation ratio. More precisely an approximation of H(n) holds in the case of SET COVER problem (where H(n) denotes the n-th harmonic number), and 1−1/e for the MAXIMUM COVERAGE problem. This result applies effortless to Greedy-RansaCov giving a provable quality measure of the solution.</p><p>Another straightforward strategy consist in solving a relaxed Linear Programming (LP) problem and converting the solution by rounding up all non-zero variables to 1. In this case <ref type="bibr" target="#b27">[32]</ref> shows that the solution achieves an approximation guarantee of a factor equal to the the frequency of the most frequent point, where the frequency of a point is the number of sets that cover that point. Our preprocessing step, besides refining the models, improves the approximation factor of the relaxed LP solution, for it actually reduces the maximal frequency of the points.</p><p>In practice, more sophisticated strategies are used by ILP solvers, but the relaxed LP solution is a good starting point. Our algorithm -dubbed ILP-RansaCov -solves (5) using the intlinprog function of MATLAB, which attempts to tighten the LP relaxation with several heuristics and falls back to branch and bound in case of failure.</p><p>Comparison with FACILITY LOCATION. The closest methods to ours in the literature are those casting multimodel fitting as a FACILITY LOCATION (FL) problem: provided a set of potential facilities (which corresponds to the pool of tentative structures), FL selects an optimal subset of facilities and assigns customers (i.e. data points) to one facility each, so as to minimize the sum of facility opening costs and the distances between customers to their assigned facilities. This leads to the optimization of a cost function composed by two terms: a modeling errori.e. customersfacility distances -which can be interpreted as a likelihood term, and a penalty term to encode model complexity -the cost to open the facilities -mimicking classical MAP-MRF objectives. Some authors solves it with ILP <ref type="bibr" target="#b25">[30,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b19">22,</ref><ref type="bibr" target="#b12">13]</ref> while others propose different combinatorial optimization techniques <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b31">36,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b16">18]</ref>. Although SET COVER and FL are related (the first can be rephrased as a special case of the second) and ILP has been used to solve both, ILP-RansaCov differs from previous work based on FL in many respects.</p><p>In first instance, FL needs to guess a correct trade-off between data fidelity and model complexity, in order to strike the proper balance between over and under fitting. For example <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9]</ref> regularizes the modeling-fitting error, expressed in terms of residual, by introducing a label costs that penalizes the number of different structures, whereas <ref type="bibr" target="#b12">[13]</ref>, aimed at fitting subspace of different dimensions to outlier-free data, exploits a penalty term encoding subspace dimension. In contrast, our formulation elude this thorny trade-off: in the outlier-free scenario SET COVER regular-izes the solution invoking the minimality of cover, while, if outliers are present, MAXIMUM COVERAGE requires the maximum number of models as a clear, intelligible parameter, instead of balancing two incommensurable quantity in the cost function.</p><p>Second, FL minimizes the fitting error on the continuum of residuals, in the same spirit of MLE estimators, while ILP-RansaCov gains resiliency to outliers by maximizing the consensusà la Ransac. This, however, comes at the price of assuming that all the structures have the same error scale, while MLE-like estimators can compute the scale along the parameters of each model.</p><p>In our formulation the rogue points will be simply left uncovered by MAXIMUM COVERAGE, whereas FL copes with outliers either by introducing a special additional model for which a constant fidelity measure has to be manually tuned <ref type="bibr" target="#b8">[9]</ref>, or by requiring an upper bound to the total number of outliers <ref type="bibr" target="#b13">[14]</ref>.</p><p>Finally, FL approaches enforce hard-membership constraints, producing a partition of the data, whereas ILP-RansaCov inherently caters for intersecting solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments on simulated data</head><p>In this section we investigate the performance of ILP-RansaCov with respect to Greedy-RansaCov (which emulates Sequential Ransac), J-Linkage <ref type="bibr" target="#b23">[28]</ref> and T-Linkage <ref type="bibr" target="#b14">[15]</ref> on synthetic data, using the same sampling and the same inlier threshold for all the methods (or, equivalently, the same P matrix). We obtained the implementations of J-Linkage and T-Linkage from <ref type="bibr">[27]</ref>. The MATLAB code of ILP-RansaCov is available on the web 2 .</p><p>The data sets <ref type="figure" target="#fig_0">(Fig. 1)</ref> consist of segments in several configurations and circles, as in <ref type="bibr" target="#b23">[28]</ref>. Each structure consists of 50 inliers points, contaminated by Gaussian noise and outlying points in different percentages (reported in Tab. 1). All the methods have been provided with the correct number of structures k; in the case of J-Linkage and T-Linkage, the largest k structures produced by the algorithms are considered.</p><p>The results are collected in <ref type="figure" target="#fig_0">Fig. 1</ref> while Tab. 1 reports the misclassification errors (ME), computed as follows: first the map between ground-truth labels and estimated ones that minimize the overall number of misclassified points is found (as in <ref type="bibr" target="#b20">[23]</ref>), then a point is deemed as correct if one of its labels corresponds to the ground-truth. The ME is the percentage of misclassified points .</p><p>First of all we can notice that in the Stair4 experiment (firstly used in <ref type="bibr" target="#b34">[39]</ref> to criticize Sequential Ransac), Greedy-RansaCov performs poorly: the shortcomings of this greedy strategy are here afoot: the incorrect selection of the first structure compromises the subsequent interpretation of the <ref type="bibr" target="#b1">2</ref>   <ref type="table">Table 1</ref>: Misclassification error (ME %) on simulated data. data. A greedy approach to the MAXIMUM COVERAGE problem yields a sub-optimal segmentation also on the Circle4 data-set, where one of the four structures is over-segmented by Greedy-RansaCov at the expense of the smaller circle in the center. On Star11 J-linkage misses a ground truth segment. During the merging process some inliers are incorrectly aggregated to spurious models, hence the recovered segment that actually corresponds to a ground truth structure collects fewer inliers, to the point that it falls outside the first k largest models and is deemed as outlier. In general the tendency of loosing inliers during the segmentation step affects J-Linkage (and T-Linkage) also in the other data-sets, e.g. it is particularly evident on Circle4, Even when the discovered inliers are enough to recover the corresponding structures, this behavior has a detrimental effect on the model estimate, for it increases the variance.</p><p>ILP-RansaCov yields reliable segmentations in all the experiments, and it achieves the best average ME. The reason can be ascribed to the non-greedy minimization strategy (w.r.t. Greedy-RansaCov) and to the departure from the partitioning paradigm (w.r.t. J-Linkage and T-Linkage). As a matter of fact, when models do not intersect, as in Stair4, the performance of J-Linkage and T-Linkage are in the same range of ILP-RansaCov.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments on real data</head><p>In this section, we demonstrate the performance of ILP-RansaCov on three classical Computer Vision applications, namely: i) vanishing point detection, ii) video motion segmentation, and iii) two-views segmentation. In all these scenarios we compare ILP-RansaCov with J-Linkage <ref type="bibr" target="#b23">[28]</ref>, Tlinkage <ref type="bibr" target="#b14">[15]</ref> and RPA <ref type="bibr" target="#b15">[16]</ref>, whose implementation is taken from <ref type="bibr">[21]</ref>. In addition, one reference method has been added to the comparison for each specific scenario, namely: MFIPG <ref type="bibr" target="#b16">[18]</ref> in the vanishing point experiments, SSC <ref type="bibr" target="#b20">[23]</ref> for video motion segmentation and RCMSA <ref type="bibr" target="#b17">[19]</ref> for twoviews segmentation. These methods have been selected because i) they are among the best performers, ii) the original code from the authors is available <ref type="figure" target="#fig_0">(MFIPG [17]</ref>, RCMSA [17], SSC [24]), and iii) they have been tested on the same respective data-sets.</p><p>MFIPG and RCMSA are considered only in one scenario out of three because the authors provided the tuning parameters only for that particular application (vanishing point detection and two-views segmentation, respectively). SSC instead is tailored specifically to subspace segmentation, hence it cannot be applied in the other two cases (where models are not linear or affine subspaces). All the algorithms but SSC and RCMSA were provided with the same pool of putative models, sampled as in <ref type="bibr" target="#b15">[16]</ref>.</p><p>Vanishing point detection. In this experiment we compare the performances of ILP-RansaCov with MFIPG on vanishing point detection using the York Urban Line Segment Database <ref type="bibr" target="#b4">[5]</ref>, or York Urban DB in short, a collection of 102 images of architectural Manhattan-like environments (i.e. scenes dominated by two or three mutually orthogonal vanishing directions). Annotated line-segments that match with the 3-d orthogonal frame of the urban scene are provided with the ground-truth, no outliers are present in the data. The aim is to group the supplied segments in order to recover two or three orthogonal vanishing points.</p><p>MFIPG (Model-Fitting-with-Interacting-Geometric-Priors) is a recently proposed method that improves on PeARL <ref type="bibr" target="#b3">[4]</ref> adding high-level geometric priors. In particular, in this application, an additional term expressing interaction between vanishing points is included into the FL formulation, to promote the extraction of orthogonal vanishing points. The global input parameters recommended in the original paper have been optimized for each single image to enhance the results. <ref type="figure">Figure 2</ref> shows three images where ILP-RansaCov achieved the worst ME, which are nevertheless qualitatively correct. <ref type="figure">Figure 3</ref>(a) reports the cumulative distribution of the ME per sequence, i.e. the value on the ordinate corresponds to the percentage number of sequences where the algorithm achieved a ME lower than the abscissa. The differences among the methods can be better appreciated by plotting the area above the cumulative distribution of ME ( <ref type="figure">Fig. 3(b)</ref>) or by analyzing the average and median ME, collated in Tab. 2. These quantitative results confirm that ILP-RansaCov is the most accurate, followed by RPA. As MFIGP enhances PeARL, figures in Tab. 2 indirectly corroborate the advantage of ILP-RansaCov over PeARL. It is worth noting that Greedy-RansaCov, a proxy of the vilified Sequential Ransac, performs better than other sophisticated methods, in this task.</p><p>Video motion segmentation. In this experiments we considered Sparse Subspace Clustering <ref type="bibr" target="#b20">[23]</ref> a state-of-the-art   technique that exploits a sparse representation to build an affinity matrix, which in turns is segmented by spectral clustering. The input data is a set of features trajectories across a video taken by a moving camera, and the aim is to recover the different rigid-bodies. We use the 51 real video sequences from the Hopkins 155 data-set <ref type="bibr" target="#b26">[31]</ref>, each containing two or three moving objects, with no outliers. Following <ref type="bibr" target="#b22">[26]</ref>, in order to deal with degenerate motions, we project the data onto an affine 4-d space where the rigidbody segmentation is translated in a 3-d plane fitting problem. <ref type="figure">Figure 4</ref> reports some sample results, in particular three sequences belonging to Traffic 2 and Others 3 subsets, respectively, where ILP-RansaCov achieves sub-optimal segmentations. <ref type="figure">Figure 5</ref> and Tab. 3 provide a comparison of the performances in terms of ME: ILP-RansaCov places in the same range of SSC and achieves the best overall results. In this case the advantage of solving the MAXIMUM COVERAGE problem with a global approach is afoot, since the greedy strategy of Greedy-RansaCov, sampling being equal, fails. Please note that, via <ref type="bibr" target="#b12">[13]</ref>, this experiment provides an indirect comparison with FLoSS.</p><p>Two-views segmentation. In this experiment we additionally compare ILP-RansaCov against RCMSA <ref type="bibr" target="#b17">[19]</ref> on the Adelaide Robust Model Fitting Data Set, or Adalai-   All the methods are given the inlier threshold computed from the available ground truth.</p><p>Some failure examples are reported in <ref type="figure">Fig. 6</ref>. The left image is an example of under-segmentation, where a unique fundamental matrix explains both the cube and the toy (red points). In the middle image ILP-RansaCov fails in detecting one planar structure (second wall of the building from the left). In the right image the campanile (on the very right) is over-segmented, and this consumes one of the available k models, thereby preventing the nearby wall to be detected.</p><p>From the data reported in <ref type="figure">Fig. 7</ref> and Tab. 4, the reader can appreciate that the ME of ILP-RansaCov is consistently lower than RCMSA and in the same range of RPA.</p><p>In order to evaluate the relative importance of multi-   Finally, we run an experiment to probe of how the execution time scales with the input dimension and where the time is spent. To this end, we run ILP-RansaCov on a line fitting problem extracted from Star11 with variable number of sampled models and number of points. The execution times, broken down for each step, are reported in <ref type="figure">Fig. 8</ref>. The instantiation of the consensus/preference matrix dominates the complexity for moderate point number, whereas ILP takes over when the number of points increases. Also, while the dependence from the number of sampled models appears to be polynomial, the execution time grows exponentially with the number of points, in accordance with the-   <ref type="formula" target="#formula_5">(6)</ref>, is negligible in terms of the running time, but it improves the quality of the solution: e.g., with reference to Tab. 4 (F), the mean ME of ILP-RansaCov without this refinement raises to 11.44.</p><p>To complete the picture on computational burden, we report in Tab. 5 the time spent by ILP-RansaCov in each experiment on real data. A comparison with other methods would have been meaningless for not all of them are coded in MATLAB as ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We formulated multi-model fitting in terms of SET COVER and MAXIMUM COVERAGE problems, yielding a simple and easy to implement method that generalizes Ransac to the case of multiple structures in a neat and principled manner.</p><p>As in previous work, the multi-model fitting problem is formulated in terms of optimization of a global cost function, thereby eluding the greediness of techniques such as Sequential/Multi-Ransac and J-linkage, but at the same time avoiding the difficult trade-off between data fidelity and complexity of other formulations, by resorting to consensus maximization. In both cases, we tackle the problem of intersecting models at the root, by replacing partitions with coverages.</p><p>ILP-RansaCov is modular with respect to the ILP solver and to the sampling strategy. Few intelligible parameters need to be set and tuned, namely the inlier threshold and the number of desired model.</p><p>In summary, we expect that this paper will offer practitioners a manageable tool for addressing a difficult and ubiquitous problem, and will provide the community a reference baseline for further advancements.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Comparison on simulated data (outliers marked as x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>A sample of the worst ILP-RansaCov results on YorkUrbanDB (vanishing point detection). Line membership is color-coded. Results on YorkUrbanDB. (a) is the cumulative distributions of the errors per sequence; (b) shows the area above the curve (the smaller the better). J-Lnkg T-Lnkg RPA MFIGP Grdy-RansaCov ILP-RansaCov Mean</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>A sample of the worst ILP-RansaCov results on Hopkins155 (video motion segmentation). Point membership is color-coded. Results on Hopkins155. (a) is the cumulative distributions of the errors per sequence; (b) shows the area above the curve (the smaller the better). J-Lnkg T-Lnkg RPA SSC Grdy-RansaCov ILP-RansaCov</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>A sample of the worst ILP-RansaCov results on AdelaideRMF (two-views segmentation). Point membership is color-coded, black crosses are points outliers. Results on AdelaideRMF. (a) is the cumulative distributions of the errors per sequence; (b) shows the area above the curve (the smaller the better).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>www.diegm.uniud.it/fusiello/demo/cov/ outliers J-Lnkg T-Lnkg Grdy-RansaCov ILP-RansaCov</figDesc><table>Stair4 
50% 
10.20 
10.00 
39.20 
12.00 
Star5 
60% 
15.20 
14.40 
10.40 
3.80 
Star11 
50% 
35.00 
33.09 
32.36 
25.18 
Circle4 
50% 
26.50 
23.00 
30.25 
11.25 

mean 
20.12 
20.12 
28.05 
13.06 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Misclassification error (ME %) on YorkUrbanDB.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Misclassification error (ME %) on Hopkins155. deRMF in short, which consists of 38 image pairs, 19 related by multiple homographies (H) and 19 by multiple fundamental matrices (F), with outliers. The task involves segmenting different planes/moving objects by fitting homographies/fundamental matrices to subsets of corresponding points.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head></head><label></label><figDesc>J-Lnkg T-LnkgRPA RCMSA Grdy-RansaCov ILP-RansaCov</figDesc><table>F 
Mean 
16.43 
9.37 
5.49 
12.37 
17.08 
6.04 
Med 
14.29 
7.80 
4.57 
9.87 
21.65 
4.27 

H 
Mean 
25.50 
24.66 
17.20 
28.30 
26.85 
12.91 
Med 
24.48 
24.53 
17.78 
29.40 
28.77 
12.34 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Misclassification error (ME %) for motion segmentation (F) and plane segmentation (H) on AdelaideRMF.ple membership w.r.t. the optimization method, we have rephrased Multi-Ransac in the framework of maximal coverage: the strategy is similar to Greedy-RansaCov, the difference being that, after a set is picked, the subsequent ones are searched among those having maximal Jaccard distance with the currently covered elements, thereby maximizing disjointedness. Even if a point can be assigned to multiple model, experiments demonstrated that the performances are consistently inferior to ILP-RansaCov (ME is: 2.97 for VP, 4.58 for video sequences, 17.01 for F and 26.85 for H), confirming the crucial role of the optimization technique.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head></head><label></label><figDesc>Figure 8: Execution time of ILP-RansaCov on simulated data w.r.t. the dimensions of the problem.</figDesc><table>3N 
4N 
5N 
6N 
7N 
8N 
9N 

# sampled models 

0 

20 

40 

60 

80 

100 

Time [s] 

# points = 550 (N) 

Preference matrix 
Refinement 
ILP 

100 200 300 400 500 600 700 800 900 

# points 

0 

50 

100 

150 

Time [s] 

# samped models = 550 

Preference matrix 
Refinement 
ILP 

YorkUrbanDB Hopkins155 Adelaide (F) Adelaide (H) 

mean 
8.09 
41.19 
52.24 
146.34 
median 
1.14 
11.56 
48.79 
51.12 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Execution time [s] of ILP-RansaCov on real data. oretical prediction.The impact of the preprocessing step, related to Eq.</figDesc><table></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In Sequential Ransac columns of P are generated sequentially: once a structure of inlier is detected, its supporting points are removed and successive hypotheses are sampled from the remaining of the data.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. L. Magri gratefully acknowledge the support of 3Dflow srl.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Beyond pairwise clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="838" to="845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust fitting of multiple structures: The statistical learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-J</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conf. on Computer Vision</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="413" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mean shift: A robust approach toward feature space analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="603" to="619" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast approximate energy minimization with label costs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Delong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Osokin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">N</forename><surname>Isack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient edgebased methods for estimating manhattan frames in urban imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Elder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Estrada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conf. on Computer Vision</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="197" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A threshold of ln n for approximating set cover</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Feige</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="634" to="652" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multi-model Estimation in the Presence of Outliers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Fouhey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Citeseer</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Tensor Decomposition for Geometric Grouping and Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Govindu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1150" to="1157" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Energy-based geometric multimodel fitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Isack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="147" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient higher-order clustering on the grassmann manifold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Govindu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conf. on Computer Vision</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Reducibility among combinatorial problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Karp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">An impossibility theorem for clustering. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="463" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Floss: Facility location for subspace segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lazic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Givoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Aarabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conf. on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Two-view motion segmentation from linear programming relaxation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">T-linkage: A continuous relaxation of j-linkage for multi-model fitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Magri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fusiello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Robust multiple model fitting with preference analysis and low-rank approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Magri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fusiello</surname></persName>
		</author>
		<idno>20.1-20.12</idno>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Interacting geometric priors for robust multimodel fitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-J</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The random cluster model for robust geometric fitting. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-J</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Suter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Usac: a universal framework for random sample consensus. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raguram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Frahm</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2022" to="2038" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Two-view multibody structureand-motion with outliers through model selection. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Suter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="983" to="995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Robust subspace clustering. CoRR, abs/1301.2603</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Soltanolkotabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Nonlinear mean shift for clustering over analytic manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Subbarao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1168" to="1175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Removing mistracking of multibody motion video database hopkins155</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sugaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kanatani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Robust multiple structures estimation with J-Linkage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Toldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fusiello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conf. on Computer Vision</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">5302</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Geometric motion segmentation and model selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">356</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1321" to="1340" />
			<date type="published" when="1740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Stochastic motion clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conf. on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="328" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A benchmark for the comparison of 3-d motion segmentation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Approximation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">V</forename><surname>Vazirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Detecting planar homographies in an image pair</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Laganiére</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Symposium on Image and Signal Processing and Analysis</title>
		<meeting>the 2nd International Symposium on Image and Signal Processing and Analysis</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="182" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">No free lunch theorems for optimization. Transaction on evolutionary computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">G</forename><surname>Macready</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="67" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A new curve detection method: randomized Hough transform (RHT)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kultanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="331" to="338" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A global optimization approach to robust multi-model fitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A unifying approach to hard and probabilistic clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shashua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conf. on Computer Vision</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="294" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Nonparametric estimation of multiple structures with outliers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kosecká</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conf. on Computer Vision</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">4358</biblScope>
			<biblScope unit="page" from="60" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The multi-RANSAC algorithm and its application to detect planar homographies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zuliani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Kenney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conf. on Image Processing</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
