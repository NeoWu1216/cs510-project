<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Laplacian Patch-Based Image Synthesis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joo</forename><forename type="middle">Ho</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inchang</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
							<email>minhkim@vclab.kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Laplacian Patch-Based Image Synthesis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Patch-based image synthesis has been enriched with global optimization on the image pyramid. Successively, the gradient-based synthesis has improved structural coherence and details. However, the gradient operator is directional and inconsistent and requires computing multiple operators. It also introduces a significantly heavy computational burden to solve the Poisson equation that often accompanies artifacts in non-integrable gradient fields. In this paper, we propose a patch-based synthesis using a Laplacian pyramid to improve searching correspondence with enhanced awareness of edge structures. Contrary to the gradient operators, the Laplacian pyramid has the advantage of being isotropic in detecting changes to provide more consistent performance in decomposing the base structure and the detailed localization. Furthermore, it does not require heavy computation as it employs approximation by the differences of Gaussians. We examine the potentials of the Laplacian pyramid for enhanced edge-aware correspondence search. We demonstrate the effectiveness of the Laplacian-based approach over the state-of-the-art patchbased image synthesis methods. * Corresponding author ture from the boundary to the interior such that the image gradients, the first derivatives of image intensity, measure directional changes of intensity around edges. The image pyramid, which denotes an image representation based on multiscale signals, has been widely used as a typical practice for enhancing structural coherence when completing missing regions in patch-based synthesis <ref type="bibr" target="#b28">[29]</ref>. Recently, the image gradients in each level of the image pyramid are used for enhancing edge structure in addition to coherent patchbased synthesis <ref type="bibr" target="#b10">[11]</ref>. Even though the latest approach of combining gradients and the image pyramid has improved the structural coherence and details in inpainting, the gradient operator is directional and thus requires twofold greater computation of multiple operators, and it introduces a significantly heavy computational burden to solve the Poisson equation. Furthermore, it presents inconsistency often with artifacts in non-integrable gradient fields.</p><p>The Laplacian operator, which is the divergence of gradients of image intensity, takes advantage of being isotropic and invariant to rotation <ref type="figure">(Figure 1c</ref>). In addition, coordinates of the Laplacian correspond to those of the edges, being well aligned to represent the image structure over edges. The Laplacian pyramid allows us to decompose the base and detail structure of an image into different spatial frequency components that can preserve structure upon decomposition. This representation has been used in many applications such as image blend/fusion, enhancement, and denoising. However, to the best of our knowledge, the potentials of the Laplacian pyramid has not been intensively exploited in previous coherent patch-based image synthesis. The proposed method is the first work that combines the Laplacian with patch-based synthesis of global coherence. In this paper, we examine the properties of the Laplacian pyramid for image completion and describe our edge-aware patch-based synthesis using a Laplacian pyramid.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Proposed first by Bertalmio et al. [6], inpainting refers to the task of filling in or completing holes, or missing or corrupted regions in images. Inpainting is classified into two categories: diffusion-based and exemplar-based methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In digital photography, we often confront a situation where certain causes, such as blocks by uninvited objects, occlusions, failures in transmission, and holes produced by different perspectives in binocular stereo, corrupt a portion of images. Accordingly we may wish to fix these corruptions with plausible contents. To address these situations, image inpainting <ref type="bibr" target="#b5">[6]</ref>, which refers to filling in a corrupted area, has received attention during the past decade. Although image inpainting has been commonly used even with novice users, there is no completely versatile inpainting algorithm that gives robust results under any conditions.</p><p>The image gradients are employed in classical inpainting methods <ref type="bibr" target="#b9">[10]</ref> for detecting and copying image struc-Diffusion-Based. Methods that belong to this category complete missing areas by propagating the geometric structures of the neighboring areas. This is accompanied with the smoothness constraints that enforce the connectivity of local structures. Diffusion can be performed locally by solving a partial different equation (PDE) <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref> and there is also a global optimization approach that minimizes the total variation <ref type="bibr" target="#b22">[23]</ref> of the inpainted area <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b16">17]</ref>. Diffusionbased inpainting is shown to be very effective in reconstructing line, curves, and small holes, but it suffers from blurring artifacts when completing large holes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exemplar-Based.</head><p>To extend the coverage of diffusionbased inpainting, exemplar-based approaches have been proposed. Within the unknown hole area this approach first determines the order, in which target patches are filled in, and then it searches similar candidate patches from known areas. Finally it composites the candidate patches on the location of the target. Subsequent to the approaches proposed by Criminisi et al. <ref type="bibr" target="#b9">[10]</ref> and Drori et al. <ref type="bibr" target="#b11">[12]</ref>, and then succeeded by the global optimization of Wexler et al. <ref type="bibr" target="#b28">[29]</ref>, variants of these works have been resorted. Sun et al. <ref type="bibr" target="#b24">[25]</ref> propagated the structures along with user-provided-guidance. Buyssens et al. <ref type="bibr" target="#b7">[8]</ref> addressed the filling order using a tensorbased data term. The candidate patches, being represented by the nearest neighbor field (NNF), were searched following the nonlocal denoising algorithm <ref type="bibr" target="#b6">[7]</ref>. This part was accelerated by introducing versatile data structures such as kd-trees <ref type="bibr" target="#b4">[5]</ref> and vp-trees <ref type="bibr" target="#b30">[31]</ref>. Barnes et el. <ref type="bibr" target="#b3">[4]</ref> proposed a randomized search method that made computation much more tractable, thus it has been broadly adopted to search correspondence. In addition, Komodakis and Tziritas <ref type="bibr" target="#b15">[16]</ref> proposed priority belief propagation to address patch composition via discrete global optimization. He and Sun <ref type="bibr" target="#b12">[13]</ref> showed that exploiting the statistics of patch offsets is effective when searching the candidate patches, and Huang et al. <ref type="bibr" target="#b13">[14]</ref> attempted to use planar structure guidance in order to take the perspective projection into account. Additionally, there have been efforts to adopt the patch sparsity <ref type="bibr" target="#b29">[30]</ref>, or to take the image super-resolution algorithm <ref type="bibr" target="#b18">[19]</ref>.</p><p>Further Coherence. Traditional patch-based inpainting algorithms, originally proposed by Wexler et al. <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref>, which compute similarity according to colors on the image pyramid, generated visually plausible results. However, some results have an inconsistent structure due to a lack of spatial coherence. Recently, the image gradients in each level of the image pyramid have been used for enhancing structural coherence <ref type="bibr" target="#b10">[11]</ref>. However, <ref type="bibr">Darabi et al.</ref> inherited the natural limitation of the image gradient operators. Since the gradient operator is directional, they compute horizontal and vertical changes of intensity, and the gradients must be solved by the Poisson equation for integration. Furthermore, this PDE-based solution often intro-duces artifacts in non-integrable gradient fields. In addition, Kalantari et al. <ref type="bibr" target="#b14">[15]</ref> enhanced the patch-based searching algorithm with additional masks that account for foreground and background, resolving typical artifacts that occurs by the traditional patch-based synthesis.</p><p>Even though both patch-based synthesis and the Laplacian pyramid have been practiced extensively for recent decades, only a few works have examined the combined application of these two approaches. To the best of our knowledge, only Drori et al. <ref type="bibr" target="#b11">[12]</ref> and Padmavathi and Soman <ref type="bibr" target="#b19">[20]</ref> utilized the Laplacian approach to solve the inpainting problem. However, the both methods take the classic heuristic inpainting approach, originally proposed by Criminisi et al. <ref type="bibr" target="#b9">[10]</ref>. Different from Criminisi, Drori et al. <ref type="bibr" target="#b11">[12]</ref> use the Gaussian pyramid for coarse-to-fine refinement and adaptive patch size depending on texture complexity in addition to the usage of the Laplacian pyramid to naturally blend the target and source patch. Padmavathi and Soman <ref type="bibr" target="#b19">[20]</ref> fundamentally follow Criminisi's heuristic approach. Even though they utilize the Gaussian and the Laplacian pyramid to separate the texture and the structure, they merely transfer the upsampled detail of low frequency to the high frequency layer without reconstructing details in the Laplacian domain. These two methods do not fully exploit the advantages of the Laplacian pyramid with the benefit of patchbased global optimization <ref type="bibr" target="#b28">[29]</ref> and also inherit the limitations of the heuristic approach <ref type="bibr" target="#b9">[10]</ref>. Furthermore, they suffer from global inconsistency, resulting in a coherent local decision around image structures. In contrast, our Laplacian approach is built on the state-of-the-art work of global energy optimization proposed by Wexler et al. <ref type="bibr" target="#b28">[29]</ref> to overcome the incoherence problem and it enhances the structural coherence by taking advantages of the Laplacian representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Laplacian Patch-Based Image Synthesis</head><p>Our inpainting leverages a Laplacian pyramid to improve structural coherence in image synthesis. Our nearest neighbor search on a Laplacian pyramid is more invariant to rotation with propagated structural information and therefore we can improve the accuracy of the correspondence search compared with the state-of-the-art methods <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b10">11]</ref> do. Also, by making use of the upsampled Gaussian and Laplacian images, we obtain more robust performance against the noise and the change of parameters. This section provides the details of proposed edge-aware image synthesis strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Laplacian Coherent Spaces</head><p>Gaussian, Gradient and Laplacian. The image pyramid offers a multi-resolution representation of an image <ref type="bibr" target="#b0">[1]</ref> and has been practiced in many applications. Creating a pyramid consists of two steps: filtering and sampling. As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, the Gaussian function (a), the gradients of the Gaussian (b) and the divergence of gradients, Laplacian (c) have been commonly used for filtering. Since convolutional filtering is a linear operation, the Laplacian of a Gaussian-filtered image ∇ 2 [h σ ⊗ f ] is identical to the image filtered with the Laplacian kernel ∇ 2 h σ ⊗ f . Downsampling the signals subsequent to the filtering builds an image pyramid.</p><formula xml:id="formula_0">h σ = 1 2πσ 2 e − x 2 + y 2 2σ 2 ∇ 2 h σ ∇h σ = ∂ ∂x h σ , ∂ ∂ y h σ ⎧ ⎨ ⎩ ⎫ ⎬ ⎭ h σ 2 − h σ 1 ( ) ≈ ∇ 2 h σ h σ 1 σ 1 = σ 2 ⎛ ⎝ ⎜ ⎞ ⎠ ⎟ h σ 2 σ 2 = 2σ ( ) (a) (b) (c) (d) (e) (f)</formula><p>In particular, the gradients ∇ x,y and the Laplacian ∇ 2 have been commonly used to detect edge structures in images. The gradients are calculated from the first partial derivatives of x and y: ∇h σ = ∂ ∂x h σ , ∂ ∂y h σ . At least two operators are required to detect the changes of local structures in images. See <ref type="figure" target="#fig_0">Figure 1</ref>. The gradients are directional edge detectors that require multiple operators for each direction; therefore, the gradient magnitude is used alternatively for detecting edges. Unlike the gradients, the Laplacian operator</p><formula xml:id="formula_1">∇ · ∇h σ = ∇ 2 h σ = ∂ 2 hσ ∂ 2 x 2 + ∂ 2 hσ ∂ 2 y 2</formula><p>is an isotropic edge detector which is invariant to rotation of the function in images. The Laplacian pyramid <ref type="figure" target="#fig_2">(Figure 2a</ref>) stores the bandpassed structural information of each frequency band. The pyramid has been used broadly for various edge-aware image processing <ref type="bibr" target="#b20">[21]</ref>.</p><p>Computing the Laplacians. Since convolution with large weighting functions is an expensive computation, the Laplacian of a Gaussian (LoG) can be approximated by simply taking a difference of two Gaussians (DoG) at different scales. See The backward computation of the gradients is notoriously expensive due to solving the Poisson equation, which may also introduce undesirable artifacts caused by non-integrable gradient fields. In contrast, the forward and backward computation of the Laplacian pyramid using the DoG is very efficient as they are virtually the operations of subtraction and summation, so the Laplacian pyramid has excellent potentials for patch-based image synthesis. In this paper, we employ the DoG-based approximation to compute the LoG efficiently. Note that for this reason, unlike other gradient-based methods such as Darabi et al. <ref type="bibr" target="#b10">[11]</ref>, our method requires no more additional computational cost, such as solving the Poisson equation, computed with traditional patch-based synthesis methods <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b2">3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Patch-Based Synthesis on a Laplacian Pyramid</head><p>The choice of the pyramid kernel operator is critical with respect to which information we derive from images. The Gaussian operator is effective in determining the base structures at each level of frequency. This operator is adopted in many image completion algorithms to achieve spatial coherence in searching correspondence and aggregating similarity, proposed by Wexler et al. <ref type="bibr" target="#b28">[29]</ref> and Barnes et al. <ref type="bibr" target="#b2">[3]</ref>. Contrary to the Gaussian, the gradient and the Laplacian operator are capable of searching edge structures of each level in images. The pyramid elements of derivatives are preserved to local regions in the spatial domain of the gradients or the Laplacian. The derivative image pyramids decompose edge localization at each level of frequency.</p><p>Recently, Darabi et al. <ref type="bibr" target="#b10">[11]</ref> introduced a correspondence search that examines not only color but also gradients in the image pyramid. They presented that examining the first derivatives is clearly beneficial in searching correspondences of structural coherence in image completion. We were motivated to improve the seminal idea of leveraging derivatives with the Laplacian. Our edge-aware search of correspondence resembles the work of Darabi et al. with two main differences of aggregated correspondence and rotation invariance as follows.</p><p>Building a Laplacian Pyramid. The input of exemplarbased image completion is a color image I and a mask image M , which segregates an image into source region S and target region T . The goal of exemplar-based image completion is to complete the target region T of image I with contents from the source region S. To use a Laplacian pyramid in image inpainting, we first build a Gaussian pyramid G for image I following <ref type="bibr" target="#b20">[21]</ref>:</p><formula xml:id="formula_2">G 0 = I, G i+1 = downsample(G i ) (i &lt; n),<label>(1)</label></formula><p>where G i is the i-th scale in the Gaussian pyramid G, and the total number of scales is n + 1, and downsample() is an operator that subsamples a filtered scale. The finest level of the Gaussian pyramid G 0 is the original image I. The i-th Gaussian scale G i+1 is a subsampled scale from the Gaussian-filtered one of the previous scale G i .</p><formula xml:id="formula_3">0 5.6E+3 &gt; 2.2E+4 2 G ∇G 2 L 2 } ,</formula><p>patch color distance of the source patches to the red target  We then compute differences of the Gaussians to derive a Laplacian pyramid L:</p><formula xml:id="formula_4">0 G G 1 (U 0 ) G 2 (U 1 ) G 3 (U 2 ) G 4 (U 3 ) 0 L 1 L 2 L 3 L G i L i (a)</formula><formula xml:id="formula_5">{ U 2 ∇y ∇ 2 U i = upsample(G i+1 )</formula><formula xml:id="formula_6">U i = upsample(G i+1 ), L i = G i − U i (i &lt; n), L n = G n ,<label>(2)</label></formula><p>where upsample() is an upsampling operator. To simplify our algorithm, we define an upsampled Gaussian pyramid U . The i-th Laplacian image L i is the detailed structures between G i and G i+1 . Since the number of levels in the Gaussian pyramid is finite, the coarsest level of the Laplacian pyramid L n is the coarsest of the Gaussian pyramid G n , called the residual, which corresponds to a tiny version of the image.</p><p>Our DoG-based Laplacian pyramid includes two image pyramids of the Gaussians and the Laplacians, shown in <ref type="figure" target="#fig_2">Figures 2(a) and (b)</ref>. The frequency of the base structure is decomposed as intensity at each level in the Gaussian pyramid, while the frequency of the edge structure is localized as the Laplacians at each level of frequency in the Laplacian pyramid. <ref type="figure" target="#fig_2">Figure 2</ref> offers an overview of our edge-aware correspondence search on the Laplacian pyramid, compared with a gradient-based search <ref type="bibr" target="#b10">[11]</ref> (d) and a traditional Gaussian-based search (e) <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b2">3]</ref>. We construct pyramids with a 5-by-5 blur kernel.</p><p>Aggregated Correspondence. Our main intuition on the selection of these two pyramids is the aggregated correspondence of the base and the edge structures. The bottom row in <ref type="figure" target="#fig_2">Figure 2</ref>(c) shows an example of the patch color distances of all the source patches to the target patch at the top-left round corner of a circular function at scales of U 2 and L 2 . The area pointed by the red arrows indicates aggregated information of the base and the detailed structures in the both pyramids. Since the random search algorithm gradually steps forward to minimize the patch color distance in Equation <ref type="formula" target="#formula_8">(3)</ref>, the aggregated edges of the base and the detail structures become significantly helpful clues for searching the correspondences of structural similarity due to the nature of the random search algorithm <ref type="bibr" target="#b10">[11]</ref>. (The brighter colors in the figure indicate more similar patch color distances.) In contrast, the distance metrics on both the gradient magnitude ||∇|| 2 (d) and the Gaussian scale (e) weight only a few number of patches outstandingly high. Consequently most of the patches' structures are ignored by the weight when calculating the weighted sum of colors for vote (see Equation <ref type="formula" target="#formula_12">(4)</ref>). These two image pyramids of the gradients and the Gaussians are used by Darabi et al. <ref type="bibr" target="#b10">[11]</ref> for the energy function of patch distance.</p><formula xml:id="formula_7">U l−2 + L l−2 (l-2) th scale image completion G l−2 U l−2 L l−2 NNF propagation U l−1 + L l−1 (l-1) th scale image completion G l−1 U l−1 L l−1 Initialize (l-1) th level image ! U 0 + L 0 0th scale image completion G 0 U 0 L 0 ! !</formula><p>Based on this observation, our objective strategy of searching for correspondence not only minimizes the distances of low-frequency base structures but also preserves the distances of high-frequency detailed structures. Our energy function resembles the iterative Expectation-Maximization (EM) algorithm following Wexler et al. <ref type="bibr" target="#b28">[29]</ref> but with the main difference of using two image pyramids of the upsampled Gaussians and the Laplacians. In the expectation step, we find similar source patches (blue square in <ref type="figure" target="#fig_2">Figure 2c</ref>) for all target patches (red square). We use the random correspondence search algorithm, proposed by Barnes et al. <ref type="bibr" target="#b2">[3]</ref>, to approximate the nearest-neighbor fields of target patches with our distance metric as follows:</p><formula xml:id="formula_8">E i (T, S) = q∈T min p∈S (αD (U i,p , U i,q ) + βD (L i,p , L i,q )),<label>(3)</label></formula><p>where i is the current level, p and q are pixel locations of target region T and source region S respectively, U i,p and L i,p denote a patch of pyramid U and L at level i at position p respectively, D is the sum of square distances (SSD) between the CIELAB <ref type="bibr" target="#b8">[9]</ref> colors of two patches, and finally α and β determine the ratio of low-frequency base scale U and high-frequency detailed scale L subject to α + β = 1. <ref type="figure" target="#fig_2">Figure 2</ref>(d), image gradients ∇ x G and ∇ y G can detect only certain structural changes along the horizontal and the vertical direction since they are directional operators (Section 3.1). Unlike the gradient-based approach, we suggest using an isotropic edge operator of the Laplacian, which has the important advantage of being invariant to rotation <ref type="bibr" target="#b17">[18]</ref>. The Laplacian responds equally to structure changes over edges in any direction in scales, detecting detailed structure more robustly. This isotropic characteristics of the Laplacians also avoid having to use multiple operators for the gradients to calculate the robust correspondence of local structures, allowing for computational efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rotation Invariance. As shown in</head><p>Combined Vote. We update target patches of an upsampled Gaussian and a Laplacian image by blending nearestneighbor source patches to maximize the similarity of target patches and source patches after searching correspondences. To accelerate the convergence, we perform weighted blending of scales. Patches of close color distances and patches close to the completion boundary are highly weighted. More details are provided in Section 4.</p><p>Laplacian Structure Reconstruction. Once the convergence of EM optimization is finished at level i, we are ready to propagate the current completion of L i and U i to the finer level i − 1. Consequently these completions at level i can be used as the initial completion of level i − 1. As shown in <ref type="figure" target="#fig_3">Figure 3</ref> and Algorithm 1, the finer scales of the completed Gaussians G i at level i can be obtained by summing the upsampled Gaussians U i and Laplacians L i at for iteration j = 0 to m do 5:</p><formula xml:id="formula_9">N i ← SEARCH(U i, Li, Ui, Li) 6: {U i, Li} ← VOTE(U i, Li, Ui, Li, N i) 7:</formula><p>end for 8:</p><formula xml:id="formula_10">Gi ← U i + Li 9:</formula><p>if i &gt; 0 then 10:</p><formula xml:id="formula_11">U i−1 ← UPSAMPLE(Gi) 11: Li−1 ← LAPLACIANRECONSTRUCTION(N i, Li−1) 12:</formula><p>end if 13: end for level i using Equation <ref type="bibr" target="#b1">(2)</ref>. The reconstructed Gaussians G i is then upsampled to completed Gaussians U i−1 in consequence. However, the finer scales of the Laplacians L i−1 at level i−1 cannot be reconstructed by this manner. Since the Laplacian scale L i−1 is supposed to hold high-frequency details, we fill in the target region of the Laplacian scales L i−1 with information of the source regions at level i − 1 by utilizing the NNF correspondence of the search patches N i obtained at level i. In this way, we can complete the base and the detailed structures in these two image pyramid from the coarse to the finest level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Implementation Detail</head><p>Vote. For the color voting stage, we inherit one from Wexler et al. <ref type="bibr" target="#b28">[29]</ref>. Here we briefly describe our voting implementation to help readers understand the entire workflow. We first compute the similarity of a target patch at pixel q and its corresponding source patch at pixel p at level l as Ψ(p, q, l) = e − D(p,q,l) 2σ 2 , where σ determines the sensitivity of detecting similarity. In addition to similarity Ψ, we calculate confidence weights Λ(q) at target pixel q that avoids boundary errors by assigning a higher confidence value to target points when they are closer to the completion boundary. This voting process assumes that the image inside the target region should be located outside the target region in the image. We combine these two metrics of similarity and confidence as a weight w q = Ψ(p, q, l)Λ(q) at target pixel q. For every target pixel q, we compute a weighted average c q of the overlapping colors ofq ∈ Q from its NNFs Nq using weight wq:</p><formula xml:id="formula_12">c q = q∈Q wqNq(q −q) q∈Q wq ,<label>(4)</label></formula><p>where Q indicates the overlapping patches over the target pixel q.   <ref type="figure" target="#fig_5">Figure 4</ref> (unit: second).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>We implemented our Laplacian image synthesis in C++ on a machine with a 3.4GHz Intel i7-3770 CPU. Our unoptimized implementation runs in a genuinely single-threaded CPU-based manner. We compare our method with the current state-of-the-art inpainting methods, including other Laplacian-based inpainting approaches. We also evaluate the influence of the parameters, such as the patch size and β in Equation <ref type="formula" target="#formula_8">(3)</ref>, in addition to the upsampled/naïve Gaussian pyramid structure in searching correspondence. <ref type="figure" target="#fig_5">Figure 4</ref> compares our method to the state-of-the-art methods, Wexler et al. <ref type="bibr" target="#b28">[29]</ref> and Darabi et al. <ref type="bibr" target="#b10">[11]</ref>. Our inpainting method synthesizes coherent base structures more robustly than other methods. In particular, the third-row results clearly show that our Laplacian patch-based method outperforms the gradient-based approach in terms of structure and detail. Our method effectively reconstructs the base structure of low spatial frequencies, e.g. the textures of rices and water in <ref type="figure" target="#fig_5">Figure 4</ref>, as our method leverages the informa- tion of the multiple frequency through the Laplacian pyramid. <ref type="table">Table 1</ref> presents the performance of the three methods in computing results in <ref type="figure" target="#fig_5">Figure 4</ref>. We used our C++ implementation for Wexler et al. and the original code for Darabi et al.. Our method is implemented in C++. Wexler took 107.33 seconds per image in average, and Darabi took 408.83 seconds per image in average, while our method took 111.62 seconds per image in average. Our method is 3.66 times faster than the gradient-based method <ref type="bibr" target="#b10">[11]</ref>. In detail, the step for Poisson reconstruction in Darabi took aver. 34.26 seconds per image, whereas our reconstruction step of the Laplacian pyramid took only aver. 0.02 seconds, revealing the computational efficiency of our method without sacrificing structural coherence in image synthesis. <ref type="figure" target="#fig_6">Figure 5</ref> shows the inpainted images of previous Laplacian-based approaches. While Padmavathi and Soman <ref type="bibr" target="#b19">[20]</ref> (b) and Drori et al. <ref type="bibr" target="#b11">[12]</ref> (c) utilize the Laplacian pyramid, they inherit the limitation of the heuristic search approach of Criminisi et al. In contrast, our method preserves global coherence (d) without suffering from the typical seam artifacts due to collision of different local propagation. See supplemental material for more results.</p><p>Varying Parameters. <ref type="figure">Figure 6</ref> shows the consistency of our method under varying patch size. For this bungee example, the size of a patch is critical to detect and propagate a roof structure. The naïve Gaussian method with large patches misses to propagate the low-level edge struc-5-by-5 7-by-7 9-by-9 <ref type="figure">Figure 6</ref>. Bungee results of a Gaussian pyramid (d), (e) and (f) and a upscaled Gaussian pyramid (a), (b) and (c). As the patch size increases, the naïve Gaussian method fails to propagate lowlevel edge information. However, the upscaled Gaussian method maintain low-level structure as (b) shows.</p><formula xml:id="formula_13">(a) (b) (c) (d) (e) (f)</formula><p>(a) (b) <ref type="figure">Figure 7</ref>. The completed results with/without the Laplacian term. Our method with the non-zero Laplacian term preserves high frequency structures as shown in (b). However, without the Laplacian term, our method fails to keep high details in a region directed by blue arrows in (a). ture <ref type="figure">(Figures 6(a), (b)</ref>, and (c)). Thanks to the nature of the upsampled Gaussian pyramid, <ref type="figure">Figures 6(d)</ref>, (e) and (f) implies that our method is able to consistently reconstructs low-edge structures with the diverse patch sizes. We investigated the influence of the parameter β in Equation <ref type="bibr" target="#b2">(3)</ref>. See <ref type="figure">Figure 7</ref>. When β is zero, only the upsampled Gaussian term remains in Equation <ref type="formula" target="#formula_8">(3)</ref> and it results in over-smoothed results for high frequency textures as shown in (a). We found that β in the range between 0.1 and 0.5 produces plausible results.</p><p>Upsampled Gaussian vs. Gaussian. As shown in <ref type="figure" target="#fig_3">Figure 3</ref>, the summation of a Laplacian L i and a upsampled Gaussian layer U i in a Laplacian pyramid results in a Gaussian layer G i , which is sharper than the upsampled  Gaussian U i . When we compute the correspondence of the base and the edge structure, we have a domain option to use either U i and G i for searching the base structure. We compare them to verify the improvement on the global coherence. <ref type="figure" target="#fig_8">Figure 9</ref> shows the results of this comparison. The Gaussian-domain search fails to capture edge structure in regions directed by blue arrows in (b) and (e) because of small patch size. Conversely, as shown in (c) and (f) our upsampled Gaussian-domain search successfully reconstructs global structures even using the same patch size. It demonstrates that adopting the upsampled Gaussian pyramid enables us to better preserve the low-level edge structure than using the naïve Gaussian pyramid does.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>We have presented an edge-aware patch-based image synthesis method based on the Laplacian pyramid. While the proposed method overcomes the shortcomings of the gradient-based synthesis such as directionality and heavy computational burden, the proposed method takes the advantages of the Laplacian pyramid properties such as aggregated correspondence and isotropic feature detection in order to improve searching correspondence with enhanced awareness of edge structures. To validate this proposed method, we demonstrate the effectiveness of this Laplacian-based approach over the state-of-the-art techniques with variety of experimental results.</p><p>Since our method stems from the single-layer patch synthesis approach <ref type="bibr" target="#b27">[28]</ref>, our approach is incapable of identifing foreground and background structure in the synthesized image. Compared to Photoshop's contents-aware fill, our results preserve global structure as coherent as possible shown in <ref type="figure" target="#fig_7">Figure 8</ref>(d). Yet, our method could often suffer from patch incoherence in the mixed situation of the foreground and background objects. Recently, Kalantari et al. <ref type="bibr" target="#b14">[15]</ref> attempted to solve this problem by masking incoherent parts of patches, as shown in <ref type="figure" target="#fig_7">Figure 8</ref>(c).</p><p>Our method is based on a Laplacian pyramid. Thus, our method inevitably inherits natural drawbacks of a Laplacian pyramid. One of the drawbacks is that a Laplacian pyramid is not scalable compared to gradients. It makes our search space restricted into two degrees of freedom: rotations and translations without scales.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>(a)-(c) Comparison of the Gaussian function hσ, one of gradients ∇hσ and Laplacian ∇ 2 hσ. (d)-(f) two different Gaussians with σ1 and σ2 and a difference of the Gaussians.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figures 1(d)-(f). When the image scale of level (l + 1) reduces in a half scale of level l in the Gaussian pyramid, the DoG can approximate the LoG with high accuracy.Figures 1(c)and 1(f) compare the similarity of the LoG and the DoG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Comparison of correspondence search on the Gaussian, the gradients, and the Laplacian pyramid. (a) shows a Gaussian and a Laplacian pyramid of a circular function. (b) indicates 1D profiles of each level. (c), (d) and (e) show patch searches on level 2: the upsampled Gaussian U , the Laplacian L, gradients ∇G and the traditional Gaussian G, respectively. The top row of (c), (d), and (e) presents the 3D visualization of image structures. The middle row offers close-up images in the level. The bottom row visualizes an example of the source patch distances to the red target patch (4×4) over the rounded edge. Contrary to (d) and (e), our NNF search (c) compares the patch distances in U and L simultaneously, where the aggregated correspondences (indicated by red arrows) of both low-frequency base and high-frequency detail structures spread smoothly, giving assistance to random correspondence searches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Overview of our implementation of Laplacian patchbased image synthesis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 1</head><label>1</label><figDesc>Laplacian-based image completion Input: image I and mask image M Output: result image G0 1: G, U, L ← CONSTRUCTPYRAMID(I) 2: initialize U , L 3: for scale i = n − 1 to 0 do 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>(a) Input images, where red region is to be completed, (b) Wexler et al.<ref type="bibr" target="#b28">[29]</ref>, (c) Darabi et al.<ref type="bibr" target="#b10">[11]</ref>, and (d) our method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Comparison with other Laplacian-based methods. Both Padmavathi and Soman (b) and Drori et al. (c) contain seam artifacts due to collision of different local propagation while our method preserves global coherence in (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Comparison with Photoshop's contents-aware fill (b) andKalantari et al. (c). Contents-aware fill often suffers from imperfect stitching, while our method maintains global coherence. However, our method inherits the limitation of single-layer patch-based synthesis, shown in the second row, while Kalantari's multi-layer approach outperforms ours with foreground and background patches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>We compare the Gaussian-domain search (b) and (e) and our upsampled Gaussian-domain search (c) and (f). We set parameters the same for both methods and the patch size is 9 × 9 for (b) and (c) and 5 × 5 for (e) and (f). Under the same patch size, (c) and (f) captures global structures, while (b) and (e) misses the image structure.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Min H. Kim gratefully acknowledges Korea NRF grants (2013R1A1A1010165 and 2013M3A6A6073718) and additional support by Samsung Electronics (G01140381) and an ICT R&amp;D program of MSIP/IITP (10041313) in addition to Sung-Hyun Choi (Samsung) for helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pyramid methods in image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Bergen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Burt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Ogden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RCA Engineer</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="33" to="41" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Filling-in by joint interpolation of vector fields and gray levels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ballester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bertalmio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Caselles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Verdera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing (TIP)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1200" to="1211" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Goldman. PatchMatch: A randomized correspondence algorithm for structural image editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="24" to="25" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The generalized Patchmatch correspondence algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Comput. Vision (ECCV)</title>
		<meeting>European Conf. Comput. Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="29" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multidimensional binary search trees used for associative searching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Bentley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="509" to="517" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bertalmio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Caselles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ballester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM. SIGGRAPH</title>
		<meeting>ACM. SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="417" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE. Conf. Comput. Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE. Conf. Comput. Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1809" to="1824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exemplar-based inpainting: Technical review and new heuristics for better geometric reconstructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Buyssens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Daisy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tschumperlé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Lézoray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing (TIP)</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">CIE Pub. 15.2, Commission Internationale de l&apos;Eclairage (CIE)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Colorimetry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<pubPlace>Vienna</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Object removal by eexemplar-based inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE. Conf. Comput. Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE. Conf. Comput. Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="721" to="728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Image melding: Combining inconsistent images using patch-based synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Darabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fragment-based image completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Drori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yeshurun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="303" to="312" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Image completion approaches using the statistics of similar patches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2423" to="2435" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Image completion using planar structure guidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="129" to="130" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving patch-based synthesis by learning patch masks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Kalantari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Darabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Photography (ICCP)</title>
		<meeting>Int. Conf. Comput. Photography (ICCP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Image completion using global optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE. Conf. Comput. Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE. Conf. Comput. Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="442" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning how to inpaint from global image statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zomet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vision (ICCV)</title>
		<meeting>Int. Conf. Comput. Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="305" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Theory of edge detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hildreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. R. Soc. Lond</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="page" from="187" to="217" />
			<date type="published" when="1167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hierarchical super-resolution-based inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">L</forename><surname>Meur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ebdelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guillemot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing (TIP)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3779" to="3790" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Laplacian pyramid based hierarchical image inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Padmavathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Soman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Image and Video Processing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="22" />
			<date type="published" when="2014" />
			<publisher>AIVP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Local laplacian filters: Edge-aware image processing with a laplacian pyramid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Hasinoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Nonlinear total variation based noise removal algorithms. Phys. D</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fatemi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="259" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mathematical models for local nontexture inpaintings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1019" to="1043" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Image completion with structure propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="861" to="868" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Estimating the gradient in the Perona-Malik equation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Voci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Eiho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sugimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sekibuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. IEEE. Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="39" to="65" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Coherence-enhancing diffusion filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision (IJCV)</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="111" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Space-time video completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wexler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE. Conf. Comput. Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE. Conf. Comput. Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Space-time completion of video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wexler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="463" to="476" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Image inpainting by patch propagation using patch sparsity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing (TIP)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1153" to="1165" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Data structures and algorithms for nearest neighbor search in general metric spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Yianilos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM-SIAM Symposium on Discrete Algorithms (SODA)</title>
		<meeting>ACM-SIAM Symposium on Discrete Algorithms (SODA)</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="311" to="321" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
