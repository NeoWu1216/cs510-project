<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pairwise Linear Regression Classification for Image Set Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingxiang</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Macau Avenida da Universidade</orgName>
								<address>
									<settlement>Taipa, Macau</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yicong</forename><surname>Zhou</surname></persName>
							<email>yicongzhou@umac.mo</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Macau Avenida da Universidade</orgName>
								<address>
									<settlement>Taipa, Macau</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rushi</forename><surname>Lan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Macau Avenida da Universidade</orgName>
								<address>
									<settlement>Taipa, Macau</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pairwise Linear Regression Classification for Image Set Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper proposes the pairwise linear regression classification (PLRC) for image set retrieval. In PLRC, we first define a new concept of the unrelated subspace and introduce two strategies to constitute the unrelated subspace. In order to increase the information of maximizing the query set and the unrelated image set, we introduce a combination metric for two new classifiers based on two constitution strategies of the unrelated subspace. Extensive experiments on six well-known databases prove that the performance of PLRC is better than that of DLRC and several state-of-theart classifiers for different vision recognition tasks: clusterbased face recognition, video-based face recognition, object recognition and action recognition. * Corresponding author.</p><p>to always obtain videos with a proper length and sufficient detectable images. Therefore, the limited-sample-query-set based classification becomes significative.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In pattern recognition and computer vision fields, images classification tasks (e.g., face recognition, object recognition and action recognition) attract a lot of researchers' attention. Good performance is known to be highly reply on classifiers. A number of classifiers were proposed, such as the nearest neighbor (NN) <ref type="bibr" target="#b3">[4]</ref>, SVM classifier <ref type="bibr" target="#b14">[15]</ref>, sparse representation-based classifications (SRC) <ref type="bibr" target="#b19">[20]</ref> and linear regression classification (LRC) <ref type="bibr" target="#b12">[13]</ref>. These classifiers use a single test sample for classification. Their classification performance, however, is generally dependent on the base or representation of individual test samples. Recently, researchers paid more attention to the image-set-based classification that is a generalization of video-based classification. They both use multiple test samples. In <ref type="bibr" target="#b7">[8]</ref>, the imageset based face recognition is considered as the same category as video-based face recognition. Several image set-based methods use only benchmarks of video databases for their evaluation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21]</ref>. However, the video-based classification is not suitable for some applications. For example, the real-time recognition systems may have difficulty For similar classification tasks, dual linear regression classification (DLRC) <ref type="bibr" target="#b2">[3]</ref> was proposed as a non-parametric approach. It borrows the idea of LRC <ref type="bibr" target="#b12">[13]</ref> and extends LRC from the single-query-sample based method to the imageset-based method. DLRC has a demonstrated better performance than a few well-known methods. However, DLRC considers only the related class-subspace for classification. That is to say, it pays attention only to minimizing the distance between the query set and the related train set.</p><p>In the paper, we proposed the pairwise linear regression classification (PLRC) for image set retrieval. As an improved version of DLRC, PLRC introduces the new unrelated subspace to maximize the distance between the query set and the unrelated images set, and utilizes a new combined metric that integrates a related metric and a new unrelated metric for classification. The effectiveness of the proposed PLRC is assessed on six popular databases. They include LFW face database <ref type="bibr" target="#b24">[25]</ref>, AR face database <ref type="bibr" target="#b11">[12]</ref> for cluster-based face recognition, Honda/UCSD database <ref type="bibr" target="#b10">[11]</ref>, CMU Mobo database <ref type="bibr" target="#b5">[6]</ref> for video-based face recognition, the Caltech101 object database <ref type="bibr" target="#b4">[5]</ref> for object recognition, UCF50 action database <ref type="bibr" target="#b13">[14]</ref> for action recognition.</p><p>The main contributions of the paper are as follows:</p><p>• We propose the unrelated subspace concept to improve the traditional of DLRC method.</p><p>• Using this concept, we introduce two strategies to constitute the unrelated subspace. The optimization problem in <ref type="bibr" target="#b17">(18)</ref> of the first strategy is based on the imageset, which is different from the previous optimization problem based on the single test sample in SRC <ref type="bibr" target="#b19">[20]</ref> and CRC <ref type="bibr" target="#b23">[24]</ref>.</p><p>• We propose the new unrelated metric, related metric and the combination metric for classification.</p><p>• Based on new metrics and two different methods of constituting the unrelated subspace, we further propose two classifiers called PLRC-I and PLRC-II for image recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dual Linear Recognition Classification</head><p>This section briefly reviews the dual linear recognition classification (DLRC) algorithm. Given the training imageset of the c th class as:</p><formula xml:id="formula_0">X c = [x c 1 x c 2 · · · x c Nc ] ∈ R q×Nc ,<label>(1)</label></formula><p>and the test image-set as:</p><formula xml:id="formula_1">Y = [y 1 y 2 · · · y n ] ∈ R q×n .<label>(2)</label></formula><p>DLRC tries to find the joint coefficients for restructuring the sample from two image-sets. First, the two image-set will be disposed as:</p><formula xml:id="formula_2">X c = [x c 1x c 2 · · ·x c Nc ] ∈ R q×Nc−1 ,<label>(3)</label></formula><formula xml:id="formula_3">andẐ = [ẑ 1ẑ2 · · ·ẑ n ] ∈ R q×n−1 ,<label>(4)</label></formula><formula xml:id="formula_4">wherex c i = x c i − x c Nc , i = 1, 2, · · · , N c − 1,ẑ i = y i − y n , i = 1, 2, · · · , n − 1.</formula><p>In order to obtain the joint coefficient vector of the two image set, the joint image set S c and test vector s c can be constituted as:</p><formula xml:id="formula_5">S c = [X c −Ẑ] ∈ R q×(Nc+n−2) ,<label>(5)</label></formula><p>and</p><formula xml:id="formula_6">s c = y n − x c Nc .<label>(6)</label></formula><p>Suppose that β c ∈ R (Nc+n−2)×1 is the joint coefficient vector ofX c andẐ, and can be calculated by solving the following equation:</p><formula xml:id="formula_7">s c = S c β c .<label>(7)</label></formula><p>Namely, β c ∈ R (Nc+n−2)×1 can be solved as:</p><formula xml:id="formula_8">β c = (S cT S c ) −1 S cT s c .<label>(8)</label></formula><p>According to DLRC, the two reconstructed images r 1 and r 2 from subspacesX c andẐ can be described as:</p><formula xml:id="formula_9">r 1 =X c [β c 1 · · · β c Nc−1 ] T + x c Nc , r 2 =Ẑ[β c Nc · · · β c Nc+n−2 ] T + y n .<label>(9)</label></formula><p>Therefore, the distance measure between the test image set and related training set can be calculated as:</p><formula xml:id="formula_10">d c r = r 1 − r 2 = s c − S c β c .<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Pairwise Linear Regression Classification</head><p>This section proposes pairwise linear regression classification (PLRC). Its flowchart is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The main contents of this section are as follows. First, two strategies of constituting the unrelated subspace are described in Subsection 3.1. Then, the related metric and unrelated metrics are computed in Subsections 3.2 and Subsection 3.3, respectively. Next, the final distance metric for classification, called combination metric, is described in Subsection 3.4. Last, Subsection 3.5 describes the relationship of the DLRC and the proposed PLRC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Construction of the Unrelated Subspace</head><p>Before constituting the unrelated subspace, the definition of unrelated subspace is described in the Definition 1. According to Definition 1, we need to select c th samples from the other classes except the c th class to constitute the unrelated subspace. In this subsection, two strategies are used to constitute the unrelated subspace, which are described as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Strategy 1</head><p>Obtain the training image-set X c of the c th class by (1) and the test image-set Y by <ref type="bibr" target="#b1">(2)</ref>. Compute the mean sample of Y as</p><formula xml:id="formula_11">y mean = 1 n n i=1 y i .<label>(11)</label></formula><p>Increase the mean sample as the last element of the original image-set Y and the test image-set will be disposed aŝ</p><formula xml:id="formula_12">Y = [ŷ 1ŷ2 · · ·ŷ n ] ∈ R q×n ,<label>(12)</label></formula><p>whereŷ i = y i − y mean , i = 1, 2, · · · , n. Suppose that we have M classes of subjects, Collect the entire class-specific set X c defined in (1) to form the complete data model as</p><formula xml:id="formula_13">X = [X 1 X 2 · · · X M ] ∈ R q× M c=1 Nc .<label>(13)</label></formula><p>Compute the mean sample of X as Step 2, the joint coefficient of the test space and related subspace is obtained. Next the two spaces will restructure two images with the coefficient. The construction procedure of test space and unrelated subspace is similar. In Step 3, the related metric and the unrelated metric are computed. It is easy to know that the smaller related metric and the larger unrelated metric are conducive to the classification. Next, the combined metric with the related metric and unrelated metric is obtained for classification.</p><formula xml:id="formula_14">x mean = 1 M N c M c=1 Nc i=1 x c i .<label>(14)</label></formula><p>Increase the mean sample as the last element of the original image-set X. The image-set X will be disposed aŝ</p><formula xml:id="formula_15">X = [x 1 1x 1 2 · · ·x M N M ] ∈ R q×L ,<label>(15)</label></formula><formula xml:id="formula_16">where L = M c=1 N c ,x c i = x c i − x c mean , i = 1, 2, · · ·</formula><p>, N c , c = 1, 2, · · · , M . In order to obtain the joint coefficient vector of the two image sets, the joint image set E and test vector e can be constituted as</p><formula xml:id="formula_17">E = [X −Ŷ ] ∈ R q×(L+n)<label>(16)</label></formula><p>and e = y mean − x mean .</p><p>Suppose that α ∈ R (L+n)×1 is the joint coefficient vector ofX andŶ , which can be calculated by solving the optimization problem as:</p><formula xml:id="formula_19">α = arg min α e − Eα 2 + λ Γα 2 ,<label>(18)</label></formula><p>where λ is a parameter, Γ is the Tikhonov matrix, which can be computed as:</p><formula xml:id="formula_20">Γ =     E 1 − e 0 0 0 0 E 2 − e 0 0 0 0 · · · 0 0 0 0 E L+n − e     . (19)</formula><p>The weighted distance between e and E can be computed as:</p><formula xml:id="formula_21">d i = E iαi − e , i = 1, 2, · · · , (L + n).<label>(20)</label></formula><p>Because the last n elements of E is the test set, and the N c elements of the c th class of E are the related set, the (n + N c ) samples will be removed from E asÊ ∈ R q×(L−Nc) .</p><formula xml:id="formula_22">Similar, suppose D = [d 1 d 2 · · · d L+n ] ∈ R 1×(L+n) , re- move n + N c distances from D asD ∈ R 1×(L−Nc)</formula><p>. Then select N c samples fromÊ, which is corresponding to the N c minimum distances ofD, to constitute a subspace. The subspace will be treated as the unrelated class subspace of the c th class and be described as:</p><formula xml:id="formula_23">U c = [u c 1 u c 2 · · · u c Nc ] ∈ R q×Nc .<label>(21)</label></formula><p>where u i =Ê j , i = 1, 2...N c , j ∈ Ω and Ω denotes the label set of the N c distances inD. The classifier based on this strategy will be called pairwise linear regression-I (PLRC-I). Noted: the optimization problem in <ref type="formula" target="#formula_0">(18)</ref> is based on the image-set, which is different from the previous optimization problem based on the single test sample in SRC <ref type="bibr" target="#b19">[20]</ref> and CRC <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Strategy 2</head><p>The Euclid distance between the y mean and a train sample X i can be computed as:</p><formula xml:id="formula_24">d i = X i − y mean , i = 1, 2, · · · , L.<label>(22)</label></formula><p>where the X i denotes the i th elements of the entire data model X.</p><formula xml:id="formula_25">Suppose D = [d 1 d 2 · · · d L ] ∈ R 1×L</formula><p>, remove the elements corresponding to the c th class from D as D ∈ R 1×(L−Nc) . Then select N c samples from X, which is corresponding to the label of N c chosen distances fromD, to constitute a subspace. The subspace will be treated as the unrelated class subspace of the c th class and be described as</p><formula xml:id="formula_26">U c = [u c 1 u c 2 · · · u c Nc ] ∈ R q×Nc .<label>(23)</label></formula><p>where u i =X j , i = 1, 2...N c , j ∈ Ω and Ω denotes the label set of the N c distances.The classifier based on this strategy will be called pairwise linear regression-II (PLRC-II).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Related Distance Metric</head><p>Obtain the training image-set X c of the c th class by (1) and the test image-set Y by <ref type="bibr" target="#b1">(2)</ref>. Compute the mean sample of X c as:</p><formula xml:id="formula_27">x c mean = 1 N c Nc i=1 x c i<label>(24)</label></formula><p>The image set X will be disposed as:</p><formula xml:id="formula_28">X c = [x c 1x c 2 · · ·x c Nc ] ∈ R q×Nc ,<label>(25)</label></formula><formula xml:id="formula_29">wherex c i = x c i − x c mean , i = 1, 2, · · · , N c .</formula><p>The y mean can be computed by <ref type="bibr" target="#b10">(11)</ref>. The image set Y can be disposed by <ref type="bibr" target="#b11">(12)</ref> asŶ . In order to obtain the joint coefficient vector of the two image set, the joint image set and test vector can be constituted as</p><formula xml:id="formula_30">S c r = [X c −Ŷ ] ∈ R q×(Nc+n)<label>(26)</label></formula><p>and</p><formula xml:id="formula_31">s c r = y mean − x c mean .<label>(27)</label></formula><p>Suppose that β c ∈ R (Nc+n)×1 is the joint coefficient vector ofX c andŶ , which can be calculated by solving the following equation:</p><formula xml:id="formula_32">s c r = S c r β c .<label>(28)</label></formula><p>and β c ∈ R (Nc+n)×1 can be solved as:</p><formula xml:id="formula_33">β c = (S c r T S c r ) −1 S c r T s c r .<label>(29)</label></formula><p>Similar to DLRC, the two reconstructed images r 1 and r 2 from subspacesX c and Y can be described as:</p><formula xml:id="formula_34">r 1 =X c [β c 1 · · · β c Nc ] T + x c mean<label>(30)</label></formula><p>and</p><formula xml:id="formula_35">r 2 =Ŷ [β c Nc+1 · · · β c Nc+n ] T + y mean .<label>(31)</label></formula><p>Use the r 1 and r 2 , the distance measure between the test image set and related training set can be calculated as follows:</p><formula xml:id="formula_36">d c r = r 1 − r 2 = s c r − S c r β c .<label>(32)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Unrelated Distance Metric</head><p>The unrelated image set U c of the c th class can be obtained by <ref type="bibr" target="#b20">(21)</ref> or <ref type="bibr" target="#b22">(23)</ref>. Compute the mean sample of U c as:</p><formula xml:id="formula_37">u c mean = 1 N c Nc i=1 u c i .<label>(33)</label></formula><p>Increase the mean sample as the last element of the original image-sets U , and it will be disposed as:</p><formula xml:id="formula_38">U c = [û c 1û c 2 · · ·û c Nc ] ∈ R q×Nc ,<label>(34)</label></formula><p>whereû c i = u c i − u c mean , i = 1, 2, · · · , N c . In order to obtain the joint coefficient vector of the two image set U c and Y , the joint image set and test vector can be constituted as:</p><formula xml:id="formula_39">S c u = [Û c −Ŷ ] ∈ R q×(Nc+n) ,<label>(35)</label></formula><p>and</p><formula xml:id="formula_40">s c u = y mean − u c mean .<label>(36)</label></formula><p>Suppose that γ ∈ R (Nc+n)×1 is the joint coefficient vector ofÛ c andŶ , which can be calculated by solving the following equation:</p><formula xml:id="formula_41">s c u = S c u γ c ,<label>(37)</label></formula><p>where γ ∈ R (Nc+n)×1 can be calculated by the least square error as:</p><formula xml:id="formula_42">γ = (S c u T S c u ) −1 S c u T s c u .<label>(38)</label></formula><p>Similar to DLRC, the two reconstructed images u 1 and u 2 from subspacesÛ C andŶ can be described as:</p><formula xml:id="formula_43">u 1 =Û c [γ c 1 · · · γ c Nc ] T + u c mean<label>(39)</label></formula><p>and</p><formula xml:id="formula_44">u 2 =Ŷ [γ c Nc+1 · · · γ c Nc+n ] T + y mean .<label>(40)</label></formula><p>The unrelated distance metric between the test image set and unrelated training set are calculated as:</p><formula xml:id="formula_45">d c u = u 1 − u 2 = s c u − S c u γ c .<label>(41)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Combined Distance Metric</head><p>After obtaining the related metric and the unrelated metric, we need a method to combine these two metrics as a better metric. It is easy to know that the minimum distance of related metric represents the best match while the maximum distance of unrelated metric represents the best match. Therefore, we combine the related metric and the unrelated metric as the combination metric as:</p><formula xml:id="formula_46">d c p = d c r /d c u<label>(42)</label></formula><p>PLRC selects the class with the minimum distance as:</p><formula xml:id="formula_47">min c * d c p , c = 1, 2, · · · , M.<label>(43)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Pairwise Linear Regression Classification (PLRC)</head><p>Inputs The entire training samples x c i , c = 1, 2, · · · , M , i = 1, 2, · · · , Nc and a test image vector x ∈ R q×1 .</p><p>Output Index of x.</p><p>1. Two strategies are used to constitute the unrelated subspace.</p><p>Their main difference is the distance metric between test set and the train set. They are described as: Strategy 1: Solve the optimization problem as:</p><formula xml:id="formula_48">α = arg min α e − Eα 2 + λ Γα 2 .</formula><p>Next, compute the sparse weighted distance as: di = Eiαi − e , i = 1, 2, · · · , (L + n).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy 2:</head><p>Compute the Eculid distance as: di = Xi − ymean , i = 1, 2, · · · , L.</p><p>Using the distances, we select Nc nearest samples from the other M − 1 classes except the c th class to constitute the unrelated subspace as:</p><formula xml:id="formula_49">Uc = [u c 1 u c 2 · · · u c Nc ] ∈ R q×Nc .</formula><p>2. Use the related subspace and the test set to compute the related distance metric as:</p><formula xml:id="formula_50">d c r = r1 − r2 = x c r − S c r β c .</formula><p>3. Use the unrelated subspace and the test set to compute the unrelated distance metric as: </p><formula xml:id="formula_51">d c u = u1 − u2 = s c u − S c u γ c .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">PLRC vs DLRC</head><p>In this subsection, we compare the similarity and difference between PLRC and DLRC as follows.</p><p>Similarity: PLRC and DLRC both follow the idea of restructuring the virtual sample of two image set for classification, and use the metric of the test set and the related train set.</p><p>Difference: For restructuring the virtual sample, DLR-C uses the last sample of the image set plus the variations while PLRC utilizes the mean sample of the image set plus the variations. In addition, PLRC not only includes the information that minimizes the distance between the test set and related train set, but also pays attention to the information that maximizes the distance between the test set and the unrelated train set. However, DLRC considers only the information that minimizes the distance between the test set and related train set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head><p>This section provides extensive experimental results to testify the performance of two proposed classifiers: PLRC-I and PLRC-II. These experiments are carried out using the following vision recognition tasks and databases: image-based face recognition on the LFW face database <ref type="bibr" target="#b24">[25]</ref> and AR face database <ref type="bibr" target="#b11">[12]</ref>, video-based face recognition on Hona/UCSD face database <ref type="bibr" target="#b10">[11]</ref> and CMU Mobo face database <ref type="bibr" target="#b5">[6]</ref>, action recognition on the UCF50 action databases <ref type="bibr" target="#b13">[14]</ref>, and object recognition on Caltech101 object databases <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Face recognition on image-based databases</head><p>This subsection tests the performance of the proposed PLRC for face recognition in wild on LFW face database and face recognition with occlusion on AR database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Face recognition in wild</head><p>LFW face database were captured in unconstrained environments such that there will be large variations in face images including pose,age, race, facial expression, lighting, occlusions, and background, etc. We use the aligned version of the LFW database, LFW-a database, to study the performance of the proposed classifiers. Note that all the images in LFW-a database are a size of 250 × 250. Following the operations in <ref type="bibr" target="#b2">[3]</ref>, we manually crop images into a size of 90 × 78. An subset of LFW contains 62 persons, each people has more than 20 face images, is used for evaluating the algorithms. Our experimental setting is identical to that in <ref type="bibr" target="#b2">[3]</ref>. That is, 10 images of each subject are selected to form the training set, while the last 10 image are used as the probe images. The proposed classifiers are compared with following methods: sparse approximated nearest points (SANP) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, affine hull based image set distance (ASIHD) <ref type="bibr" target="#b1">[2]</ref>, convex hull based image set distance (CSIHD) <ref type="bibr" target="#b1">[2]</ref>, manifold discriminant analysis (MDA) <ref type="bibr" target="#b15">[16]</ref>, SRC+NN <ref type="bibr" target="#b19">[20]</ref>, LRC+NN <ref type="bibr" target="#b12">[13]</ref>, and DLRC <ref type="bibr" target="#b2">[3]</ref>. All methods use the downscaled images of size of 10 × 10 and 15 × 10 as in <ref type="bibr" target="#b2">[3]</ref>. The classification results of all methods are illustrated in <ref type="table">Table 1</ref>. For the images with size of 10 × 10, the proposed PLRC-II achieves identical performances with the MDA method. Another classifier, PLRC-I, obtains the most satisfactory recognition rate compared with other methods. For images with size of 15 × 10, our proposed PLRC-I and PLRC-II classifiers both obtain the highest recognition rate of 96.77%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Face recognition with occlusion</head><p>In this experiment, we study the performance of the proposed classifiers using the well-known AR database. There are over 4000 face images of 126 subjects (70 men and 56 women) in the database. We use the cropped AR database that includes 2600 face images of 100 individuals. The face images of each individual contain different expressions, lighting conditions, wearing sun glasses and wearing scarf. They were manually cropped into 40 × 40 pixels. For this database, the proposed classifiers are compared with following state-of-the-art approaches: SANP <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, ASIHD <ref type="bibr" target="#b1">[2]</ref>, CSIHD <ref type="bibr" target="#b1">[2]</ref>, LRC+NN <ref type="bibr" target="#b12">[13]</ref>, and DLRC <ref type="bibr" target="#b2">[3]</ref>, respectively. This experiment is run as follows: 5 samples per person are used as Gallery set, and the rest 21 samples are divided into 3 probe sets with the same size. The recognition rates of different classifiers have been presented in Table 2. The experimental results show that the PLRC-II obtains significant improvements compared with SANP, ASI-HD, CSIHD, and LRC+NN methods. The result of DLRC is one percentage higher than that of PLRC-II. The recognition rate of PLRC-I surpasses both of DLRC and PLRC-II more than one percentage. From this experiment, we know that the unrelated subspace based on the sparse optimization is better than that based on the Eculid distance for face recognition with occlusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Face Recognition on Video-based Databases</head><p>This subsection tests the performance of PLRC for face recognition on video-based databases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Honda/UCSD face database</head><p>There are totally 59 video clips of 20 subjects in the Honda/UCSD data <ref type="bibr" target="#b10">[11]</ref>. Each subject has 2 videos at least. 20 videos are named training videos and the rest 39 test videos. We conduct the experiment as the identical setting in <ref type="bibr" target="#b7">[8]</ref>.</p><p>That is, the Viola-Jone cascaded face detector is applied to extract the face images from all frame successively in each video. We carry out the experiment using the first 50 frames in each video for this database. The shared database by <ref type="bibr" target="#b7">[8]</ref> is used. For the video clips that contain less than 50 frames, all frames are selected in the experiment. The following methods are chosen for comparison: DCC <ref type="bibr" target="#b9">[10]</ref>, MMD <ref type="bibr" target="#b17">[18]</ref>, MDA <ref type="bibr" target="#b15">[16]</ref>, AHISD <ref type="bibr" target="#b1">[2]</ref>, CHISD <ref type="bibr" target="#b1">[2]</ref>, MSM <ref type="bibr" target="#b21">[22]</ref>, SANP <ref type="bibr" target="#b7">[8]</ref>, RNP <ref type="bibr" target="#b22">[23]</ref>, and DLRC <ref type="bibr" target="#b2">[3]</ref>. <ref type="table">Table 3</ref> lists all recognition rates of these classifiers on this database. We can find that the recognition rates of PLRC-II, AHISD, RNP, and DLRC are all equal 87.18%, which is much better than that of DC-C and MMD methods. The PLRC-I classifier obtains the highest accuracy 89.74% for this database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">CMU Mobo face database</head><p>The CMU Mobo database <ref type="bibr" target="#b5">[6]</ref> consists the video sequences of 25 subjects that were captured on a treadmill. All except for the last sequence contain different videos collected in the following walking patterns, i.e., holding a ball, fast walking, slow walking, and incline walking. Following the common setting, we use the videos of the first 24 subjects to generate the video-based face databases. In <ref type="bibr" target="#b7">[8]</ref>, the Viola-Jones algorithm is used to obtain the faces from videos. Each image is extracted the local binary pattern (LBP) features. We exploit the public processed LBP histogram features to test different classifiers. The proposed classifiers are compared with following methods, namely DCC <ref type="bibr" target="#b9">[10]</ref>, MMD <ref type="bibr" target="#b17">[18]</ref>, MDA <ref type="bibr" target="#b15">[16]</ref>, AHIS-D <ref type="bibr" target="#b1">[2]</ref>, CHISD <ref type="bibr" target="#b1">[2]</ref>, MSM <ref type="bibr" target="#b21">[22]</ref>, SANP <ref type="bibr" target="#b7">[8]</ref>, RNP <ref type="bibr" target="#b22">[23]</ref>, and DLRC <ref type="bibr" target="#b2">[3]</ref>. To provide fair comparison, this experiment is set identically to <ref type="bibr" target="#b7">[8]</ref>, namely the "10 random splits" strategy is considered. <ref type="table">Table 4</ref> reports the recognition rates of all methods. We can see that the two proposed classifiers achieve similar performance for this database, and they both work better than other comparative algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Object Classification</head><p>In this experiment, we apply a challenging object database, Caltech101 database, to study the performance of the proposed methods. This database includes over 9000 images for 102 classes (like airplanes, elephant, pyramid, and sunflower, etc). For each image category, there are about 31 to 800 images. In the experiment, we select a subject of 102 subjects, and each contains 30 object images. Each image in this database is about a size of 300 × 200, which is transformed to spatial pyramid feature <ref type="bibr" target="#b8">[9]</ref>. The following methods are selected for comparison, namely CR-C+NN <ref type="bibr" target="#b23">[24]</ref>, RH-ISCRC <ref type="bibr" target="#b25">[26]</ref>, KCH-ISCRC <ref type="bibr" target="#b25">[26]</ref>, LRC+NN <ref type="bibr" target="#b12">[13]</ref>, and DLRC <ref type="bibr" target="#b2">[3]</ref>. The experiment here is set as follows:</p><p>• Scheme 1: 5 samples per class are used Gallery set, the rest 25 samples are divided into 5 probe sets. Each set contains 5 samples.</p><p>• Scheme 2: 10 samples per class are used Gallery set, the rest 20 samples are divided into 4 probe sets. Each contains 5 samples.</p><p>The performances of all testing methods are presented in comparable performance on this database using Scheme 1, they lead an improvement of more than two percentages compared with the second best result 70.20 %. For the Scheme 2, the PLRC-II classifier work slightly better than DLRC methods, while PLRC-I outperforms DLRC about 3 percentages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Action Recognition</head><p>This experiment evaluates the proposed method using the action recognition application. The challenging database, UCF50 database <ref type="bibr" target="#b13">[14]</ref>, is selected here. There are totally 6,676 videos for 50 action categories in the UCF50 database collected from YouTube. In the experiment, 5000 videos of 50 categories with 100 videos are used. Our proposed method is compared following algorithms: SAN-P <ref type="bibr" target="#b7">[8]</ref>, RH-ISCRC <ref type="bibr" target="#b25">[26]</ref>, KCH-ISCRC <ref type="bibr" target="#b25">[26]</ref> and DLRC <ref type="bibr" target="#b2">[3]</ref>. To extensively test the performance of all testing methods, our experiments are conducted by following scheme:</p><p>• Scheme: 20 video samples per class are used Gallery set, the resting 80 video samples are divided into 4 probe set, each contains 20 video samples. <ref type="table">Table 6</ref> reports the recognition rates (RR) of all methods. It can be seen that PLRC-I outperforms all other methods more than 3%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Run Time</head><p>Run Time is another important aspect to evaluate an algorithm. This experiment compares the run time of the proposed PLRC classifiers with other methods using the UCF50 action database. All competing classifiers are obtained with a desktop PC with 3.5GHz Intel CPU and 16 GB memory. The comparison results are given in <ref type="table">Table 6</ref>. The result shows that The computational cost of PLRC-I and PLRC-II are both more than that of DLRC and lower than that of SANP. The computational cost of PLRC-II are about 2 times that of DLRC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, a novel framework called pairwise linear regression classification (PLRC) is proposed for image recognition. Compared to DLRC, PLRC increases the unrelated subspace for classification. Based on the different methods of constituting the unrelated subspace, two classifiers are proposed in this paper. In order to prove the performance of two classifiers, a lot of experiments are evaluated on six database for three classification tasks: image-based face recognition, video-based face recognition and object recognition. All experimental results confirm the effectiveness of two proposed classification algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Definition 1 :</head><label>1</label><figDesc>Suppose that there are M classes. There exists a specific test set with N c samples belongs to the c th class. If another set U also contains N c samples from the other M − 1 classes except the c th class, this set U will be called unrelated subspace.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>The flowchart of the proposed PLRC. In Step 1, the related subspace and test space of the c th class are reconstituted by increasing the mean sample as the last element of the original sets. The unrelated subspace is chosen from the entire training space with the specific strategy. In</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>4 .</head><label>4</label><figDesc>Combine the related metric and the unrelated metric as the combined metric as: selects the class with the minimum distance as:min c * d c p , c = 1, 2, · · · , M.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 .</head><label>5</label><figDesc>We can observe that PLRC-I and PLRC-II obtainTable 6. The recognition rate (RR) and run time of several classifiers on UCF50 action database.</figDesc><table>Classifier 
Scheme 1 
Scheme 2 
KCH-ISCRC 
69.81 
76.72 
RH-ISCRC 
65.09 
79.17 
CRC+NN 
60.20 
62.50 
LRC+NN 
41.96 
51.47 
DLRC 
70.20 
80.39 
PLRC-I 
72.75 
83.09 
PLRC-II 
72.35 
80.64 

Table 5. The recognition rate (RR) of several classifiers on the 
Caltech101 object database. 

Classifier 
RR 
Run Time 
SANP 
67.00 
18.96874 
RH-ISCRC 
69.00 
5.68937 
KCH-ISCRC 
65.00 
1.28978 
DLRC 
66.00 
1.30427 
PLRC-I 
72.50 
6.26050 
PLRC-II 
66.00 
2.99981 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Face recognition with image sets using manifold density divergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Arandjelović</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="581" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Face recognition based on image sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cevikalp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2567" to="2573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dual linear regression based classification for face cluster recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2673" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Nearest neighbor pattern classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1967" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="21" to="27" />
		</imprint>
		<respStmt>
			<orgName>TIT</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="70" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The cmu motion of body (mobo) database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sparse approximated nearest points for image set classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Mian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Owens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="121" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Face recognition using sparse approximated nearest points between image sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Mian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Owens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">T-PAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1992" to="2004" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Label consistent k-svd: Learning a discriminative dictionary for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2651" to="2664" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Discriminative learning and recognition of image set classes using canonical correlations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>T-PAMI</publisher>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1005" to="1018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Videobased face recognition using probabilistic appearance manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">313</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Pca versus lda</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Kak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="228" to="233" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Linear regression for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Togneri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bennamoun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">T-PAMI</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2106" to="2112" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Recognizing 50 human action categories of web videos. Machine Vision and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="971" to="981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Recognizing human actions: a local svm approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schüldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="32" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Manifold discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="429" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Covariance discriminative learning: A natural and efficient approach to image set classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2496" to="2503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Manifold-manifold distance with application to face recognition based on image set</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Discriminant analysis on riemannian manifold of gaussian distributions for face recognition with image sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Set based discriminative ranking for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mukunoki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="497" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Face recognition using temporal image sequence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-I</forename><surname>Maeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. Third IEEE International Conference on</title>
		<meeting>Third IEEE International Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="318" to="323" />
		</imprint>
	</monogr>
	<note>Automatic Face and Gesture Recognition</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Face recognition based on regularized nearest points between image sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th IEEE International Conference and Workshops on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note>Automatic Face and Gesture Recognition (FG)</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Sparse representation or collaborative representation: Which helps face recognition? In ICCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="471" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multi-scale patch based collaborative representation for face recognition with margin distribution optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Shiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="822" to="835" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Image set-based collaborative representation for face recognition. Information Forensics and Security</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.-K</forename><surname>Shiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1120" to="1132" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
