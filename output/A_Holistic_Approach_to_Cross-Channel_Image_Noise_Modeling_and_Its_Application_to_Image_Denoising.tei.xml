<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Holistic Approach to Cross-Channel Image Noise Modeling and its Application to Image Denoising</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seonghyeon</forename><surname>Nam</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Yonsei University</orgName>
								<orgName type="institution" key="instit2">Osaka University</orgName>
								<orgName type="institution" key="instit3">Yonsei University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngbae</forename><surname>Hwang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Yonsei University</orgName>
								<orgName type="institution" key="instit2">Osaka University</orgName>
								<orgName type="institution" key="instit3">Yonsei University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuyuki</forename><surname>Keti</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Yonsei University</orgName>
								<orgName type="institution" key="instit2">Osaka University</orgName>
								<orgName type="institution" key="instit3">Yonsei University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matsushita</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Yonsei University</orgName>
								<orgName type="institution" key="instit2">Osaka University</orgName>
								<orgName type="institution" key="instit3">Yonsei University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seon</forename><forename type="middle">Joo</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Yonsei University</orgName>
								<orgName type="institution" key="instit2">Osaka University</orgName>
								<orgName type="institution" key="instit3">Yonsei University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Holistic Approach to Cross-Channel Image Noise Modeling and its Application to Image Denoising</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modelling and analyzing noise in images is a fundamental task in many computer vision systems. Traditionally, noise has been modelled per color channel assuming that the color channels are independent. Although the color channels can be considered as mutually independent in camera RAW images, signals from different color channels get mixed during the imaging process inside the camera due to gamut mapping, tone-mapping, and compression. We show the influence of the in-camera imaging pipeline on noise and propose a new noise model in the 3D RGB space to accounts for the color channel mix-ups. A data-driven approach for determining the parameters of the new noise model is introduced as well as its application to image denoising. The experiments show that our noise model represents the noise in regular JPEG images more accurately compared to the previous models and is advantageous in image denoising.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Noise is one of the most fundamental problems in computer vision and image processing. In computer vision literature, many works mention noise as one of the main sources that explain the error of their systems and emphasize the necessity of establishing robustness against noise. But what really is image noise and how can we explain it?</p><p>Informally, noise explains the uncertainty of the light measurement in an image. A low noise value would indicate that the observed intensity value is highly likely to be the ground truth intensity and vice versa. Since many computer vision algorithms rely on accurate light measurement, it is important to have a noise model that explains the properties of image noise accurately.</p><p>What is interesting is that all of the existing image noise models fall short of explaining what is really happening to noise in the images that most people (both regular consumers and vision researchers) use today -JPEG images * Authors contributed equally to this work. in the sRGB color space. A key assumption used in existing noise models is that the noise is independent between different color channels. While this channel independency is valid for linear vision cameras or RAW images, which are unprocessed sensor-level measurements, the assumption breaks down as the R,G,B values are heavily mixed during the in-camera image processing <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15]</ref>. Furthermore, image compression, typically in JPEG format, significantly affects the noise characteristics; however, the effect of the compression noise has not been explicitly considered in the past <ref type="bibr" target="#b0">1</ref> .</p><p>This work attempts to seek deeper understanding about image noise and to come up with a better explanation about the noise compared to the previous noise models. Previous noise models either only fit to a limited number of cases, or they were only validated with synthetic images created with their own models. Even in the image denoising works, the quantitative performance of denoising is evaluated with synthetic images created with a per channel independent Gaussian model <ref type="bibr" target="#b4">[5]</ref>, which does not describe the noise in real photographs as we will see later in this paper. Therefore, we argue for a new image noise model that better explains the properties of noise in images that most people use today.</p><p>The contributions of this paper are as follows:</p><p>• We provide observations and analysis on the effect of the in-camera imaging process on noise and introduce a new cross-channel noise model. We develop a colordepenent noise model in the 3D RGB space that can simultaneously take into account the correlation between the color channels and the JPEG compression effect.</p><p>• We further propose a data-driven approach for automatically determining the noise in the 3D RGB space from observed color images. Specifically, we use a simple multi-layer perceptron (MLP) to infer the parameters of the noise model. Note that we use the neu-ral network (NN) to compute the noise model, which is fundamentally different from using NNs for image denoising <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b1">2]</ref>.</p><p>• We validate our model and the parameter estimation method using real images instead of synthetic images and show that applying our new noise model can improve the image denoising performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The most common noise model used in computer vision is the channel-independent Gaussian model <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24]</ref> because of its simplicity. However, the Gaussian noise model is found inflexible to describe the actual noise in real images, and therefore, several more sophisticated noise models have been recently proposed. In <ref type="bibr" target="#b5">[6]</ref>, Foi et al. proposed a Poissonian-Gaussian noise model for single-image raw data to consider signal-dependent and signal-independent noise components separately. Granados et al. <ref type="bibr" target="#b7">[8]</ref> presented a noise model that takes into account both temporal and the spatial noise for reconstructing high-dynamic range (HDR) images. Their weighting function produces statistically optimal estimates under the assumption of compound Gaussian noise. Hwang et al. <ref type="bibr" target="#b11">[12]</ref> presented a difference based noise model using the Skellam distribution to represent the distribution of intensity differences. They showed that the difference-based modeling has a more significant linear relationship between the intensity and the noise parameters.</p><p>The methods described above all operate with RAW images or images from a linear vision camera <ref type="bibr" target="#b11">[12]</ref>. While noise modeling of RAW image data is useful for some specific tasks, most of the images used in computer vision go through an in-camera imaging pipeline. In a seminal work by Healey and Kondepudy <ref type="bibr" target="#b9">[10]</ref>, five main sources for image noise in the camera imaging process were identified as photon shot, fixed pattern, dark current, readout, and quantization noise, and they presented a statistical model in which the variance of noise is linearly proportional to the observed intensity.</p><p>In <ref type="bibr" target="#b18">[19]</ref>, Liu et al. presented a more general noise model that fits the in-camera imaging pipeline, which includes processes such as white balancing and camera response functions (gamma correction). They used the in-camera imaging model from <ref type="bibr" target="#b22">[23]</ref> and defined the noise level function (NLF) as the variation of standard deviation of the noise distribution according to image brightness. Using the space of camera response functions <ref type="bibr" target="#b8">[9]</ref>, they used a Bayesian MAP estimation to infer the NLF from a single image. In spite of insufficient information to estimate image noise, their method showed good performance when applied to noise removal <ref type="bibr" target="#b18">[19]</ref> and image deblurring <ref type="bibr" target="#b12">[13]</ref>.</p><p>While the methods described above are effective, each color channel is still treated independently in these works.</p><p>In <ref type="bibr" target="#b14">[15]</ref>, Kim et al. described a new in-camera imaging model that well fits modern cameras by showing the effect of the gamut mapping step, which is a 3D nonlinear mapping (RGB to RGB). Their work intrinsically indicates the limitation of channel-independent noise modeling because of the mixture of color channels due to the gamut mapping and color space transformations. In addition to such mixtures, JPEG compression process <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b17">18]</ref> adds further mixing of color channels. Our goal is to accurately model and determine such cross-channel image noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Noise Model in the 3D RGB Space</head><p>This section analyzes the effects of the in-camera imaging process and JPEG compression on noise and propose a noise model that can accurately represent them. <ref type="figure" target="#fig_0">Figure 1</ref> shows the influence of each procedure in the incamera imaging pipeline on noise. The top row of the figure lists the imaging steps described in <ref type="bibr" target="#b14">[15]</ref>. To verify how the noise characteristics are altered through the procedures, we first took a RAW image with many homogeneous color patches with a Canon EOS-5D Mark III camera. We then simulated the imaging pipeline using the calibrated camera parameters from <ref type="bibr" target="#b14">[15]</ref> and observed the changes of the noise distributions. As shown in the first plots in <ref type="figure" target="#fig_0">Fig. 1</ref> (b) and (c), both the Skellam parameter <ref type="bibr" target="#b11">[12]</ref> and the variance <ref type="bibr" target="#b18">[19]</ref> linearly increase with the intensity value in the RAW image. While this linear relationship is still largely maintained after going through the demosaicing and white balancing/linear color transformations, the linear relationship drastically breaks down with the gamut mapping and tone mapping processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Noise through the In-camera Imaging Process</head><p>We ran another experiment to see how the mix-up of R,G,B channel values (mainly due to 3D gamut mapping) influence the image noise. We took images as shown in <ref type="figure" target="#fig_1">Fig. 2</ref> (a) with a Nikon D800 camera, which records images in three different formats: RAW, uncompressed TIFF, and JPEG. The uncompressed TIFF image allows us to analyze the effect of the whole imaging pipeline without the compression effect. With these different formats of images, we computed the covariance matrices for each pixel from 1,000 temporal images of a static scene, some of which are shown in <ref type="figure" target="#fig_1">Fig. 2</ref> (b-d). They show the magnitude of elements in the covariance matrix; from the variances of R,G,B to the covariance R/G, R/B, and G/B. At the RAW level, the noise in different channels are indeed independent. However, we can observe that the covariance scores significantly increase as the image goes through the imaging pipeline, and reach the point where we cannot simply ignore the cross-channel noise.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RAW image RGB image</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Effect of the JPEG Compression on Noise</head><p>Figures 1 and 2 show that JPEG compression has a significant effect on the noise characteristics. With a typical JPEG compression, an image is compressed by dividing the image region into 8×8 patches and processing those patches separately. Therefore, the level of compression may differ patch by patch, and the influence of the compression to noise would also depend on the patch content. The noise characteristics depend not only on a single pixel RGB value but also on other pixels in the patch. Therefore, even for a particular RGB value, the noise characteristics would vary according to the other pixels in the patch.</p><p>The examples of the effect of the JPEG compression on noise are visualized in <ref type="figure" target="#fig_2">Fig. 3</ref>. After recording 1,000 JPEG images of a static scene, we fit covariance matrices to different pixels. <ref type="figure" target="#fig_2">Figure 3</ref> shows the covariance matrices of several pixels that have the same RGB value in the form of ellipsoids. As expected, the pixels (having the same RGB value) that are located in similar patches show the similar covariance structures ( <ref type="figure" target="#fig_2">Fig. 3 (a)</ref>), while pixels in visually different patches exhibit diverse covariance structures ( <ref type="figure" target="#fig_2">Fig. 3 (b)</ref>). These examples indicate that a good noise model should be able to explain noise's dependence on both the scene and the pixel color.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Noise Model in the 3D RGB Space</head><p>To properly account for the image noise discussed in previous subsections, we propose a noise model that is characterized by a covariance matrix in the RGB color space. Based on the observations as shown in <ref type="figure" target="#fig_4">Fig. 4</ref>, we model the noise as the signal-dependent multivariate Gaussian distribution. In <ref type="figure" target="#fig_4">Fig. 4 (b)</ref>-(e), the Q-Q plots show the ordered squared Mahalanobis distance of samples versus the estimated quantiles from a chi-square distribution with 3 degrees of freedom. The linear relationships as shown on the plots mean that the samples follow a multivariate Gaussian distribution <ref type="bibr" target="#b10">[11]</ref>. The empirical example in <ref type="figure" target="#fig_4">Fig. 4</ref> (f) also supports for the multivariate (3D) Gaussian model.</p><p>In addition to the multivariate Gaussian model, we also consider the local patch contents in our model to deal with the content dependency due to the JPEG compression. With this consideration, the noise of an image pixel (x, y) is determined by the (R,G,B) values of the pixel I(x, y) as well as the 8 × 8 patch in which the pixel (x, y) is located. We ignore the pixel position in the patch for simplicity.</p><p>Putting it altogether, our noise model in the 3D RGB space is written mathematically as:</p><p>I(x, y) = I(x, y)+N 0, Σ(I(x, y), p xy ) ,</p><formula xml:id="formula_0">Σ(I(x, y), p xy ) =   σ 2 r σ rg σ rb σ rg σ 2 g σ gb σ rb σ gb σ 2 b   ,<label>(1)</label></formula><p>where I(x, y) is the true intensity of I(x, y), and p xy is the 8 × 8 color patch value. N (0, Σ(I(x, y), p xy )) is the zero mean multivariate Gaussian distribution of noise with the covariance matrix Σ(I(x, y), p xy ) that is the function of the true intensity I(x, y) and its corresponding patch p xy .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Data-driven Noise Estimation Algorithm</head><p>In theory, the proposed model in Eq. (1) should be defined for every possible patch with each pixel value in the 3D RGB space, which is computed as 256 (8×8×3) . It is unrealistic to compute and store the noise model parameters for all those colors and patch values. Therefore, we employ a data-driven approach based on a multi layer perceptron (MLP) for determining the noise parameters of pixels in a given image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Collection</head><p>For the MLP to perform well, collecting a large number of quality data is essential. We captured training images for 11 static scenes, 500 JPEG images per scene, and computed the mean image of each scene to generate the ground truth noise-free images. 2 Some of the captured scenes are shown in <ref type="figure" target="#fig_6">Fig. 5</ref>. For each dataset, the covariance for each pixel, which is computed using the temporal stack of images, is fed into the system for training along with its (R,G,B) values and the 8 × 8 × 3 patch information. The training is done per camera model and settings such as ISO, and the total amount of data per set is about 13 million patches for an image with resolution 7360 × 4912 (98% of the data is used for the training and 2% for the validation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">MLP based Noise Estimation Method</head><p>A multi-layer perceptron (MLP) is a feed-forward neural network that trains a nonlinear transformation of vectorvalued input layer. The input layer is mapped to the output layer via several hidden layers. Formally, MLPs are defined as</p><formula xml:id="formula_1">x (n+1) = g(b (n) + W (n) x (n) ),<label>(2)</label></formula><p>where x (n+1) is the value of (n + 1)-th layer (x (1) is the input layer). W (n) and b (n) are trainable weights and a bias. For the nonlinear activation function g, a sigmoid, a tanh, or ReLU <ref type="bibr" target="#b15">[16]</ref> is used. When n is more than 2, the MLPs can be used as a universal approximator, which is able to learn any nonlinear mapping. Therefore, we use an MLP with our training data to find the complex nonlinear mapping from the RGB value of a pixel and its surrounding patch to its corresponding covariance matrix. At first, we had expected that the MLP for our problem would require a large number of layers and units. However, we have found that a single hidden layer MLP is enough to learn the nonlinear correlation of our data. Specifically, the structure of our MLP is <ref type="bibr">(195,</ref><ref type="bibr">200,</ref><ref type="bibr" target="#b5">6)</ref>, which are the number of units in each layer <ref type="bibr" target="#b2">3</ref> . Note that the number of parameters of the MLP is considerably small compared to the original problem space where we need a covariance matrix per combination of color and patch (256 (8×8×3) ). With the small number of parameters and its regression power, <ref type="bibr" target="#b1">2</ref> Using the mean of temporal images has been used as noise-free image <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>. <ref type="bibr" target="#b2">3</ref> The input layer is the concatenation of RGB color <ref type="formula" target="#formula_2">(3)</ref>   MLP serves as an efficient and accurate modeling tool for our noise modelling problem.</p><p>The trained MLP can be seen as a regressor, which can predict the covariance matrix for any given (R,G,B) value and its patch. We can formally express the MLP-based noise estimation method as</p><formula xml:id="formula_2">Σ(I(x, y), p xy ) = h(f (I(x, y), p xy ))),<label>(3)</label></formula><p>where the input I(x, y) and p xy are the same as those in Eq. (1). Because the output covariance matrix is symmetric, we only use the half of the matrix. h is a function that converts the 6 dimensional output to the 3 × 3 covariance matrix. To ensure that the covariance matrix is positivedefinite, we replace zero or negative eigenvalues of the matrix with a small positive value. Our MLP f is trained by minimizing the following cost function:</p><formula xml:id="formula_3">L = 1 N i h −1 (Σ(I i (x, y), p xy,i )) − f (I i (x, y), p xy,i ) 2 ,<label>(4)</label></formula><p>where h −1 is the inverse function of h. In our implementation, we use the ReLU as the activation function and stochastic gradient descent <ref type="bibr" target="#b16">[17]</ref> as the optmization method. Also, the learning rate was set to 0.0001 and the training iteration was set to a million with 64 batch size. On average, the learning took 20 minutes with the machine with NVIDIA GTX Titan X GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Results</head><p>To verify the accuracy of our noise estimation, we compare the estimated noise covariance with the ground truth covariance computed from training set. We used the following distance measure introduced in <ref type="bibr" target="#b6">[7]</ref> as the similarity between covariance matrices:  <ref type="figure">Fig. 6</ref>. The values are the median and the mean value of covariance matrix errors in Eq. 5. Small value means better performance. Regardless of the scene, ISO and the camera, our model represent the noise more accurately.</p><formula xml:id="formula_4">d(A, B) = n i=1 ln 2 λ i (A, B),<label>(5)</label></formula><p>(a) (b) (c) (d) (e) <ref type="figure">Figure 6</ref>. Test images used in <ref type="table">Table 1</ref>. From left to right, 1, 4, 7, 10, and 13 (bold). where λ i <ref type="figure">(A, B)</ref> is the i-th generalized eigenvalue of Ax = λBx.</p><p>Since no previous noise model can be fit to real data as ours, direct comparisons with previous models are difficult. The closest model that can be used is the noise level function (NLF) in <ref type="bibr" target="#b18">[19]</ref>, so we compared our model to NLF as shown in <ref type="table">Table 1</ref>. For NLF, we computed NLFs separately for each color channel by obtaining the lower bound of intensity-variance pairs from 500 static images, which is the upper bound of noise as shown in <ref type="figure" target="#fig_7">Fig. 7</ref>. From the variances of three channels, we generated the covariance matrix with zero off-diagonal terms. The table validates our model esstimation process and also shows that it represents the noise in real images better than the NLF. <ref type="figure" target="#fig_8">Figure 8</ref> shows a qualitative analysis of our new noise model and its parameter estimation. It verifies that our multivariate Gaussian model which is an ellipsoid fits well with the observed data samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Image Denoising Application</head><p>To study the effectiveness of our model and its estimation method, we apply our method to image denoising, which is a process of estimating the true intensity corresponding to the scene radiance from the noisy observations. For image denoising, we adopt the Bayesian non-local means (BNLM) method in <ref type="bibr" target="#b13">[14]</ref>, which is an extension of the nonlocal means denoising algorithm <ref type="bibr" target="#b0">[1]</ref> with more robust similarity measures. Non-local means algorithms denoise the images based on the nature of self-similarity in natural images.</p><p>Let I be the noisy observation of a pixel (r, g, b) and I be the denoised color. We can apply the BNLM to compute I, which is expressed as</p><formula xml:id="formula_5">I i = j∈Ni e − 1 2 √ d 2 (i,j)− √ 2M −1 2 I j j∈Ni e − 1 2 √ d 2 (i,j)− √ 2M −1 2 ,<label>(6)</label></formula><p>where i and j are pixel positions, N i is the set of neighboring pixels of i, and M is the number of pixels in patch times the number of channels. The squared dissimilarity measure d 2 (i, j) is originally the squared Euclidean distance normalized by σ 2 . But, in our problem it is changed to the squared Mahalanobis distance, which is expressed as</p><formula xml:id="formula_6">d 2 (i, j) = (I Pi − I Pj ) T Σ −1 Pi (I Pi − I Pj ) = d∈P (I i+d − I j+d ) T Σ −1 i+d (I i+d − I j+d ),<label>(7)</label></formula><p>where I Pi and I Pj are M dimensional vectorized patches whose center pixel is i and j, respectively and Σ Pi is the covariance matrix of I Pi . d 2 (i, j) can be rewritten as the sum of each pixel distance, where P is the set of disparities d from center pixel within patch. For each pixel i + d, Σ i+d is the 3 × 3 covariance matrix of the pixel. <ref type="table">Table 2</ref> and <ref type="figure">Figure 9</ref> show the experimental results of image denoising both quantitatively and qualitatively. BNLM denoising with our noise model is compared with BM3D <ref type="bibr" target="#b4">[5]</ref>, original BNLM <ref type="bibr" target="#b13">[14]</ref>, and BNLM with NLF noise model <ref type="bibr" target="#b18">[19]</ref>. For BM3D and original BNLM, σ is computed by averaging the ground truth (GT) σ of every pixels in the whole image. For all noise models applied to BNLM, 5 × 5 patch and 35 × 35 search window are used, which are sufficient for both the quality and the time complexity.</p><p>For vast majority of cases, denoising using our noise model outperformed other models quantitatively. The quality of denoising using our noise model is more apparent in the qualitative examples shown in <ref type="figure">Figure 9</ref>. These experiments support the need for a new image noise model that are both color and content dependent. We would also like to point out that the experiments in <ref type="table">Table 2</ref> and <ref type="figure">Figure 9</ref> are meaningful as the first noise evaluation on real image data (to the best of our knowledge) as most previous noise evaluations were done on either RAW images or on simulated data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we presented a new noise model in the 3D RGB space considering both the cross-channel dependency and the scene dependency of the noise in consumer camera images. We empirically showed that the noise characteristics change through the in-camera imaging process and the JPEG compression. The observations showed that a new noise model and the estimation method are necessary as previous noise models cannot explain those factors. To estimate the noise, we collected training image sets for various scenes and proposed a data-driven noise estimation algorithm using a multi layer perceptron. We validated our method using real images and applied it to image denoising, which showed large improvement over the previous work. In the future, we are interested in applying our work to other computer vision applications including radiometric calibration and HDR imaging.  <ref type="figure">Figure 9</ref>. Qualitative denoising performance comparisons. (a) and (b) are data 7 and 8 in <ref type="table">Table 2</ref>, respectively. In addition to the quantitative values, we can observe that denoising with our noise model outperform others in this example.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Changes in the noise variance distribution through the pipeline In-camera imaging pipeline and changes in noise distribution through the pipeline. (a) shows block diagram sequences of incamera imaging pipeline. (b) and (c) show the changes in the Skellam and the variance distribution through the pipeline, respectively. Noise chracteristic drastically changes with the gamut mapping and the tone mapping processes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Covariance magnitude changes of some pixels after incamera imaging pipeline and JPEG compression. (a) is the test image scene which was captured in a RAW, an uncompressed TIFF and a JPEG format by Nikon D800. (b)-(d) shows the changes in the covariance terms during the imaging pipeline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>JPEG compression effect on 8×8 patch. (a) shows the ellipsoids of covariance matrices of the same RGB value in similar patches have similar shapes. (b) shows the ellipsoids vary according to the patch the color is in. The ellipsoids represent 95% confidence interval of distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>and bivariate Gaussian distributions of pixel 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Multivariate Gaussian fitting test on real data. (a) A test image captured 10, 000 times using a Samsung Galaxy S6 smartphone camera (ISO 800, 80% compression). (b)-(e) Multivariate Q-Q plot of four selected pixels. The linear relationships indicate that the samples follow multivariate Gaussian distribution<ref type="bibr" target="#b10">[11]</ref>. (f) Shows the color distribtion of pixel 4. It empirically shows that the noise should be modelled as a multivariate (3D) Gaussian distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>and vectorized 8 × 8 color patch (192).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Some samples of the scenes in our dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>The NLF computed from our ground truth. The points are minimum variances of each intensity. We obtain the NLF by fitting the intensity-variance pairs of each channel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>Some noise estimation results of our model. Each shows two covariance ellipsoids which are our estimation (red) and the groundtruth (white). Also, black dots are actual color points from 500 temporal images. Our estimation is quite accurate compared with the ground truth and fits well with the noise distribution of real JPEG image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>Table 2. Denoising performance comparisons. In vast majority of cases, our noise model outperforms other models for denoising in both the PSNR and the SSIM.</figDesc><table>Image # 

Camera Settings 
Noisy Image 
BM3D [5] 
BNLM [14] 
σ from GT 
σ from GT 
NLF [19] from GT 
Ours 
Camera 
ISO 
PSNR 
SSIM 
PSNR 
SSIM 
PSNR 
SSIM 
PSNR 
SSIM 
PSNR 
SSIM 
1 
Nikon D800 
1600 

35.47 
0.957 
36.15 
0.964 
37.59 
0.980 
36.61 
0.972 
37.99 
0.982 
2 
35.71 
0.954 
36.57 
0.964 
39.42 
0.990 
37.61 
0.981 
40.36 
0.992 
3 
34.81 
0.989 
35.47 
0.991 
37.40 
0.995 
35.91 
0.993 
38.30 
0.996 
Average 
35.33 
0.967 
36.06 
0.973 
38.14 
0.988 
36.71 
0.982 
38.89 
0.990 

4 
Nikon D800 
3200 

33.26 
0.978 
34.00 
0.982 
38.10 
0.992 
35.99 
0.988 
39.01 
0.993 
5 
32.89 
0.988 
33.43 
0.989 
35.17 
0.995 
33.84 
0.991 
36.75 
0.996 
6 
32.91 
0.951 
33.53 
0.957 
38.33 
0.987 
35.92 
0.976 
39.06 
0.990 
Average 
33.02 
0.972 
33.65 
0.976 
37.20 
0.991 
35.25 
0.985 
38.27 
0.993 
7 
Nikon D800 
6400 

29.63 
0.862 
29.97 
0.872 
33.35 
0.954 
31.91 
0.933 
34.61 
0.963 
8 
29.97 
0.921 
30.33 
0.928 
32.25 
0.967 
30.94 
0.950 
33.21 
0.970 
9 
29.87 
0.914 
30.21 
0.921 
32.67 
0.962 
31.13 
0.940 
33.22 
0.970 
Average 
29.82 
0.899 
30.17 
0.907 
32.76 
0.961 
31.33 
0.941 
33.68 
0.968 

10 
Nikon D600 
3200 

33.28 
0.968 
33.70 
0.972 
34.74 
0.978 
34.27 
0.975 
34.98 
0.979 
11 
33.77 
0.990 
34.33 
0.992 
36.20 
0.995 
35.54 
0.995 
35.95 
0.995 
12 
35.21 
0.939 
35.75 
0.954 
40.57 
0.987 
38.42 
0.979 
41.15 
0.989 
Average 
34.09 
0.966 
34.59 
0.973 
37.17 
0.987 
36.08 
0.983 
37.36 
0.988 

13 
Canon 5D Mark III 
3200 

37.00 
0.976 
37.79 
0.984 
38.44 
0.986 
37.97 
0.987 
38.37 
0.988 
14 
33.88 
0.983 
34.34 
0.986 
35.27 
0.988 
34.39 
0.986 
35.37 
0.990 
15 
33.83 
0.977 
34.27 
0.979 
34.78 
0.982 
34.13 
0.979 
34.91 
0.983 
Average 
34.90 
0.979 
35.47 
0.983 
36.16 
0.985 
35.50 
0.984 
36.22 
0.987 

Noisy Image 
BM3D + σ 

BNLM + σ 
BNLM + NLF 

BNLM + Ours 
Mean Image 

(a) 

Noisy Image 
BM3D + σ 

BNLM + σ 
BNLM + NLF 

BNLM + Ours 
Mean Image 

(b) 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that our problem is to analyze the effect of compression on the noise level, which is different from dealing with the blocky JPEG noise or artifacts<ref type="bibr" target="#b17">[18]</ref>.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Image denoising: Can plain neural networks compete with BM3D?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Modeling radiometric uncertainty for vision with tone-mapped color images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zickler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2185" to="2198" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A learning-based approach to reduce JPEG artifacts in image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-d transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Practical poissonian-gaussian noise modeling and fitting for single-image raw-data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Trimeche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1737" to="1754" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A metric for covariance matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Förstner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Moonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Geodesy-The Challenge of the 3rd Millennium</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="299" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Optimal HDR reconstruction with linear digital cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Granados</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ajdin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modeling the space of camera response functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grossberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1272" to="1282" />
			<date type="published" when="2004-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Radiometric CCD camera calibration and noise estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Healey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kondepudy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="276" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multivariate normal plotting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J R</forename><surname>Healy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series C (Applied Statistics)</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="161" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Difference-based image noise modeling using skellam distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1329" to="1341" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Image deblurring and denoising using color priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1550" to="1557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bayesian non-local means filter, image redundancy and adaptive dictionaries for noise removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kervrann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boulanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Coup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Scale-Space and Variational Meth</title>
		<meeting>Conf. Scale-Space and Variational Meth</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A new in-camera imaging model for color computer vision and its application</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Susstrunk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2289" to="2302" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient backprop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: Tricks of the trade</title>
		<editor>G. Orr and M. K.</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A contrast enhancement framework with JPEG artifacts suppression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision</title>
		<meeting>European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatic estimation and removal of noise from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="299" to="314" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Practical signal-dependent noise parameter estimation from a single noisy image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Okutomi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4361" to="4371" />
			<date type="published" when="2014-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A statistical approach to background subtraction for surveillance systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ohta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="481" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Thresholding for change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Rosin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="274" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Statistical calibration of ccd imaging process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2001-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Pfinder: Real-time tracking of the human body</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Azarbaygaui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="780" to="785" />
			<date type="published" when="1997-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Image denoising and inpainting with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
