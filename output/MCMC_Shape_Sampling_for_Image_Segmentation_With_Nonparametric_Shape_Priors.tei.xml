<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MCMC Shape Sampling for Image Segmentation with Nonparametric Shape Priors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ertunc</forename><surname>Erdil</surname></persName>
							<email>ertuncerdil@sabanciuniv.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Sabanci University</orgName>
								<address>
									<postCode>34956</postCode>
									<settlement>Tuzla, Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinan</forename><surname>Yıldırım</surname></persName>
							<email>sinanyildirim@sabanciuniv.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Sabanci University</orgName>
								<address>
									<postCode>34956</postCode>
									<settlement>Tuzla, Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Müjdat</forename><forename type="middle">Ç</forename><surname>Etin</surname></persName>
							<email>mcetin@sabanciuniv.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Sabanci University</orgName>
								<address>
									<postCode>34956</postCode>
									<settlement>Tuzla, Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Tasdizen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Utah University</orgName>
								<address>
									<addrLine>Salt Lake City</addrLine>
									<region>UT</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MCMC Shape Sampling for Image Segmentation with Nonparametric Shape Priors</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Segmenting images of low quality or with missing data is a challenging problem. Integrating statistical prior information about the shapes to be segmented can improve the segmentation results significantly. Most shape-based segmentation algorithms optimize an energy functional and find a point estimate for the object to be segmented. This does not provide a measure of the degree of confidence in that result, neither does it provide a picture of other probable solutions based on the data and the priors. With a statistical view, addressing these issues would involve the problem of characterizing the posterior densities of the shapes of the objects to be segmented. For such characterization, we propose a Markov chain Monte Carlo (MCMC) samplingbased image segmentation algorithm that uses statistical shape priors. In addition to better characterization of the statistical structure of the problem, such an approach would also have the potential to address issues with getting stuck at local optima, suffered by existing shape-based segmentation methods. Our approach is able to characterize the posterior probability density in the space of shapes through its samples, and to return multiple solutions, potentially from different modes of a multimodal probability density, which would be encountered, e.g., in segmenting objects from multiple shape classes. We present promising results on a variety of data sets. We also provide an extension for segmenting shapes of objects with parts that can go through independent shape variations. This extension involves the use of local shape priors on object parts and provides robustness to limitations in shape training data size.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Prior knowledge about the shapes to be segmented is required for segmentation of images involving limited and low quality data. In many applications, object shapes come from multiple classes (i.e., the prior shape density is "mul-Test Images Samples <ref type="figure">Figure 1</ref>. Examples of MCMC sampling. First row: on an object with a unimodal shape density. Second row: on an object with a multimodal shape density.</p><p>timodal") and the algorithm does not know the class of the object in the scene. For example, in the problem of segmenting objects in a natural scene (e.g., cars, planes, trees, etc.), a segmentation algorithm should contain a training set of objects from different classes. Another example of a multimodal density is the shape density of multiple handwritten digits, e.g., in an optical character segmentation and recognition problem. In this paper, we consider segmentation problems that involve limited and challenging image data together with complex and potentially multimodal shape prior densities. The shape-based segmentation approach of Tsai et al. <ref type="bibr" target="#b19">[20]</ref> uses a parametric model for an implicit representation of the segmenting curve by applying principal component analysis to a training data set. Such techniques can handle only unimodal, Gaussian-like shape densities and cannot deal with "multimodal" shape densities. Kim et al. <ref type="bibr" target="#b11">[12]</ref> and Cremers et al. <ref type="bibr" target="#b5">[6]</ref> propose nonparametric methods for handling multimodal shape densities by extending Parzen density estimation to the space of shapes. These methods minimize an energy function containing both data fidelity and shape terms, and find a solution at a local optimum. Having such a point estimate does not provide any measure of the degree of confidence/uncertainty in that result or any information about the characteristics of the posterior density, especially if the prior shape density is multimodal. Such a more detailed characterization might be beneficial for further higher-level inference goals such as object recognition and scene interpretation.</p><p>Our contributions in this paper are twofold. First, as the major contribution, we present a Markov chain Monte Carlo (MCMC) sampling approach that uses nonparametric shape priors for image segmentation. Our MCMC sampling approach is able to characterize the posterior shape density by returning multiple probable solutions and avoids the problem of getting stuck at a single local optimum. To the best of our knowledge, this is the first approach that performs MCMC shape sampling-based image segmentation through an energy functional that uses nonparametric shape priors and level sets. We present experimental results on several data sets containing low quality images and occluded objects involving both unimodal and multimodal shape densities. As a second contribution, we provide an extension within our MCMC framework, that involves a local shape prior approach for scenarios in which objects consist of parts that can exhibit independent shape variations. This extension allows learning shapes of object parts independently and then merging them together. This leads to more effective use of potentially limited training data. We demonstrate the effectiveness of this approach on a challenging segmentation problem as well.</p><p>Some exemplary results of our MCMC shape sampling approach that uses nonparametric shape priors are illustrated in <ref type="figure">Figure 1</ref>. The first row of <ref type="figure">Figure 1</ref> shows three different samples obtained by our approach given the partially occluded aircraft test image in the first column of the corresponding row. In this experiment, the training set contains only examples of aircraft shapes, i.e., the shape density is unimodal, meaning that there are no well-defined subclasses. The second row of the figure contains an MCMC shape sampling example on handwritten digits. In this example, the training set consists of examples from ten different digit classes. Here, our approach is able to find multiple probable solutions from different modes of the shape density.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Most of the sampling-based segmentation methods in the literature use an energy functional that include only a data fidelity term <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b8">9]</ref> which means that they are only capable of segmenting objects whose boundaries are mostly visible. Among these approaches, Fan et al. <ref type="bibr" target="#b8">[9]</ref> have developed a method that utilizes both implicit (level set) and explicit (marker-based) representations of shape. The proposal distribution generates a candidate sample by randomly perturbing a set of marker points selected on the closed curve. Due to the use of marker points in perturbation, this ap-proach is only applicable to segmentation of simply connected shapes, i.e., it cannot handle topological changes. Later, Chang et al. <ref type="bibr" target="#b1">[2]</ref> have proposed an efficient MCMC sampling approach on a level set-based curve representation that can handle topological changes. Random curve perturbation is performed through an addition operator on the level set representation of the curve. Additive perturbation is generated by sampling from a Gaussian distribution. They also introduce some bias to the additive perturbation with the gradient of the energy function to achieve faster convergence. The method is further extended in <ref type="bibr" target="#b2">[3]</ref> to achieve order of magnitude speed up in convergence by developing a sampler whose samples at every iteration are accepted. Additionally, they incorporate topological constraints to exploit prior knowledge of the shape topology.</p><p>Chen et al. <ref type="bibr" target="#b4">[5]</ref> use the shape prior term suggested by Kim et al. <ref type="bibr" target="#b11">[12]</ref> and Cremers et al. <ref type="bibr" target="#b5">[6]</ref> together with a data fidelity term in the energy functional. Samples are generated by constructing a smooth normal perturbation at a single point on the curve which preserves the signed distance property of the level set. The method is restricted to segmentation of simply connected shapes due to its inability to handle topological changes. Therefore, the approach is not applicable to shapes with complex boundaries.</p><p>De Bruijne et al. <ref type="bibr" target="#b6">[7]</ref> propose a particle filter-based segmentation approach that exploits both shape and appearance priors. The method assumes that the underlying shape distribution is unimodal. Therefore, it cannot handle cases when the shapes in the training set comes from a multimodal density.</p><p>Eslami et al. <ref type="bibr" target="#b7">[8]</ref> propose a shape model that learns binary shape distributions using a type of deep Boltzmann machine <ref type="bibr" target="#b18">[19]</ref> and generates samples using block-Gibbs sampling. The model is able to learn multimodal shape densities, however, samples generated from the distribution come only from a particular class closest to the observed data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Metropolis-Hastings Sampling in the Space of Spaces</head><p>With a Bayesian perspective, segmentation can be viewed as the problem of estimating the boundary C based on image data:</p><formula xml:id="formula_0">p(C|data) ∝ exp(−E(C))<label>(1)</label></formula><p>where,</p><formula xml:id="formula_1">E(C) = E data (C) + E shape (C) = − log p(data|C) − log p C (C)<label>(2)</label></formula><p>In this paper, we present an algorithm to draw samples from p(C|data) which is, in general, a complex distribution and is not possible to sample from directly.</p><p>MCMC methods were developed to draw samples from a probability distribution when direct sampling is nontrivial. We use Metropolis-Hastings sampling <ref type="bibr" target="#b15">[16]</ref> which has been previously used for image segmentation <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b1">2]</ref>. In Metropolis-Hastings sampling, instead of directly sampling from p, a proposal distribution q is defined and samples from q are accepted in such a way that samples from p are generated asymptotically. The Metropolis-Hastings acceptance probability is defined as</p><formula xml:id="formula_2">P r C (t+1) = C (t+1) |C (t) = min π(C (t+1) ) π(C (t) ) . q(C (t) |C (t+1) ) q(C (t+1) |C (t) )</formula><p>Metropolis-Hastings ratio , 1 .</p><p>(</p><p>The Metropolis-Hastings threshold, η, is randomly generated from the uniform distribution in [0, 1]. The candi-</p><formula xml:id="formula_4">date (proposed) sample C (t+1) is accepted if P r C (t+1) = C (t+1) |C (t) is greater than η. Otherwise, C (t+1) = C (t) .</formula><p>In <ref type="bibr">Equation 3</ref>, C (t) and C (t+1) represent the current sample and proposed sample, respectively. The superscripts (t) and (t + 1) denote the sampling iteration count, and π(C) ∝ exp(−E(C)). After a sufficient number of iterations (i.e., the mixing time) a single sample from the posterior is produced by converging to the stationary distribution. Evaluating the acceptance probability is a key point in MCMC methods. Correct evaluation of the acceptance probability satisfies the sufficient conditions for convergence to the desired posterior distribution: detailed balance and ergodicity. Therefore, the problem turns into the correct computation of forward q(C (t+1) |C (t) ) and reverse q(C (t) |C (t+1) ) transition probabilities of the proposal distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">MCMC Shape Sampling using Nonparametric Shape Priors</head><p>We assume that the curve at the 0 th sampling iteration, C (0) , is the curve that is found by minimizing only the data fidelity term, E data (C). We use piecewise-constant version of the Mumford-Shah functional <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b0">1]</ref> for data driven segmentation. One can consider optimizing more sophisticated energy functions such as mutual information <ref type="bibr" target="#b12">[13]</ref>, J-Divergence <ref type="bibr" target="#b10">[11]</ref>, and Bhattacharya Distance <ref type="bibr" target="#b16">[17]</ref> to obtain C (0) . Also, using an MCMC sampling based approach for data driven segmentation can enrich the sampling space since it would allow subsequent MCMC shape sampling to use several initial curves to start from. After the curve finds all the portions of the object boundary identifiable based on the image data only (e.g., for a high SNR image with an occluded object, one would expect this stage to capture the non-occluded portions of the object reasonably well), we activate the process of generating samples from the underlying space of shapes using nonparametric shape priors.</p><p>The overall proposed MCMC shape sampling algorithm is given in Algorithm 1. The steps of the algorithm are explained in the following three subsections. Randomly select class of C (0) as introduced in Section 4.1.</p><p>3:</p><formula xml:id="formula_5">for t = 0 → (N − 1) do ⊲ N : # of sampling iterations 4:</formula><p>Generate candidate sampleC (t+1) from curvẽ C (t) as introduced in Section 4.2.</p><p>⊲ The steps between 5 -10 are introduced in Section 4.3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Calculate Metropolis-Hastings ratio, P r 6:</p><formula xml:id="formula_6">η = U [0,1] 7: if (t + 1) = 1 OR η &lt; P r then 8:C (t+1) =C (t+1)</formula><p>⊲ Accept the candidate 9: </p><formula xml:id="formula_7">else 10:C (t+1) =C (t) ⊲ Reject</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Random class decision</head><p>Suppose that we have a training set C = {C 1 , . . . , C n } consisting of shapes from n different classes where each</p><formula xml:id="formula_8">class C i = {C ij |j ∈ [1, m i ] ∈ Z} contains m i different example shapes.</formula><p>We align training shapes C ij intoC ij using the alignment approach presented in Tsai et al. <ref type="bibr" target="#b19">[20]</ref> in order to remove the artifacts due to pose differences such as translation, rotation, and scaling.</p><p>We exploit the shape prior term p C (C) proposed by Kim et al. <ref type="bibr" target="#b11">[12]</ref> to select the class of the curveC (0) . The prior probability density function of the curve evaluated at sampling iteration zero is</p><formula xml:id="formula_9">p C (C (0) ) = 1 n n i=1 1 m i mi j=1 k(d L2 (φC (0) , φC ij ), σ) (4)</formula><p>where k(., σ) is a 1D Gaussian kernel with kernel size σ, d L2 (., .) is the L 2 distance metric and φ denotes the level set representation of a curve. Also, note thatC (0) is the aligned version of C (0) with the training set. By exploiting <ref type="bibr">Equation 4</ref>, we can compute the prior probability density of the shapes in C i evaluated atC (0) , p ′ Ci (C (0) ), as follows</p><formula xml:id="formula_10">p ′ Ci (C (0) ) ∝ 1 m i mi j=1 k(d L2 (φC(0) , φC ij ), σ).<label>(5)</label></formula><p>We randomly select a class for shapeC (0) where the probability of selecting a class is proportional to the value of p ′ Ci (C (0) ) computed in Equation <ref type="bibr" target="#b4">5</ref>. When we generate multiple samples, the random class selection step helps us obtain more samples from the classes having higher probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Generating a candidate sample</head><p>In this section, we explain how to generate a candidate sample from the proposal distribution q. Once the class of C (0) is randomly selected, we perform curve perturbation exploiting the training samples in this class. LetC r be the set that contains the training shapes from the selected class r. We randomly choose γ training shapes fromC r where the probability of selecting each shape is proportional to its similarity withC (t) . We compute the similarity between a training shapeC rj andC (t) as the value of the probability density function, s, atC rj where,</p><formula xml:id="formula_11">sC(t) (C rj ) ∝ k(d L2 (φC(t) , φC rj ), σ).<label>(6)</label></formula><p>Note that a training shape can be selected multiple times and random training shape selection is repeated in each sampling iteration. We represent the set composed of randomly selected γ training shapes at sampling iteration t byC (t)</p><p>R . Finally, we define the forward perturbation for the curvẽ C (t) with level sets as follows:</p><formula xml:id="formula_12">φC(t+1) = φC(t) + αf (t)<label>(7)</label></formula><p>We choose f (t) as the negative gradient of the energy function given in Equation 2 in order to move towards a more probable configuration in each perturbation. Here, α indicates the step size for gradient descent. Note that we use randomly selected training samples,C Rj ∈C (t) R , for curve perturbation. Mathematically this is expressed as</p><formula xml:id="formula_13">f (t) = − ∂E(φC(t) ) φC(t) = ∂ log p(data|C (t) ) ∂t + 1 pC(t) (C (t) ) 1 γ 1 σ γ j=1 k(d L 2 (φC(t) , φC Rj ), σ)(φC Rj − φC(t) )<label>(8)</label></formula><p>In other words, updating the curveC (t) toward the negative gradient direction of the energy functional produces the candidate curveC (t+1) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Evaluating the Metropolis-Hastings ratio</head><p>Computation of the first fraction in the Metropolis-Hastings ratio in Equation 3 is straightforward since π(C) ∝ exp(−E(C)). Recall that the candidate curvẽ C (t+1) is dependent on the forward perturbation f (t) . Therefore, we compute the forward perturbation probability by considering the value of the probability density function, s, for each randomly selected training shapeC Rj ∈C (t) R as follows:</p><formula xml:id="formula_14">q(C (t+1) |C (t) ) = C Rj ∈C (t) Rj s(C Rj )<label>(9)</label></formula><p>Similarly, the reverse perturbation probability in sampling iteration (t + 1) is computed as the probability of selecting random shapes inC (t−1) R which have been used to produce the curveC (t) :</p><formula xml:id="formula_15">q(C (t) |C (t+1) ) = C Rj ∈C (t−1) Rj s(C Rj )<label>(10)</label></formula><p>Note that, given the above formulations, computation of the reverse perturbation probability is not possible for candidate curveC <ref type="bibr" target="#b0">(1)</ref> , the curve at sampling iteration 1, since we have to use information from sampling iteration −1 for evaluation of Equation 10, which is not available. Therefore, we accept the candidate sampleC (1) without evaluating the Metropolis-Hastings ratio and consider the abovementioned steps for generating samples after sampling iteration 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Discussion on sufficient conditions for MCMC sampling</head><p>Convergence to the correct stationary distribution is crucial in MCMC methods. Convergence is guaranteed with two sufficient conditions: (1) that the chain is ergodic, and (2) that detailed balance is satisfied in each sampling iteration. Ergodicity is satisfied when the Markov chain is aperiodic and irreducible. Aperiodicity of a complicated Markov chain is a property that is hard to prove as attested in the literature <ref type="bibr" target="#b9">[10]</ref>.</p><p>Detailed balance is satisfied as long as the Metropolis-Hastings ratio in Equation 3 is calculated correctly. We have already described how we compute the Metropolis-Hastings ratio in the previous section. Empirical results show that a stationary distribution is most likely reached since our samples converge. Related pieces of work in <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b1">[2]</ref>, and <ref type="bibr" target="#b4">[5]</ref> argue that the Markov chain is unlikely to be periodic because the space of segmentations is so large. Similarly, we can also assert that our Markov chain is unlikely to be periodic. Even if the chain is periodic in exceptional cases, the average sample path converges to the stationary distribution as long as the chain is irreducible. Irreducibility of a Markov chain requires showing that transitioning from any state to any other state has finite probability. Chen et al. <ref type="bibr" target="#b4">[5]</ref> and Chang et al. <ref type="bibr" target="#b1">[2]</ref> provide valid arguments that the Markov chain is irreducible whereas Fan et al. <ref type="bibr" target="#b8">[9]</ref> does not discuss this property. As explained in the previous section, curve perturbation in our framework is performed with randomly selected training samplesC (t) R and each shape has finite probability to be selected at any sampling iteration. With this perspective, we can also argue that each move between shapes has finite probability in our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Extension to MCMC Sampling using Local Shape Priors</head><p>In this section, we consider the problem of segmenting objects with parts that can go through independent shape variations. We propose to use local shape priors on object parts to provide robustness to limitations in shape training size <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b14">15]</ref>. Let us consider the motivating example shown in <ref type="figure" target="#fig_1">Figure 2</ref>. In this example, there are three images of walking silhouettes: two for training and one for testing. Note that the left leg together with the right arm of the test silhouette involves missing regions. When segmenting the test image using nonparametric shape priors <ref type="bibr" target="#b11">[12]</ref> based on global training shapes 1 , the result may not be satisfactory (see the rightmost image in the first row of <ref type="figure" target="#fig_1">Figure 2</ref>), because the shapes in the training set do not closely resemble the test image. This motivates us to represent shapes with local priors such that resulting segmentation will mix and match information from independent object parts (e.g., by taking information about the the right arm from the first training shape and about the left leg from the second training shape).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training images Test image Segmentation with global priors</head><p>Local shape priors with colored patches Activated local shape priors Expected segmentation Our idea of constructing local shape priors is straightforward. Once the training shapes are aligned, we divide the shapes into patches, such that each patch contains a different local shape region. Each patch is indicated by a different color in the second row of <ref type="figure" target="#fig_1">Figure 2</ref>. Note that the patches representing the same local shape have identical size. For MCMC shape sampling using local shape priors, it is straightforward to adapt the formulation in the previous sections to consider local priors. In particular, instead of choosing random global shapes using the values computed by Equation 6, we compute these values for each patch (local shape) and select random patches among all training images. Note that evaluation of forward and reverse perturbation probabilities should also be modified accordingly. <ref type="bibr" target="#b0">1</ref> Unless otherwise stated, the shape priors we use are global. We explicitly refer to global shape priors when we need to distinguish them from local shape priors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experimental Results</head><p>In this section, we present empirical results of our MCMC shape sampling algorithm on segmentation of potentially occluded objects in low-quality images. Note that, when dealing with segmentation of objects with unknown occlusions, E data (C) increases when the shape term delineates the boundaries in the occluded region. This can lead to overall increasing effect on E(C (t) ) for a candidate curve and to the rejection of the candidate sample. In order to increase the acceptance rate of our approach, we use π(C) ∝ exp(−E shape (C)) instead of π(C) ∝ exp(−E(C)) in our experiments involving occluded objects (see supplementary material for experiments involving missing data in which we use π(C) ∝ exp(−E(C))). This does not cause any problem in practice since the data fidelity term (together with the shape prior term) is involved in the curve perturbation step, enforcing consistency with the data.</p><p>We perform experiments on several data sets: aircraft <ref type="bibr" target="#b11">[12]</ref>, MNIST handwritten digits <ref type="bibr" target="#b13">[14]</ref>, and walking silhouettes <ref type="bibr" target="#b5">[6]</ref>. In the following subsections, we present quantitative and visual results together with discussions of the experiments for each data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Experiments on the aircraft data set</head><p>The aircraft data set <ref type="bibr" target="#b11">[12]</ref> contains 11 synthetically generated binary aircraft images as shown in the top row of <ref type="figure" target="#fig_2">Figure 3</ref>. We construct the test images shown in the middle and the bottom rows of the same figure by cropping the left wings from the binary images to simulate occlusion and by adding different amounts of noise. Note that the test images shown in the middle row of <ref type="figure" target="#fig_2">Figure 3</ref> (test image set -1) have higher SNR than the ones shown in the bottom row (test image set -2). In our experiments, we use this data set in leave-one-out fashion, i.e., we use one image as test and the remaining 10 binary images for training.</p><p>In <ref type="figure" target="#fig_3">Figure 4</ref>(a), we present some visual and quantitative results on the first three images from the test image set -1 shown in <ref type="figure" target="#fig_2">Figure 3</ref>. In this experiment, we generate 500 samples using our shape sampling approach for each test image. We also obtain segmentations using the optimization-based segmentation approach of Kim et al. <ref type="bibr" target="#b11">[12]</ref> (see the second column of <ref type="figure" target="#fig_3">Figure 4(a)</ref>). We compare each sample and the result of Kim et al. <ref type="bibr" target="#b11">[12]</ref> with the corresponding ground truth image using precision -recall values and the F-measure. The samples with the best Fmeasure value are shown in the third column of <ref type="figure" target="#fig_3">Figure 4(a)</ref>. Finally, we plot the precision -recall values (PR plots) for each sample and for the result of Kim et al. <ref type="bibr" target="#b11">[12]</ref> in the fourth column of <ref type="figure" target="#fig_3">Figure 4(a)</ref>. Here, the data fidelity term keeps the curve at the object boundaries and shape prior term helps to complete the shape in the occluded part. In our approach, since we select the most probable subset of training images and evolve the curve with the weighted average of these im- ages, the results of our approach are more likely to produce better fits for the occluded part. In the experiments shown in <ref type="figure" target="#fig_3">Figure 4</ref>(a), our approach can generate better samples than the result of Kim et al. <ref type="bibr" target="#b11">[12]</ref> in all test images. Moreover, our algorithm is able to generate many different samples in the solution space. By looking at these samples, one can also have more information about the confidence in a particular solution.</p><p>We also perform experiments on the aircraft test image set -2 shown in <ref type="figure" target="#fig_2">Figure 3</ref> and present results on the first three images in <ref type="figure" target="#fig_3">Figure 4(b)</ref>. The segmentation problem in this image set is more challenging than the previous case because of lower SNR. We perform experiments with the same settings as in test image set -1 and present the results in the same way in <ref type="figure" target="#fig_3">Figure 4(b)</ref>. In this case, we have to give more weight to the shape prior term during evolution to complete the occluded part because of the high amount of noise. Because of the limited role of the data fidelity term, the curve starts losing some part of the boundary after the shape term is turned on since the role of the data term is limited. Therefore, in this case, not only the occluded part but also the other parts of the aircraft shape approach a weighted average of the objects in the training set during curve evolution. Note from <ref type="figure" target="#fig_3">Figure 4</ref>(b) that the results of Kim et al. <ref type="bibr" target="#b11">[12]</ref> on different test images are very similar to one another. However, our sampling approach produces more diverse samples including better ones than the result of Kim et al. <ref type="bibr" target="#b11">[12]</ref> in terms of F-measure in most cases. Additional results on all remaining test images shown in <ref type="figure" target="#fig_2">Figure 3</ref> can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Experiments on the MNIST data set</head><p>In this section, we present empirical results on the MNIST handwritten digits <ref type="bibr" target="#b13">[14]</ref> data set which includes a multimodal shape density (i.e, training set contains shapes from multiple classes corresponding to different modes of the shape density). The MNIST handwritten digits data set contains 60,000 training examples and 10,000 test images from 10 different digit classes. In our experiments, we take a subset of 100 images for training such that each class con-tains 10 training examples. Test images, none of which are contained in the training set, are obtained by cropping some parts of the digits and adding noise. The test images that we use in our experiments are shown in <ref type="figure" target="#fig_4">Figure 5</ref>.</p><p>In our experiments on the MNIST data set, we generate 1000 samples using our shape sampling approach. In order to interpret our results, we use three methodologies: (1) Compute the average energy for each class by considering the samples generated in that class. Choose the best three classes with respect to average energy values. Display the best three samples from each class in terms of energy. These samples are most likely good representatives of the modes of the target distribution, (2) Compute the histogram images H(x) which indicate in what percentage of the samples a particular pixel is inside the boundary. This can be simply computed by summing up all the binary samples and dividing by the number of samples <ref type="bibr" target="#b8">[9]</ref>. H(x) can be computed for each class for problems involving multimodal shape densities. We draw the marginal confidence bounds, the bounds where H(x) = 0.1 and H(x) = 0.9, over the test image for each class, (3) Count the number of samples obtained from each class. This can allow a probabilistic interpretation of the results. <ref type="figure" target="#fig_5">Figure 6</ref> demonstrates the average shape energy for each class, E shape (C), as a function of sampling iterations for test image MNIST -1. We note that while the average energy appears to be smoothly converging, the energy for each sample path can sharply increase and decrease. The plot of class 9 in <ref type="figure" target="#fig_5">Figure 6</ref> exhibits such a such pattern because there is only one sample generated from this class. As the number of samples generated in each class increases, the average sample path converges to a stationary distribution.   all the three test images is shown in <ref type="table">Table 1</ref>. This allows us to make a probabilistic interpretation of the segmentation results. One can evaluate the confidence level of the results by analyzing the number of samples generated from a class over all samples. In different segmentation applications, one can investigate solutions obtained from different parts of the posterior probability density. Especially, in the case of multimodal shape densities, segmentation results obtained from multiple modes might be interesting and might offer reasonable solutions. <ref type="figure" target="#fig_6">Figure 7</ref> shows some visual results obtained from the experiments on the MNIST data set. For each test image, we display the results from the best three digit classes where, the quality of each class is computed as the average energy, E(C), of the samples in that class. Also, for each class, we show three samples having the best energy values. These results show that our algorithm is able to find reasonable solutions from different modes of the posterior density. In <ref type="figure" target="#fig_6">Figure 7</ref>, we also present marginal confidence bounds (MCB images) obtained from the samples in each class. The figure demonstrates the marginal confidence bounds at different levels of the histogram image, H(x), for the best classes in all test images. H(x) = 0.1 and H(x) = 0.9 indicate the low probability and the high probability regions, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Experiments on the walking silhouettes data set</head><p>In this experiment, we test the performance of local shape priors extension of our MCMC shape sampling approach and compare it with the one that uses global shape priors, as well as with the method of Kim et al. <ref type="bibr" target="#b11">[12]</ref>. We choose a subset of 30 binary images of a walking person from the walking silhouettes data set <ref type="bibr" target="#b5">[6]</ref>. A subset of 16 images shown in <ref type="figure" target="#fig_8">Figure 8</ref> among these 30 binary images are used for training. The remaining 14 binary images are used to construct test images by adding a high amount of noise.</p><p>For the sake of brevity, we present results on 3 test images in <ref type="figure">Figure 9</ref>. Additional results can be found in the supplementary material. Similar to the evaluations performed for the aircraft data set, we plot the PR values for each sample obtained by our approaches (with global and local priors) and by the approach of Kim et al. <ref type="bibr" target="#b11">[12]</ref>. According to the results, our proposed approach with global shape priors <ref type="table">MCB  image  The best 3 samples  MCB  image  The best 3 samples  MCB  image  The best 3</ref>     <ref type="figure">Figure 9</ref>. Experiments on walking silhouettes data set. In the PR curves, the '×'marks the sample having the best F-measure value obtained using the proposed approach (with either global or local shape priors), and the '×'marks that of segmentation of Kim et al. <ref type="bibr" target="#b11">[12]</ref>. produces samples that have F-measure values better than or equal to the result of Kim et al. <ref type="bibr" target="#b11">[12]</ref> in all test images. By using local shape priors, we can generate even better samples than both Kim et al. <ref type="bibr" target="#b11">[12]</ref> and the approach with global shape priors. Moreover, it seems that our approach based on local shape priors is able to sample the space more effectively than the approach with global shape priors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We have presented a MCMC shape sampling approach for image segmentation that exploits prior information about the shape to be segmented. Unlike existing MCMC sampling methods for image segmentation, our approach can segment objects with occlusion and suffering from severe noise, using nonparametric shape priors. We also provide an extension of our method for segmenting shapes of objects with parts that can go through independent shape variations by using local shape priors on object parts. Empirical results on various data sets demonstrate the potential of our approach in MCMC shape sampling. The implementation of the proposed method is available at spis.sabanciuniv.edu/data_code.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Motivating example for using local shape priors in walking silhouettes data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>The aircraft data set. Top row: Training set, middle row: test image set -1 and bottom row: test image set -2. Note that we remove the corresponding training image from the training set for each test image in our experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Experiments on aircraft data set. Note that each row contains the results for a different test image. In the PR plots, '×'and '×'mark the samples produced by our approach where '×'indicates the sample with the best F-measure value, and '×'marks that of segmentation of Kim et al.<ref type="bibr" target="#b11">[12]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Test images from the MNIST data set. From left to right: MNIST -1, MNIST -2, and MNIST -3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Average shape energy (E shape (C)) across all sampling iterations for all digit classes for test image MNIST -1. Note that the number of iterations start from 300 in x-axis because the previous iterations involve segmentation with the data term only.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Experiments on the MNIST data set. Note that in MCB images, red and green contours are the marginal confidence bounds at H(x) = 0.1 and H(x) = 0.9, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>The training set for the walking silhouettes data set.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Active contours without edges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Image processing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="266" to="277" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient mcmc sampling with implicit shape representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2081" to="2088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficient topologycontrolled sampling of implicit shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Image Processing (ICIP)</title>
		<meeting>the IEEE International Conference on Image Processing (ICIP)</meeting>
		<imprint>
			<date type="published" when="2012-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep learning shape priors for object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1870" to="1877" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Markov chain monte carlo shape sampling using level sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Radke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on Computer Vision Workshops (ICCV Workshops)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="296" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Kernel density estimation and intrinsic alignment for shape priors in level set segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="335" to="351" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Image segmentation by shape particle filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Pattern Recognition (ICPR)</title>
		<meeting>the 17th International Conference on Pattern Recognition (ICPR)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="722" to="725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The shape boltzmann machine: a strong model of object shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="155" to="176" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mcmc curve sampling for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Levitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention (MICCAI)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="477" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">markov chain monte carlo in practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Gilks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Spiegelhalter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast texture segmentation model based on the shape operator and active contour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Houhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Thiran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nonparametric shape priors for active contour-based image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3021" to="3044" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A nonparametric statistical method for image segmentation using information theory and curve evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yezzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1486" to="1502" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Disjunctive normal shape and appearance priors with applications to image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mesadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cetin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention (MICCAI)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="703" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Equation of state calculations by fast computing machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Metropolis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Teller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of chemical physics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1087" to="1092" />
			<date type="published" when="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Image segmentation using active contours driven by the bhattacharyya gradient flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Michailovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tannenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2787" to="2801" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Optimal approximations by piecewise smooth functions and associated variational problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on pure and applied mathematics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="577" to="685" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="448" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A shape-based approach to the segmentation of medical imagery using level sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yezzi</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tempany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Grimson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
