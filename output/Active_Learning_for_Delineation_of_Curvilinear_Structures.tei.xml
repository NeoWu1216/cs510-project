<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Active Learning for Delineation of Curvilinear Structures</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Mosinska-Domanska</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bern</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Sznitman</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bern</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Przemysław</forename><surname>Głowacki</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bern</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
							<email>pascal.fua@epfl.chraphael.sznitman@artorg.unibe.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Bern</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Active Learning for Delineation of Curvilinear Structures</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many recent delineation techniques owe much of their increased effectiveness to path classification algorithms that make it possible to distinguish promising paths from others. The downside of this development is that they require annotated training data, which is tedious to produce.</p><p>In this paper, we propose an Active Learning approach that considerably speeds up the annotation process. Unlike standard ones, it takes advantage of the specificities of the delineation problem. It operates on a graph and can reduce the training set size by up to 80% without compromising the reconstruction quality.</p><p>We will show that our approach outperforms conventional ones on various biomedical and natural image datasets, thus showing that it is broadly applicable.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Complex curvilinear structures are widespread in nature. They range in size from solar filaments as seen through telescopes to road networks in aerial images, blood vessels in medical imagery, and neural structures in micrographs. These very diverse structures have different appearances and it has recently been shown that training classifiers to assess whether an image path is likely to be a structure of interest is key to improving the performance of automated delineation algorithms <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>However, while such Machine-Learning based algorithms are effective, they still require significant amounts of manual annotation for training purposes. For everyday scenes, this can be done by crowd-sourcing <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b14">15]</ref>. In more specialized areas such as neuroscience or medicine, this is impractical because only experts whose time is scarce and precious can do this reliably. This problem is particularly acute when dealing with 3D image stacks, which are much more difficult to interact with than regular 2D images and require special expertise. It is further compounded by the fact that data preparation processes tend to be complicated and not easily repeatable leading the curvilinear (a) (b) <ref type="figure">Figure 1</ref>: Images of two different neural structures obtained using confocal microscopy. The enormous variety of curvilinear structures requires problem-specific training datasets even in case of the same modality.</p><p>structures to exhibit very different appearances as shown in <ref type="figure">Fig. 1</ref>. This means that a classifier trained on one acquisition will not perform very well on a new one, even when using the same modality.</p><p>In this paper, we propose an Active Learning (AL) approach that exploits the specificities of delineation algorithms to massively reduce the effort and drudgery involved in collecting sufficient amounts of training data. At the heart of all AL methods is a query mechanism that enables the system to ask a user to label a few well chosen data samples, which it has selected based on how informative the answers are likely to be. AL has been successfully deployed in areas such as Natural Language Processing <ref type="bibr" target="#b26">[27]</ref>, Computer Vision <ref type="bibr" target="#b10">[11]</ref>, and Bioinformatics <ref type="bibr" target="#b15">[16]</ref>. While it has made it possible to train classifiers with less of human intervention, none of the algorithms can exploit the fact that, for delineation purposes, the paths to be annotated form a graph in which neighborhood and geometric relationships can and should be considered.</p><p>In our approach, we explicitly use these relationships to derive multi-sample entropy estimates, which are better surrogates of informativeness than the entropy of individual samples that is typically used <ref type="bibr" target="#b12">[13]</ref>. As a result, our queries focus more effectively on ambiguous regions in image space, that is, those at the boundary between positive and negative examples.</p><p>To avoid having to retrain the system after each individual query and further increase efficiency, we also integrate into our approach a batch strategy that lets the system ask the user several questions simultaneously. It incorporates density measures that ensure that the batches are diverse in features, representative of the delineation problem at hand and located near each other in the images so as to facilitate the interaction. This is particularly important in 3D volumes where scrolling from one region to another far away is cumbersome and potentially confusing for the user.</p><p>In short, our contribution is an AL approach that is tailored for the delineation of complex linear structures. In that sense, it is specialized. However, it is also generic in the sense that it can handle a wide variety of different structures. We will show that it outperforms more traditional approaches on both 2-and 3-D datasets representing different kinds of linear structures, that is, roads, blood vessels, and neural structures.</p><p>In the reminder of this paper, we first review existing AL techniques applicable to our problem and discuss their limitations for this purpose. We then introduce our approach and show how we combine information propagation and density measures to streamline the annotation process. Finally, we compare the performance of our approach against conventional techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>AL is predicated on the idea that, given even very small amount of annotated data, the learning algorithm can actively choose additional instances that would be most profitable to label next. Starting from a small randomly chosen and manually annotated set of samples, iterating this process can drastically reduce the need for further human annotation since only the most informative ones are considered. This has been demonstrated in applications ranging from Natural Language Processing to Bioinformatics in which unlabeled data is readily available but annotation is expensive <ref type="bibr" target="#b23">[24]</ref>.</p><p>All such AL methods require a criterion for sample selection. The most popular one is uncertainty, usually defined as proximity to the classifier's decision boundary. When the classifier is probabilistic, this can be evaluated in terms of entropy <ref type="bibr" target="#b24">[25]</ref>. In practice, Uncertainty Sampling can be incorporated into most supervised learning methods such as SVMs <ref type="bibr" target="#b26">[27]</ref>, Boosting <ref type="bibr" target="#b8">[9]</ref> and Neural Networks <ref type="bibr" target="#b3">[4]</ref>.</p><p>Another family of AL algorithms called query-bycommittee <ref type="bibr" target="#b4">[5]</ref> uses different automated "experts" to assign potentially different labels to each sample. Those for which the disagreement is the greatest are prime candidates for manual annotation.</p><p>Most practical AL algorithms allow the human to annotate batches of samples before retraining the classifier. This spares the need to wait for potentially lengthy computations to finish between each intervention. However, Uncertainty Sampling as described above can easily end up querying outliers and in batch mode -redundant instances, which is inefficient. This is usually addressed by considering not only the information gain potentially delivered by labelling each individual sample, but also the representativeness of each batch, which is accomplished by density-based methods. In <ref type="bibr" target="#b24">[25]</ref>, Settles and Carven introduce a information density-weighted framework, which favours samples that are not only uncertain but also representative of the underlying distribution. The main problem associated with this approach is finding the weighting of the two terms. Li and Guo <ref type="bibr" target="#b13">[14]</ref> propose choosing a weight at each iteration that would minimise the future generalisation error. This approach is however computationally expensive, as it requires recomputing the underlying model many times and may additionally lead to overfitting. Recently, Ebert et al. <ref type="bibr" target="#b5">[6]</ref> proposed exploiting Reinforcement Learning to induce timevarying trade-off between exploration and exploitation sampling criteria.</p><p>Most of the methods discussed above originate from fields other than that of Computer Vision. They rarely exploit the contextual or spatial relations that are prevalent in images except for a few cases. In <ref type="bibr" target="#b25">[26]</ref> contextual image properties are used to find the image regions that would convey the most information about other uncertain areas with which they are contextually related. In <ref type="bibr" target="#b17">[18]</ref> a perplexity graph modelling similarities between images enables efficient hierarchical subquery evaluation. In video segmentation application <ref type="bibr" target="#b7">[8]</ref>, the obtained labels are propagated in a semi-supervised manner on a graph consisting of spatial, temporal and prior edges. Then, the most uncertain frame is selected for the next annotation. We will show that propagating information after preliminary classification and computing uncertainty only after this acts as a regularizer and is advantageous over estimating informativeness based only on the result of classifier. The AL approach to segmenting CT scans of <ref type="bibr" target="#b9">[10]</ref> incorporates context in terms of generative anatomy models. The notion of geometric uncertainty for segmentation is introduced in <ref type="bibr" target="#b11">[12]</ref>. Like our algorithm, it relies on exchanging probability values between neighbours, but does not account for dataset diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Active Learning for Delineation</head><p>Graph-based network reconstruction algorithms have recently shown superior performance compared to methods based on segmentation. They not only recover the geometry of the problem, but also the correct connectivity, which is crucial in applications such as neuroscience <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b20">21]</ref>. They largely owe their performance to supervised Machine Learning techniques that allow them to recognize promising linear paths. These methods usually start by computing a tubularity measure, which quantifies the likelihood that a tubular structure exists at given image location. Next, a set of subsampled high-tubularity superpixels <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b18">19]</ref> or longer paths <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b20">21]</ref> are extracted. Each of them can be considered as an edge e i belonging to overcomplete spatial graph G and characterized by a feature vector x i . Given two possible class labels (y i = 1 ) and (y i = 0 ) , a discriminative classifier assigns to each edge e i probability of belonging to the structure of interest p(y i = 1 |x i ) or to the background, p(y i = 0 |x i ).</p><p>The optimal subgraph T ⇤ can then be taken to be tree that minimizes the cost function over all trees T that are subgraphs of G</p><formula xml:id="formula_0">X ei2E T − log p(y i =1|x i ) p(y i =0|x i ) ,<label>(1)</label></formula><p>where E T represents the edges of T . Provided that one does not take into account the geometry of the tree but only its topology, this can be shown to be Maximum a Posteriori estimate. In practice, however, it is more effective to formulate the MAP problem in terms of pairs of consecutive edges. This makes it possible to introduce better geometric constraints <ref type="bibr" target="#b28">[29]</ref> and to find generic subgraphs as opposed to only trees <ref type="bibr" target="#b27">[28]</ref>. Whether using single edges or pairs, the key requirement for this kind of approach to perform well is that the classifiers used to estimate the probabilities of Eq. 1 should be well-trained. This is especially important in ambiguous parts of the images such as those depicted by <ref type="figure" target="#fig_0">Fig. 2</ref>.</p><p>This necessitates significant amounts of ground-truth annotations to capture the large variability of the data and to cope with imaging artefacts and noise. To decrease the amounts of necessary time and effort, we introduce an AL algorithm that is suited to delineation problems represented on a graph. At each iteration it selects a sequence of consecutive edges from an overcomplete graph, such as the one described above, which should be labeled next in order to decrease the uncertainty in the most ambiguous image regions.</p><p>In theory the sequences could be of arbitrary length, that is 1,2, or more. In practice, we will see that 2 is near optimal because 2 consecutive edges are enough to capture some amount of geometry and because querying at each iteration more than 2 edges does not update the model frequently enough.</p><p>In the results section, we will use the algorithm of <ref type="bibr" target="#b27">[28]</ref>, which operates on edge pairs to produce the final delineations. <ref type="bibr" target="#b0">1</ref> However, our approach is generic and could be <ref type="bibr" target="#b0">1</ref> The code is not publicly available but the authors gave us a binary </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Approach</head><p>In this section, we first cast the traditional Uncertainty Sampling approach into our chosen delineation framework. We then introduce our approach to probability propagation designed to rapidly identify ambiguous image regions and prevent the so-called sampling bias that may lead the classifier to explore irrelevant parts of the feature space. Finally, we combine this with an approach to batch density-based learning that simplifies the interaction while guaranteeing that the batches are representative and diverse enough to achieve rapid convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Random and Uncertainty Sampling</head><p>The simplest strategy for picking samples to be annotated is to randomly choose them from a pool of unlabeled ones in so called Random Sampling (RS). As discussed in Section 2, Uncertainty Sampling (US) is a simple and popular approach to more efficient learning by querying first the most uncertain samples according to a metric, such as Shannon entropy. version of it.</p><p>In our case, as discussed in Section 3, each edge e i of the spatial graph G is assigned a feature vector x i computed from the pixels surrounding the corresponding path. Let</p><formula xml:id="formula_1">p t (y i = y|x i ) for y ∈{0, 1}<label>(2)</label></formula><p>be the probabilities computed by classifier C t after t AL iterations that e i lies on the centreline of a true structure or not. Let also S t be the set of N t annotated samples (x j ,y j ) 1jNt used to train C t . p 0 denotes the probabilities returned by the classifier using the small initial batch S 0 of annotated samples. When training is complete after T iterations, p T is then used to compute the probabilities that appear in Eq. 1.</p><p>Given a classifier C t−1 trained using the training set S t−1 , AL iteration t involves choosing one or more unlabeled edges, asking the user to label them, adding them to the training set S t−1 to form S t and, finally, training classifier C t . In RS, this is done by randomly picking one or more x not already in S t−1 . In US, it is done by computing for each x the entropy:</p><formula xml:id="formula_2">H(x)=− log(p t−1 (y =0|x))p t−1 (y =0|x) − log(p t−1 (y =1|x))p t−1 (y =1|x) (3)</formula><p>and selecting the vector(s) with the highest entropy. Since H(x) is largest when the classifier returns a 0.5 value and minimum when it returns values close to zero or one, this assumes that those vectors whose probability of being a true path is computed to be 0.5 are the most uncertain and closest to the decision boundary. Therefore annotating them is likely to help refine the shape of that boundary. This approach can be effective but it can also fall victim to sampling bias. This happens when the current classifier is so inaccurate that its decision boundary is far away from the real one and the learner ends up focusing on an irrelevant part of the feature space. Our approach is designed to avoid this trap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Probability Propagation</head><p>The probability p t returned by the path classifier takes into account the appearance of only a single path. By doing so, it neglects the information present in the wider neighborhood, provided by the other paths in the graph that share an endpoint with it. In particular, it ignores the fact that contiguous paths are more likely to share labels than non contiguous ones.</p><p>To account for this, we took inspiration from the semisupervised learning method of <ref type="bibr" target="#b30">[31]</ref> and implemented a modified version of it that propagates probabilities instead of labels. There, the label propagation is used to classify a large pool of unlabelled examples having only a few labelled instances. In our Probability Propagation Sampling (PPS) strategy we propagate the probabilities assigned by the base classifier to identify samples that differ significantly from their neighbourhood i.e. those that after regularization will have probability closest to 0.5.</p><p>Let P 0 be an N × 2 matrix. Its entries are the probabilities p t (y i = y|x i ) of Eq. 2 for all N samples and y ∈{0, 1}, except for already annotated ones for which we clamp the values to zero or one depending on their label. The information is then propagated as follows:</p><formula xml:id="formula_3">1. Build an N × N affinity matrix W ∈ R N ⇥N with elements w ij =e x p ( −||x i − x j || 2 /2σ 2 )</formula><p>if e i and e j share a node and zero otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Build a symmetric matrix</head><formula xml:id="formula_4">S = D −1/2 WD −1/2 , where D is diagonal with elements d ii = P j w ij .</formula><p>3. Iterate P i+1 = αSP i +(1−α)P 0 followed by normalization of the rows of P i+1 until convergence, where α ∈ (0, 1) specifies how much information is exchanged between neighbors and how much of the original information is retained. The series was shown to converge to P ⇤ =(I − αS) −1 P 0 [31] and we will use the closed-form solution.</p><p>The complexity of the propagation algorithm is O(N 3 ) and of computing similarity matrix W -O(N 2 D), where D is feature dimensionality. After the probability propagation, we can compute the entropy of each path at AL iteration t, but this time using the new estimates of probability p ⇤ :</p><formula xml:id="formula_5">H(x)=− log(p ⇤ t−1 (y =0|x))p ⇤ t−1 (y =0|x) − log(p ⇤ t−1 (y =1|x))p ⇤ t−1 (y =1|x) (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Density-based Batch Query</head><p>The scheme of Section 4.2 involves retraining the classifier each time the user has annotated a new sample, forcing them to wait for the computation to be over before intervening again. As discussed in Section 2, this is impractical and most practical AL approaches work in batch-mode, that is, they allow the user to annotate several samples before retraining.</p><p>In our case, samples are image paths and it is much easier to sample several paths in the same image region than over a wide space, which would imply scrolling through a potentially large 2D image or, worse, 3D image stack. Our solution to this is to present the annotator with consecutive paths represented by adjacent edges in the spatial graph G of Section 3. However, in order to be effective, individual paths should be:</p><p>1. informative to ensure that the new labels truly bring new information, 2. representative, that is, inliers of the statistical distribution of all samples, <ref type="bibr" target="#b2">3</ref>. diverse, that is, different from each other and from the already labeled ones.</p><p>The entropy measure of Eq. 4 can be used to assess the first of these three desirable properties. To measure the other two, we use the N × N affinity matrix f W obtained using the same parameters as the matrix W of Section 4.2, but whose elements are measures of pairwise similarity between each of the N samples in the feature space, not only the neighbours in image.</p><p>Let L be the indices of already labelled edges and E k be the set of all possible edge index combinations denoting k consecutive paths. For each E ∈ E k , we can compute the following similarity measures:</p><formula xml:id="formula_6">σ G (E)= X i2E X 1jN w ij (5) σ L (E)= X i2E X l2L w il (6) σ I (E)= X i2E X j2E,j6 =i w ij ,<label>(7)</label></formula><p>where σ G (E) is a global similarity measure, σ L (E) measures similarity to already labelled samples and σ I (E) similarity within the batch. Intuitively, we want to maximize σ G to ensure representativeness and minimize σ L and σ I to improve diversity and explore the whole feature space. We therefore take</p><formula xml:id="formula_7">µ(E)= σ G (E) − σ L (E) − σ I (E) σ G (E) ,<label>(8)</label></formula><p>to be our measure of both diversity and representativeness. This formulation does not require constructing any additional graphs in the feature space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Combining Informativeness and Density Measure</head><p>PPS allows us to take advantage of the current model while density-based query enables exploration of the feature space. In order to combine those two effects at each AL iteration we query the batch</p><formula xml:id="formula_8">E ⇤ = arg max E2E k µ(E)( X i2E H(x i ))<label>(9)</label></formula><p>where H is the entropy measure of Eq. 4 and µ(E) is calculated as in Eq. 8. In our Density-Probability Propagation Sampling (DPPS) the effects of exploration and exploitation are balanced during AL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>In this section, we present our results; we first describe our experimental setup and baselines. We then introduce a synthetic dataset to help visualize the query decisions made by the different strategies. Finally, we show that our approach outperforms the conventional and state-of-the-art techniques on four real datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Setup</head><p>We apply our AL approach for reconstruction of curvilinear networks in 2-and 3-D images. As discussed in Section 3, the overcomplete graphs, as well as the final delineations obtained once the classifiers have been properly trained are constructed using the delineation algorithm of <ref type="bibr" target="#b27">[28]</ref>. The feature vectors associated to each path are based on Histogram of Oriented Gradients specially designed for linear structures. They capture the contrast, orientation, and symmetry of the paths.</p><p>The probabilities of Eq. 1 are computed by feeding the feature vectors to Gradient Boosted Decision Trees <ref type="bibr" target="#b1">[2]</ref> with an exponential loss. We found it well suited to interactive applications because it can be retrained fast, that is in under 3s for all the examples we show in this paper. To avoid overfitting especially in the initial stages of AL, we set the number of weak learners to 50, maximum tree depth to 2 and shrinkage to 0.06. Each tree is optimized using 50% of randomly selected data. Out of possible 303 features, 50 are investigated at each split. The classifier returns score F that can be then converted to probability using the logistic correction <ref type="bibr" target="#b19">[20]</ref>, that is,</p><formula xml:id="formula_9">p(y =1|x)= 1 1+exp(−2F (x))</formula><p>.</p><p>The edge connectivity matrix of Section 4.2 is computed on the basis of the overcomplete graphs. The annotated ground truth data we have for all datasets, allows us to simulate the user intervention. We assume edges that are 10 pixels/voxels apart from the corresponding ground-truth path and with a normalised intersection exceeding 0.5 to be positive. We start each query by a random selection of 4 data points belonging to each class (background/network). Unless stated otherwise, we query 2 consecutive paths during each iteration and this choice is explained in Section 5.4. We proceed until the total number of labelled samples reaches 100. Each AL trial is repeated 30 times and the results are then averaged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Baselines</head><p>We compare the two versions of our approach, Probability Propagation Sampling (PPS) and Density Probability Propagation Sampling (DPPS) as described in Sections 4.2 and 4.4, to the following baselines:</p><p>• Random Sampling (RS) -selecting a random pair at each iteration. • Uncertainty Sampling (US) -selecting a pair with the highest sum of individual entropies as given by Eq. 3.</p><p>• Query-By-Committee (QBC) -selecting a pair that causes the greatest disagreement in a set of hypotheses, here represented by trees in a Random Forest. We measure the disagreement using the definition of <ref type="bibr" target="#b4">[5]</ref>.</p><p>Moreover, we compare the real datasets also to the following state-of-the art methods:</p><p>• Information Density (ID) <ref type="bibr" target="#b24">[ 25]</ref> -similarly to our method it combines uncertainty and density terms to select the next sample.</p><p>• Reinforcement Active Learning Formulation (RALF) <ref type="bibr" target="#b5">[ 6]</ref> -combines AL and reinforcement learning that allows for time-varying trade-off between exploration and exploitation.</p><p>For calibration purposes, we also report the classification performance using all the available training data at once (Full), that is, without any AL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Synthetic Dataset</head><p>To compare the qualitative behavior of different strategies, we create a synthetic dataset. In the image space depicted by <ref type="figure" target="#fig_1">Fig. 3a</ref>, a positive class is surrounded by a negative one, which resembles what happens when trying to find real linear paths surrounded by spurious ones. We created feature space depicted by <ref type="figure" target="#fig_1">Fig. 3b</ref> by transforming the image coordinates and adding random noise so that the decision boundary in feature space does not correspond to the one in Euclidean space. We built the required spatial graph by connecting each point to its 10 nearest-neighbors in image space. We compute the weighting matrix W using RBF kernel with σ = 1 and set probability propagation α to 0.9.</p><p>As can be seen in <ref type="figure" target="#fig_1">Fig. 3c</ref>, PPS and DPPS outperform the baselines and after querying 90 examples match the performance obtained by training on the whole training set. This corresponds to a 80% reduction in annotation effort. Furthermore, DPPS does better than PPS early on.</p><p>In <ref type="figure" target="#fig_1">Fig. 3d</ref>, we use a heat map in feature space to depict the the most frequently queried regions and overlay the optimal decision boundary in red. They indicate that propagating information in a spatial graph helps refine the search space faster than simple uncertainty query. Introducing density measures further constrains the search space making the process more effective and sampling more uniformly around the optimal decision boundary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Real Datasets</head><p>Roads The dataset consists of 2D aerial images of roads. They include road patches occluded by trees and contain road-like structures such as driveways, thus making the classification task difficult.  <ref type="table">Table 1</ref>: Area under the learning curve for all tested methods. An example of such learning curve is depicted in <ref type="figure">Fig.5a</ref>.</p><p>We compute the weighting matrix W using RBF kernel with σ = 1 and set probability propagation α to 0.9. The graph is constructed using only training data and during the whole AL process the classifier does not have access to test data. As shown in <ref type="figure">Fig. 5a</ref> and <ref type="table">Table 1</ref>, both our approaches outperform the baselines and reach the full-dataset performance after as few as 50 samples, which corresponds to 75% reduction in annotation effort. Interestingly, the accuracy keeps increasing above the Full dataset accuracy. This behavior was already reported in <ref type="bibr" target="#b22">[23]</ref> and suggests that in some cases a well chosen subset of data produces better generalization than the complete set. The analysis of the most frequently queried samples shown in <ref type="figure" target="#fig_3">Fig. 6a</ref> reveals that our method selects mainly the occluded paths and those at the intersections between two roads of different sizes or a road and a driveway. They correspond to the ambiguous cases discussed in Section 3 and presented in <ref type="figure" target="#fig_0">Fig. 2c</ref> and <ref type="figure" target="#fig_0">Fig. 2d</ref>. This makes it possible to learn the correct connectivity pattern and avoid mistakes as we postulated in Sec-tion 3. To verify this, we compare not only the classification performance, but also the quality of the final reconstruction. We run the full reconstruction framework with classification followed by an optimization step and evaluate the reconstruction using the DIADEM score <ref type="bibr" target="#b0">[1]</ref>. It ranges from 0 to 1 with 1 being a perfect reconstruction. As shown in <ref type="figure" target="#fig_3">Fig. 6c</ref>, our approach outperforms the baselines also in terms of the quality of the final reconstruction. Interestingly, we again get a better result than by training with the Full dataset.</p><p>These results were obtained by querying pairs of edges. To test the influence of the length of the sequences we query, as discussed at the end of Section 3, we reran the experiments using singletons, pairs, and triplets. As can be seen in <ref type="figure" target="#fig_4">Fig. 7</ref>, using pairs tends to give the best results and this is what we will do in the remainder of this paper. Note that we assume that annotating one edge counts as one label, but in reality the effort of annotating several consecutive edges is less than labeling the same number of instances at random locations, as the user does not need to scroll from one region to another.</p><p>Blood vessels The image stacks depicting directionselective retinal ganglion cells were acquired with confocal microscopes. They contain many cycles and branch crossings. We compute the weighting matrix W using RBF kernel with σ = 0.7 and set α to 0.9. As shown in <ref type="figure">Fig. 5b</ref>, our two methods bring about improvements, especially at the  Axons dataset consists of 3D 2-photon microscopy images of axons in a mouse brain. The main challenge associated with these images is low resolution in the z-dimension resulting in some disjoint branches being merged into one, which drastically changes the connectivity of the final solution. We compute the weighting matrix W using RBF kernel with σ = 3 and set α to 0.9. The accuracy plot <ref type="figure">(Fig. 5c)</ref> reveals that yet again our method performs better than the baselines, especially in the later stages of learning, and result in a 65% reduction in the training effort. As seen in <ref type="figure" target="#fig_3">Fig 6b,</ref> the most frequently queried edges are concentrated in the regions where two branches seem to intersect in the xy-plane. In <ref type="figure" target="#fig_3">Fig. 6d</ref> we show that this again improves the quality of the final reconstruction.</p><p>Brightfield neurons The dataset consists of 3D images of neurons from biocytin-stained rat brains acquired using brightfield microscopy. As in the Axons dataset, the z-resolution is low. The corresponding training graph is much bigger than in the previous 2 cases and consists of more than 3000 edges, most of which are negative. To assess the performance of different methods, we compute the VOC score <ref type="bibr" target="#b6">[7]</ref> instead of accuracy. This is due to the fact that in this dataset around 95% of the edges are negative and the VOC score does not take into account true negatives. We compute the weighting matrix W using RBF kernel with σ =1and set α to 0.9. As seen in <ref type="figure">Fig. 5d</ref> and <ref type="table">Table 1</ref>, our methods outperform the baselines. For RALF, we can notice the possible effects of bias trap, when the performance does not change for a few iterations, even though more and more labels are queried.</p><p>Note that each of the experiments was repeated 30 times and the results are averaged. In <ref type="table" target="#tab_0">Table 2</ref> we present also the variance of the results. In all but one cases except for one PPS approach shows smaller variance than the baselines and DPPS yields even lower variance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper we introduced an approach to incorporating the geometrical information that increases the effectiveness of AL for the delineation of curvilinear networks. Additionally, we introduced a density-based strategy, which ensures that the selected batches are informative, diverse and representative of the underlying distribution. It also allows us to query sequences of consecutive paths, further reducing the annotation effort. Our approach showed superior performance for a wide range of networks and imaging modalities when compared to a number of conventional methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Ambiguous image regions. (a) Branch intersection. (b) Discontinuities due to uneven tissue staining. (c) Discontinuities due to occlusion by a tree. (d) Linear structures such as driveways that should be ignored. used in conjunction with any delineation pipeline that represents the problem on a graph and requires supervised edge classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Synthetic dataset: (a) samples in the Euclidean space (b) samples in the feature space. (c) Classification results. (d) Query heat-maps in the feature space; the red circle indicates the optimal decision boundary. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Training images with superimposed overcomplete graphs (a) Roads (b) Blood vessels (c) Axons (d) Brightfield neurons. Classification results for the (a) Roads (b) Blood vessels (c) Axons (d) Brightfield neurons datasets. Shaded area corresponds to one standard deviation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>The most frequently queried samples for the (a) Roads and (b) Axons datasets. They often coincide with the ambiguous cases as discussed in Section 3. Averaged DIADEM scores of final reconstruction for the (c) Roads and (d) Axons datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>The classification performance for different batch sizes for the Roads dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Variance of the results. beginning of AL.</figDesc><table></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>The authors would like to thank Ksenia Konyushkova, Róger Bermúdez Chacón and Carlos Becker for valuable discussion and advice.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Digital Reconstruction of Axonal and Dendritic Morphology DIADEM Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ascoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Supervised Feature Learning for Curvilinear Structure Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rigamonti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<imprint>
			<date type="published" when="2013-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hierarchical Discriminative Framework for Detecting Tubular Structures in 3D Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Breitenreicher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sofka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Britzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information Processing in Medical Imaging</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Active Learning with Statistical Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Committee-Based Sampling For Training Probabilistic Classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Engelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth International Conference on Machine Learning</title>
		<meeting>the Twelfth International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Ralf: A reinforced active learning formulation for object class recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The Pascal Visual Object Classes Challenge (VOC2010) Results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">,</forename><forename type="middle">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Combining Self Training and Active Learning for Video Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient Multiclass Boosting Classification with Active Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Erekia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIAM International Conference</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Combining Generative and Discriminative Models for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Montillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Processing in Medical Imaging</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Active Learning with Gaussian Processes for Object Categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Introducing Geometry into Active Learning for Image Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Konyushkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sznitman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Sequential Algorithm for Training Text Classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR proceedings on Research and Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adaptive Active Learning for Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Microsoft COCO: Common Objects in Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Active learning with support vector machine applied to gene expression data for cancer classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chemistry Information and Computer Science</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Active Visual Recognition with Expertise Estimation in Crowdsourcing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hierarchical Subquery Evaluation for Active Learning on a Graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">Mac</forename><surname>Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Brostow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mind the Gap: Modeling Local and Global Context in (Road) Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Montoya-Zegarra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wegner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ladicky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Obtaining Calibrated Probabilities from Boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Machine Learning Based Approach to Fiber Tractography Using Classifier Voting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Neher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gtz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Norajitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Maier-Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Automatic Morphological Reconstruction of Neurons from Multiphoton and Confocal Microscopy Images Using 3D Tubular Models. Neuroinformatics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santamaría-Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hernandez-Herrera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Papadakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Saggau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename><surname>Kakadiaris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Less is More: Active Learning with Support Vector Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">From Theories to Queries : Active Learning in Practice. Active Learning and Experimental Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An analysis of active learning strategies for sequence labeling tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Craven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Beyond active noun tagging: Modeling contextual interactions for multi-class active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Siddiquie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Support Vector Machine Active Learning with Applications to Text Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Reconstructing Loopy Curvilinear Structures Using Integer Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Turetken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Benmansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Automated Reconstruction of Tree Structures Using Path Classifiers and Mixed Integer Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Turetken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Benmansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Road Networks as Collections of Minimum Cost Paths. International Society for Photogrammetry and Remote Sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wegner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Montoya-Zegarra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning with Local and Global Consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
