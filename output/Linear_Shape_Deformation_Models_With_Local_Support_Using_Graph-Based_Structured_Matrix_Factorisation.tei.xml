<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Linear Shape Deformation Models with Local Support using Graph-based Structured Matrix Factorisation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Bernard</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Centre Hospitalier de Luxembourg</orgName>
								<address>
									<country key="LU">Luxembourg</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Luxembourg Centre for Systems Biomedicine</orgName>
								<orgName type="institution">University of Luxembourg</orgName>
								<address>
									<country key="LU">Luxembourg</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gemmar</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Luxembourg Centre for Systems Biomedicine</orgName>
								<orgName type="institution">University of Luxembourg</orgName>
								<address>
									<country key="LU">Luxembourg</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Trier University of Applied Sciences</orgName>
								<address>
									<settlement>Trier</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hertel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Centre Hospitalier de Luxembourg</orgName>
								<address>
									<country key="LU">Luxembourg</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Goncalves</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Luxembourg Centre for Systems Biomedicine</orgName>
								<orgName type="institution">University of Luxembourg</orgName>
								<address>
									<country key="LU">Luxembourg</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Thunberg</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Luxembourg Centre for Systems Biomedicine</orgName>
								<orgName type="institution">University of Luxembourg</orgName>
								<address>
									<country key="LU">Luxembourg</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Linear Shape Deformation Models with Local Support using Graph-based Structured Matrix Factorisation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>α = +[ PCA (global support) Our (local support) PCA (global support) Our (local support) PCA (global support)</p><p>Figure 1. Global support factors of PCA lead to implausible body shapes, whereas the local support factors of our method give more realistic results. See our accompanying video for animated results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Representing 3D shape deformations by highdimensional linear models has many applications in computer vision and medical imaging. Commonly, using Principal Components Analysis a low-dimensional subspace of the high-dimensional shape space is determined. However, the resulting factors (the most dominant eigenvectors of the covariance matrix) have global support, i.e. changing the coefficient of a single factor deforms the entire shape. Based on matrix factorisation with sparsity and graph-based regularisation terms, we present a method to obtain deformation factors with local support. The benefits include better flexibility and interpretability as well as the possibility of interactively deforming shapes locally. We demonstrate that for brain shapes our method outperforms the state of the art in local support models with respect to generalisation and sparse reconstruction, whereas for body shapes our method gives more realistic deformations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Due to their simplicity, linear models in highdimensional space are frequently used for modelling nonlinear deformations of shapes in 2D or 3D space. For example, Active Shape Models (ASM) <ref type="bibr" target="#b11">[11]</ref>, based on a sta-tistical shape model, are popular for image segmentation. Usually, surface meshes, comprising faces and vertices, are employed for representing the surfaces of shapes in 3D. Dimensionality reduction techniques are used to learn a lowdimensional representation of the vertex coordinates from training data. Frequently, an affine subspace close to the training shapes is used. To be more specific, mesh deformations are modelled by expressing the vertex coordinates as the sum of a mean shapex and a linear combination of M modes of variation Φ = [Φ 1 , . . . , Φ M ], i.e. the vertices deformed by the weight or coefficient vector α are given by y(α) =x + Φα, see <ref type="figure">Fig. 1</ref>. Commonly, by using Principal Components Analysis (PCA), the modes of variation are set to the most dominant eigenvectors of the sample covariance matrix. PCA-based models are computationally convenient due to the orthogonality of the eigenvectors of the (real and symmetric) covariance matrix. Due to the diagonalisation of the covariance matrix, an axis-aligned Gaussian distribution of the weight vectors of the training data is obtained. A problem of PCA-based models is that eigenvectors have global support, i.e. adjusting the weight of a single factor affects all vertices of the shape <ref type="figure">(Fig. 1)</ref>.</p><p>Thus, in this work, instead of eigenvectors, we consider more general factors as modes of variation that have local support, i.e. adjusting the weight of a single factor leads only to a spatially localised deformation of the shape <ref type="figure">(Fig. 1)</ref>. The set of all factors can be seen as a dictionary for representing shapes by a linear combination of the factors.</p><p>Benefits of factors with local support include more realistic deformations (cf. <ref type="figure">Fig. 1</ref>), better interpretability of the deformations (e.g. clinical interpretability in a medical context <ref type="bibr" target="#b29">[29]</ref>), and the possibility of interactive local mesh deformations (e.g. editing animated mesh sequences in computer graphics <ref type="bibr" target="#b24">[24]</ref>, or enhanced flexibility for interactive 3D segmentation based on statistical shape models <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">PCA Variants</head><p>PCA is a non-convex problem that admits the efficient computation of the global optimum, e.g. by Singular Value Decomposition (SVD). However, the downside is that the incorporation of arbitrary (convex) regularisation terms is not possible due to the SVD-based solution. Therefore, incorporating regularisation terms into PCA is an active field of research and several variants have been presented: Graph-Laplacian PCA <ref type="bibr" target="#b18">[18]</ref> obtains factors with smoothly varying components according to a given graph. Robust PCA <ref type="bibr" target="#b8">[8]</ref> formulates PCA as a convex low-rank matrix factorisation problem, where the nuclear norm is used as convex relaxation of the matrix rank. A combination of both Graph-Laplacian PCA and Robust PCA has been presented in <ref type="bibr" target="#b28">[28]</ref>. The Sparse PCA (SPCA) method <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b39">39]</ref> obtains sparse factors. Structured Sparse PCA (SSPCA) <ref type="bibr" target="#b17">[17]</ref> additionally imposes structure on the sparsity of the factors using group sparsity norms, such as the mixed ℓ 1 /ℓ 2 norm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Deformation Model Variants</head><p>In <ref type="bibr" target="#b21">[21]</ref>, the flexibility of shape models has been increased by using PCA-based factors in combination with a per-vertex weight vector, in contrast to a single weight vector that is used for all vertices. In <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b35">35]</ref>, it is shown that additional elasticity in the PCA-based model can be obtained by manipulation of the sample covariance matrix. Whilst both approaches increase the flexibility of the shape model, they result in global support factors.</p><p>In <ref type="bibr" target="#b29">[29]</ref>, SPCA is used to model the anatomical shape variation of the 2D outlines of the corpus callosum. In <ref type="bibr" target="#b33">[33]</ref>, 2D images of the cardiac ventricle were used to train an Active Appearance Model based on Independent Component Analysis (ICA) <ref type="bibr" target="#b16">[16]</ref>. Other applications of ICA for statistical shape models are presented in <ref type="bibr" target="#b31">[31,</ref><ref type="bibr" target="#b38">38]</ref>. The Orthomax method, where the PCA basis is determined first and then rotated such that it has a "simple" structure, is used in <ref type="bibr" target="#b30">[30]</ref>. The major drawback of SPCA, ICA and Orthomax is that the spatial relation between vertices is completely ignored.</p><p>The Key Point Subspace Acceleration method based on Varimax, where a statistical subspace and key points are automatically identified from training data, is introduced in <ref type="bibr" target="#b22">[22]</ref>. For mesh animation, in <ref type="bibr" target="#b32">[32]</ref> the clusters of spatially close vertices are determined first by spectral clustering, and then PCA is applied for each vertex cluster, resulting in one sub-PCA model per cluster. This two-stage procedure has the problem, that, due to the independence of both stages, it is unclear whether the clustering is optimal with respect to the deformation model. Also, a blending procedure for the individual sub-PCA models is required. A similar approach of first manually segmenting body regions and then learning a PCA-based model has been presented in <ref type="bibr" target="#b37">[37]</ref>.</p><p>The Sparse Localised Deformation Components method (SPLOCS) obtains localised deformation modes from animated mesh sequences by using a matrix factorisation formulation with a weighted ℓ 1 /ℓ 2 norm regulariser <ref type="bibr" target="#b24">[24]</ref>. Local support factors are obtained by explicitly modelling local support regions, which are in turn used to update the weights of the ℓ 1 /ℓ 2 norm in each iteration. This makes the non-convex optimisation problem even harder to solve and dismisses convergence guarantees. With that, a suboptimal initialisation of the support regions, as presented in the work, affects the quality of the found solution.</p><p>The compressed manifold modes method <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b23">23]</ref> has the objective to obtain local support basis functions of the (discretised) Laplace-Beltrami operator of a single input mesh. In <ref type="bibr" target="#b19">[19]</ref>, the authors obtain smooth functional correspondences between shapes that are spatially localised by using an ℓ 1 norm regulariser in combination with the row and column Dirichlet energy. The method proposed in <ref type="bibr" target="#b27">[27]</ref> is able to localise shape differences based on functional maps between two shapes. Recently, the Shape-from-Operator approach has been presented <ref type="bibr" target="#b5">[6]</ref>, where shapes are reconstructed from more general intrinsic operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Aims and Main Contributions</head><p>The work presented in this paper has the objective of learning local support deformation factors from training data. The main application of the resulting shape model is recognition, segmentation and shape interpolation <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. Whilst our work remedies several of the mentioned shortcomings of existing methods, it can also be seen as complementary to SPLOCS, which is more tailored towards artistic editing and mesh animation. The most significant difference to SPLOCS is that we aim at letting the training shapes automatically determine the location and size of each local support region. This is achieved by formulating a matrix factorisation problem that incorporates regularisation terms which simultaneously account for sparsity and smoothness of the factors, where a graph-based smoothness regulariser accounts for smoothly varying neighbour vertices. In contrast to SPLOCS or sub-PCA, this results in an implicit clustering that is part of the optimisation and does not require an initialisation of local support regions, which in turn simplifies the optimisation procedure. Moreover, by integrating a smoothness prior into our framework we can handle small training datasets, even if the desired number of factors exceeds the number of training shapes. Our optimisation problem is formulated in terms of the Structured Low-Rank Matrix Factorisation framework <ref type="bibr" target="#b13">[13]</ref>, which has appealing theoretical properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methods</head><p>First, we introduce our notation and linear shape deformation models. Then, we state the objective and its formulation as optimisation problem, followed by the theoretical motivation. Finally, the block coordinate descent algorithm and the factor splitting method are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Notation</head><p>I p denotes the p×p identity matrix, 1 p the p-dimensional vector containing ones, 0 p×q the p × q zero matrix, and S + p the set of p × p positive semi-definite matrices. Let A ∈ R p×q . We use the notation A A,B to denote the submatrix of A with the rows indexed by the (ordered) index set A and columns indexed by the (ordered) index set B. The colon denotes the full (ordered) index set, e.g. A A,: is the matrix containing all rows of A indexed by A. For brevity, we write A r to denote the p-dimensional vector formed by the r-th column of A. The operator vec(A) creates a pqdimensional column vector from A by stacking its columns, and ⊗ denotes the Kronecker product.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Linear Shape Deformation Models</head><p>Let X k ∈R N ×3 be the matrix representation of a shape comprising N points (or vertices) in 3 dimensions, and let {X k : 1 ≤ k ≤ K} be the set of K training shapes. We assume that the rows in each X k correspond to homologous points. Using the vectorisation x k = vec(X k )∈R 3N , all x k are arranged in the matrix X=[x 1 , . . . , x K ]∈R 3N ×K . We assume that all shapes have the same pose, are centred at the mean shapeX, i.e. k X k =0 N ×3 , and that the standard deviation of vec(X) is one.</p><p>Pairwise relations between vertices are modelled by a weighted undirected graph G=(V, E, ω) that is shared by all shapes. The node set V={1, . . . , N } enumerates all N vertices, the edge set E⊆{1, . . . , N } 2 represents the connectivity of the vertices, and ω∈R |E| + is the weight vector. The (scalar) weight ω e of edge e=(i, j) ∈ E denotes the affinity between vertex i and j, where "close" vertices have high value ω e . We assume there are no self-edges, i.e. (i, i) / ∈E. The graph can either encode pairwise spatial connectivity, or affinities that are not of spatial nature (e.g. symmetries, or prior anatomical knowledge in medical applications).</p><p>For the standard PCA-based method <ref type="bibr" target="#b11">[11]</ref>, the modes of variation in the M columns of the matrix Φ∈R 3N ×M are defined as the M most dominant eigenvectors of the sample covariance matrix C= 1 K−1 XX T . However, we consider the generalisation where Φ contains general 3Ndimensional vectors, the factors, in its M columns. In both cases, the (linear) deformation model (modulo the mean shape) is given by</p><formula xml:id="formula_0">y(α) = Φα ,<label>(1)</label></formula><p>with weight vector α ∈ R M . Due to vectorisation, the rows with indices {1, . . . , N }, {N +1, . . . , 2N } and {2N +1, . . . , 3N } of y (or Φ), correspond to the x, y and z components of the N vertices of the shape, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Objective and Optimisation Problem</head><p>The objective is to find Φ = [Φ 1 , . . . , Φ M ] and A = [α 1 , . . . , α K ] ∈ R M ×K for a given M &lt; 3N such that, according to eq. (1), we can write</p><formula xml:id="formula_1">X ≈ ΦA ,<label>(2)</label></formula><p>where the factors Φ m have local support. Local support means that Φ m is sparse and that all active vertices, i.e. vertices that correspond to the non-zero elements of Φ m , are connected by (sequences of) edges in the graph G. Now we state our problem formally as an optimisation problem. The theoretical motivation thereof is based on <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">7,</ref><ref type="bibr" target="#b13">13]</ref> and is recapitulated in section 2.4, where it will also become clear that our chosen regularisation term is related to the Projective Tensor Norm <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">13]</ref>.</p><p>A general matrix factorisation problem with squared Frobenius norm loss is given by</p><formula xml:id="formula_2">min Φ,A X − ΦA 2 F + Ω(Φ, A) ,<label>(3)</label></formula><p>where the regulariser Ω imposes certain properties upon Φ and A. The optimisation is performed over some compact set (which we assume implicitly from here on). An obvious property of local support factors is sparsity. Moreover, it is desirable that neighbour vertices vary smoothly. Both properties together seem to be promising candidates to obtain local support factors, which we reflect in our regulariser. Our optimisation problem is given by</p><formula xml:id="formula_3">min Φ∈R 3N ×M A∈R M ×K X−ΦA 2 F + λ M m=1 Φ m Φ (A m,: ) T A ,<label>(4)</label></formula><p>where · Φ and · A denote vector norms.</p><formula xml:id="formula_4">For z ′ ∈ R K , z ∈ R 3N , we define z ′ A = λ A z ′ 2 , and<label>(5)</label></formula><formula xml:id="formula_5">z Φ = λ 1 z 1 +λ 2 z 2 + λ ∞ z H 1,∞ + λ G Ez 2 . (6)</formula><p>Both ℓ 2 norm terms will be discussed in section 2.4. The ℓ 1 norm is used to obtain sparsity in the factors. The (mixed)</p><formula xml:id="formula_6">ℓ 1 /ℓ ∞ norm is defined by z H 1,∞ = g∈H z g ∞ ,<label>(7)</label></formula><p>where z g denotes a subvector of z indexed by g ∈ H. By using the collection H = {{i, i + N, i + 2N } : 1 ≤ i ≤ N }, a grouping of the x, y and z components per vertex is achieved, i.e. within a group g only the component with largest magnitude is penalised and no extra cost is to be paid for the other components being non-zero. The last term in eq. (6), the graph-based ℓ 2 (semi-)norm, imposes smoothness upon each factor, such that neighbour elements according to the graph G vary smoothly. Based on the incidence matrix of G, we choose E such that</p><formula xml:id="formula_7">Ez 2 = d∈{0,N,2N } (i,j)=ep∈E ω ep (z d+i − z d+j ) 2 . (8)</formula><p>As such, E is a discrete (weighted) gradient operator and E · 2 2 corresponds to Graph-Laplacian regularisation <ref type="bibr" target="#b18">[18]</ref>. E is specified in the supplementary material.</p><p>The structure of our problem formulation in eqs. (4), (5), (6) allows for various degrees-of-freedom in the form of the parameters. They allow to weigh the data term versus the regulariser (λ), control the rank of the solution (λ A and λ 2 together, cf. last paragraph in section 2.4), control the sparsity (λ 1 ), control the amount of grouping of the x, y and z components (λ ∞ ) and control the smoothness λ G . The number of factors M has an impact on the size of the support regions (for small M the regions tend to be larger, whereas for large M they tend to be smaller).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Theoretical Motivation</head><p>For a matrix X ∈ R 3N ×K and vector norms · Φ and · A , let us define the function</p><formula xml:id="formula_8">ψ M (X) = min {(Φ∈R 3N ×M , A∈R M ×K ): ΦA=X} M m=1 Φ m Φ (A m,: ) T A . (9)</formula><p>The function ψ(·)= lim M →∞ ψ M (·) defines a norm known as Projective Tensor Norm or Decomposition Norm <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">13]</ref>.</p><formula xml:id="formula_9">Lemma 1. For any ǫ &gt; 0 there exists an M (ǫ) ∈ N such that ψ(X) − ψ M (ǫ) (X) &lt; ǫ. Proof. For ψ(X) there are sequences {Φ i } ∞ i=1 and {A T i } ∞ i=1 such that ψ(X) = ∞ i=1 Φ i Φ A T i A . Let l m = m i=1 Φ i Φ A T i A .</formula><p>The sequence l m is monotone, bounded from above and convergent. Let l ∞ = ψ(X) denote its limit. Since the sequence is convergent, there is</p><formula xml:id="formula_10">M (ǫ) such that l ∞ − l j &lt; ǫ for j ≥ M (ǫ).</formula><p>We now proceed by introducing the optimisation problem</p><formula xml:id="formula_11">min Z X − Z 2 F + λψ M (Z) .<label>(10)</label></formula><p>Next, we establish a connection between problem (10) and our problem <ref type="bibr" target="#b3">(4)</ref>. First, we assume that we are given a solution pair (Φ, A) minimising problem (4). By defining Z = ΦA, Z is a solution to problem <ref type="bibr" target="#b10">(10)</ref>. Secondly, assume we are given a solution Z minimising problem <ref type="bibr" target="#b10">(10)</ref>.</p><p>To find a solution solution pair (Φ, A) minimising problem (4), one needs to compute the (Φ, A) that achieves the minimum of the right-hand side of (9) for a given Z.</p><p>This shows that given a solution to one of the problems, one can infer a solution to the other problem. Next we reformulate problem <ref type="bibr" target="#b10">(10)</ref>. Following <ref type="bibr" target="#b13">[13]</ref>, we define the matrices Q ∈ R 3N +K×M , Y ∈ R 3N +K×3N +K as</p><formula xml:id="formula_12">Q = Φ A T , Y = QQ T = ΦΦ T ΦA A T Φ T A T A ,<label>(11)</label></formula><p>and the function F :</p><formula xml:id="formula_13">S + 3N +K → R as F (Y) = F (QQ T ) = X − ΦA 2 F + λψ M (ΦA) . (12) Let Y * = arg min Y∈S + 3N +K F (Y) .<label>(13)</label></formula><p>For a given Y * , problem <ref type="formula" target="#formula_0">(10)</ref> is minimised by the upperright block matrix of Y * . The difference between <ref type="formula" target="#formula_0">(10)</ref> and <ref type="bibr" target="#b13">(13)</ref> is that the latter is over the set of positive semi-definite matrices, which, at first sight, does not present any gain. However, under certain conditions, the global solution for Q, rather than the product Y = QQ T , can be obtained directly <ref type="bibr" target="#b7">[7]</ref>. In <ref type="bibr" target="#b0">[1]</ref> it is shown that if Q is a rank deficient local minimum of F (QQ T ), then it is also a global minimum. Whilst these results only hold for twice differentiable functions F , Haeffele et al. have presented analogous results for the case of F being a sum of a twice-differentiable term and a non-differentiable term <ref type="bibr" target="#b13">[13]</ref>, such as ours above. As such, any (rank deficient) local optimum of problem (4) is also a global optimum. If in ψ(·), both · Φ and · A are the ℓ 2 norm, ψ(·) is equivalent to the nuclear norm, commonly used as convex relaxation of the matrix rank <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b26">26]</ref>. In order to steer the solution towards being rank deficient, we include ℓ 2 norm terms in · Φ and · A (see <ref type="bibr" target="#b4">(5)</ref> and <ref type="formula">(6)</ref>). With that, part of the regularisation term in (4) is the nuclear norm that accounts for low-rank solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Block Coordinate Descent</head><p>A solution to problem (4) is found by block coordinate descent (BCD) <ref type="bibr" target="#b36">[36]</ref> (algorithm 1). It employs alternating proximal steps, which can be seen as generalisation of gradient steps for non-differentiable functions.</p><p>Since com-</p><formula xml:id="formula_14">repeat // update Φ Φ ′ ← Φ − ǫΦ∇Φ X − ΦA 2 F // gradient step (loss) for m = 1, . . . , M do // proximal step Φ (penalty) Φm ← prox λ · Φ (Am,: ) T A (Φ ′ m ) // update A A ′ ← A − ǫ A ∇ A X − ΦA 2 F // gradient step (loss) for m = 1, . . . , M do // proximal step A (penalty) Am,: ← prox λ Φm Φ · A ((A ′ m,: ) T ) T until convergence</formula><p>Algorithm 1: Simplified view of block coordinate descent. For details see <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b36">36]</ref>. puting the proximal mapping is repeated in each iteration, an efficient computation is essential. The proximal mapping of · A in eq. (5) has a closed-form solution by block soft thresholding <ref type="bibr" target="#b25">[25]</ref>. The proximal mapping of · Φ in eq. (6) is solved by dual forward-backward splitting <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b10">10]</ref> (see supplementary material). The benefit of BCD is that it scales well to large problems (cf. complexity analysis in the supplementary material). However, a downside is that by using the alternating updates one has only guaranteed convergence to a Nash equilibrium point <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b36">36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Factor Splitting</head><p>Whilst solving problem (4) leads to smooth and sparse factors, there is no guarantee that the factors have only a single local support region. In fact, as motivated in section 2.4, the solution of eq. (4) is steered towards being low-rank. However, the price to pay for a low-rank solution is that capturing multiple support regions in a single factor is preferred over having each support region in an individual factor (e.g. for M = 2 and any a = 0, b = 0, the matrix Φ = [Φ 1 Φ 2 ] has a lower rank when</p><formula xml:id="formula_15">Φ 1 = [a T b T ] T and Φ 2 = 0, com- pared to Φ 1 = [a T 0 T ] T and Φ 2 = [0 T b T ] T ).</formula><p>A simple yet effective way to deal with this issue is to split factors with multiple disconnected support regions into multiple (new) factors (see supplementary material). Since this is performed after the optimisation problem has been solved, it is preferable over pre-or intra-processing procedures <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b24">24]</ref> since the optimisation remains unaffected and the data term in eq. (4) does not change due to the splitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Results</head><p>We compared the proposed method with PCA <ref type="bibr" target="#b11">[11]</ref>, kernel PCA (kPCA, cf. 3.2.2), Varimax <ref type="bibr" target="#b14">[14]</ref>, ICA <ref type="bibr" target="#b16">[16]</ref>, SPCA <ref type="bibr" target="#b17">[17]</ref>, SSPCA <ref type="bibr" target="#b17">[17]</ref>, and SPLOCS [24] on two real datasets, brain structures and human body shapes. Only our method and the SPLOCS method explicitly aim to obtain local support factors, whereas the SPCA and SSPCA methods obtain sparse factors (for the latter the ℓ 1 /ℓ 2 norm with groups defined by H, cf. eq. (7), is used). The methods kPCA, SPCA, SSPCA, SPLOCS and ours require to set various parameters, which we address by random sampling (see supplementary material).</p><p>For all evaluated methods a factorisation ΦA is obtained. W.l.o.g. we normalise the rows of A to have standard deviation one (since ΦA = ( 1 s Φ)(sA) for s = 0). Then, the factors in Φ are ordered descendingly according to their ℓ 2 norms.</p><p>In our method, the number of factors may be changed due to factor splitting, thus, in order to allow a fair comparison, we only retain the first M factors. Initially, the columns of Φ are chosen to M (unique) columns selected randomly from I 3N . This is in accordance with <ref type="bibr" target="#b13">[13]</ref>, where empirically good results are obtained using trivial initialisations. Convergence plots for different initialisations can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Quantitative Measures</head><p>For x = vec(X) andx = vec(X), the average error</p><formula xml:id="formula_16">e avg (x,x) = 1 N N i=1 X i,: −X i,: 2<label>(14)</label></formula><p>and the maximum error</p><formula xml:id="formula_17">e max (x,x) = max i=1,...,N X i,: −X i,: 2<label>(15)</label></formula><p>measure the agreement between shape X and shapeX. The reconstruction error for shape x k is measured by solving the overdetermined system Φα k = x k for α k in the least-squares sense, and then computing e avg (x k , Φα k ) and e max (x k , Φα k ), respectively.</p><p>To measure the specificity error, n s shape samples are drawn randomly (n s =1000 for the brain shapes and n s =100 for the body shapes). For each drawn shape, the average and maximum errors between the closest shape in the training set are denoted by s avg and s max , respectively. For simplicity, we assumed that the parameter vector α follows a zero mean Gaussian distribution, where the covariance matrix C α is estimated from the parameter vectors α k of the K training shapes. With that, a random shape sample x r is generated by drawing a sample of the vector α r from its distribution and setting x r = Φα r . The specificity can be interpreted as a score for assessing how realistic synthesized shapes are on a coarse level of detail (the contribution of errors on fine details to the specificity score is marginal due to the dominance of the errors on coarse scales).</p><p>For evaluating the generalisation error, a collection of index sets I ⊂ 2 {1,...,K} is used, where each set J ∈ I denotes the set of indices of the test shapes for one run and |I| is the number of runs. We used five-fold cross-validation, i.e. |I| = 5 and each set J contains round( K 5 ) random integers from {1, . . . , K}. In each run, the deformation factors ΦJ are computed using only the shapes with in-dicesJ = {1, . . . , K} \ J . For all test shapes x j , where j ∈ J , the parameter vector α j is determined by solving ΦJ α j = x j in the least-squares sense. Eventually, the average reconstruction error e avg (x j , ΦJ α j ) and the maximum reconstruction error e max (x j , ΦJ α j ) are computed for each test shape, which we denote as g avg and g max , respectively. Moreover, the sparse reconstruction errors g 0.05 avg and g 0.05 max are computed in a similar manner, with the difference that α j is now determined by using only 5% of the rows (selected randomly) of ΦJ and x j , denoted byΦJ andx j . For that, we minimise ΦJ α j −x j with respect to α j , which is a least-squares problem with Tikhonov regularisation, where Γ is obtained by Cholesky factorisation of C α = Γ T Γ. The purpose of this measure is to evaluate how well a deformation model interpolates an unseen shape from a small subset of its points, which is relevant for shape model-based surface reconstruction <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Brain Structures</head><p>The first evaluated dataset comprises 8 brain structure meshes of K=17 subjects <ref type="bibr" target="#b3">[4]</ref>. All 8 meshes together have a total number of N =1792 vertices that are in correspondence among all subjects. Moreover, all meshes have the same topology, i.e. seen as graphs they are isomorphic. A single deformation model is used to model the deformation of all 8 meshes in order to capture the interrelation between the brain structures. We fix the number of desired factors to M =96 to account for a sufficient amount of local details in the factors. Whilst the meshes are smooth and comparably simple in shape (cf. <ref type="figure" target="#fig_2">Fig. 3)</ref>, a particular challenge is that the training dataset comprises only K=17 shapes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Second-order Terms</head><p>Based on anatomical knowledge, we use the brain structure interrelation graph G bs = (V bs , E bs ) shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, where an edge between two structures denotes that a deformation of one structure may have a direct effect on the deformation of the other structure. Using G bs , we now build a  distance matrix that is then used in the SPLOCS method and our method. For o ∈ V bs , let g o ⊂ {1, . . . , N } denote the (ordered) indices of the vertices of brain structure o. Let D euc ∈ R N ×N be the Euclidean distance matrix, where (D euc ) ij = X i,: −X j,: 2 is the Euclidean distance between vertex i and j of the mean shapeX. Moreover, let D geo ∈ R N ×N be the geodesic graph distance matrix of the mean shapeX using the graph induced by the (shared) mesh topology. By D o euc ∈ R |go|×|go| and D o geo ∈ R |go|×|go| we denote the Euclidean distance matrix and the geodesic distance matrix of brain structure o, which are submatrices of D euc and D geo , respectively. Letd o denote the average vertex distance between neighbour vertices of brain structure o. We define the normalised geodesic graph distance matrix of brain structure o byD o geo = 1 d o D o geo and the matrix D geo ∈ R N ×N is composed by the individual blocksD o geo . The normalised distance matrix between structure o and o is given byD o,õ</p><formula xml:id="formula_18">bs = 2 d o +dõ [(D euc ) go,gõ −1 |go| 1 T |gõ| d o,õ min ] ∈ R |go|×|gõ| , where d o,õ</formula><p>min is the smallest element of (D euc ) go,gõ . The (symmetric) distance matrixD bs ∈ R N ×N between all structures is constructed by</p><formula xml:id="formula_19">(D bs ) go,gõ = D o,õ bs if (o,õ) ∈ E bs 0 |go|×|gõ| else .<label>(16)</label></formula><p>For the SPLOCS method we used the distance matrix D = α DDgeo + (1 − α D )D bs . For our method, we construct the graph G = (V, E, ω) (cf. section 2.2) by having an edge</p><formula xml:id="formula_20">e = (i, j) in E for each ω e = α D exp(−(D geo ) 2 i,j ) + (1 − α D ) exp(−(D bs ) 2</formula><p>ij ) that is larger than the threshold θ = 0.1. In both cases we set α D = 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Dealing with the Small Training Set</head><p>For PCA, Varimax and ICA the number of factors cannot exceed the rank of X, which is at most K−1 for K&lt;3N . For the used matrix factorisation framework, setting M to a value larger than the expected rank of the solution but smaller than full rank has empirically led to good results <ref type="bibr" target="#b13">[13]</ref>. However, since our expected rank is M = 96 and the full rank is at most K−1 = 16, this is not possible.</p><p>We compensate the insufficient amount of training data by assuming smoothness of the deformations. Based on concepts introduced in <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b35">35]</ref>, instead of the data matrix X, we factorise the kernelised covariance matrix K. The standard PCA method finds the M most dominant eigenvectors of the covariance matrix C by the (exact) factorisation C = Φ diag(λ 1 , . . . , λ K−1 )Φ T . The kernelised covariance K allows to incorporate additional elasticity into the resulting deformation model. For example, K=I 3N results in independent vertex movements <ref type="bibr" target="#b35">[35]</ref>. A more interesting approach is to combine the (scaled) covariance matrix with a smooth vertex deformation. We define</p><formula xml:id="formula_21">K = 1 vec(XX T ) ∞ XX T + K euc , with K euc = I 3 ⊗ K ′ euc ∈ R 3N ×3N . Using the bandwidth β, K ′ euc is given by (K ′ euc ) ij = exp(−( (D euc ) ij 2β vec(D euc ) ∞ ) 2 ) .<label>(17)</label></formula><p>Setting Φ to the M most dominant eigenvectors of the symmetric and positive semi-definite matrix K gives the solution of kPCA <ref type="bibr" target="#b4">[5]</ref>. In terms of our proposed matrix factorisation problem in eq. (4), we find a factorisation ΦÃ of K, instead of factorising the data X. Since the regularisation term remains unchanged, the factor matrix Φ∈R 3N ×M is still sparse and smooth (due to · Φ ). Moreover, due to the nuclear norm term being contained in the product · Φ · A (cf. section 2.4), the resulting factorisation ΦÃ is steered towards being low-rank, in favour of the elaborations in section 2.4. However, the resulting matrixÃ∈R M ×3N now contains the weights for approximating K by a linear combination of the columns of Φ, rather than approximating the data matrix X by a linear combination of the columns of Φ. For the known Φ, the weights that best approximate the data matrix X are found by solving the linear system ΦA=X in the least-squares sense for A∈R M ×K .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Results</head><p>The magnitude of the deformation of the first three factors are shown in <ref type="figure" target="#fig_2">Fig. 3</ref>, where it can be seen that only SPCA, SSPCA, SPLOCS and our method obtain sparse deformation factors. The SPCA and SSPCA methods do not incor-  <ref type="figure">Figure 4</ref>. Boxplots of the quantitative measures for the brain shapes dataset. In each plot, the horizontal axis shows the individual methods and the vertical axis the error scores described in section 3.1. Compared to SPLOCS, which is the only other method explicitly striving for local support deformation factors, our method has a smaller generalisation error and sparse reconstruction error. The sparse but not spatially localised factors obtained by SPCA and SSPCA (cf. <ref type="figure" target="#fig_2">Fig. 3</ref>) result in a large maximum sparse reconstruction error (bottom right).</p><p>porate the spatial relation between vertices and as such the deformations are not spatially localised (see red arrows in <ref type="figure" target="#fig_2">Fig. 3</ref>, where more than a single region is active). The factors obtained by SPLOCS are non-smooth and do not exhibit local support, in contrast to our method, where smooth deformation factors with local support are obtained.</p><p>The quantitative results presented in <ref type="figure">Fig. 4</ref> reveal that our method has a larger reconstruction error. This can be explained by the fact that due to the sparsity and smoothness of the deformation factors a very large number of basis vectors is required in order to exactly span the subspace of the training data. Instead, our method finds a simple (sparse and smooth) representation that explains the data approximately, in favour of Occam's razor. The average reconstruction error is around 1mm, which is low considering that the brain structures span approximately 6cm from left to right. Considering specificity, all methods are comparable. PCA, Varimax and ICA, which have the lowest reconstruction errors, have the highest generalisation errors, which underlines that these methods overfit the training data. The kPCA method is able to overcome this issue due to the smoothness assumption. SPCA and SSPCA have good generalisation scores but at the same time a very high maximum reconstruction error. Our method and SPLOCS are the only ones that explicitly strive for local support factors. Since our method outperforms SPLOCS with respect to generalisation and sparse reconstruction error, we claim that our method outperforms the state of the art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Human Body Shapes</head><p>Our second experiment is based on 1531 female human body shapes <ref type="bibr" target="#b37">[37]</ref>, where each shape comprises 12500 vertices that are in correspondence among the training set. Due to the large number of training data and the high level of details in the meshes, we directly factorise the data matrix X. The edge set E now contains the edges of the triangle mesh topology and the weights for edge e = (i, j) ∈ E are given by ω e = exp(−(</p><formula xml:id="formula_22">(Deuc)ij d ) 2 )</formula><p>, whered denotes the average vertex distance between neighbour vertices. Edges with weights lower than θ=0.1 are ignored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Results</head><p>Quantitatively the evaluated methods have comparable performance, with the exception that ICA has worse overall performance <ref type="figure">(Fig. 5)</ref>. The most noticeable difference between the methods is the specificity error, where SPCA, SSPCA and our method perform best.  SPCA, SSPCA, SPLOCS and our method obtain factors with local support. Apparently, for large datasets, sparsity alone, as used in SPCA and SSPCA, is sufficient to obtain local support factors. However, our method is the only one that explicitly aims for smoothness of the factors, which leads to more realistic deformations, as shown in <ref type="figure">Fig. 7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>We presented a novel approach for learning a linear deformation model from training shapes, where the resulting factors exhibit local support. By embedding sparsity and <ref type="figure">Figure 7</ref>. Shapesx−1.5Φm for SPCA (m=1), SSPCA (m=3), SPLOCS (m=1) and our (m=1) method (cf. <ref type="figure" target="#fig_4">Fig. 6</ref>). Our method delivers the most realistic per-factor deformations. smoothness regularisers into a theoretically well-grounded matrix factorisation framework, we model local support regions implicitly, and thus get rid of the initialisation of the size and location of local support regions, which so far has been necessary in existing methods. On the small brain shapes dataset that contains relatively simple shapes, our method improves the state of the art with respect to generalisation and sparse reconstruction. For the large body shapes dataset containing more complex shapes, quantitatively our method is on par with existing methods, whilst it delivers more realistic per-factor deformations. Since articulated motions violate our smoothness assumption, our method cannot handle them. However, when smooth deformations are a reasonable assumption, our method offers a higher flexibility and better interpretability compared to existing methods, whilst at the same time delivering more realistic deformations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Brain structure interrelation graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>The colour-coded magnitude (blue corresponds to zero, yellow to the maximum deformation in each plot) for the three deformation factors with largest ℓ2 norm is shown in the rows. The factors obtained by SPCA and SSPCA are sparse but not spatially localised (see red arrows). Our method is the only one that obtains local support factors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 Figure 5 .</head><label>65</label><figDesc>Boxplots of the quantitative measures in each column for the body shapes dataset. Quantitatively all methods have comparable performance, apart from ICA which performs worse.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>The deformation magnitudes reveal that SPCA, SSPCA, SPLOCS and our method obtain local support factors (in the second factor of our method the connection is at the back). The bottom row depicts randomly drawn shapes, where only the methods with local support deformation factors result in plausible shapes.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Yipin Yang and colleagues for making the human body shapes dataset publicly available; Benjamin D. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<title level="m">Convex sparse matrix factorizations. arXiv.org</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Shape-aware 3D Interpolation using Statistical Shape Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Salamanca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thunberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hertel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goncalves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gemmar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Shape Symposium</title>
		<meeting>Shape Symposium<address><addrLine>Delemont</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Salamanca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thunberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jentsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lamecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zachow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hertel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goncalves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gemmar</surname></persName>
		</author>
		<title level="m">Shape-aware Surface Reconstruction from Sparse Data. arXiv.org</title>
		<imprint>
			<date type="published" when="2016-02" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast correspondences for statistical shape models of brain structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vlassis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gemmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Husch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thunberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goncalves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hertel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Medical Imaging</title>
		<meeting><address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning (Information Science and Statistics)</title>
		<meeting><address><addrLine>Secaucus, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag New York, Inc</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Shape-from-Operator: Recovering Shapes from Intrinsic Operators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kourounis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="page" from="265" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wiley Online Library</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Local minima and convergence in low-rank semidefinite programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Burer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Monteiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Robust principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<idno>11:1-11:37</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Dualization of signal recovery problems. Set-Valued and Variational Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Combettes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dũng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Vũ</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Proximal splitting methods in signal processing. In Fixed-point algorithms for inverse problems in science and engineering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Combettes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Pesquet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="185" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Active Shape Models -Smart Snakes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1992" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Combining point distribution models with shape models based on finite element analysis. Image and Vision Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Structured low-rank matrix factorization: Optimality, algorithm, and applications to image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haeffele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML-14)</title>
		<meeting>the 31st International Conference on Machine Learning (ICML-14)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Modern factor analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Harman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976" />
			<publisher>University of Chicago Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An inverse power method for nonlinear eigenproblems with applications in 1-spectral clustering and sparse PCA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bühler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="847" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Independent Component Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Karhunen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001-04" />
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Structured sparse principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jenatton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS Proceedings 9</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Graph-Laplacian PCA: Closed-form solution and robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Functional correspondence by matrix completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kovnatsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="905" to="914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kovnatsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Glashoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<title level="m">MADMM: a generic algorithm for non-smooth optimization on manifolds. arXiv.org</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A locally deformable statistical shape model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Last</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Winkelbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Wahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Eichhorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bootz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning in Medical Imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="51" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Key point subspace acceleration and soft caching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">74</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Compressed manifold modes for mesh processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Varanasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Theobalt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Magnor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="35" to="44" />
		</imprint>
		<respStmt>
			<orgName>Wiley Online Library</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sparse localized deformation components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Varanasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Magnor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Proximal algorithms. Foundations and Trends in Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Guaranteed minimumrank solutions of linear matrix equations via nuclear norm minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fazel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Parrilo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Map-based exploration of intrinsic shape differences and variability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Rustamov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Azencot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ben-Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chazal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">72</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Robust Principal Component Analysis on Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shahid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kalofolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sparse Decomposition and Modeling of Anatomical Shape Variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sjostrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rostrup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ryberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Studholme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Baezner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fazekas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pantoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Inzitari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Waldemar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1625" to="1635" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Sparse modeling of landmark and texture variability using the orthomax criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Stegmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sjöstrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Larsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Medical Imaging</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="61441" to="61441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Extraction of myocardial contractility patterns from short-axes MR images using independent component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Suinesiaputra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Üzümcü</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Reiber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">P</forename><surname>Lelieveldt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Mathematical Methods in Medical and Biomedical Image Analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="75" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Interactive region-based linear 3d face models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Tena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">76</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Üzümcü</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sonka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H C</forename><surname>Reiber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">P F</forename><surname>Lelieveldt</surname></persName>
		</author>
		<title level="m">ICA vs. PCA Active Appearance Models: Application to Cardiac MR Segmentation. MICCAI</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="451" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Boundary finding with correspondence using statistical shape models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">H</forename><surname>Staib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="338" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Boundary finding with prior shape and smoothness models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">H</forename><surname>Staib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A block coordinate descent method for regularized multiconvex optimization with applications to nonnegative tensor factorization and completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Semantic Parametric Reshaping of Human Body Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Second International Conference on 3D Vision</title>
		<meeting>the 2014 Second International Conference on 3D Vision</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">02</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Wavelet-Based Independent Component Analysis For Statistical Shape Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zewail</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elsafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Durdle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Canadian Conference on Electrical and Computer Engineering</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1325" to="1328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Sparse principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="265" to="286" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
