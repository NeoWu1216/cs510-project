<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Blind Image Deblurring Using Dark Channel Prior</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinshan</forename><surname>Pan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Dalian University of Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">UC</orgName>
								<address>
									<settlement>Merced</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Harvard University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Sun</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Harvard University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">NVIDIA</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanspeter</forename><surname>Pfister</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Harvard University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">UC</orgName>
								<address>
									<settlement>Merced</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Blind Image Deblurring Using Dark Channel Prior</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>a) Input (b) Our results (c) Dark channel of (a) (d) Dark channel of (b) Figure 1. Deblurring result on a challenging low-light image. The blur process makes the dark channel of the blurred image less sparse (c). Enforcing sparsity on the dark channel of the recovered image favors clean images over blurred ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We present a simple and effective blind image deblurring method based on the dark channel prior. Our work is inspired by the interesting observation that the dark channel of blurred images is less sparse. While most image patches in the clean image contain some dark pixels, these pixels are not dark when averaged with neighboring highintensity pixels during the blur process. This change in the sparsity of the dark channel is an inherent property of the blur process, which we both prove mathematically and validate using training data. Therefore, enforcing the sparsity of the dark channel helps blind deblurring on various scenarios, including natural, face, text, and low-illumination images. However, sparsity of the dark channel introduces a non-convex non-linear optimization problem. We introduce a linear approximation of the min operator to compute the dark channel. Our look-up-table-based method converges fast in practice and can be directly extended to non-uniform deblurring. Extensive experiments show that our method achieves state-of-the-art results on deblurring natural images and compares favorably methods that are well-engineered for specific scenarios.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Blind image deblurring aims to recover a blur kernel and a sharp latent image from a blurred image. This is a classical image and signal processing problem <ref type="bibr" target="#b21">[22]</ref>, which has been an active research effort in the vision and graphics community within the last decade. This problem becomes increasingly important as more photos are taken using hand-held cameras, particularly with smart phones. Camera shake is often inevitable and the resulting image blur is usually undesirable. As captured moments are ephemeral and difficult to reproduce, it is of great interest to remove blur for a higher-quality image.</p><p>When the blur is uniform and spatially invariant, we can model the blur process with the convolution operation</p><formula xml:id="formula_0">B = I ⊗ k + n,<label>(1)</label></formula><p>where B, I, k, and n denote the blur image, latent image, blur kernel, and noise, respectively, and ⊗ is the convolution operator. As only B is available, we need to recover both I and k simultaneously. This problem is highly ill-posed because many different pairs of I and k give rise to the same B, e.g., blurred images and delta blur kernels.</p><p>To make blind deblurring well posed, existing methods make assumptions on blur kernels, latent images, or both <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b35">36]</ref>. For example, numerous methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref> assume sparsity of image gradients, which has been widely used in low-level vision tasks including denoising, stereo, and optical flow. Levin et al. <ref type="bibr" target="#b18">[19]</ref> show that deblurring methods based on this prior tend to favor blurry images over original clear images, especially for algorithms formulated within the maximum a posterior (MAP) framework. To remedy this problem, a heuristic edge selection step <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b33">34]</ref> is often necessary to achieve state-of-the-art results in the MAP framework. New natural image priors have also been introduced that favor clean images over blurred ones, e.g., normalized sparsity prior <ref type="bibr" target="#b16">[17]</ref>, L 0 -regularized prior <ref type="bibr" target="#b35">[36]</ref>, and internal patch recurrence <ref type="bibr" target="#b23">[24]</ref>. However, these natural image models do not generalize well to specific images, such as face <ref type="bibr" target="#b24">[25]</ref>, text <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b25">26]</ref>, and lowillumination <ref type="bibr" target="#b11">[12]</ref> images.</p><p>We present a deblurring algorithm that achieves competitive results on both natural and specific images. Our work is motivated by an interesting observation on the blur process: dark channels (smallest values in a local neighborhood) of blurred images are less dark. Intuitively, when a dark pixel is averaged with neighboring high-intensity pixels during the blur process, its intensity increases. We show theoretically and empirically that this generic property of the blur process holds for many images. This inspires us to propose an L 0 -regularization term to minimize the dark channel of the recovered image. This new term favors clean images over blurred images in the restoration process.</p><p>Optimizing the new L 0 -regularized dark channel term is challenging. The L 0 norm is highly non-convex and the optimization involves a non-linear minimum operation. We propose an approximate linear operator based on look-up tables for the min operator, and solve the linearized L 0 minimization problem by half-quadratic splitting methods. The proposed algorithm converges quickly in practice and can be naturally extended to non-uniform deblurring tasks.</p><p>The contributions of this work are as follows: (1) we theoretically prove that the blur (convolution) operation increases the values of the dark channel pixels; (2) we empirically confirm our analysis using a dataset of 3,200 clean and blurred image pairs; (3) we introduce an L 0 -regularization term to enforce sparsity on the dark channel of latent images and develop an efficient optimization scheme; (4) our algorithm achieves state-of-the-art performance on widely-used natural image deblurring benchmarks <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b28">29]</ref>, and competitive results on specific deblurring tasks, including text, face, and low-illumination images, which are not well handled by most recent deblurring methods for natural images. Further, our method also works on non-uniform deblurring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In recent years, we have witnessed significant advances in single image deblurring <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b15">16]</ref> mainly due to the use of statistical priors on natural images and selection of salient edges for kernel estimation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>Fergus et al. <ref type="bibr" target="#b6">[7]</ref> use a mixture of Gaussians to learn an image gradient prior via variational Bayesian inference. Levin et al. <ref type="bibr" target="#b18">[19]</ref> show that the variational Bayesian inference method <ref type="bibr" target="#b6">[7]</ref> is able to avoid trivial solutions while naive MAP based methods may not. However, the variational Bayesian approach is computationally expensive, and efficient methods require approximation <ref type="bibr" target="#b19">[20]</ref>.</p><p>Efficient methods based on MAP formulations have been developed with different likelihood functions and image priors <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref>. In particular, heuristic edge selection methods for kernel estimation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b33">34]</ref> have been proposed and demonstrated effective for the MAP estimation framework <ref type="bibr" target="#b15">[16]</ref>. However, the assumption that strong edges exist in the latent images may not always hold.</p><p>To better reconstruct sharp edges for kernel estimation, recent exemplar-based methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29]</ref> exploit information contained in both a blurred input and example images from an external dataset. However, querying a large external dataset is computationally expensive.</p><p>Numerous recent methods exploit domain-specific statistical properties for deblurring, such as text <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b25">26]</ref>, face <ref type="bibr" target="#b24">[25]</ref>, and low-illumination images <ref type="bibr" target="#b11">[12]</ref>. While these domain-specific methods generate better results than generic deblurring algorithms, each application requires specific operations or significant engineering effort. In this work, we propose a generic algorithm based on how the blur process affects the dark channel.</p><p>The dark channel prior was introduced by He et al. for single image dehazing <ref type="bibr" target="#b9">[10]</ref> based on the assumption that the dark channel in the haze-free outdoor image is zero. In this work, we make the less restrictive assumption that the dark channel of the original image is sparse instead of zero, and we show that the proposed method is able to deblur a large variety of images. To enforce the sparsity of the dark channel, we develop a novel optimization scheme for the resulting non-linear non-convex problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Convolution and Dark Channel</head><p>To motivate our work, we first describe the dark channel and then its role in image deblurring. For an image I, the dark channel <ref type="bibr" target="#b9">[10]</ref> is defined by</p><formula xml:id="formula_1">D(I)(x) = min y∈N (x) min c∈{r,g,b} I c (y) ,<label>(2)</label></formula><p>where x and y denote pixel locations; N (x) is an image patch centered at x; and I c is the c-th color channel. If I is a gray-scale image, we have min c∈{r,g,b} I c (y) = I(y). The dark channel prior is mainly used to describe the minimum values in an image patch. He et al. <ref type="bibr" target="#b9">[10]</ref> observe that the dark channel of outdoor, haze-free images is almost zero. We find that most, although not all, elements of the dark channel are zero for natural images (see <ref type="figure" target="#fig_0">Figure 2</ref>(a) and (c)). However, most elements in the dark channel of blurred images are nonzero, as shown in <ref type="figure" target="#fig_0">Figure 2</ref>(b) and (d).</p><p>To explain why the dark channel of blurred images are less sparse, we derive some properties of the blur (convolution) operation. For discrete signals (images), convolution is defined as the sum of the product of the two signals after one is reversed and shifted</p><formula xml:id="formula_2">B(x) = z∈Ω k I(x+[ s 2 ]−z)k(z),<label>(3)</label></formula><p>where Ω k and s denote the domain and size of blur kernel k, k(z) ≥ 0, z∈Ω k k(z) = 1, and [·] denotes the rounding operator. We note that (3) can be regarded as the sum of a locally weighted linear combination of I. Why do blurred images have fewer dark pixels? Intuitively, the weighted sum of pixel values in a local neighborhood is larger than the minimum pixel value in the neighborhood, i.e., convolution increases the values of the dark pixels. Mathematically, we have the following proposition. Proposition 1: Let N (x) denote a patch centered at pixel x with size the same as the blur kernel. We have:</p><formula xml:id="formula_3">B(x) ≥ min y∈N (x) I(y).<label>(4)</label></formula><p>Proof. Based on the definition of convolution (3), we have</p><formula xml:id="formula_4">B(x) = z∈Ω k I(x+ s 2 −z)k(z) ≥ z∈Ω k min y∈N (x) I(y)k(z) = min y∈N (x) I(y) z∈Ω k k(z) = min y∈N (x) I(y).</formula><p>Note that when x is the dark pixel in its neighborhood, i.e., I(x) = min y∈N (x) I(y), B(x) ≥ I(x). This means that the intensity values of dark pixels in I tend to become larger after the convolution, as shown in <ref type="figure" target="#fig_0">Figure 2</ref>.</p><p>Proposition 1 enables us to derive two properties to describe the changes caused to blurred images by convolution: </p><formula xml:id="formula_5">D(B)(x) ≥ D(I)(x).<label>(5)</label></formula><p>Please see the supplementary material for the detailed proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Property 2:</head><p>Let Ω denote the domain of an image I. If there exist some pixels x ∈ Ω such that I(x) = 0, we have:  where the L 0 norm · 0 counts the nonzero elements of D(I). Property 2 directly follows from Property 1.</p><formula xml:id="formula_6">D(B)(x) 0 &gt; D(I)(x) 0 ,<label>(6)</label></formula><p>We further validate our analysis using a dataset of 3,200 natural images. <ref type="bibr" target="#b0">1</ref> As shown in <ref type="figure" target="#fig_3">Figure 3</ref>, the dark channels of clear images have significantly more zero elements than those of blurred images. This property also holds for other image types, such as text and saturated images (please see Section 7 and the supplemental material for the statistics). Thus, the sparsity of dark channels is a natural metric to distinguish clear images from blurred images. This observation motivates us to introduce a new regularization term to enforce sparsity of dark channels in latent images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Model and Optimization</head><p>From our analysis and observations, we use the D(I) 0 norm to measure sparsity of dark channels. We add this constraint to a standard formulation for image deblurring as</p><formula xml:id="formula_7">min I,k I ⊗ k − B 2 2 + γ k 2 2 + µ ∇I 0 + λ D(I) 0 ,<label>(7)</label></formula><p>where the first term imposes that the convolution output of the recovered image and the blur kernel should be similar to the observation; the second term is used to regularize the solution of the blur kernel; the third term on image gradients retains large gradients and removes tiny details <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b35">36]</ref>; γ, µ, and λ are weight parameters. We use coordinate descent to alternatively solve for the latent image I:</p><formula xml:id="formula_8">min I I ⊗ k − B 2 2 + µ ∇I 0 + λ D(I) 0 ,<label>(8)</label></formula><p>and the blur kernel k:</p><formula xml:id="formula_9">min k I ⊗ k − B 2 2 + γ k 2 2 .<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Estimating the Latent Image I</head><p>Minimizing <ref type="formula" target="#formula_8">(8)</ref> is computationally intractable because of the L 0 -regularized term and the non-linear function D(·).</p><p>To tackle the L 0 -regularized term, we use the half-quadratic splitting L 0 minimization approach <ref type="bibr" target="#b34">[35]</ref>. Similar to <ref type="bibr" target="#b25">[26]</ref>, we introduce the auxiliary variables u with respect to D(I) and g = (g h , g v ) corresponding to image gradients in the horizontal and vertical directions. The objective function (8) can be rewritten as:</p><formula xml:id="formula_10">min I,u,g I ⊗ k − B 2 2 + α ∇I − g 2 2 + β D(I) − u 2 2 + µ g 0 + λ u 0 ,<label>(10)</label></formula><p>where α and β are penalty parameters. When α and β are close to infinity, the solution of (10) approaches that of (8) <ref type="bibr" target="#b31">[32]</ref>. We can solve (10) by alternatively minimizing I, u, and g while fixing the other variables. Note that given I, the subproblems of solving for the auxiliary variables u and g do not involve the nonlinear function D(·). Now we will explain how to deal with the nonlinear min operator when solving for I:</p><formula xml:id="formula_11">min I I ⊗ k − B 2 2 + α ∇I − g 2 2 + β D(I) − u 2 2 . (11)</formula><p>Our observation is that the non-linear operation D(I) is equivalent to a linear operator M applied to the vectorized image I. <ref type="bibr" target="#b1">2</ref> Let y = argmin z∈N (x) I(z). M satisfies:</p><formula xml:id="formula_12">M(x, z) = 1, z = y, 0, otherwise.<label>(12)</label></formula><p>Multiplying the x-th row of M with I gives the value of the pixel y, i.e., I(y) or equivalently D(I)(x) (see the top row in <ref type="figure" target="#fig_4">Figure 4</ref>). Given the previous estimated intermediate latent image, we can construct the desired matrix M according to <ref type="bibr" target="#b11">(12)</ref>, as shown in <ref type="figure" target="#fig_4">Figure 4</ref>. For the true clear image, MI = D(I) strictly holds. Without the clear image, we compute an approximation of M using the intermediate result at each iteration. As the intermediate result becomes closer to the clear image, M approaches to the desired D. Empirically, we find that the approximation scheme converges well, as shown in <ref type="figure" target="#fig_1">Figure 15</ref>.</p><p>Given the selection matrix M, we solve for I by:</p><formula xml:id="formula_13">min I T k I − B 2 2 + α ∇I − g 2 2 + β MI − u 2 2 ,<label>(13)</label></formula><p>where T k is a Toeplitz (convolution) matrix of k, B, g, and u denote vector forms of B, g, and u, respectively. The matrix-vector production with respect to the Toeplitz matrix can be achieved using the Fast Fourier Transform (FFT) <ref type="bibr" target="#b31">[32]</ref>. The solution of (13) can be obtained according to <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b35">36]</ref>. <ref type="bibr" target="#b1">2</ref> For consistency, we use D(I) to denote the vector form of D(I).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intermediate image I D(I)</head><p>Visualization of u u Given I, we compute u and g separately by:</p><formula xml:id="formula_14">min u β D(I) − u 2 2 + λ u 0 , min g α ∇I − g 2 2 + µ g 0 .<label>(14)</label></formula><p>We note that <ref type="formula" target="#formula_0">(14)</ref> is an element-wise minimization problem. Thus, the solution of u is:</p><formula xml:id="formula_15">u = D(I), |D(I)| 2 λ β , 0, otherwise,<label>(15)</label></formula><p>and similarly for the solution of g. The algorithmic details of (10) are presented in the supplemental material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Estimating Blur Kernel k</head><p>Given I, the kernel estimation in <ref type="formula" target="#formula_9">(9)</ref> is a least squares problem. We note that kernel estimation methods based on gradients have been shown to be more accurate <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b35">36]</ref> (see analysis in the supplemental material). Thus, we estimate the blur kernel k by:</p><formula xml:id="formula_16">min k ∇I ⊗ k − ∇B 2 2 + γ k 2 2 .<label>(16)</label></formula><p>Similar to existing approaches <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b35">36]</ref>, we obtain the solution of (16) by FFTs. After obtaining k, we set the negative elements of k to 0, and normalize k so that k satisfies our definition of the blur kernel. Similar to state-of-the-art methods, the proposed kernel estimation process is carried out in a coarse-to-fine manner using an image pyramid <ref type="bibr" target="#b4">[5]</ref>. Algorithm 1 shows the main steps for the kernel estimation algorithm on one pyramid level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Extension to Non-Uniform Deblurring</head><p>Our method can be directly extended to handle nonuniform deblurring where the blurred images are acquired from moving cameras (e.g., rotational and translational  movements) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33]</ref>. Based on the geometric model of camera motion <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b32">33]</ref>, the non-uniform blur model can be expressed as:</p><formula xml:id="formula_17">B = t k t H t I + n,<label>(17)</label></formula><p>where I and n denote vector forms of I, n in <ref type="formula" target="#formula_0">(1)</ref>; t is the index of camera pose samples; H t is a matrix derived from the homography matrix in <ref type="bibr" target="#b32">[33]</ref>; k t is the weight corresponding to the t-th camera pose, which satisfies k t ≥ 0 and t k t = 1. Similar to <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b16">(17)</ref> can be expressed as:</p><formula xml:id="formula_18">B = KI + n = Ak + n,<label>(18)</label></formula><p>where k is a vector and its element is composed of the weight k t . Based on (18), the non-uniform deblurring process is achieved by alternatively minimizing: min</p><formula xml:id="formula_19">I KI − B 2 2 + λ D(I) 0 + µ ∇I 0<label>(19)</label></formula><p>and min</p><formula xml:id="formula_20">k Ak − B 2 2 + γ k 2 2 .<label>(20)</label></formula><p>We employ the fast forward approximation <ref type="bibr" target="#b10">[11]</ref> to estimate the latent image I and the weight k. The algorithmic details are presented in the supplementary material. Our MAT-LAB code is publicly available on the authors' websites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experimental Results</head><p>We examine our method on two natural image deblurring datasets <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b28">29]</ref> and compare it to state-of-the-art natural image deblurring methods. Then, we evaluate our method using text <ref type="bibr" target="#b25">[26]</ref>, face <ref type="bibr" target="#b24">[25]</ref>, and low-illumination <ref type="bibr" target="#b11">[12]</ref> images and further compare it to methods specially designed for these tasks. Finally, we report results on images undergoing non-uniform blurs. Due to the comprehensive experiments performed, we only show a small portion of the results in the main paper. Please see the supplementary document for more and larger result images.</p><p>Parameter setting: In all experiments, we set λ = µ = 0.004, γ = 2, and the neighborhood size to compute the dark channel in (2) to be 35 (please see the supplemental material for analysis). We empirically set max iter = 5 as a trade-off between accuracy and speed. As our focus is on the kernel estimation, We follow the practice <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b33">34]</ref> to use a non-blind deblurring method to recover the final latent image with our estimated kernel. We use the non-blind method <ref type="bibr" target="#b25">[26]</ref> unless otherwise mentioned. Our MATLAB code is publicly available on the authors' websites.</p><p>Natural images: We use the image dataset by Köhler et al. <ref type="bibr" target="#b15">[16]</ref>, which contains 4 images and 12 blur kernels. The PSNR value is computed by comparing each restored image with 199 clear images captured along the camera motion trajectory. As shown in <ref type="figure" target="#fig_5">Figure 5</ref>(a), our method has the highest average PSNR among all the methods evaluated. <ref type="figure">Figure 6</ref> shows results on a challenging example with heavy blur. Although state-of-the-art methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b33">34]</ref> are able to deal with large blur in most places, their deblurred images contain moderate ringing artifacts. In contrast, our result has fewer artifacts and clearer details.</p><p>Next, we evaluate our method on the dataset by Sun et al. <ref type="bibr" target="#b28">[29]</ref>, which contains 80 images and 8 blur kernels. For fair comparisons, we use the provided codes of state-of-theart methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36]</ref> to estimate blur kernels and use the non-blind deblurring method <ref type="bibr" target="#b37">[38]</ref> to generate the final deblurring results. We use the error ratio <ref type="bibr" target="#b18">[19]</ref> as the quality metric. As <ref type="figure" target="#fig_5">Figure 5</ref>(b) shows, our method consistently outperforms state-of-the-art methods.</p><p>We further test our method using a real natural image <ref type="figure">(Figure 7)</ref>. We use the same non-blind deconvolution method <ref type="bibr" target="#b25">[26]</ref> with blur kernels estimated by each method. While several state-of-the-art methods <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b35">36]</ref> produce strong ringing artifacts and blur effects, our method generate clearer images. The deblurred image by our method without the dark channel prior contains considerable artifacts, suggesting the effectiveness of the dark channel prior. Text images: <ref type="table">Table 1</ref> summarizes the PSNR results on the text image dataset <ref type="bibr" target="#b25">[26]</ref>, which contains 15 clear text images and 8 blur kernels. The average PSNR by our method is at least 1.7dB higher than those by other natural image deblurring methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36]</ref> and less than 0.9dB lower than that by the specially-designed method <ref type="bibr" target="#b25">[26]</ref>. Visually, the recovered image by our method compares favorably to that by <ref type="bibr" target="#b25">[26]</ref>  <ref type="figure">(Figure 8</ref>).</p><p>Low-illumination images: Blurred images captured in low-illumination scenes are particularly challenging for most deblurring methods, because they often have saturated pixels that interfere with the kernel estimation process <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12]</ref>. For example, the kernel estimate by <ref type="bibr" target="#b35">[36]</ref> looks like a delta kernel due to the influence of saturated regions as shown in <ref type="figure">Figure 9</ref>(b); and the deblurred image has significant residual blur. Compared with the clean image, the (a) Input (b) Cho and Lee <ref type="bibr" target="#b4">[5]</ref> (c) Xu and Jia <ref type="bibr" target="#b33">[34]</ref> (d) Ours without D(I) (e) Ours with D(I) <ref type="figure">Figure 6</ref>. Visual comparisons using one challenging image from the dataset <ref type="bibr" target="#b15">[16]</ref>. The deblurred images from other methods are from the reported results in <ref type="bibr" target="#b15">[16]</ref>. The recovered image by the proposed algorithm with the dark channel prior is visually more pleasing. <ref type="table">Table 1</ref>. Quantitative evaluations on the text image dataset <ref type="bibr" target="#b25">[26]</ref>. Our method outperforms several recent deblurring methods for natural images and is comparable to the method designed for text images <ref type="bibr" target="#b25">[26]</ref>. <ref type="bibr">Cho</ref> and Lee <ref type="bibr" target="#b4">[5]</ref> Xu and Jia <ref type="bibr" target="#b33">[34]</ref> Krishnan et al. <ref type="bibr" target="#b16">[17]</ref> Levin et al. <ref type="bibr" target="#b19">[20]</ref> Xu et al. <ref type="bibr" target="#b35">[36]</ref> Pan et al. <ref type="bibr">[</ref>  blurred image with saturated regions also has a less sparse dark channel. As a result, directly applying our method produces results comparable to <ref type="bibr" target="#b11">[12]</ref>, which has been specifically designed for low-light conditions. Face images: Blurred face images are also challenging for methods designed for natural images, because they contain fewer edges or textures <ref type="bibr" target="#b24">[25]</ref> for kernel estimation. As shown in <ref type="figure" target="#fig_1">Figure 10</ref>, our method compares favorably against <ref type="bibr" target="#b24">[25]</ref>, which explicitly explores facial structures using an examplar dataset. Non-uniform deblurring: As our method can naturally be (a) Input (b) Xu et al. <ref type="bibr" target="#b35">[36]</ref> (c) Hu et al. <ref type="bibr" target="#b11">[12]</ref> (d) Ours extended to deal with non-uniform blur, we also report results on an image degraded by spatially-variant motion blur in <ref type="figure" target="#fig_1">Figure 11</ref> (please see the supplemental material for more examples and large images). Compared with the state-ofthe-art non-uniform deblurring method <ref type="bibr" target="#b35">[36]</ref>, our method generates images with fewer artifacts and clearer textures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Analysis and Discussions</head><p>It is surprising that the dark channel prior enables us to design a method that outperforms state-of-the-art methods on natural images but also obtains competitive results on (a) Input (b) Krishnan et al. <ref type="bibr" target="#b16">[17]</ref> (c) Whyte et al. <ref type="bibr" target="#b32">[33]</ref> (d) Xu et al. <ref type="bibr" target="#b35">[36]</ref> (e) Ours (f) Our kernels <ref type="figure" target="#fig_1">Figure 11</ref>. The dark channel prior directly applies to images with non-uniform blur. The parts in red boxes in (b)-(d) still contain ringing artifacts and residual blurs. (Best viewed on highresolution display with zoom-in.) specific scenarios without using domain knowledge. In this section, we further analyze the proposed method, compare it with related methods, and discuss its limitations.</p><p>Effectiveness of the dark channel prior: Our method without the dark channel prior reduces to the deblurring method of Xu et al. <ref type="bibr" target="#b35">[36]</ref>. To ensure fair comparison, we disable the dark channel prior in our implementation. As shown in <ref type="figure" target="#fig_0">Figure 12</ref>(f) and (g), using the dark channel prior generates intermediate results with more sharp edges, which favors clear images and facilitates kernel estimation. Also, the dark channel of the intermediate results becomes sparser with more iterations <ref type="figure" target="#fig_0">(Figure 12(h)</ref>). We quantitatively evaluate our method with and without the dark channel prior using two benchmark datasets <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b18">19]</ref>. The results in <ref type="figure" target="#fig_1">Figure 13</ref> show that the dark channel prior consistently improves deblurring. In particular, our method with the dark channel prior has 100% success rate on the dataset by Levin et al. <ref type="bibr" target="#b18">[19]</ref>. All these results concretely demonstrate the effectiveness of the dark channel prior. Favored minimum of the energy function: The dark channel prior is effective because it has lower energy for clear images than for blurred ones. Two notable methods <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b23">24]</ref> also have energy functions with similar properties. However, they are mainly designed for natural images and are less effective for specific scenarios (e.g., text and low-illumination images). For example, the normalized sparsity prior <ref type="bibr" target="#b16">[17]</ref> gives lower energy to clear natural images than blurred images, but does not always favor clear text images ( <ref type="figure" target="#fig_1">Figure 14(b)</ref>). In contrast, the dark channel prior favors clear text images <ref type="figure" target="#fig_1">(Figure 14(a)</ref>). In <ref type="bibr" target="#b23">[24]</ref>, internal patch recurrence is exploited for image deblurring. The method performs well when images have repeated patterns among patches, but may fail otherwise. Our analysis and observation suggest that the dark channel prior can broadly apply to scenarios where blur makes the dark channel less sparse.</p><p>He et al. <ref type="bibr" target="#b9">[10]</ref> first introduce the dark channel prior for image dehazing. They assume that all elements of the dark channel are zero, which mainly holds for outdoor haze-free (a) Input (b) Xu et al. <ref type="bibr" target="#b35">[36]</ref> (c) Pan et al. <ref type="bibr" target="#b25">[26]</ref> (d) Ours</p><p>(e) Intermediate results of <ref type="bibr" target="#b25">[26]</ref> (f) Intermediate results of our method without using dark channel prior images. In contrast, our analysis shows that, generally, the blur operation makes the dark channel of clean images less sparse. Therefore, we assume that the dark channel of clear images is sparse. Empirically, this assumption holds not only for natural images, but also for specific scenarios, including text <ref type="figure" target="#fig_1">(Figure 14</ref>(a)) and saturated images <ref type="figure" target="#fig_1">(Figure 1</ref>). Note that the dark channel prior and domain knowledge are more likely to be complementary than contradictory. Future work could study the relationship between these complementary priors.</p><p>Relation with L 0 -regularized deblurring methods: Two previous methods <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b35">36]</ref> have used L 0 -regularized priors for deblurring. The method <ref type="bibr" target="#b35">[36]</ref> assumes L 0 sparsity on image gradients, which performs well on natural images but is less effective for text images <ref type="figure">(Figure 8(b)</ref>). The method <ref type="bibr" target="#b25">[26]</ref> assumes L 0 sparsity on both the intensity and gradients for deblurring text images. The L 0 -regularized intensity term plays a key role in text image deblurring, because the intensity values (histograms) of text images are close to two- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ours without dark channel Ours</head><p>(a) Results on the dataset <ref type="bibr" target="#b15">[16]</ref> (b) Results on the dataset <ref type="bibr" target="#b18">[19]</ref>  <ref type="figure" target="#fig_1">Figure 13</ref>. Quantitative results of our method with and without the dark channel prior on two benchmark datasets. The dark channel prior consistently improves the results. In particular, our method with the dark channel prior has 100 % success at error ratio 2 on the dataset by Levin et al. <ref type="bibr" target="#b18">[19]</ref>.  <ref type="figure" target="#fig_1">Figure 14</ref>. Statistics of different priors on the text image deblurring dataset <ref type="bibr" target="#b25">[26]</ref>. The normalized sparsity prior <ref type="bibr" target="#b16">[17]</ref> (i.e., L1/L2) sometimes favors blurred text images.</p><p>tone. However, the intensity histograms of natural images are more complex than those of text images, and this prior is not applicable to natural image deblurring problems <ref type="figure">(Figure 7(d)</ref>). The intermediate results in <ref type="figure" target="#fig_0">Figure 12</ref>(e) also show that although this L 0 -regularized intensity term helps preserve significant contrast compared to (f), it fails to recover useful structures for kernel estimation. Convergence property: As our energy function is nonlinear and highly non-convex, a natural question is whether our optimization method converges (to a good local minimum). We quantitatively evaluate convergence properties of our method on the benchmark dataset by Levin et al. <ref type="bibr" target="#b18">[19]</ref>. <ref type="figure" target="#fig_1">Figure 15</ref>(a) and (b) suggest that the proposed method converges after less than 50 iterations, in terms of the average kernel similarity values <ref type="bibr" target="#b12">[13]</ref> and the energies computed from <ref type="bibr" target="#b6">(7)</ref>. Note that the kernel estimation methods based on image intensity (i.e., <ref type="bibr" target="#b8">(9)</ref>) and gradients (i.e., <ref type="bibr" target="#b15">(16)</ref>) have similar convergence properties. More discussions are included in the supplemental material.</p><p>Computational complexity: Compared to the L 0regularized methods <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b35">36]</ref>, our method additionally requires computing the dark channel and look-up table. The complexity of this step is O(N ) and independent of patch size <ref type="bibr" target="#b17">[18]</ref>, where N is the number of pixels. This is the main bottleneck. Other steps can be accelerated by FFTs. Our method takes about 17 seconds for a 255 × 255 image on a computer with an Intel Core i7-4790 processor and 28 G-  <ref type="formula" target="#formula_0">(15)</ref> is likely to be D(I) as the value of λ β will be much smaller than that of D(I). Thus, the constraint D(I) 0 would have no effect on the intermediate latent image estimation. As a result, our method with and without the dark channel have almost the same result (see the supplemental material). In addition, our method assumes that only the blur process changes the sparseness of the dark channel. Significant noise may affect the dark pixels of an image, which accordingly interferes with the kernel estimation (see the supplemental material for examples and more discussions). Future work will consider joint deblurring and denoising using the dark channel prior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Concluding Remarks</head><p>Based on an analysis of the convolution operation and its effect on the dark channel of blurred images, we have introduced a simple and effective blind image deblurring algorithm. The proposed dark channel prior captures the changes to blurred images caused by the blur process, and favors clear images over blurred ones in the deblurring process. To restore images regularized by the dark channel prior, we develop an effective optimization algorithm based on a half-quadratic splitting strategy and look-up tables. The proposed algorithm does not require heuristic edge selection steps or any complex processing techniques in kernel estimation, e.g., shock filtering and bilateral filtering. Furthermore, the proposed algorithm is easily extended to handle non-uniform blur. Our algorithm achieves state-of-theart results on deblurring natural images, and performs favorably against specialized methods for faces, texts, and lowillumination conditions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Blurred images have less sparse dark channels than clear images. The blur process (convolution) outputs a weighted average of pixels in a neighborhood and tends to increase the value of the minimum pixel. Top: images; bottom: corresponding dark channels computed with an image patch size of 35×35.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Property 1 :</head><label>1</label><figDesc>Let D(B) and D(I) denote the dark channel of the blurred and clear images, we have:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Intensity histograms for dark channels of both clear and blurred images in a dataset of 3,200 natural images. Blurred images have far fewer zero dark channel pixels than clear ones, confirming our analysis in the text. The dark channel of each image has been computed with an image patch size of 35 × 35.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Top: computing the dark channel D(I) of an image I by the non-linear min operator is equivalent to multiplying a linear selection matrix M with the vectorized image I. The three squares in the intermediate image denote adjacent image patches for computing the dark channel, where the minimum intensity value in each patch is marked with different colors. Bottom: the transpose M ⊤ enforces identified dark pixels to be consistent with u.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Pan et al. Michaeli and Irani Sun et al. Xu et al. Levin et al. Krishnan et al. Cho and Lee(a) Results on dataset<ref type="bibr" target="#b15">[16]</ref> (b) Results on dataset<ref type="bibr" target="#b28">[29]</ref> Quantitative evaluations on two benchmark datasets. Our method performs competitively against the state-of-the-art.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>( d )Figure 7 .Figure 8 .</head><label>d78</label><figDesc>Pan et al. [26] (e) Ours without D(I) (f) Ours with D(I) Comparisons on a real natural image. The parts in red boxes in (b)-(e) still contain significant residual blur. (Best viewed on high-resolution display with zoom-in.) (a) Input (b) Xu et al. [36] (c) Pan et al. On text images, our generic method generates results comparable to methods tailored to text. (Best viewed on highresolution display with zoom-in.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .Figure 10 .</head><label>910</label><figDesc>Results on a saturated image. The deblurring results are all generated by the non-blind deconvolution method [12]. Residual blur and ringing artifacts exist in the red boxes in (b)-(c). (Best viewed on high-resolution display with zoom-in.) (a) Input (b) Pan et al. [25] (c) Xu et al. Comparisons on blurred face images. Our method compares favorably with<ref type="bibr" target="#b24">[25]</ref>, which uses a face datasest to explore face structures for deblurring face images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>( g )Figure 12 .</head><label>g12</label><figDesc>Intermediate results of our method using dark channel prior (h) The intermediate dark channel results Deblurred images by several methods are shown in (a)-(d), and the intermediate results over iterations (from left to right) are shown in (e)-(h). With the dark channel prior, our method recovers intermediate results containing more sharp edges for kernel estimation. The dark channels of the intermediate results become darker, which favor clear images and facilitate kernel estimation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 15 .</head><label>15</label><figDesc>Fast convergence property of our method, which empirically validates our approximation of the non-linear operator.B RAM (see supplemental material for the running time of other methods and more discussions). Limitations: Despite its robust performance on a variety of challenging datasets, our method has limitations. When a clear image has no dark pixels, the dark channel prior is less likely to help kernel estimation. In this situation, Property 2 does not hold and D(B)(x) 0 = D(I)(x) 0 . The solution of u given by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Algorithm 1 Blur kernel estimation algorithmInput: Blurred image B. initialize k with results from the coarser level. Blur kernel k and intermediate latent image I.</figDesc><table>while i ≤ max iter do 
solve for I using (10). 
solve for k using (16). 
end while 
Output: </table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The images are from both BSDS<ref type="bibr" target="#b22">[23]</ref> and the Internet. The datasets are available on the authors' websites.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Framelet based blind motion deblurring from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-F</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="562" to="572" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Total variation blind deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="370" to="375" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An effective document image deblurring algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="369" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Text image deblurring using text-specific properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="524" to="537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast motion deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH Asia</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Handling outliers in non-blind image deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="495" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Removing camera shake from a single photograph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGGRAPH</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="787" to="794" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Curless. Single image deblurring using motion density functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="171" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deblurring by example using dense correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hacohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2384" to="2391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Single image haze removal using dark channel prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast removal of non-uniform camera shake</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="463" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deblurring lowlight images with light streaks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Good regions to deblur</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="59" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Mathematical models and practical solvers for uniform motion deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">PSF estimation using sharp edge prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recording and playback of camera shake: Benchmarking blind deconvolution with a real-world database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Mohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="27" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Blind deconvolution using a normalized sparsity measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2657" to="2664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Streaming maximum-minimum filter using no more than three comparisons per element</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lemire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nordic Journal of Computing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="328" to="339" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Understanding and evaluating blind deconvolution algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="1964" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efficient marginal likelihood optimization in blind deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Direct sparse deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Bertozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An iterative technique for the rectification of observed distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Lucy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Astronomy Journal</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="745" to="754" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Blind deblurring using internal patch recurrence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Michaeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deblurring face images with exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deblurring text images via L0-regularized intensity and gradient prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2901" to="2908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">High-quality motion deblurring from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGGRAPH</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">73</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Rotational motion deblurring of a rigid object from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Edge-based blur kernel estimation using patch priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCP</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Richardson-lucy deblurring for scenes under a projective motion path</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1603" to="1618" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deblurring using regularized locally adaptive kernel regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Takeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="550" to="563" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A new alternating minimization algorithm for total variation image reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="248" to="272" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Non-uniform deblurring for shaken images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Whyte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Two-phase kernel estimation for robust motion deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Image smoothing via L0 gradient minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH Asia</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">174</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Unnatural L0 sparse representation for natural image deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1107" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sparse representation based blind image deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICME</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">From learning models of natural image patches to whole image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="479" to="486" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
