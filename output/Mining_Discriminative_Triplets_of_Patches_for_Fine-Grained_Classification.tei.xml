<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mining Discriminative Triplets of Patches for Fine-Grained Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaming</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonghyun</forename><surname>Choi</surname></persName>
							<email>jhchoi@umiacs.umd.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Comcast Labs DC</orgName>
								<address>
									<postCode>20005</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><forename type="middle">I</forename><surname>Morariu</surname></persName>
							<email>morariu@umiacs.umd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Mining Discriminative Triplets of Patches for Fine-Grained Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fine-grained classification involves distinguishing between similar sub-categories based on subtle differences in highly localized regions; therefore, accurate localization of discriminative regions remains a major challenge. We describe a patch-based framework to address this problem. We introduce triplets of patches with geometric constraints to improve the accuracy of patch localization, and automatically mine discriminative geometrically-constrained triplets for classification. The resulting approach only requires object bounding boxes. Its effectiveness is demonstrated using four publicly available fine-grained datasets, on which it outperforms or achieves comparable performance to the state-of-the-art in classification.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The task of fine-grained classification is to recognize sub-ordinate categories belonging to the same superordinate category <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b24">25]</ref>. The major challenge is that fine-grained objects share similar overall appearance and only have subtle differences in highly localized regions. To effectively and accurately find these discriminative regions, some previous approaches utilize humansin-the-loop <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b39">40]</ref>, or require semantic part annotations <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48]</ref> or 3D models <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b24">25]</ref>. These methods are effective, but they require extra keypoint/part/3D annotations from humans, which are often expensive to obtain. On the other hand, recent research on discriminative mid-level visual elements mining <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27]</ref> automatically finds discriminative patches or regions from a huge pool and uses the responses of those discriminative elements as a mid-level representation for classification. However, this approach has mainly been applied to scene classification and not typically to fine-grained classification. This is probably due to the fact that the discriminative patches needed for fine-grained categories need to be more accurately localized than for scene classification.</p><p>To avoid the cost of extra annotations, we propose a patch-based approach for fine-grained classification that overcomes the difficulties of previous discriminative midlevel approaches. Our approach requires only object bounding box annotations and belongs to the category of weaklyannotated fine-grained classification <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b23">24]</ref>. Two issues need to be addressed. The first issue is accurately localizing discriminative patches without requiring extra annotations. Localizing a single patch based only on its appearance remains challenging due to noisy backgrounds, ambiguous repetitive patterns and pose variations. Instead, we localize triplets of patches with the help of geometric constraints. Previously, triple or higher-order constraints have been used in image matching and registration <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b45">46]</ref>, but they have not been integrated into a patchbased classification framework. Our triplets consist of three appearance descriptors and two simple, but efficient, geometric constraints, which can be used to remove accidental detections that would be encountered if patches were localized individually. One attractive property of triplets over simpler models (e.g., pairs) is that they can be used to model rich geometric relationships while providing additional invariance (e.g., to rotation) or robustness (e.g., to perspective changes).</p><p>The second issue is automatically discovering discriminative geometrically-constrained triplets from the huge pool of all possible triplets of patches. The key insight is that fine-grained objects share similar overall appearance. Therefore, if we retrieve the nearest neighbors of a training image, we obtain samples from different classes with al-most the same pose, from which potentially discriminative regions can be found. Similar ideas have been adopted in <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b22">23]</ref>, but they aggregate results obtained from local neighborhood processing without further analysis across the whole dataset. In contrast, our discriminative triplet mining framework uses sets of overall similar images to propose potential triplets, and only selects good ones by measuring their discriminativeness using the whole training set or a large portion of it.</p><p>We evaluate our approach on four publicly available finegrained datasets and obtain comparable results to the stateof-the-art without expensive annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Triplets of Patches with Geometric Constraints</head><p>In this section, we discuss two geometric constraints encoded within triplets of patches and describe a triplet detector incorporating these constraints.</p><p>Suppose we have three patch templates T A , T B and T C , with their centers located at points A, B and C, respectively. Each template T i (i ∈ {A, B, C}) can be a feature vector extracted from a single patch or an averaged feature vector of patches from the corresponding locations of several positive samples. Given an image, let A ′ , B ′ and C ′ be three patches possibly corresponding to A, B and C, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Order Constraint and Shape Constraint</head><p>The order constraint encodes the ordering of the three patches ( <ref type="figure">Figure 2</ref>). For triplet {A, B, C}, consider the two vectors − − → AB and −→ AC. Treating them as three dimensional vectors with the third dimension being 0, it follows that</p><formula xml:id="formula_0">− − → AB × −→ AC = (0, 0, Z ABC ).<label>(1)</label></formula><p>Let</p><formula xml:id="formula_1">G ABC = sign(Z ABC ),<label>(2)</label></formula><p>which indicates whether the three patches are arranged clockwise (G ABC = 1) or counterclockwise (G ABC = −1), as can be seen in <ref type="figure">Figure 2</ref>. There is a side-test interpretation of this constraint <ref type="bibr" target="#b13">[14]</ref>. If we fix two patches, say B and C, G ABC = 1 means that A lies on the left side of the line passing between B and C, while G ABC = −1 indicates A is on the right side. Therefore, a simple penalty function between {A, B, C} and {A ′ , B ′ , C ′ } based on the order constraint can be defined as</p><formula xml:id="formula_2">p o (G ABC , G A ′ B ′ C ′ ) = 1 − η o l(G A ′ B ′ C ′ = G ABC ),<label>(3)</label></formula><p>where 0 ≤ η o ≤ 1 controls how important the order constraint is, and the indicator function is defined as The shape constraint measures the shape of the triangle defined by three patch centers ( <ref type="figure">Figure 3</ref>). Let Θ ABC = {θ A , θ B , θ C } denote the angles of triangle ABC, and <ref type="figure">Figure 3</ref>. We define a shape penalty function by comparing corresponding angles as</p><formula xml:id="formula_3">l(G A ′ B ′ C ′ = G ABC ) = 1, G A ′ B ′ C ′ = G ABC 0, G A ′ B ′ C ′ = G ABC .<label>(4)</label></formula><formula xml:id="formula_4">Θ A ′ B ′ C ′ = {θ A ′ , θ B ′ , θ C ′ } denote the angles of triangle A ′ B ′ C ′ , as displayed in</formula><formula xml:id="formula_5">p s (Θ A ′ B ′ C ′ , Θ ABC ) =1 − η s i∈{A,B,C} |cos(θ i ) − cos(θ i ′ )| 6 ,<label>(5)</label></formula><p>where η s ∈ [0, 1] controls how important the shape constraint is. The denominator 6 in Eq. (5) ensures that 0 ≤ p s ≤ 1, since |cos(θ i ) − cos(θ i ′ )| ≤ 2. {cos(θ i )} and {cos(θ i ′ )} can be easily computed from inner products. The motivation for introducing this second constraint is that we use the relatively loose order constraint to perform coarse verification and use the shape constraint for finer adjustments. As will be demonstrated in Section 4.1, the two constraints contain complementary information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Triplet Detector</head><p>Our triplet detector consists of three appearance models and the two geometric constraints. We construct three linear weights {w A , w B , w C } from the patch templates {T A , T B , T C }, and our triplet detector becomes</p><formula xml:id="formula_6">T = {w A , w B , w C , G ABC , Θ ABC }.<label>(6)</label></formula><p>For any triplet</p><formula xml:id="formula_7">{A ′ , B ′ , C ′ } with features {T A ′ , T B ′ , T C ′ } and geometric parameters {G A ′ B ′ C ′ , Θ A ′ B ′ C ′ }, its detec- tion score is defined as S A ′ B ′ C ′ = (S A (T ′ A ) + S B (T ′ B ) + S C (T ′ C )) · p o · p s ,<label>(7)</label></formula><p>where p o , p s are defined by Eq. (3), Eq. (5) respectively, and the appearance scores are defined as</p><formula xml:id="formula_8">S i (T i ′ ) = w T i T i ′ , i ∈ {A, B, C}.<label>(8)</label></formula><p>To make triplet detection practical, three technical details must be addressed. The first is how to efficiently obtain the maximum response of a triplet detector in an image. In principle, we could examine all possible triplets from the combinations of all possible patches and simply compute</p><formula xml:id="formula_9">{A * , B * , C * } = argmax {A ′ ,B ′ ,C ′ } S A ′ B ′ C ′ .<label>(9)</label></formula><p>However, this is too expensive since the number of all possible triplets will be O(N 3 ) for N patches. Instead, we adopt a greedy approach. We first find the top K nonoverlapping detections for each appearance detector independently. Then we evaluate the K 3 possible triplets and select the one with the maximum score defined by Eq. <ref type="formula" target="#formula_7">(7)</ref>. The second technical detail is how to obtain the linear weights w i from a patch template T i . For efficiency, we use the LDA model introduced by <ref type="bibr" target="#b19">[20]</ref> </p><formula xml:id="formula_10">w i = Σ −1 (T i − µ) ,<label>(10)</label></formula><p>where µ is the mean of features from all patches in the dataset, and Σ is the corresponding covariance matrix. The LDA model is efficient since it constructs the model for negative patches (µ and Σ) only once. Our triplet detector is able to handle moderate pose variations. However, if we flip an image, both the appearance (e.g. the dominant direction of an edge) and the order of the patches will change. We address this issue by applying the triplet detector to the image and its mirror, generating two detection scores, and choose the larger score as the response. This simple technique proves effective in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Discriminative Triplets for Fine-Grained Classification</head><p>In this section, we describe how to automatically mine discriminative triplets with the geometric constraints and generate mid-level representations for classification with the mined triplets. We present the overview of our framework in <ref type="figure" target="#fig_0">Figure 1</ref>. In the triplet initialization stage, we use a nearest-neighbor approach to propose potential triplets, taking advantage of the fact that instances of fine-grained objects share similar overall appearance. Then we verify the discriminativeness of the candidate triplets using the whole <ref type="figure">Figure 4</ref>. Some examples of a set of neighboring images. The query image is highlighted with a red box. Since fine-grained objects share similar overall appearance, the neighborhood consists of samples from different classes with the same pose.</p><p>training set or a large portion of it, and select discriminative ones according to an entropy-based measure. For classification, we concatenate the maximum responses of the selected discriminative triplets to construct mid-level image representations. The key to our approach is proposing candidate triplets locally and selecting discriminative ones globally, avoiding the insufficient data problems of other nearest-neighbor based fine-grained approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Triplet Initialization</head><p>To reduce the computational burden of triplet mining, we initialize candidate triplets using potentially discriminative patches in a nearest-neighbor fashion. The overview of the procedure is displayed in <ref type="figure" target="#fig_2">Figure 5</ref>. Construct Neighborhood. For a seed training image I 0 with class label c 0 , we extract features <ref type="bibr" target="#b5">[6]</ref> of the whole image X 0 and use it to retrieve the nearest neighbors from the training set. Since fine-grained objects have similar overall appearance, the resulting set of images consists of training images from different classes with almost the same pose ( <ref type="figure">Figure 4</ref>). This first step results in a set of roughly aligned images, so that potentially discriminative regions can be found by comparing corresponding regions across the images. We refer to the set consisting of a seed training image and its nearest neighbors as a neighborhood. Find Candidate Regions. We regard each neighborhood as a stack of aligned images with their class labels and locate potentially discriminative regions. Consider the set of patches at the same location of each image. For each location (x, y), let F i (x, y) be the features extracted from the patch in the i th image and let c i be its label. Denote the set of observed class labels as C. The discriminative score at (x, y) is simply defined as the ratio of between-class variation and in-class variation, i.e.</p><formula xml:id="formula_11">d(x, y) = c∈C F c (x, y) − F (x, y) 2 c∈C ci=c F i (x, y) − F c (x, y) 2 ,<label>(11)</label></formula><p>where F (x, y) is the averaged feature of all patches at location (x, y), and F c (x, y) is the average of patches from class c. We compute discriminative scores d(x, y) for patch locations in a sliding window fashion, with patch size 64 × 64 and stride 8, and choose the patch locations with top scores.</p><p>To ensure the diversity of the regions, non-maximum suppression is used to allow only a small amount of overlap. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Propose Candidate Triplets.</head><p>For a neighborhood generated from the seed image with class label c 0 , candidate triplets are proposed as follows. We first select all positive samples with label c 0 in the neighborhood. For each positive sample, we extract features from patches at the discriminative patch locations obtained in the last step. Then for patch location i, the patch template T i is obtained by averaging the features of all the positive samples. We propose candidate triplets by selecting all possible combinations of three patch locations. To avoid duplicate triplets, we rank three patch locations by their discriminative scores Eq. <ref type="bibr" target="#b10">(11)</ref>. We construct triplet detectors with geometric constraints from these patch triplets as discussed in Section 2.2.</p><p>In practice, in each neighborhood we find the top 6 discriminative locations and propose <ref type="bibr" target="#b5">6</ref> 3 = 20 candidate triplets. By considering all the neighborhoods for every class, we obtain the pool of candidate triplets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Discriminative Triplets Mining by Entropy Scores</head><p>Candidate triplets are constructed from potentially discriminative regions measured by Eq. <ref type="bibr" target="#b10">(11)</ref>. However, this measure is computed only within a small neighborhood and might be noisy due to lack of data. On the other hand, recent approaches to scene understanding <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b20">21]</ref> mine discriminative patches using a large portion of the training data and obtain very good results. Consequently, we select discriminative triplets by evaluating each candidate triplet on the broader dataset.</p><p>For each triplet detector obtained in Section 3.1, we detect triplets in each training image and obtain the maximum detection score as discussed in Section 2.2, i.e., find the top K detections for each appearance detector, consider all K 3 triplets, and choose the one with maximum geometricallypenalized score Eq. <ref type="bibr" target="#b6">(7)</ref>. We obtain the top detections within the training set along with their corresponding class labels. If a triplet is discriminative across the training set, the top detections are expected to arise from only one or a few classes. Therefore, if we calculate the entropy of the class distribution over the top detections, the entropy should be low. Let p(c|T) denote the probability of top detections coming from class c for triplet T. Then</p><formula xml:id="formula_12">H(c|T) = c p(c|T) log p(c|T)<label>(12)</label></formula><p>is an entropy-based measure that has been effectively used by <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b12">13]</ref> for patch selection. We calculate this measure for all candidate triplets and choose the ones with the lowest entropy to form the set of discriminative triplets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Mid-Level Image Representations for Classification</head><p>Finally, we use the maximum responses of the mined discriminative triplet detectors to construct a mid-level representation for an image. The dimension of the mid-level representation equals the number of triplet detectors, with each detection score occupying one dimension in the image-level descriptor. The mid-level representation is used as the input for a linear SVM to produce the classification result. We refer to the image-level descriptor as a Bag of Triplets (BoT).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Triplet Localization with Geometric Constraints</head><p>We first design a simple experiment to demonstrate that the geometric constraints described in Section 2 can actually improve patch localization, assuming we already have a good patch set. To achieve this goal, we use the FG3DCar dataset provided by <ref type="bibr" target="#b28">[29]</ref>. This dataset consists of 300 car Source Image</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appearance Only</head><p>Appearance + Shape Source Image Appearance Only Appearance + Order <ref type="figure">Figure 6</ref>. Visualization of the effects of the two geometric constraints. Red boxes are incorrectly localized patches. The order constraint roughly checks the geometric arrangement of three patches and can eliminate incidental false detections which happen to have high appearance score; the shape constraints enforce finer adjustments on patch locations than the order constraint.</p><p>images from 30 classes, with each image annotated with 64 ground-truth landmark points. Cars in this dataset have large pose variations, which makes triplet localization difficult. Experimental Settings.</p><p>The experiment is designed as follows. For each image, we construct a good set of 64 patches by extracting the ones located at the annotated landmarks. We repeatedly and randomly select two images from the same class and obtain two corresponding sets of 64 patches with their locations. Then we randomly select three patches from one image (denoted as Image 1) to construct a triplet detector in Eq. (6) and attempt to find the corresponding triplet in the pool of 64 patches of the other (denoted as Image 2). During the experiment, patches are represented by the Fisher Vector features provided by <ref type="bibr" target="#b28">[29]</ref>.</p><p>The following four methods are evaluated on this task. The decision procedure of the three methods with gemetric constraints is discussed in Section 2.2.</p><p>• Appearance Only (Baseline): Independently apply each patch detector, and choose the detection with the highest score. The detected triplet consists of the three top individual detections. In this method, only the appearance features of the three patches are used.</p><p>• Order Constraint: Use the appearance and the order constraint by setting η s = 0 in Eq. (5), such that p s = 1 (no shape penalty) always holds in Eq. (7).</p><p>• Shape Constraint: Use the appearance and the shape constraint by setting η o = 0 in Eq. (3), such that p o = 1 (no order penalty) always holds in Eq. (7).</p><p>• Combined: Use both geometric constraints. In practice, we set η o = 0.5 and η s = 1.</p><p>Due to large pose changes, several landmark locations are highly overlapped with each other in some images. Therefore, during evaluation, each patch is regarded as correctly localized if the detected patch is (i) the same as the ground truth corresponding patch; (ii) highly overlapped with the ground truth corresponding patch, with overlap/union ratio greater than 50%. Each triplet is regarded as successfully localized if all of its three patches are correctly localized. We randomly select 1000 image pairs, and for each pair we randomly test 1000 triplets. The accuracy of triplet localization is the percentage of successfully localized triplets over all the 1 million triplets evaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Result and Analysis.</head><p>We demonstrate triplet localization accuracy and relative improvement over baseline in Table 1. Even though we have a human-annotated pool of patches, localization is challenging with appearance only, since the pose variations are large and the appearance detector is learnt with only one positive sample. As we add geometric constraints, we obtain cumulative improvement over the baseline. Typical examples indicating the effects of the two constraints are displayed in <ref type="figure">Figure 6</ref>. The order constraint, which is relatively loose, tends to roughly check the geometric arrangement of three patches. It can eliminate the patches which happen to have a very high appearance score. On the other hand, the shape constraint enforces fine adjustment, which is complementary to the order constraint. With the two geometric constraints combined, the improvement is significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Fine-Grained Classification</head><p>We demonstrate fine-grained classification results on three standard fine-grained car datasets. No extra annotation beyond object bounding boxes is used throughout the experiments. When comparing results, we refer to our approach as Bag of Triplets (BoT).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">14-Class BMVC Cars Dataset Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset.</head><p>The fine-grained car dataset provided by <ref type="bibr" target="#b36">[37]</ref> (denoted as  consists of 1904 images of cars from 14 classes. <ref type="bibr" target="#b36">[37]</ref> has split the data into 50% train, 25% val and 25% test. We follow this setting for evaluation. Experimental Settings.</p><p>The implementation details of our discriminative triplet mining approach are briefly stated as follows. Each image is cropped to its bounding box and resized such that the width is 500 (aspect ratio maintained). The patch size is set to be 64 × 64 and HOG features are extracted to represent the patches for fair comparison to preivously reported results. In the triplet initialization stage, for each seed image we construct the neighborhood of size 20 including itself. As mentioned in Section 3.1, for each neighborhood we propose the top 6 discriminative patch locations and propose 6 3 = 20 triplets for mining. In the triplet mining stage, we obtain the top detections across the whole training set and calculate entropy measure Eq. <ref type="bibr" target="#b11">(12)</ref>. Then we select 300 discriminative triplets per class. Finally, the mid-level representation has dimension 14 × 300 = 4200, which is fed into the linear SVM implemented by LIBLINEAR <ref type="bibr" target="#b10">[11]</ref>.</p><p>We test the following two cases:</p><p>• Without Geometric Constraints (Without Geo): In the discriminative mining and mid-level representation construction stages, we adopt the "Appearance Only" triplet detection strategy described in Section 4.1.</p><p>• With Geometric Constraints (With Geo): Each time we use a triplet detector, we use Eq. (7) and related techniques in Section 2.2 to incorporate the two constraints. By comparing the two cases, we quantitatively test the effectiveness of geometric constraints.</p><p>Results and Analysis. We compare our results with previous work, citing the results from <ref type="bibr" target="#b28">[29]</ref>, which has provided a summary of previously published results on BMVC-14.</p><p>It includes several baseline methods such as LLC <ref type="bibr" target="#b40">[41]</ref> and PHOW <ref type="bibr" target="#b37">[38]</ref> with codebook size 2048, Fisher Vector (FV) <ref type="bibr" target="#b32">[33]</ref> with 256 Gaussian Mixture Model (GMM) components, as well as structDPM <ref type="bibr" target="#b36">[37]</ref> and BB-3D-G <ref type="bibr" target="#b24">[25]</ref> specifically designed for the task. Among these methods, BB-3D-G <ref type="bibr" target="#b24">[25]</ref> used extra 3D models, while others only used ground truth bounding boxes as we did. The results are summarized in <ref type="table">Table 2</ref>. Our method without geometric constraints outperforms all three baseline methods. When geometric constraints are further added, our approach not only outperforms the best reported result using only bounding boxes with a noticeable margin, but it also outperforms the BB-3D-G method which uses extra 3D model fitting. It is worth mentioning that our method with triplet geometric constraints outperforms the DPM-based method <ref type="bibr" target="#b36">[37]</ref>, which incorporates root-part pair-wise constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Accuracy (%) LLC <ref type="bibr" target="#b40">[41]</ref> 84.5 PHOW <ref type="bibr" target="#b37">[38]</ref> 89.0 FV <ref type="bibr" target="#b32">[33]</ref> 93.9 structDPM <ref type="bibr" target="#b36">[37]</ref> 93.5 BB-3D-G <ref type="bibr" target="#b24">[25]</ref> 94.5 BoT (HOG Without Geo) 94.1 BoT (HOG With Geo) 96.6 <ref type="table">Table 2</ref>. Results on BMVC-14 dataset. We plot the performance as a function of the number of discriminative triplets per class (with geometric constraints) in <ref type="figure" target="#fig_3">Figure 7</ref>. When we use only 10 triplets/class, the performance of 84.9% already outperforms the baseline LLC <ref type="bibr" target="#b40">[41]</ref>, suggesting that the mined discriminative triplets are highly informative. As we increase the number of triplets per class, performance more or less saturates after 100 triplets/class, although the best performance is at 300 triplets/class. Therefore, when we deal with largescale datasets such as the Stanford Cars dataset below, we can use a smaller number of triplets to construct lowerdimensional mid-level descriptors without much loss in performance. As the number of triplets/class exceeds 300, the performance decreases, suggesting that the remaining triplets, which rank low by our criteria, do not add discriminatively useful information.</p><p>We further visualize the most discriminative triplet measured by the entropy score Eq. (12) for all 14 classes in <ref type="figure">Figure 8</ref>. The triplets in the figure accurately localize the subtle discriminative regions, which are highly consistent with human perception, such as the distinctive side vent grill of Chevrolet Corvette (the second image in the second row of <ref type="figure">Figure 8</ref>, see <ref type="figure">Figure 8</ref> for more details). This empirically explains why our triplets are highly informative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">196-Class Stanford Cars Dataset Results</head><p>Dataset. The Stanford Cars Dataset <ref type="bibr" target="#b24">[25]</ref> contains 16,185 car images from 196 classes (denoted as Cars-196). The <ref type="figure">Figure 8</ref>. Visualization of the most discriminative triplet (measured by Eq. (12)) for each class in BMVC-14 proposed by our method. The triplets accurately capture the subtle discriminative information of each class, which is highly consistent with human perception. For instance, for the first image in the first row, the triplet captures the curvy nature of Volkswagen Beetle such as rounded hood; for the first image in the second row, the triplet focuses on the rear cargo of the pick-up truck, since Ford F-Series is the only pick-up in the dataset; for the last image in the first row, the triplet highlights the frontal face of Jeep Wrangler. data split provided by <ref type="bibr" target="#b24">[25]</ref> is 8,144 training images and 8,041 testing images, where each class has been roughly split 50-50. We follow this setting in our experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Settings.</head><p>Our method focuses on generating effective mid-level representations and is independent from the choice of low-level features. In this experiment, in order to fairly compare to both the traditional methods without using extra data/annotation and the more recent ones which finetune ImageNet pre-trained Convolutional Neural Networks (CNN), we evaluate our approach using both HOG and CNN features as the low-level representations of the patches. When extracting CNN features, we directly use the off-the-shelf ImageNet pre-trained CNN model as a general feature extractor without any finetuning. For fair comparison, we adopt the popular 16-layer VGGNet-16 <ref type="bibr" target="#b34">[35]</ref> as the network architecture, and extract features from pool 4 layer, which is the max-pooled output of its 10 th convolutional layer.</p><p>Also, we adapt our approach slightly to handle such a large-scale dataset. Instead of traversing the whole dataset, when retrieving nearest-neighbors for a seed image with class label c 0 , we regard class c 0 as the positive class, randomly select 29 other classes as negative classes, and retrieve nearest-neighbors within the training images from these 30 classes; when finding top detections for a triplet from class c 0 , we use the training images from class c 0 and 14 randomly selected negative classes. Additionally, since we have empirically determined that the discriminative triplets are informative in <ref type="figure" target="#fig_3">Figure 7</ref>, we select 150 discriminative triplets per class. Except for the settings described above, other parameters remain the same as those in Section 4.2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Analysis.</head><p>Our baselines include LLC <ref type="bibr" target="#b40">[41]</ref> as HOG-based baseline and AlexNet <ref type="bibr" target="#b25">[26]</ref> as CNN baselines. For CNN, we cite the result of training an AlexNet from scratch on Cars-196 without extra data (AlexNet From Scratch) <ref type="bibr" target="#b22">[23]</ref> and the result of finetuning an ImageNet pretrained AlexNet on Cars-196 (AlexNet Finetuned) <ref type="bibr" target="#b42">[43]</ref>. We also compare with previously published results including BB-3D-G <ref type="bibr" target="#b24">[25]</ref>, ELLF <ref type="bibr" target="#b22">[23]</ref>, FT-HAR-CNN <ref type="bibr" target="#b42">[43]</ref>, Bilinear CNN (B-CNN) <ref type="bibr" target="#b27">[28]</ref> and the method with the highest reported accuracy so far <ref type="bibr" target="#b23">[24]</ref>. It is worth mentioning that the last three approaches <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b23">24]</ref> are CNN-based, where <ref type="bibr" target="#b42">[43]</ref> is AlexNet based, <ref type="bibr" target="#b27">[28]</ref> is VGGNet-16 based, and <ref type="bibr" target="#b23">[24]</ref> is 19-layer VGGNet-19 based. <ref type="bibr" target="#b42">[43]</ref> finetunes a CNN with the help of another 10,000 images of cars without finegrained labels; the best result of <ref type="bibr" target="#b27">[28]</ref> is achieved by finetuning a two-stream CNN architecture; <ref type="bibr" target="#b23">[24]</ref> integrates segmentation, graph-based alignment, finetuned R-CNN <ref type="bibr" target="#b16">[17]</ref> and SVM to produce its best result.</p><p>The results are displayed in <ref type="table">Table 3</ref>. Even though we adopted relatively "economical" settings, our method behaves stably and operates at the state-of-the-art performance. When using HOG as low-level patch representation, our approach not only greatly outperforms the HOG-based baseline (LLC) (by more than 15%), but it even outperforms the CNN baseline of finetuned AlexNet by a fairly noticeable margin (more than 2%) -a significant achievement since we are only using HOG and geometric constraints without any extra data or annotations. When using offthe-shelf CNN features, our method with geometric constraints outperforms B-CNN <ref type="bibr" target="#b27">[28]</ref> which uses two streams of VGGNet-16, and obtained quite comparable results to the state-of-the-art <ref type="bibr" target="#b23">[24]</ref>. Furthermore, our method does not perform finetuning and depends on the strength of our discriminative triplet mining itself, which is supported by the results, rather than the learning capability of CNNs.</p><p>To intuitively demonstrate the effectiveness of the geometric constraints, we plot the image-level BoT descriptors from a few classes in the second and third columns of <ref type="figure" target="#fig_4">Figure 9</ref>. For each class we plot the averaged BoT descriptor across all test samples from that class. <ref type="figure" target="#fig_4">Figure 9</ref> shows that after introducing the geometric constraints, the BoT descriptor becomes more peaked at the corresponding class, since the geometric constraints help learn more discriminative triplets which generate more peaky responses, as well as penalizing those incorrect detections from other classes which happen to have high appearance scores (which can be clearly seen from the second row of <ref type="figure" target="#fig_4">Figure 9</ref>). This discriminative capability is achieved during test time, showing Method Accuracy (%) LLC * <ref type="bibr" target="#b40">[41]</ref> 69.5 BB-3D-G <ref type="bibr" target="#b24">[25]</ref> 67.6 ELLF * <ref type="bibr" target="#b22">[23]</ref> 73.9 AlexNet From Scratch <ref type="bibr" target="#b22">[23]</ref> 70.5 AlexNet Finetuned <ref type="bibr" target="#b42">[43]</ref> 83.1 FT-HAR-CNN <ref type="bibr" target="#b42">[43]</ref> 86.3 B-CNN <ref type="bibr" target="#b27">[28]</ref> 91.3 Best Result in <ref type="bibr" target="#b23">[24]</ref> 92.8 BoT(HOG Without Geo) * 84.6 BoT(HOG With Geo) * 85.7 BoT(CNN Without Geo) 91.2 BoT(CNN With Geo) 92.5 <ref type="table">Table 3</ref>. Results on Cars-196 dataset. Items with "*" indicate that no extra annotations/data are involved. that our approach generalizes very well. Finally, we visualize the most discriminative triplet measured by Eq. <ref type="bibr" target="#b11">(12)</ref> in the first column of <ref type="figure" target="#fig_4">Figure 9</ref>. Similar to <ref type="figure">Figure 8</ref>, our approach captures the subtle difference of fine-grained categories and accurately localizes the discriminative regions, which are highly interpretable by humans. For example, it highlights the distinctive air grill and rounded fender of Bugatti Veyron, and the classical headlight and tail of Porsche.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">100-Class FGVC-Aircraft Dataset Results</head><p>Finally, to demonstrate that our approach is effective in multiple fine-grained domains, we briefly present our results on FGVC-Aircraft dataset <ref type="bibr" target="#b30">[31]</ref>, which contains 10,000 images from 100 classes of aircrafts and is of similar scale to the Method Accuracy (%) Symbiotic <ref type="bibr" target="#b4">[5]</ref> 75.9 Fine-tuned AlexNet <ref type="bibr" target="#b18">[19]</ref> 78.9 Fisher Vector <ref type="bibr" target="#b18">[19]</ref> 81.5 B-CNN <ref type="bibr" target="#b27">[28]</ref> 84.1 BoT (CNN without Geo) 86.7 BoT (CNN with Geo) 88.4 <ref type="table">Table 4</ref>. Results on FGVC-Aircraft dataset.</p><p>Cars-196 dataset (16185 images from 196 classes). For fair comparison, we use the standard train/test split provided by the dataset provider <ref type="bibr" target="#b30">[31]</ref> and the parameter settings of our approach are exactly the same as those in Section 4.2.2. We report our results in <ref type="table">Table 4</ref>. Our approach using CNN features (without fine-tuning) outperforms state-of-the-art (VGGNet-16 based) <ref type="bibr" target="#b27">[28]</ref> by a noticeable margin. The results suggest that our approach performs well in various fine-grained domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We proposed a mid-level patch-based approach for fine-grained classification. We first introduce triplets of patches with two geometric constraints to improve localizing patches, and automatically mine discriminative triplets to construct mid-level representations for fine-grained classification. Experimental results demonstrated that our discriminative triplets mining framework performs very well on both mid-scale and large-scale fine-grained classification datasets, and outperforms or obtains comparable results to the state-of-the-art.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Summary of our discriminative triplet mining framework. Candidate triplets are initialized from sets of neighboring images and selected by how discriminative they are across the training set. The mid-level representation consists of the maximum responses of the selected triplets with geometric constraints, which is fed into a linear SVM for classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Visualization of the order constraint. Top: Patch A, B and C are arranged in clockwise order. The direction of −→ AB × −→ AC points into the paper, and GABC = 1. Bottom: A ′ , B ′ and C ′ are arranged in counterclockwise order. The direction of the cross product points out of the paper, and G A ′ B ′ C ′ = −1. Visualization of the shape constraint. The constraint compares the three angles of two triplets. Intuitively, p o penalizes by η o when {A ′ , B ′ , C ′ } violates the order constraint defined by {A, B, C}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 .</head><label>5</label><figDesc>Visualization of the triplet initialization stage. (a) A seed image from class c0 is used to construct its nearest-neighbor set including itself. (b) Discriminative score map is generated from the stack of neighboring images. (c) Patch locations with top discriminative scores are selected by non-maximum suppression. (d) Images from positive class (class c0) are selected to generate triplets. (e) Triplets are generated from positive samples at locations proposed in (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 .</head><label>7</label><figDesc>Classification accuracy with respect to the number of triplets per class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 9 .</head><label>9</label><figDesc>(a) Visualization of the most discriminative triplets of two example classes in Cars-196. (b)(c) The averaged image-level BoT descriptor across all test samples in the corresponding class. Each dimension in the BoT is generated by the response of a mined triplet. The color bars are used to describe the dimensions correponding to the responses of triplets from different classes.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements This work was partially supported by ONR MURI Grant N000141010934.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">POOF: part-based one-vs.-one features for fine-grained categorization, face verification, and attribute estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Birdsnap: Large-scale fine-grained visual categorization of birds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Visual recognition with humans in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Babenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Symbiotic segmentation and part localization for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fine-grained crowdsourcing for fine-grained recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mid-level visual element discovery as discriminative mode seeking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">What makes paris look like paris?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A tensorbased algorithm for high-order graph matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Duchenne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">LIB-LINEAR: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Birdlets: Subordinate categorization using volumetric primitives and pose-normalized appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Oza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">I</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mining midlevel features for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">É</forename><surname>Fromont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="186" to="203" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Wide-baseline multiple-view correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Birds of a feather flock together -local learning of mid-level representations for fine-grained recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Freytag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Denzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV Workshop on Parts and Attributes</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Smeulders, and T. Tuytelaars. Fine-grained categorization by alignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gavves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G M</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Nonparametric part transfer for fine-grained recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Göring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Freytag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Denzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Revisiting the fisher vector for fine-grained classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Gosselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="92" to="98" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Discriminative decorrelation for clustering and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Blocks that shout: Distinctive parts for scene classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Juneja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">P 3 &amp; beyond: Solving energies with higher order cliques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning features and parts for fine-grained recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fine-grained recognition without part annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">3d object representation for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International IEEE Workshop on 3D Representation and Recognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Mid-level deep pattern mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bilinear CNN models for fine-grained visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roychowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Jointly optimizing 3d model fitting and fine-grained classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">I</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dog breed classification using part localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Fine-grained visual classification of aircraft. CoRR, abs/1306</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">5151</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Cats and dogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">M</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Improving the fisher kernel for large-scale image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Which looks like which: Exploring inter-class relationships in fine-grained visual categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Unsupervised discovery of mid-level discriminative patches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fine-grained categorization for 3d scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pepik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Vlfeat: an open and portable library of computer vision algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fulkerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Multimedia</title>
		<meeting>the 18th International Conference on Multimedia<address><addrLine>Firenze, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-10-25" />
			<biblScope unit="page" from="1469" to="1472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The caltech-ucsd birds 200-2011 dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Technical Report CNS-TR</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Similarity comparisons for interactive finegrained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">V</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Locality-constrained linear coding for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Caltech-ucsd birds 200</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<idno>CNS-TR-2010-001</idno>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
			<pubPlace>Caltech</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Hyper-class augmented and regularized deep learning for fine-grained image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Unsupervised template learning for fine-grained object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A codebook-free and annotation-free approach for fine-grained image categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Bradski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Probabilistic graph and hypergraph matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shashua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Pose pooling kernels for sub-category recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deformable part descriptors for fine-grained recognition and attribute prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">N</forename><surname>Iandola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
