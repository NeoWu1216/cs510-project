<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Zero-Shot Learning via Joint Latent Similarity Embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziming</forename><surname>Zhang</surname></persName>
							<email>zzhang14@bu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical &amp; Computer Engineering</orgName>
								<orgName type="institution">Boston University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatesh</forename><surname>Saligrama</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical &amp; Computer Engineering</orgName>
								<orgName type="institution">Boston University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Zero-Shot Learning via Joint Latent Similarity Embedding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Zero-shot recognition (ZSR) deals with the problem of predicting class labels for target domain instances based on source domain side information (e.g. attributes) of unseen classes. We formulate ZSR as a binary prediction problem. Our resulting classifier is class-independent. It takes an arbitrary pair of source and target domain instances as input and predicts whether or not they come from the same class, i.e. whether there is a match. We model the posterior probability of a match since it is a sufficient statistic and propose a latent probabilistic model in this context. We develop a joint discriminative learning framework based on dictionary learning to jointly learn the parameters of our model for both domains, which ultimately leads to our class-independent classifier. Many of the existing embedding methods can be viewed as special cases of our probabilistic model. On ZSR our method shows 4.90% improvement over the state-of-the-art in accuracy averaged across four benchmark datasets. We also adapt ZSR method for zero-shot retrieval and show 22.45% improvement accordingly in mean average precision (mAP).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Zero-shot learning (ZSL) deals with the problem of learning to classify previously unseen class instances. It is particularly useful in large scale classification where labels for many instances or entire categories can often be missing. One popular version of ZSL is based on the so-called source and target domains. In this paper we consider the source domain as a collection of class-level vectors, where each vector describes side information of one single class with, for instance, attributes <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b30">31]</ref>, language words/phrases <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b33">34]</ref>, or even learned classifiers <ref type="bibr" target="#b38">[39]</ref>. The target domain is described by a distribution of instances (e.g. images, videos, etc.) <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b37">38]</ref>. During training, we are given source domain side information and target domain data corresponding to only a subset of classes, which we call seen classes. During test time for the source domain, side information is then provided for unseen classes. A tar- <ref type="figure">Figure 1</ref>. Illustration of our joint latent space model with images as target domain and text-documents as source domain. The bar graph next to the (latent) topics indicate the mixture weights of the topics. The links between the topics indicate the co-occurrence (thicker lines depicting larger likelihood values). Our method is based on learning a class-independent similarity function using seen class training data, which measures the likelihood of a source domain class vector and a target domain data sample being the same class, regardless of their true underlying classes. get domain instance from an unknown unseen class is then presented. The goal during test time is to predict the class label for the unseen target domain instance. Intuition: In contrast to previous methods (e.g. <ref type="bibr" target="#b1">[2]</ref>) which explicitly learn the relationships between source and target domain data, we posit that for both domains there exist corresponding latent spaces, as illustrated in <ref type="figure">Fig. 1</ref>, where there is a similarity function independent of class labels.</p><p>Our supposition implies that, regardless of the underlying class labels, there is a statistical relationship between latent co-occurrence patterns of corresponding source and target instance pairs when the instance pairs describe the same thing. For example, with our supposition the "zebra" image in <ref type="figure">Fig. 1</ref> on the left will share an underlying statistical relationship with the description of zebra in text on the right, and that this relationship can be inferred by means of a class-independent "universal" similarity function <ref type="bibr" target="#b0">1</ref> .</p><p>To mathematically formalize this intuition we formulate zero-shot recognition (ZSR) as a binary classification problem. In this framework, we train a score function that takes an arbitrary source-target instance pair as input and outputs a likelihood score that the paired source and target instances come from the same class. We apply this score function on a given target instance to identify a corresponding source vector with the largest score. In this way our score function generalizes to unseen classes since it does not explicitly depend on the actual class label.</p><p>We train our binary predictor (i.e. score function) using seen class source and target domain data. It is well-known that for a binary classification problem the posterior probability of the binary output conditioned on data is a sufficient statistic for optimal detection. This motivates us to propose a latent parameterized probabilistic model for the posterior. We decompose the posterior into source/target domain data likelihood terms and a cross-domain latent similarity function. We develop a joint discriminative learning framework based on dictionary learning to jointly learn the parameters of the likelihood and latent similarity functions.</p><p>In test-time unseen source domain vectors are revealed. We estimate their corresponding latent source embeddings. Then, for an arbitrary target-instance, we estimate the latent target embedding. Finally we score each pair of source and target domain embeddings using our similarity function and classify based on these scores. <ref type="figure">Fig. 1</ref> illustrates a specific scenario where visual and word embedding functions are learned using training data from seen classes and are utilized to estimate embeddings for unseen data. We test our method on four challenging benchmark datasets (i.e. aP&amp;Y, AwA, CUB, SUN-attribute). Our performance on average shows 4.9% improvement in recognition accuracy. We also adapt ZSR method for zero-shot retrieval and show 22.45% improvement in mean average precision across these datasets.</p><p>Our proposed general probabilistic model is a systematic framework for ZSR. Indeed, existing methods including <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b24">25]</ref> can be precisely interpreted as special cases of our method. We test our algorithm on several ZSL benchmark datasets and achieve state-of-the-art results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Related Work</head><p>(i) Attribute prediction: A significant fraction of zeroshot methods are based on building attribute classifiers that transfer target domain data into source domain attribute space. For instance, <ref type="bibr" target="#b25">[26]</ref> used semantic knowledge bases to learn the attribute classifiers. <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40]</ref> proposed several (probabilistic or discriminative) attribute prediction methods using the information from attributes, classes, and objects. <ref type="bibr" target="#b22">[23]</ref> proposed combining seen class classifiers linearly to build unseen class classifiers. <ref type="bibr" target="#b13">[14]</ref> proposed first linearly projecting both source and target domain data into a common space and then training a max-margin multi-label classifiers for prediction. <ref type="bibr" target="#b31">[32]</ref> proposed a related regularization based method for training classifiers. The main issue in such methods is that they may suffer from noisy source/target data, which often results in poor prediction. In contrast, our joint latent space model is robust to the noise issues on account of the nature of latent space learning.</p><p>(ii) Linear embedding: This type of methods are based on embedding both source and target domain data into a feature space characterized by the Kronecker product of source domain attributes and target domain features. Linear classifiers are trained in the product space. For instance, <ref type="bibr" target="#b0">[1]</ref> created such spaces using label embedding, and <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b33">34]</ref> utilized deep learning for the same purpose. Recently <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> introduced semi-supervised max-margin learning to learn the label embedding.</p><p>(iii) Nonlinear embedding: Similar to linear embedding, here the Kronecker product feature space is constructed after a nonlinear mapping of the original features. This literature includes <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b43">44]</ref>, where <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b43">44]</ref> embed source and target domain data nonlinearly into known semantic spaces (i.e. seen classes) in an unsupervised or supervised way, and <ref type="bibr" target="#b2">[3]</ref> employed deep neural networks for associating the resulting embeddings.</p><p>Different from these (linear or nonlinear) embedding based zero-shot methods, our method learns a joint latent space for both domains using structured learning. The learned joint space is used not only to fit each instance well (by dictionary learning) but also to enable recognition (by bilinear classifiers) during test time.</p><p>(iv) Other methods: Less related to our method includes approaches based on semantic transfer propagation <ref type="bibr" target="#b29">[30]</ref>, transductive multi-view embedding <ref type="bibr" target="#b11">[12]</ref>, random forest approach <ref type="bibr" target="#b14">[15]</ref>, and semantic manifold distance <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Our Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Problem Setting</head><p>Let us motivate our approach from a probabilistic modeling perspective. This will in turn provide a basis for structuring our discriminative learning method. We denote by X (s) the space of source domain vectors, by X (t) the space of target domain vectors, and by Y the collection of all classes. Following convention, the random variables are denoted by capital letters, namely, X (s) , X (t) , Y and instances of them by lower-case letters x (s) , x (t) , y.</p><p>Zero-shot learning is a special case where the class corresponding to the source domain instance is revealed during test time and thus there is no uncertainty regarding the class label for any source domain vector. Thus the problem reduces to assigning target domain instances to source domain vectors (and in turn to classes) during testing. For exposition we denote by y (s) the label for the source domain instance x (s) ∈ X (s) even though we know that y (s) is identical to the true class label y. With this in mind, we predict a class label y (t) for target domain instance x (t) ∈ X (t) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">General Probabilistic Modeling</head><p>Abstractly, we can view ZSR as a problem of assigning a binary label to a pair of source and target domain instances, namely whether or not y (st) ∆ = [y (s) = y (t) ] holds. We view our goal in terms of evaluating how likely this proposal is true, i.e. p(y (st) | x (s) , x (t) ). Indeed, Bayes Optimal Risk theory tells us that the optimal classifier (see Eq. 6 in <ref type="bibr" target="#b8">[9]</ref>), f (x (s) , x (t) ), is obtained by suitably thresholding the posterior of y (st) conditioned on data, namely,</p><formula xml:id="formula_0">f (x (s) , x (t) ) log p(y (st) | x (s) , x (t) ) Ident &gt; &lt; Diff θ<label>(1)</label></formula><p>where θ ∈ R is a threshold parameter. Here Ident is the hypothesis that source/target data describe the same class.</p><p>Diff is the hypothesis that they are different. Our latent embedding model supposes that the observed and latent random variables form a Markov chain <ref type="bibr" target="#b5">[6]</ref>:</p><formula xml:id="formula_1">X (s) ↔ Z (s) ↔ Y ↔ Z (t) ↔ X (t) .<label>(2)</label></formula><p>This implies that the source domain data, X (s) , and its associated embedding, Z (s) is independent of the target X (t) , Z (t) conditioned on the underlying class Y (if they belong to the same class) and unconditionally independent if they belong to different classes. It follows that the posterior can be factored</p><formula xml:id="formula_2">as p(y (st) , z (s) , z (t) | x (s) , x (t) ) = p(y (st) | z (s) , z (t) )p(z (s) , z (t) | x (s) , x (t)</formula><p>). Next note that, in the absence of class information, it is reasonable to assume that an arbitrary pair of source and target domain latent embeddings are essentially independent, namely, p(z (s) , z (t) ) ≈ p(z (s) )p(z (t) ). Consequently, the posterior probability can be expressed as follows:</p><formula xml:id="formula_3">p(y (st) | x (s) , x (t) ) (3) = p(z (s) |x (s) )p(z (t) |x (t) )p(y (st) |z (s) , z (t) )dz (s) dz (t) ,</formula><p>where, z (s) ∈ R hs and z (t) ∈ R ht denote the latent coefficient vectors in the corresponding h s -dim and h t -dim latent spaces, respectively. Here (z (s) , z (t) ) defines the joint latent embedding for data pair (x (s) , x (t) ). This factorization provides us two important insights: (i) Class-independent Embeddings: Note that the expression in Eq. 3 informs us that the probability kernels p(z (s) |x (s) ), p(z (t) |x (t) ) characterizing the latent embeddings depend only on the corresponding data instances, x (s) , x (t) and independent of the underlying class labels.</p><p>(ii) Class-independent Similarity Kernel: The expression in Eq. 3 reveals that the term p(y (st) |z (s) , z (t) ) is a classinvariant function that takes arbitrary source and target domain embeddings as input and outputs a likelihood of sim-ilarity regardless of underlying class labels (recall that predicting y (st) ∆ = [y (s) = y (t) ] is binary). Consequently, at a conceptual level, our framework provides a way to assign similarities of class membership between arbitrary target domain vectors and source domain vectors while circumventing the intermediate step of assigning class labels.</p><p>In our context the joint probability distributions and latent conditionals are unknown and must be estimated from data. Nevertheless, this perspective provides us with a structured way to estimate them from data. An important issue is that Eq. 3 requires integration over the latent spaces, which is computationally cumbersome during both training and testing. To overcome this issue we lower bound Eq. 3 by a straightforward application of Jensen's inequality:</p><formula xml:id="formula_4">log p(y (st) | x (s) , x (t) ) (4) ≥ max z (s) ,z (t) log p(z (s) |x (s) )p(z (t) |x (t) )p(y (st) |z (s) , z (t) )</formula><p>.</p><p>In training and testing below, we employ this lower bound as a surrogate for the exact but cumbersome similarity function between source and target domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Training</head><p>During training we are given independent instances of source and target domain instances, x</p><formula xml:id="formula_5">(s) i , x (t)</formula><p>j , and a binary label y (st) ij indicating whether or not they belong to the same class. We parameterize the probability kernels in Eq. 4</p><formula xml:id="formula_6">using p B (z (s) |x (s) ), p D (z (t) |x (t) ), p W (y (st) | z (s) , z (t) )</formula><p>in terms of data-independent parameters B, D, W respectively, and estimate them discriminatively using training data. To reduce the computational complexity using Eq. 4, we instead propose the following training objective as the lower bound of RHS in Eq. 4 over the source and target domain data:</p><formula xml:id="formula_7">max B,D,W max {z (s) i },{z (t) j } C i=1 log p B (z (s) i |x (s) i ) (5) + N j=1 log p D (z (t) j |x (t) j ) + C i=1 N j=1 log p W (y (st) ij | z (s) i , z (t) j ),</formula><p>where C is the size of the source domain training data (number of observed class labels) and N is the size of the target domain training data. Salient Aspects of our Training Algorithm: Based on Eq. 5 our objective is two-fold. We need to learn a lowdimensional latent embedding that not only accurately represents the observed data in each domain but also is capable of inferring cross-domain statistical relationships when one exists. Note that the first two log-likelihoods in Eq. 5 are data fitting terms, and the last one measures the joint latent similarity between the two latent vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Jointly latent embedding learning algorithm</head><formula xml:id="formula_8">Input : training data {(x (s) i , y (s) i )} and {(x (t) j , y (t) j )} Output : {z (s) i }, {z (t) j }, B, D, W Initialize B, D; ∀i, z (s) i ← arg max z (s) i log p B (z (s) i |x (s) i ); ∀j, z (t) j ← arg max z (t) j log p D (z (t) j |x (t) j ); W ← arg max W C i=1 N j=1 log p W (y (st) ij | z (s) i , z (t) j ); repeat ∀i, z (s) i ← arg max z (s) i log p B (z (s) i |x (s) i ) + N j=1 log p W (y (st) ij | z (s) i , z (t) j ); ∀j, z (t) j ← arg max z (t) j log p D (z (t) j |x (t) j ) + C i=1 log p W (y (st) ij | z (s) i , z (t) j ); B ← arg max C i=1 log p B (z (s) i |x (s) i ); D ← arg max N j=1 log p D (z (t) j |x (t) j ); W ← arg max W C i=1 N j=1 log p W (y (st) ij | z (s) i , z (t) j ); until Converge to a local minimum; return {z (s) i }, {z (t) j }, B, D, W</formula><p>With this insight we propose a general alternating optimization algorithm to jointly learn {z</p><formula xml:id="formula_9">(s) i }, {z (t) j }, B, D, W in Eq. 5 in Alg. 1.</formula><p>This follows from the exchangeability of two max operators. In this way our learning algorithm guarantees convergence to a local optimum within finite number of iterations. Also since the update rules for ∀i, z  Our approach diverts from some of the previous works such as <ref type="bibr" target="#b13">[14]</ref> where source domain vectors for unseen classes are also known during training. This perspective lets one exploit knowledge of unseen source domain classes during training. In contrast we are not provided unseen data for either the source or target domains. Thus, our dataindependent variables B, D, W do not contain any information about unseen data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Testing</head><p>In order to avoid confusion we index unseen class data with i ′ , j ′ corresponding to source and target domain respectively. The seen class training data is indexed as before with i, j. During test-time the source domain data  </p><formula xml:id="formula_10">{(x (s) i ′ , y (s) i ′ )}</formula><formula xml:id="formula_11">i ′ }, {z (t) j ′ } ∀i ′ , z (s) i ′ ← arg max z (s) i ′ log p B (z (s) i ′ |x (s) i ′ ) + N j=1 log p W (−1|z (s) i ′ , z (t) j ); ∀j ′ , z (t) j ′ ← arg max z (t) j ′ log p D (z (t) j ′ |x (t) j ′ ) + C i=1 log p W (−1|z (s) i , z (t) j ′ ); return {z (s) i ′ }, {z (t) j ′ } B, D,</formula><formula xml:id="formula_12">i ′ , z (t)</formula><p>j ′ for all the unseen-class data from both source and target domains, respectively. This naturally suggests the optimization algorithm in Alg. 2 at test time. Note that while the second term during this estimation process appears unusual we are merely exploiting the fact that the unseen class has no intersection with seen classes. Consequently, we can assume that y</p><formula xml:id="formula_13">(st) i ′ j = −1, y (st) ij ′ = −1.</formula><p>Notice that the latent vector computation is again amenable to fast parallel or distributed computing. Decision function: We next compute the likelihood of being the same class label, i.e. p(y</p><formula xml:id="formula_14">(st) i ′ j ′ |x (s) i ′ , x (t) j ′ ), for an arbi- trary target domain data x (t) j ′ using the source domain data (x (s) i ′ , y (s) i ′ ). We denote y (st) i ′ j ′ as x (t)</formula><p>j ′ sharing the same source domain class label with x (s) i ′ . There are two options: The first option is to directly employ latent estimates z</p><formula xml:id="formula_15">(s) i ′ , z (t) j ′ for x (s) i ′ , x (t)</formula><p>j ′ , respectively. Based on Eq. 5 this leads to the following expression (which is evidently related to the one employed in <ref type="bibr" target="#b43">[44]</ref>):</p><formula xml:id="formula_16">y (t) j ′ = y (s) i ′ * , i ′ * = arg max i ′ log p W (y (st) i ′ j ′ |z (s) i ′ , z (t) j ′ ) . (6)</formula><p>A second option is based on the lower bound surrogate as in Eq. 4. This option leads us to:</p><formula xml:id="formula_17">y (t) j ′ = y (s) i ′ * ,<label>(7)</label></formula><formula xml:id="formula_18">i ′ * = arg max i ′ log p B (z (s) i ′ |x (s) i ′ ) + log p W (y (st) i ′ j ′ |z (s) i ′ , z (t) j ′ ) .</formula><p>Note that the decision function in Eq. 7 is different from the one in Eq. 6, which is widely used in embedding methods (see Sec. 2.3.1), in that we also employ the source domain fit to identify the class label. Intuitively this option is meaningful because the information we have is asymmetric. We have a single source domain vector per class which captures the strongest information about that class. Consequently, our choice here reflects the fact that we can be confident about our prediction if the model can fit in the source domain data meaningfully.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Parameterization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Generalization of Existing Works</head><p>Our probabilistic model can be considered as generalization of many embedding methods for ZSL, including label embedding methods <ref type="bibr" target="#b0">[1]</ref>, output embedding methods <ref type="bibr" target="#b1">[2]</ref>, and semantic similarity embedding methods <ref type="bibr" target="#b43">[44]</ref>.</p><p>Linear embedding methods such as <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> directly set z (s) ∆ = x (s) for source domain and z (t) ∆ = x (t) for target domain. These methods do not employ a latent space. Thus log p(y (st) | x (s) , x (t) ) = log p W (y (st) | z (s) , z (t) ). We can map these methods to a special case of our method by parameterizing log p W (y (st) | z (s) , z (t) ) in terms of a regularized hinge loss.</p><p>Our probabilistic model also provides an explanation for nonlinear embedding methods such as those in <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b43">44]</ref>. For instance, in <ref type="bibr" target="#b43">[44]</ref> the source and target domain data is encoded independently by sparse coding (for p(z (s) |x (s) )) and nonlinear similarity functions such as intersection (for p(z (t) |x (t) )), respectively, and the regularized hinge loss (for log p W (y (st) | z (s) , z (t) )) is used for prediction.</p><p>In general we can also introduce arbitrary nonlinear mapping functions (e.g. deep neural networks <ref type="bibr" target="#b2">[3]</ref>) to parameterize our probabilistic model for generating the latent spaces as long as they satisfy our probabilistic model, namely, the posterior is modeled using data fit terms and the crossdomain latent similarity term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Supervised Dictionary Learning</head><p>In this section we develop a supervised dictionary learning formulation to parameterize Eq. 5. Specifically, we map data instances into the latent space as the coefficients based on a learned dictionary, and formulate an empirical risk function as the similarity measure which attempts to minimize the regularized hinge loss with the joint latent embeddings.</p><p>For purpose of exposition we overload notation in Sec. 2.2.1 and let B ∈ R ds×hs , D ∈ R dt×ht , W ∈ R hs×ht as the source domain dictionary, target domain dictionary, and the cross-domain similarity matrix in the joint latent space, respectively. Here d s and d t are original feature dimensions, and h s and h t are the sizes of dictionaries. Then given the seen class source domain data {(x</p><formula xml:id="formula_19">(s) i , y (s) i )} and target domain data {(x (t) j , y (t)</formula><p>j )}, we choose to parameterize the three log-likelihoods in Eq. 5, denoted by log p B , log p D , log p W , respectively using dictionary learning and regularized hinge loss as follows. For source domain embedding, following <ref type="bibr" target="#b43">[44]</ref>, we enforce source domain latent coefficients to lie on a simplex (see Eq. 8 below). For target domain embedding, we follow the convention. We allow the latent vectors to be arbitrary while constraining the elements in the dictionary to be within the unit ball. Specifically, ∀i, ∀j, we have,</p><formula xml:id="formula_20">− log p B ∝ λ (s) 1 2 z (s) i 2 2 + λ (s) 2 2 x (s) i − Bz (s) i 2 2 ,<label>(8)</label></formula><formula xml:id="formula_21">s.t. z (s) i ≥ 0, e T z (s) i = 1, − log p D ∝ λ (t) 1 2 z (t) j 2 2 + λ (t) 2 2 x (t) j − Dz (t) j 2 2 ,<label>(9)</label></formula><formula xml:id="formula_22">s.t. ∀k, D k 2 2 ≤ 1, − log p W ∝ λ W 2 W 2 F + max 0, 1 − 1 y (st) ij z (s) i T Wz (t) j ,<label>(10)</label></formula><p>where · F and · 2 are the Frobenius norm and ℓ 2 norm operators, ≥ is an entry-wise operator, [·] T is the matrix transpose operator, e is a vector of 1's, and ∀k, D k denotes the k-th row in the matrix D. Observe that our method leverages association between the source domain and target domain vectors across all seen classes and learns a single matrix for all classes. Our objective function utilizes a hinge loss to penalize misassociations between source and target pairs in the joint latent space.</p><p>Training &amp; Cross-Validation: We hold-out data corresponding to two randomly sampled seen classes and train our method using Alg. 1 on the rest of the seen classes for different combinations of regularization parameters. Training is performed by substituting Eq. 8, 9, and 10 into Alg. 1. For efficient computation, we utilize proximal gradient algorithms <ref type="bibr" target="#b27">[28]</ref> with simplex projection <ref type="bibr" target="#b7">[8]</ref> for updating z (s) i , ∀i and z (t) j , ∀j, respectively. We use linear SVMs to learn W.</p><p>Testing: We substitute Eq. 8, 9, and 10 into Alg. 2 and run it by fixing all the parameters learned during training. This leads to estimation of the latent embeddings for unseen class source and target domain data. Then we apply Eq. 6 or 7 to predict the class label for target domain data.  </p><formula xml:id="formula_23">(i) init. ∀z (s) i , ∀z (t) j + init. ∀z (s) i ′ , ∀z<label>(t</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>We test our method on four benchmark image datasets for zero-shot recognition and retrieval, i.e. aPascal &amp; aYahoo (aP&amp;Y) <ref type="bibr" target="#b9">[10]</ref>, Animals with Attributes (AwA) <ref type="bibr" target="#b16">[17]</ref>, Caltech-UCSD Birds-200-2011 (CUB-200-2011) <ref type="bibr" target="#b35">[36]</ref>, and SUN Attribute <ref type="bibr" target="#b28">[29]</ref>. <ref type="table" target="#tab_2">Table 1</ref> summarizes the statistics in each dataset. In our experiments we utilized the same experimental settings as <ref type="bibr" target="#b43">[44]</ref>. For comparison purpose we report our results averaged over 3 trials 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Implementation</head><p>(i) Cross validation: Similar to <ref type="bibr" target="#b43">[44]</ref>, we utilize cross validation to tune the parameters. Precisely, we randomly select two seen classes from training data for validation purpose, train our method on the rest of the seen classes, and record the performance using different parameter combinations. We choose the parameters with the best average performance on the held-out seen class data.</p><p>(ii) Dictionary initialization: For source domain, we initialize the dictionary B to be the collection of all the seen class attribute vectors on aP&amp;Y, AwA, and CUB-200-2011, because of the paucity of the number of vectors. On SUN, however, for computational reasons, we initialize B using KMeans with 200 clusters on the attribute vectors.</p><p>For target domain, we utilize the top eigenvectors of all training data samples to initialize the dictionary D. In <ref type="figure" target="#fig_3">Fig. 2(a)</ref>, we show the effect of varying the size of D on our accuracy on AwA and SUN Attribute datasets. As we see, within small ranges of dictionary size, our performance changes marginally. We set the initial sizes to be 40, 200, 300, and 200, for the four datasets respectively, and then tune them using cross validation.</p><p>(iii) Regularization parameters in Eq. 8, 9, and 10: We do a grid search to tune these parameters. In order to show how well our method adapts to different parameters, we display salient results in <ref type="figure" target="#fig_3">Fig. 2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Benchmark Comparison</head><p>On the four datasets, we perform two different tasks: (1) zero-shot recognition and (2) zero-shot retrieval. While both tasks are related, they measure different aspects of the system. Task 1 is fundamentally about classification of each target data instance. Task 2 measures which target domain samples are matched to a given source domain vector, and we adapt our recognition system for the purpose of retrieval. Specifically, given a source domain unseen class attribute vector we compute the similarities for all the unseen target domain data and sort the similarity scores. We can then compute precision, recall, average precision (AP) etc. to measure retrieval accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Zero-Shot Recognition</head><p>Recognition accuracy for each method is presented in Table 2. We also perform an ablative study in order to understand the contribution of different parts of our system. We experiment with the three parts of our system: (1) dictionary learning; (2) test-time latent variable estimation; <ref type="bibr" target="#b2">(3)</ref> incorporating source domain data fit term in prediction. Note that the source and target domain dictionaries B and D are initialized in the beginning of the dictionary learning process (see Sec 3.1 (ii)). Consequently, we can bypass dictionary learning (deleting repeat loop in Alg 1) and understand its impact. Next we can ignore the similarity function term for estimating the latent embeddings for unseen data during test-time. Finally, we can choose one of the two prediction rules (Eq. 6 or Eq. 7) to determine the utility of using source domain data fit term for prediction. We denote by "init. ∀z</p><formula xml:id="formula_24">(s) i , ∀z (t)</formula><p>j " when dictionary learning is bypassed; We denote by "init. ∀z</p><formula xml:id="formula_25">(s) i ′ , ∀z (t)</formula><p>j ′ " when similarity term is ignored during test-time. We list all the 8 choice combinations for our system in <ref type="table" target="#tab_3">Table 2</ref> (i) to (viii).</p><p>The overall best result is obtained for the most complex system using all parts of our system. For instance, as seen from (i) and (vii) we can see 3.70% gain in average recognition accuracy. Our algorithm "(viii) Alg. 1 + Alg. 2 + Eq. 7" achieves the best result among all the competitors, significantly outperforming the state-of-the-art by 4.90%. In the rest of the paper, we refer to (viii) as our method by default. <ref type="table" target="#tab_3">Table 2</ref> also demonstrates that on average, (a) the decision function in Eq. 7 performs better than that in Eq. 6, and (b) test-time learning of unseen class latent embeddings using Alg. 2 is more important than dictionary learning. For instance, by comparing (i) with (ii), using Eq. 7 the performance gains are 1.39% improvement over Eq. 6. We see modest gains (0.55%) from (iii) to (v). Still our ablative study demonstrates that on individual datasets there is no single system that dominates other system-level combinations. Indeed, for aP&amp;Y (vi) is worse than (v).</p><p>We visually depict (see <ref type="figure">Fig. 3</ref>) the learned test-time un-seen class embeddings, using t-SNE <ref type="bibr" target="#b34">[35]</ref> on AwA to facilitate better understanding of our results with respect to the state-of-art <ref type="bibr" target="#b43">[44]</ref>. Our method appears to learn more separable embeddings regardless of the target domain features (decaf <ref type="bibr" target="#b6">[7]</ref> or verydeep <ref type="bibr">-19)</ref>. Indeed, as seen in <ref type="figure">Fig. 3 (b,d)</ref> the embeddings appear to be more cluttered than those in (a,c). Next, in <ref type="figure">Fig. 4</ref> we plot the cosine similarity matrices for the learned embeddings as in <ref type="bibr" target="#b43">[44]</ref> on the AwA dataset. Note that <ref type="bibr" target="#b43">[44]</ref> employs so called semantic similarity embedding (SSE). The figures demonstrate that our method can generate a cosine similarity matrix which is much more similar to the source domain attribute cosine similarity (a). <ref type="figure">Fig. 3</ref> and <ref type="figure">Fig. 4</ref> together demonstrate that our method is capable of aligning the source and target domain data better than the state-of-the-art method <ref type="bibr" target="#b43">[44]</ref>. In addition it is capable of learning qualitatively better (clustered) embedding representations for different classes, leading to improvements in recognition accuracy on the four benchmark datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Zero-Shot Retrieval</head><p>We list comparative results for the mean average precision (mAP) for the four datasets in <ref type="table" target="#tab_6">Table 3</ref>. Since retrieval is closely related to recognition and, SSE <ref type="bibr" target="#b43">[44]</ref> is the state-ofart, we focus on comparisons with it. As we can see our method significantly and consistently outperforms SSE by 22.45% on average. Our superior performance in retrieval is due to the better domain alignment and more clustered embedding representations. This leads to better matching of target domain data to source domain vectors. Our retrieval results are based on adapting the recognition models    <ref type="figure">Figure 6</ref>. Top-5 zero-shot retrieval results using our method for class (from top to down) "Pig", "Raccoon", "Rat", and "Seal", respectively. Images with red rectangles are false-positive returns.</p><p>for the retrieval task. It is possible that incorporating pairwise ranking constraints into the training (e.g. into Eq. 10 for our method) may improve performance, but it is outside the scope of this paper.</p><p>We again attempt to further analyze our method on the AwA dataset. We list class-wise AP as well as mAP comparison in <ref type="table" target="#tab_7">Table 4</ref>, and illustrate the precision-recall curves for different methods in <ref type="figure" target="#fig_5">Fig. 5</ref>. Our method achieves over 70% AP for 6 out of 10 classes, and performs the best in 6 out of 10 classes. <ref type="figure" target="#fig_5">Fig. 5</ref> depicts illustrative examples for different categories. Nevertheless, we note that for some classes our method is unable to achieve satisfactory performance (although other methods also suffer from performance degradation). For instance, we only get 28.18% AP for class "seal". Note that in <ref type="figure">Fig. 4(e)</ref>, we can see that the last row (or column), which corresponds to "seal", shows some relatively high values in off-diagonal elements. This is because the problem of differentiating data within this class from data from other classes is difficult. Similar situations can be observed in SSE as well.</p><p>We also visualize our retrieval results in <ref type="figure">Fig. 6</ref> with the top-5 returns for "difficult" cases (classes with AP less than 50%) in <ref type="table" target="#tab_7">Table 4</ref>. Interestingly for the most difficult class "seal", all five images are correct. This is probably because the global patterns such as texture in the images are similar, leading to highly similar yet discriminative CNN features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>In this paper we propose a novel general probabilistic method for ZSL by learning joint latent similarity embeddings for both source and target domains. Based on the equivalence of ZSR and binary prediction, and the conditional independence between observed data and predicted class, we propose factorizing the likelihood of binary prediction using our probabilistic model to jointly learn the latent spaces for each domain. In this way, we generate a joint latent space for measuring the latent similarity between source and target data. Our similarity function is invariant across different classes, and hence intuitively it fits well to ZSR with good generalization to unseen classes. We further propose a new supervised dictionary learning based ZSR algorithm as parameterization of our probabilistic model. We conduct comprehensive experiments on four benchmark datasets for ZSL with two different tasks, i.e. zero-shot recognition and retrieval. We evaluate the importance of each key component in our algorithm, and show significant improvement over the state-of-the-art. Possible applications are person re-identification <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref> and zero-shot activity retrieval <ref type="bibr" target="#b4">[5]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>are independent given ∀j, z</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>parameters B, D, W , we can potentially utilize parallel or distributed computing to train our models. This has obvious computational benefits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>0, λ W ≥ 0 are fixed during training. Cross validation is used to estimate these parameters by holding out a portion of seen classes (see Sec. 3.1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Effect of (a) the size of target domain dictionary, and (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .Figure 4 .</head><label>34</label><figDesc>t-SNE visualization comparison between (a, c) SSE<ref type="bibr" target="#b43">[44]</ref> and (b, d) our method using decaf and verydeep-19 features on AwA testing data from unseen classes, respectively. Clearly our method can better separate features from different classes. Comparison of cosine similarity matrices created using different features on AwA testing data using (a) source domain attribute vectors, (b, d) SSE<ref type="bibr" target="#b43">[44]</ref> with decaf and verydeep-19, and (c, e) our method with decaf and verydeep-19, respectively. Brighter colors depict larger values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Illustration of precision-recall curve comparison on AwA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>for all the unseen classes are revealed. We are then presented with an instance of unseen target domain data, {x (t) j ′ }. Our objective is to identify an unseen source domain vector that best matches the unseen instance. As inputs for our test-time algorithm we are also given seen class latent embeddings {z Test-time estimation of latent embeddings</figDesc><table>(s) 

i } and {z 

(t) 

j } and the parameters 

Algorithm 2 Input 
: test data {(x 

(s) 

i ′ , y 

(s) 

i ′ )} and {x 

(t) 

j ′ }; learned latent embed-
dings for seen classes (training data) {z 

(s) 

i } and {z 

(t) 

j }; 
learned parameters B, D, W during training 

Output : {z 

(s) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>W that are all learned during training. Since we perform ZSR in the joint latent space, we have to estimate these new latent vectors z</figDesc><table>(s) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 1 .</head><label>1</label><figDesc>Statistics of different datasets, where "bin." and "cont." stand for binary value and continuous value, respectively.</figDesc><table>Dataset 
# instances # attributes # seen/unseen classes 
aP&amp;Y 
15,339 
64 (cont.) 20 / 12 
AwA 
30,475 
85 (cont.) 40 / 10 
CUB-200-2011 11,788 
312 (bin.) 150 / 50 
SUN Attribute 14,340 
102 (bin.) 707 / 10 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 2 .</head><label>2</label><figDesc>Zero-shot recognition accuracy comparison (%) on the four datasets. Except for<ref type="bibr" target="#b1">[2]</ref> where AlexNet<ref type="bibr" target="#b17">[18]</ref> is utilized for extracting CNN features, for all the other methods we use vgg-verydeep-19<ref type="bibr" target="#b32">[33]</ref> CNN features.</figDesc><table>Method 
aP&amp;Y 
AwA 
CUB-200-2011 SUN Attribute Ave. 
Akata et al. [2] 
-
61.9 
40.3 
-
-
Lampert et al. [19] 
38.16 
57.23 
-
72.00 
-
Romera-Paredes and Torr [32] 
24.22±2.89 
75.32±2.28 -
82.10±0.32 
-
SSE-INT [44] 
44.15±0.34 
71.52±0.79 30.19±0.59 
82.17±0.76 
57.01 
SSE-ReLU [44] 
46.23±0.53 
76.33±0.83 
30.41±0.20 
82.50±1.32 
58.87 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 3 .</head><label>3</label><figDesc>Retrieval performance comparison (%) using mAP.</figDesc><table>Method 
aP&amp;Y AwA CUB SUN Ave. 
SSE-INT [44] 
15.43 46.25 4.69 58.94 31.33 
SSE-ReLU [44] 14.09 42.60 3.70 44.55 26.24 
Ours 
38.30 67.66 29.15 80.01 53.78 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 .</head><label>4</label><figDesc>Retrieval performance comparison (%) using AP on AwA. Chim. Panda Leop. Cat Pig Hipp. Whale Racc. Rat Seal mAP 76.05 19.67 50.12 20.33 32.83 74.88 78.31 50.52 21.85 37.96 46.25 94.20 24.81 19.24 69.08 14.73 57.51 97.56 24.11 7.59 17.20 42.60 91.75 94.06 91.09 76.95 33.00 84.85 95.13 47.05 34.58 28.18 67.66</figDesc><table></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Intuitively this is a plausible mechanism. We as humans tend to draw connections from different sources to improve our understanding of objects/concepts.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Our code and CNN features can be downloaded at https:// zimingzhang.wordpress.com/.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We thank the anonymous reviewers for their very useful comments. This material is based upon work supported in part by the U.S. Department of Homeland Security, Science and Technology Directorate, Office of University Programs, under Grant Award 2013-ST-061-ED0001, by ONR Grant 50202168 and US AF contract FA8650-14-C-1728. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the social policies, either expressed or implied, of the U.S. DHS, ONR or AF.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Labelembedding for attribute-based classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Evaluation of output embeddings for fine-grained image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Predicting deep zero-shot convolutional neural networks using textual descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.00511</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automatic attribute discovery and characterization from noisy web data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient activity retrieval through semantic graph queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Castanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Elements of Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Series in Telecommunications and Signal Processing</title>
		<imprint>
			<publisher>Wiley-Interscience</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 31st International Conference on Machine Learning</title>
		<meeting>The 31st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="647" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Efficient projections onto the l 1-ball for learning in high dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chandra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="272" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Pattern classification and scene analysis 2nd ed</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Stork</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Describing objects by their attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Endres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Devise: A deep visual-semantic embedding model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2121" to="2129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Transductive multi-view embedding for zero-shot recognition and annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Zero-shot object recognition by semantic manifold distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2635" to="2644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Efficient max-margin multi-label classification with applications to zero-shot learning. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Zero-shot recognition with unreliable attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3464" to="3472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for zero-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning Multiple Layers of Features from Tiny Images. Master&apos;s thesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Attribute-based classification for zero-shot visual object categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Max-margin zero-shot learning for multi-class classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semi-supervised zero-shot classification with label representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A joint learning framework for attribute models and object descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sellamanickam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1227" to="1234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Costa: Co-occurrence statistics for zero-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gavves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G M</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="2441" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Metric learning for large scale image classification: Generalizing to new classes at near-zero cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="488" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Zero-shot learning by convex combination of semantic embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Zeroshot learning with semantic output codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palatucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1410" to="1418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Interactively building a discriminative vocabulary of nameable attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1681" to="1688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Proximal algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Optimization</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="127" to="239" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The sun attribute database: Beyond categories for deeper scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="59" to="81" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Transfer learning in a transductive setting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Evaluating knowledge transfer and zero-shot learning in a large-scale setting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1641" to="1648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An embarrassingly simple approach to zero-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Zero-shot learning through cross-modal transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ganjoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="935" to="943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">85</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<title level="m">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A unified probabilistic approach modeling relationships between attributes and objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2120" to="2127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Zeroshot event detection using multi-modal fusion of weakly supervised concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bondugula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Luisier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Natarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2665" to="2672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Designing category-level attributes for discriminative visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="771" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Attribute-based transfer learning for object categorization with zero/one training example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Aloimonos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="127" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A novel visual word cooccurrence model for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV Workshop on Visual Surveillance and Re-Identification</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Group membership prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">PRISM: Person re-identification via structured matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.4444</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Zero-shot learning via semantic similarity embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
