<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Cross-Domain Landmarks for Heterogeneous Domain Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao-Hung</forename><forename type="middle">Hubert</forename><surname>Tsai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for IT Innovation</orgName>
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Ren</forename><surname>Yeh</surname></persName>
							<email>yryeh@nknu.edu.tw</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">National Kaohsiung Normal University</orgName>
								<address>
									<settlement>Kaohsiung</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang</forename><forename type="middle">Frank</forename><surname>Wang</surname></persName>
							<email>ycwang@citi.sinica.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Research Center for IT Innovation</orgName>
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Cross-Domain Landmarks for Heterogeneous Domain Adaptation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>While domain adaptation (DA) aims to associate the learning tasks across data domains, heterogeneous domain adaptation (HDA) particularly deals with learning from cross-domain data which are of different types of features. In other words, for HDA, data from source and target domains are observed in separate feature spaces and thus exhibit distinct distributions. In this paper, we propose a novel learning algorithm of Cross-Domain Landmark Selection (CDLS) for solving the above task. With the goal of deriving a domain-invariant feature subspace for HDA, our CDLS is able to identify representative cross-domain data, including the unlabeled ones in the target domain, for performing adaptation. In addition, the adaptation capabilities of such cross-domain landmarks can be determined accordingly. This is the reason why our CDLS is able to achieve promising HDA performance when comparing to state-of-the-art HDA methods. We conduct classification experiments using data across different features, domains, and modalities. The effectiveness of our proposed method can be successfully verified.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>When solving standard machine learning and pattern recognition tasks, one needs to collect a sufficient amount of labeled data for learning purposes. However, it is not always computationally feasible to collect and label data for each problem of interest. To alleviate this concern, domain adaptation (DA) aims to utilize labeled data from a source domain, while only few (or no) labeled data can be observed in the target domain of interest <ref type="bibr" target="#b26">[27]</ref>. In other words, the goal of DA is to transfer the knowledge learned from an auxiliary domain, so that the learning task in the target domain can be solved accordingly.</p><p>A variety of real-world applications have been benefited from the recent advances of DA (e.g., sentiment analysis <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b32">33]</ref>, Wi-Fi localization <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>, visual object classification <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b7">8]</ref>, and cross-language text classification <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b28">29]</ref>). Generally, most existing DA approaches like <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b5">6]</ref> consider that source and target-domain data are collected using the same type of features. Such problems can be referred to homogeneous domain adaptation, i.e., cross-domain data are observed in the same feature space but exhibit different distributions.</p><p>On the other hand, heterogeneous domain adaptation (HDA) <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b27">28]</ref> deals with a even more challenging task, in which cross-domain data are described by different types of features and thus exhibit distinct distributions (e.g., training and test image data with different resolutions or encoded by different codebooks). Most existing approaches choose to solve HDA by learning feature transformation, which either projects data from one domain to the other, or to project cross-domain data to a common subspace for adaptation purposes <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b18">19]</ref>.</p><p>As noted in <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref>, exploiting unlabeled targetdomain instances during adaptation would be beneficial for HDA. Following their settings, we choose to address semisupervised HDA in this paper. To be more precise, a sufficient amount and few labeled data will be observed in the source and target domains, respectively. And, the remaining target-domain data (to be classified) will also be presented during the learning process. In our work, we propose a learning algorithm of Cross-Domain Landmark Selection (CDLS) for solving HDA. Instead of viewing all cross-domain data to be equally important during adaptation, our CDLS derives a heterogeneous feature transformation which results in a domain-invariant subspace for associating cross-domain data. In addition, the representative source and target-domain data will be jointly exploited for improving the adaptation capability of our CDLS. Once the adaptation process is complete, one can simply project cross-domain labeled and unlabeled target domain data into the derived subspace for performing recognition. Illustration of our CDLS is shown in <ref type="figure">Figure 1</ref>.</p><p>The contributions of this paper are highlighted below:</p><p>• We are among the first to exploit heterogenous source and target-domain data for learning cross-domain landmarks, aiming at solving semi-supervised HDA problems. • By learning the adaptability of cross-domain data (including the unlabeled target-domain ones), our CDLS derives a domain-invariant feature space for improved adaptation and classification performances.</p><p>• Experiments on classification tasks using data across different features, datasets, and modalities data are considered. Our CDLS is shown to perform favorably against state-of-the-art HDA approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Most existing HDA methods consider a supervised setting, in which only labeled source and target-domain data are presented during adaptation. Generally, these HDA approaches can be divided into two categories. The first group of them derive a pair of feature transformation (one for each domain), so that source and target-domain data can be projected into a common feature space for adaptation and recognition <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b40">41]</ref>. For example, Shi et al. <ref type="bibr" target="#b31">[32]</ref> proposed heterogeneous spectral mapping (HeMap), which selects source-domain instances for relating crossdomain data via spectral embedding. Wang and Mahadevan <ref type="bibr" target="#b37">[38]</ref> chose to solve domain adaptation by manifold alignment (DAMA), with the goal of preserving label information during their alignment/adaptation process. Duan et al. <ref type="bibr" target="#b11">[12]</ref> proposed heterogeneous feature augmentation (HFA) for learning a common feature subspace, in which SVM classifiers can be jointly derived for performing recognition.</p><p>On the other hand, the second category of existing HDA methods learn a mapping matrix which transforms the data from one domain to another <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b39">40]</ref>. For example, Kulis et al. <ref type="bibr" target="#b20">[21]</ref> proposed asymmetric regularized cross-domain transformation (ARC-t) for associating crossdomain data with label information guarantees. Hoffman et al. <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref> considered a max-margin domain transformation (MMDT) approach, which adapts the observed prediction models (i.e., SVMs) across domains. Similarly, Zhou et al. <ref type="bibr" target="#b41">[42]</ref> presented an algorithm of sparse heterogeneous feature representation (SHFR), which relate the predictive structures produced by the prediction models across do-mains for addressing cross-domain classification problems.</p><p>Nevertheless, the above HDA approaches only considered labeled source and target-domain data during adaption. As noted in literature on homogeneous domain adaptation <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b21">22]</ref>, unlabeled target-domain data can be jointly exploited for adaptation. Such semi-supervised settings have been shown to be effective for DA. Recent HDA approaches like <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref> also benefit from this idea. For example, inspired by canonical correlation analysis, Wu et al. <ref type="bibr" target="#b38">[39]</ref> presented an algorithm of heterogeneous transfer discriminant-analysis of canonical correlations (HTDCC). Their objective is to minimize canonical correlation between inter-class samples, while that between the intra-class ones can be maximized. Li et al. <ref type="bibr" target="#b22">[23]</ref> extended HFA <ref type="bibr" target="#b11">[12]</ref> to a semi-supervised version (i.e., SHFA), and further exploited projected unlabeled target-domain data into their learning process. Recently, Xiao and Guo <ref type="bibr" target="#b39">[40]</ref> proposed semi-supervised kernel matching for domain adaptation (SSKMDA), which determines a feature space while preserving cross-domain data locality information. They also proposed a semi-supervised HDA approach of subspace co-projection (SCP) in <ref type="bibr" target="#b40">[41]</ref>, and chose to minimize the divergence between cross-domain features and their prediction models. However, both SSKMDA and SCP require additional unlabeled source-domain data for HDA.</p><p>It is worth noting that, techniques of instance reweighting or landmark selection have been applied for solving domain adaptation problems <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b0">1]</ref>. Existing methods typically weight or select source-domain data, and only homogeneous DA settings are considered. Moreover, no label information from either domain is taken into consideration during the adaptation process. Based on the above observations, we address semi-supervised HDA by proposing CDLS for learning representative landmarks from crossdomain data. Our CDLS is able to identify the contributions of each landmark when matching cross-domain classconditional data distributions in the derived feature space. This is why improved HDA performance can be expected (see our experiments in Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Proposed Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem Settings and Notations</head><formula xml:id="formula_0">Let D S = {x i s , y i s } n S i=1 = {X S , y S } denote source- domain data,</formula><p>where each instance x s ∈ R d S is assigned with label y s ∈ L = {1, . . . , C} (i.e., a Ccardinality label set). For HDA with a semi-supervised setting, we let</p><formula xml:id="formula_1">D L = {x i l , y i l } n L i=1 = {X L , y L } and D U = {x i u , y i u } n U i=1 = {X U ,</formula><p>y U } as labeled and unlabeled target-domain data, respectively. We have x l , x u ∈ R d T and y l , y u ∈ L. Note that d S = d T , since source and target-domain data are of different types of features. In a nutshell, for solving semi-supervised HDA, we observe d S -dimensional source-domain data D S , few labeled d T -dimensional target-domain data D L , and all unlabeled target-domain data D U (to be recognized) during adaptation. Our goal is to predict the labels y U for X U .</p><p>For semi-supervised HDA, only few labeled data are presented in the target domain, while the remaining unlabeled target-domain instances are seen during the adaptation process. Nevertheless, a sufficient number of labeled data will be available in the source domain for performing adaptation. Different from <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41]</ref>, we do not require any additional unlabeled source-domain data for adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Cross-Domain Landmark Selection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Matching cross-domain data distributions</head><p>Inspired by the recent HDA approaches of <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b39">40]</ref>, we learn a feature transformation A which projects source-domain data to the subspace derived from the targetdomain data. In this derived subspace, our goal is to associate cross-domain data with different feature dimensionality and distinct distributions. Such association is achieved by eliminating the domain bias via matching cross-domain data distributions (i.e., marginal distributions P T (X T ) and P S (A ⊤ X S ), and the conditional ones P T (y T |X T ) and P S (y S |A ⊤ X S )). Unfortunately, direct estimation of P T (y T |X T ) and P S (y S |A ⊤ X S ) is not possible. As an alternative solution suggested in <ref type="bibr" target="#b23">[24]</ref>, we choose to match the estimated P T (X T |y T ) and P S (A ⊤ X S |y S ) by Bayes' Theorem <ref type="bibr" target="#b3">[4]</ref>.</p><p>As noted above, we first project all target-domain data into a m-dimensional subspace via PCA (note that m ≤ min{d S , d T }). In the remaining of this paper, we use x l and x u to denote reduced-dimensional labeled and unlabeled target-domain data, respectively. As a result, the linear transformation to be learned is A ∈ R m×d S . It is worth noting that, this dimension reduction stage is to prevent possible overfitting caused by mapping low-dimensional data in a high-dimensional space. Later in our experiments, we will vary the dimension number m for the completeness of our evaluation.</p><p>Recall that, as discussed in Section 2, most existing HDA works consider a supervised setting. That is, only labeled data in the target domain are utilized during training. In order to match cross-domain data distributions for such standard supervised HDA settings, we formulate the problem formulation as follows:</p><formula xml:id="formula_2">min A E M (A, D S , D L ) + E C (A, D S , D L ) + λ A 2 ,<label>(1)</label></formula><p>where E M and E C measure the differences between crossdomain marginal and conditional data distributions, respectively. The last term in <ref type="formula" target="#formula_2">(1)</ref> is penalized by λ to prevent overfitting A.</p><p>To solve (1), we resort to statistics to measure the probability density for describing data distributions. As suggested in <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b23">24]</ref>, we adopt empirical Maximum Mean Discrepancy (MMD) <ref type="bibr" target="#b15">[16]</ref> to measure the difference between the above cross-domain data distributions. As a result,</p><formula xml:id="formula_3">E M (A, D S , D L ) can be calculated as EM (A, DS, DL) = 1 nS n S i=1 A ⊤ x i s − 1 nL n L i=1 x i l 2 .<label>(2)</label></formula><p>For matching cross-domain conditional data distributions, we determine E C (A, D S , D L ) as:</p><formula xml:id="formula_4">EC (A, DS, DL) = C c=1 1 n c S n c S i=1 A ⊤ x i,c s − 1 n c L n c L i=1 x i,c l 2 + 1 n c S n c L n c S i=1 n c L j=1 A ⊤ x i,c s − x j,c l 2 ,<label>(3)</label></formula><p>where x i,c l indicates the labeled target-domain instance of class c, and n c L denotes the number of labeled target-domain instances in that class. Similarly, x i,c s is the source-domain data of class c, and n c S represents the number of sourcedomain data of class c.</p><p>In <ref type="formula" target="#formula_4">(3)</ref>, the first term calculates the difference between class-wise means for matching the approximated classconditional distributions (see <ref type="bibr" target="#b23">[24]</ref> for detailed derivations), while the second term enforces the embedding of transformed within-class data <ref type="bibr" target="#b36">[37]</ref>. We note that, since only labeled cross-domain data are utilized in (1), its solution for HDA can be considered as a supervised version of our CDLS (denoted as CDLS sup in Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">From supervised to semi-supervised HDA</head><p>To adopt the information of unlabeled target-domain data for improved adaptation, we advocate the learning of the landmarks from cross-domain data when deriving the aforementioned domain-invariant feature subspace.</p><p>Extended from (1), our proposed algorithm crossdomain landmark selection (CDLS) exploits heterogenous data across domains, with the ability to identify the adaptation ability of each instance with a properly assigned weight. Instances in either domain with a nonzero weight will be considered as a landmark.</p><p>With the above goal, the objective function of our CDLS can be formulated as follows:</p><formula xml:id="formula_5">min A,α,β E M (A, D S , D L , X U , α, β)+ E C (A, D S , D L , X U , α, β) + λ A 2 , s.t. {α c i , β c i } ∈ [0, 1] , α c⊤ 1 n c S = β c⊤ 1 n c U = δ,<label>(4)</label></formula><p>where α = [α 1 ; · · · ; α c ; · · · ; α C ] ∈ R n S and β = [β 1 ; · · · ; β c ; · · · ; β C ] ∈ R n U are the weights observed for all labeled and unlabeled data in source and target domains, respectively. We have</p><formula xml:id="formula_6">α c = [α c 1 ; · · · ; α c n c S ] and β c = [β c 1 ; · · · ; β c n c U ],</formula><p>where n c S and n c U denote the total numbers of the corresponding instances of or predicted as class c in the associated domain.</p><p>In <ref type="formula" target="#formula_5">(4)</ref>, δ ∈ [0, 1] controls the portion of cross-domain data in each class to be utilized for adaptation. If δ = 0, our CDLS would turn into its supervised version as described in Section 3.2.1. While we fix δ = 0.5 in our work, additional analysis on the selection and effect of δ will be provided in our experiments. We also note that, since the number of labeled target-domain instances X L is typically small in semi-supervised HDA, all of such data will be viewed as the most representative landmarks to be utilized during adaptation (i.e., no additional weights required for X L ).</p><p>The E M in (4) matches marginal cross-domain data distributions for HDA. With x l and x u indicating reduceddimensional labeled and unlabeled target-domain data, we calculate E M by:</p><formula xml:id="formula_7">E M (A, D S , D L , X U , α, β) = 1 δnS nS i=1 α i A ⊤ x i s − 1 nL+δnU nL i=1 x i l + nU i=1 β i x i u 2 .<label>(5)</label></formula><p>To match cross-domain conditional data distributions via E C , we apply SVM trained from labeled cross-domain data to predict the pseudo-labels y i u for x i u (as described later in Section 3.3.3). With { y i u } n U i=1 assigned for X U , the E C term in (4) can be expressed as:</p><formula xml:id="formula_8">E C (A, D S , D L , X U , α, β) = C c=1 E c cond + 1 e c E c embed ,<label>(6)</label></formula><p>where</p><formula xml:id="formula_9">E c cond = 1 δn c S n c S i=1 αiA ⊤ x i,c s − 1 n c L + δn c U   n c L i=1 x i,c l + n c U i=1 βi x i,c u   2 , E c embed = n c S i=1 n c L j=1 αiA ⊤ x i,c s − x j,c l 2 + n c L i=1 n c U j=1 x i,c l − βj x j,c u 2 + n c U i=1 n c S j=1 βi x i,c u − αj A ⊤ x j,c s 2 ,</formula><p>It can be seen that, E C term in <ref type="formula" target="#formula_8">(6)</ref> is extended from <ref type="formula" target="#formula_4">(3)</ref> by utilizing unlabeled target-domain data with pseudo-labels. Similar to (3), we match cross-domain class-conditional distributions and preserve local embedding of transformed data of each class using via E c cond and E c embed , respectively. The normalization term in <ref type="formula" target="#formula_8">(6)</ref> is calculated as e c = δn c S n c L + δn c L n c U + δ 2 n c U n c S . With both E M and E C defined, we address semisupervised HDA by solving <ref type="formula" target="#formula_5">(4)</ref>. This allows us to learn the proper weights α and β for the representative instances from both domains (i.e., cross-domain landmarks). As a result, our derived feature transformation A will result in a feature subspace with improved adaptation capability. This will be verified later by our experiments in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Optimization</head><p>We now discuss how we solve the optimization problem of (4). Similar optimization process can be applied to solve the supervised version of (1), which is presented in the Supplementary.</p><p>It can be seen that, the semi-supervised learning problem of (4) is a non-convex joint optimization problem with respect to A, α, and β. By advancing the technique of iterative optimization, we alternate between the learning of feature transformation A and landmark weights α and β. The latter also involves the prediction of pseudo-labels for unlabeled target-domain data. We now describe the optimization process below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Optimizing A</head><p>Given the weights of α and β fixed, we take the derivative of (4) with respect to A and set it equal to zero. The closed form solution of A can be derived as:</p><formula xml:id="formula_10">A = λI dS + X S H S X S ⊤ −1 X S H L X ⊤ L + H U X ⊤ U ,<label>(7)</label></formula><p>where I d S is a d S -dimensional identity matrix, matrices {X S ∈ R d S ×n S , X L ∈ R m×n L , X U ∈ R m×n U } represent source, transformed labeled and unlabeled targetdomain instances, respectively. Each entry (H S ) i,j in H S ∈ R n S ×n S denotes the derivative coefficient associated with x i s ⊤ x j s . Similar remarks can be applied to the matrices H L ∈ R n S ×n L and H U ∈ R n S ×n U . Detailed derivations are available in the Supplementary. <ref type="formula" target="#formula_2">(1)</ref>  Update transformation A by <ref type="formula" target="#formula_10">(7)</ref> 5:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Cross-Domain Landmark Selection (CDLS) Input: Labeled source and target-domain data</head><formula xml:id="formula_11">D S = {x i s , y i s } n S i=1 , D L = {x i l , y i l } n L i=1 ; unlabeled target- domain data {x i u } n U i=1 ; feature dimension m; ratio δ; parameter λ 1: Derive an m-dim. subspace via PCA from {x i l } n L i=1 and {x i u } n U i=1 2: Initialize A by</formula><p>Update landmark weights {α,β} by <ref type="formula" target="#formula_14">(9)</ref> 6:</p><p>Update pseudo-labels { y i u } n U i=1 by Section 3.3.3 7: end while Output: Predicted labels</p><formula xml:id="formula_12">{y i u } n U i=1 of {x i u } n U i=1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Optimizing α and β</head><p>With transformation A observed, we reformulate (4) as:</p><formula xml:id="formula_13">min α,β 1 2 α ⊤ K S,S α + 1 2 β ⊤ K U,U β − α ⊤ K S,U β − k S,L ⊤ α + k U,L ⊤ β s.t. {α c i , β c i } ∈ [0, 1] , α c⊤ 1 n c S = β c⊤ 1 n c U = δ.<label>(8)</label></formula><p>In <ref type="formula" target="#formula_13">(8)</ref>, each entry (K S,S ) i,j in K S,S ∈ R n S ×n S is the coefficient associated with (A ⊤ x i s ) ⊤ A ⊤ x j s , and each entry (k S,L ) i in k S,L ∈ R n S denotes the sum of the coefficients of (A ⊤ x i s ) ⊤ x j l over all x j l . Similar remarks can be applied to K S,U ∈ R n S ×n U , K U,U ∈ R n U ×n U , and k U,L ∈ R n U (see the Supplementary for detailed derivations).</p><p>With the above formulation, one can apply existing Quadratic Programming (QP) solvers and optimize the following problem instead:</p><formula xml:id="formula_14">min zi∈[0,1],Z ⊤ V=W 1 2 Z ⊤ BZ + b ⊤ Z,<label>(9)</label></formula><p>where</p><formula xml:id="formula_15">Z = α β , B = K S,S −K S,U −K ⊤ S,U K U,U , b = −k S,L k U,L , V = V S 0 n S ×C 0 n U ×C V U ∈ R (n S +n U )×2C with (V S ) ij = 1 if x i s ∈ class j 0 otherwise (V U ) ij = 1 if x i u predicted as class j 0 otherwise , W ∈ R 1×2C with (W) c = δn c S if c ≤ C δn c−C U if c &gt; C .</formula><p>Webcam DSLR <ref type="figure">Figure 2</ref>. Example images of Caltech-256 and Office dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Label prediction for X U</head><p>Given the feature transformation and the observed landmarks, we train linear SVMs <ref type="bibr" target="#b4">[5]</ref> using all transformed labeled cross-domain data with the associated weights. As a result, the labels of unlabeled target-domain data</p><formula xml:id="formula_16">{ x i u } n U i=1</formula><p>can be predicted accordingly.</p><p>To start our optimization process, we apply the supervised version of CDLS (i.e., Section 3.2.1) to initialize the transformation A and the pseudo-labels { y i u } n U i=1 . The pseudo code of our CDLS is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets and Settings</head><p>We first address the task of cross-domain object recognition, and consider the use of Office + Caltech-256 (C) datasets <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b16">17]</ref>. The Office dataset contains images collected from threee sub-datasets : Amazon (A) (i.e., images downloaded from the Internet), Webcam (W) (i.e., lowresolution images captured by web cameras), and DSLR (D) (i.e., high-resolution images captured by digital SLR cameras). This dataset has objects images of 31 categories, and Caltech-256 contains 256 object categories. Among these objects, 10 overlapping categories are selected for our experiments. <ref type="figure">Figure 2</ref> shows example images of the category of laptop computer. Following <ref type="bibr" target="#b13">[14]</ref>, two different types of features are considered for cross-domain object recognition: DeCAF 6 <ref type="bibr" target="#b10">[11]</ref> and SURF <ref type="bibr" target="#b2">[3]</ref>. We note that, the latter is described in terms of Bag-of-Words (BOW) features via kmeans clustering. The feature dimensions of DeCAF 6 and SURF are 4096 and 800, respectively.</p><p>We also solve the problem of cross-lingual text categorization, and apply the Multilingual Reuters Collection <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b1">2]</ref> dataset for experiments. This dataset contains about 11, 000 articles from 6 categories in 5 languages (i.e., English, French, German, Italian, and Spanish). To extract the features from these articles, we follow the settings in <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b22">23]</ref> in which all the articles are represented by BoW with TF-IDF, followed by PCA for dimension reduction (with 60% energy preserved). The reduced dimensions with respect to different language categories English, French, German, Italian, and Spanish are 1, 131, 1, 230, 1, 417, 1, 041, and 807, respectively.</p><p>For simplicity, we fix the ratio δ = 0.5 for all our ex- periments. We follow <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19]</ref> and set λ = 1 2 for regularizing A. We also fix m = 100 as the reduced dimensionality for the derived feature subspace. Later, we will provide analyses on convergence and parameter sensitivity in Section 4.4 for verifying the robustness of our CDLS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluations</head><p>For evaluation, we first consider the performance of the baseline approach of SVM t , which indicates the use of SVMs learned from only labeled target-domain data X L . To compare our approach with state-of-the-art HDA methods, we consider HeMap <ref type="bibr" target="#b31">[32]</ref>, DAMA <ref type="bibr" target="#b37">[38]</ref>, MMDT <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>, and SHFA <ref type="bibr" target="#b22">[23]</ref>. As noted earlier, since both SSKMDA <ref type="bibr" target="#b39">[40]</ref> and SCP <ref type="bibr" target="#b40">[41]</ref> require additional unlabeled data from the source domain for adaptation, we do not include their results for comparisons. Finally, we consider the supervised version of our CDLS (denoted as CDLS sup, see Section 3.2.1), which simply derives feature transformation without learning cross-domain landmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Object recognition across feature spaces</head><p>To perform cross-feature object recognition on Office + Caltech-256 (C), two different types of features are available: SURF vs. DeCAF 6 . If one of them is applied for describing the source-domain data, the other will be utilized for representing those in the target domain. For sourcedomain data with SURF features, we randomly choose 20 images per category as labeled data. As for the target domain with DeCAF 6 , we randomly choose 3 images per object category as labeled data, and the rest images in each category as the unlabeled ones to be recognized. The same procedure is applied to the uses of DeCAF 6 and SURF for describing source and target-domain data, respectively. <ref type="table" target="#tab_2">Table 1</ref> lists the average classification results with 10 random trials. Since the number of images in DSLR (D) is much smaller than those in other domains (i.e., Amazon (A), Webcam (W), and Caltech-256 (C)), we only report the recognition performance on A, W, and C. Also, the performance of HeMap was much poorer than all other approaches (e.g., 11.7% on C for DeCAF 6 to SURF), so we do not include its performance in the table. From <ref type="table" target="#tab_2">Table 1</ref>, it can be seen that the methods of DAMA and CDLS sup did not always achieve comparable performance as the baseline approach of SVM t did. A possible explanation is that these two HDA approaches only related cross-domain heterogeneous data by deriving feature transformation for alignment purposes. For other HDA ones like MMDT, and SHFA, they additionally adapted the prediction models across-domain and thus produced improved results. Nevertheless, our CDLS consistently achieved the best performance across all categories. This supports the use of our HDA approach for cross-feature object recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Object recognition across features and datasets</head><p>In this part of the experiments, we have source and targetdomain data collected from distinct datasets and also described by different types of features. We adopt the same settings in Section 4.2.1 for data partition, while the only difference is that we choose DSLR as the target domain with others as source domains. <ref type="table" target="#tab_3">Table 2</ref> lists the average classification results from 10 random trials. From this table, we see that existing HDA approaches generally produced slightly improved results than the use of SVM t . Again, our proposed CDLS is observed to perform favorably against all HDA methods. It is worth repeating that, our improvement over CDLS sup verifies the idea of exploiting information from unlabeled samples to select representative cross-domain landmarks for HDA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Cross-lingual text categorization</head><p>To perform cross-lingual text categorization, we view articles in different languages as data in different domains. In our experiments, we have {English, French, German, or Italian} as the source domain, and randomly selected 100 articles from each as labeled data. On the other hand, we have Spanish as the target domain; for the target-domain data, we vary the number of labeled articles (from {5, 10, 15, 20}) per category, and randomly choose 500 articles from the remaining ones (per category) as the unlabeled data to be categorized. <ref type="figure" target="#fig_0">Figure 3</ref> illustrates the results over different numbers of labeled target-domain data. From this figure, it can be seen  that the performances of all approaches were improved with the increase of the number of labeled target-domain data, while the difference between HDA approaches and SVM t became smaller. We also list the categorization results in <ref type="table" target="#tab_4">Table 3</ref> (with 10 and 20 labeled target-domain instances per category). From the results presented in both <ref type="figure" target="#fig_0">Figure 3</ref> and <ref type="table" target="#tab_4">Table 3</ref>, the effectiveness of our CDLS for cross-lingual text categorization can be successfully verified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Remarks on Cross-Domain Landmarks</head><p>Recall that the weights α and β observed for instances from each domain indicates its adaptation capability. That is, a labeled source-domain instance with a large α c i and an unlabeled target-domain instance with a large β c i would indicate that they are related to the labeled target-domain data of the same class c.</p><p>In <ref type="figure" target="#fig_2">Figure 4</ref>, we visualize the embedding for the adapted data and cross-domain landmarks using t-distributed stochastic neighbor embedding (t-SNE) <ref type="bibr" target="#b35">[36]</ref>. Moreover, in <ref type="figure" target="#fig_3">Figure 5</ref>, we show example images and landmarks observed with different weights from two categories laptop computer and bike on Caltech-256 → DSLR (with SURF to DeCAF 6 ). It can be seen that, the source-domain images with larger weights were not only more representative in terms of the category information, they were also visually more similar to the target-domain images of the class of interest. The same remarks can also be applied to the unlabeled target-domain data viewed as landmarks. It is also worth noting that, unlabeled target-domain images with smallers weights would be more likely to be mis-classified.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Convergence and Parameter Sensitivity</head><p>To further analyze the convergence property of our CDLS and assess its parameter sensitivity, we conduct additional experiments on cross-domain object recognition using C to D (with SURF to DeCAF 6 ). As discussed in Section 3.3, we alternate between the variables to be optimized when solving our CDLS.</p><p>We report the recognition performance with respect to the iteration number in <ref type="figure" target="#fig_4">Figure 6</ref>(a), in which we observe that the performance converged within 10 iterations. This observation is consistent to those of our other HDA experiments in this paper. As for the parameters of interest, we first discuss the selection of the dimension m of the reduced feature space. We vary the dimension number m and perform cross-domain recognition on the above cross-domain pairs. The results are presented in <ref type="figure" target="#fig_4">Figure 6</ref>(b). From this figure, we see that the performance increased when m was larger, while such performance improvements became marginal for m beyond 100. Thus, m = 100 would be a preferable choice for our experiments.  Recall that the ratio δ in (4) controls the portion of crossdomain landmarks to be exploited for adaptation. <ref type="figure" target="#fig_4">Figure  6</ref>(c) presents the performance of CDLS with different δ values. It is worth repeating that, CDLS would be simplified as the supervised version CDLS sup if δ = 0, as illustrated by the flat dotted line in <ref type="figure" target="#fig_4">Figure 6</ref>(c). As expected, using all (δ = 1) or none (δ = 0) of the cross-domain data as landmarks would not be able to achieve satisfactory HDA performance. Therefore, the choice of δ = 0.5 would be reasonable in our experiments.</p><p>Finally, <ref type="figure" target="#fig_4">Figure 6</ref>(d) presents the results of CDLS and CDLS sup with varying λ values for regularizing A. From this figure, it can be seen that fixing λ = 1 2 as suggested by <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19]</ref> would also be a reasonable choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We proposed Cross-Domain Landmark Selection (CDLS) for performing heterogeneous domain adaptation (HDA). In addition to the ability to associate heterogeneous data across domains in a semi-supervised setting, our CDLS is able to learn representative cross-domain landmarks for deriving a proper feature subspace for adaptation and classification purposes. Since the derived feature subspace matches cross-domain data distribution while eliminating the domain differences, we can simply project labeled cross-domain data to this domain-invariant subspace for recognizing the unlabeled target-domain instances. Finally, we conducted experiments on three classification tasks across different features, datasets, and modalities. Our CDLS was shown to perform favorably against state-of-the-art HDA approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>Classification results on cross-lingual text categorization using Multilingual Reuters Collection. Note that Spanish is viewed as the target domain, while the source domains are selected from (a) English, (b) French, (c) German, and (d) Italian, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>For example, the image bounded by the red rectangle in Figure 5 was recognized as a similar yet different object category of monitor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Landmarks (with different weights) observed from source and target-domain data in the recovered subspace.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Example images and landmarks (with the observed weights) for Caltech-256 → DSLR (with SURF to DeCAF6). The object categories are (a) laptop computer and (b) bike. Note that the image bounded by the red rectangle was mis-classified as monitor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Analysis on convergence and parameter sensitivity using Caltech-256 with SURF to DSLR with DeCAF6. The parameters of interests are (a) iteration number, (b) reduced dimensionality m, (c) ratio δ, and (d) regularization parameter λ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table>Classification results (%) with standard deviations for 
cross-feature object recognition. 

S,T 
SVM t 
DAMA 
MMDT 
SHFA 
CDLS sup 
CDLS 
SURF to DeCAF 6 
A, A 
87.3±0.5 87.4±0.5 89.3±0.4 88.6±0.3 
86.7±0.6 
91.7±0.2 
W, W 87.1±1.1 87.2±0.7 87.3±0.8 90.0±1.0 
88.5±1.4 
95.2±0.9 
C, C 
76.8±1.1 73.8±1.2 80.3±1.2 78.2±1.0 
74.8±1.1 
81.8±1.1 
DeCAF 6 to SURF 
A, A 
43.4±0.9 38.1±1.1 40.5±1.3 42.9±1.0 
45.6±0.7 
46.4±1.0 
W, W 57.9±1.0 47.4±2.1 59.1±1.2 62.2±0.7 
60.9±1.1 
63.1±1.1 
C, C 
29.1±1.5 18.9±1.3 30.6±1.7 29.4±1.5 
31.6±1.5 
31.8±1.2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 2 .</head><label>2</label><figDesc>Classification results (%) with standard deviations for object recognition across feature representations and datasets.</figDesc><table>S,T 
SVM t 
DAMA 
MMDT 
SHFA 
CDLS sup 
CDLS 
SURF to DeCAF 6 
A, D 
90.9±1.1 

91.5±1.2 92.1±1.0 93.4±1.1 
92.0±1.2 
96.1±0.7 
W, D 
91.2±0.9 91.5±0.8 92.4±0.9 
91.0±1.1 
95.1±0.8 
C, D 
91.0±1.3 93.1±1.2 93.8±1.0 
91.9±1.3 
94.9±1.5 
DeCAF 6 to SURF 
A, D 
54.4±1.0 

53.2±1.5 53.5±1.3 56.1±1.0 
54.3±1.3 
58.4±0.8 
W, D 
51.6±2.2 54.0±1.3 57.6±1.1 
57.8±1.0 
60.5±1.0 
C, D 
51.9±2.1 56.7±1.0 57.3±1.1 
54.8±1.0 
59.4±1.2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 3 .</head><label>3</label><figDesc>Classification results with standard deviations for cross-lingual text categorization with Spanish as the target domain.</figDesc><table>Source 
Articles 

# labeled target domain data / category = 10 
# labeled target domain data / category = 20 
SVMt 
DAMA 
MMDT 
SHFA 
CDLS sup 
CDLS 
SVMt 
DAMA 
MMDT 
SHFA 
CDLS sup 
CDLS 
English 

66.7±0.9 

67.4±0.7 68.2±1.0 67.8±0.7 
69.6±0.8 
70.8±0.7 

73.1±0.6 

73.6±0.7 74.2±0.8 74.1±0.4 
76.2±0.6 
77.4±0.7 
French 
67.8±0.6 68.3±0.8 68.1±0.6 
69.3±0.8 
71.2±0.8 
73.7±0.7 74.6±0.7 74.5±0.6 
76.4±0.4 
77.6±0.7 
German 
67.3±0.6 67.9±1.0 68.4±0.7 
69.3±0.7 
71.0±0.8 
73.7±0.7 74.9±0.8 74.7±0.5 
76.6±0.6 
78.0±0.6 
Italian 
66.2±1.0 67.0±0.9 68.0±0.7 
69.5±0.8 
71.7±0.8 
73.6±0.7 74.6±0.7 74.5±0.5 
76.1±0.5 
77.5±0.7 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported in part by the Ministry of <ref type="table">Science and Technology of Taiwan under Grants MOST103-2221-E-001-021-MY2, MOST104-2221-E-017-016, and  MOST104-2119-M-002-039.</ref> </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Landmarks-based kernelized subspace alignment for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Aljundi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Emonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Muselet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sebban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning from multiple partially observed views-an application to multilingual text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Goutte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Surf: Speeded up robust features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Libsvm: A library for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2011" />
			<publisher>TIST</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Joint transfer and batch-mode active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chattopadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Panchanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Co-training for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Assembling heterogeneous domain adaptation methods for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chidlovskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gangwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cross Language Evaluation Forum (CLEF)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Selective transfer machine for personalized facial action unit detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Translated learning: Transfer learning across different feature spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-R</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning with augmented features for heterogeneous domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Domain adaptation from multiple sources: A domain-dependent regularization approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Neural Networks and Learning Systems (T-NNLS)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Transductive transfer machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Farajidavar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Campos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference of Computer Vision (ACCV)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A kernel method for the two-sample-problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Caltech-256 object category dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient learning of domain-invariant image representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representation (ICLR)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Asymmetric and category invariant feature transformations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In International Journal of Computer Vision</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Correcting sample selection bias by unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">What you saw is not what you get: Domain adaptation using asymmetric kernel transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Co-regularization based semi-supervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daume</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning with augmented features for supervised and semi-supervised heterogeneous domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Transfer feature learning with joint distribution adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adaptive localization in a dynamic wifi environment through multi-view learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Domain adaptation via transfer component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Neural Networks and Learning Systems (T-NNLS)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Knowledge and Data Engineering (TKDE)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Visual domain adaptation: A survey of recent advances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Signal Processing Magazine</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Cross-language text classification using structural correspondence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generalized domain-adaptive dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Transfer learning on heterogenous feature spaces via spectral transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Data Mining (ICDM)</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A co-regularization approach to semi-supervised learning with multiple views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML) workshop</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Simultaneous deep transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference in Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">NRC&apos;s PORTAGE system for WMT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ueffing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Larkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL) workshop</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Machine Learning Research (JMLR)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Manifold alignment without correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Heterogeneous domain adaptation using manifold alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Cross-view action recognition over heterogeneous feature spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference in Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Feature space independent semisupervised domain adaptation via kernel matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Semi-supervised subspace coprojection for multi-class heterogeneous domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Machine Learning (ECML)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Heterogeneous domain adaptation for multiple classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics (AISTATS)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Heterogeneous transfer learning for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-R</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
