<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-Adaptive Matrix Completion for Heart Rate Estimation from Face Videos under Realistic Conditions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Tulyakov</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Trento</orgName>
								<address>
									<addrLine>Via Sommarive 9</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Alameda-Pineda</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Trento</orgName>
								<address>
									<addrLine>Via Sommarive 9</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
							<email>eliricci@fbk.eu</email>
							<affiliation key="aff1">
								<orgName type="institution">Fondazione Bruno Kessler</orgName>
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Perugia</orgName>
								<address>
									<addrLine>Via Duranti 93</addrLine>
									<postCode>06123</postCode>
									<settlement>Perugia</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Yin</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">State University of New York at Binghamton</orgName>
								<address>
									<postCode>13902</postCode>
									<settlement>Binghamton</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
							<email>jeffcohn@pitt.edu</email>
							<affiliation key="aff4">
								<orgName type="department">Robotics Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Pittsburgh</orgName>
								<address>
									<postCode>15260</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
							<email>niculae.sebe@unitn.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Trento</orgName>
								<address>
									<addrLine>Via Sommarive 9</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Self-Adaptive Matrix Completion for Heart Rate Estimation from Face Videos under Realistic Conditions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent studies in computer vision have shown that, while practically invisible to a human observer, skin color changes due to blood flow can be captured on face videos and, surprisingly, be used to estimate the heart rate (HR). While considerable progress has been made in the last few years, still many issues remain open. In particular, stateof-the-art approaches are not robust enough to operate in natural conditions (e.g. in case of spontaneous movements, facial expressions, or illumination changes). Opposite to previous approaches that estimate the HR by processing all the skin pixels inside a fixed region of interest, we introduce a strategy to dynamically select face regions useful for robust HR estimation. Our approach, inspired by recent advances on matrix completion theory, allows us to predict the HR while simultaneously discover the best regions of the face to be used for estimation. Thorough experimental evaluation conducted on public benchmarks suggests that the proposed approach significantly outperforms state-ofthe-art HR estimation methods in naturalistic conditions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>After being shown in <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b17">18]</ref> that changes invisible to the naked eye can be used to estimate the heart rate from a video of human skin, this topic has attracted a lot of attention in the computer vision community. These subtle changes encompass both color <ref type="bibr" target="#b26">[27]</ref> and motion <ref type="bibr" target="#b3">[4]</ref> and they are induced by the internal functioning of the heart. Since faces appear frequently in videos and due to recent and sig-Time <ref type="figure">Figure 1</ref>. Motivation: Given a video sequence, automatic HR estimation from facial features is challenging due to target motion and facial expressions. Facial features extracted over time in different parts of the face (purple rectangles) show different temporal dynamics and are subject to noise, as they are heavily affected by movements and illumination changes. In this paper, we propose a novel approach to simultaneously estimate the HR signal and select the reliable face regions at each time for robust HR prediction. nificant improvements in face tracking and alignment methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b28">29]</ref>, facial-based remote heart rate estimation has recently become very popular <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>Classical approaches successfully addressed this problem under laboratory-controlled conditions, i.e. imposing constraints on the subject's movements and requiring the absence of facial expressions and mimics <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b3">4]</ref>. Therefore, such methods may not be suitable for real world applications, such as monitoring drivers inside a vehicle or people exercising. Long-time analysis constitutes a further limitation of existing works <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19]</ref>. Indeed, instead of es-timating the instantaneous heart rate, they provide the average HR measurement over a long video sequence. The main disadvantage of using a long analysis window is the inability to capture interesting short-time phenomena, such as a sudden HR increase/decrease due to specific emotions <ref type="bibr" target="#b21">[22]</ref>.</p><p>In practice, another problem faced by researchers developing automatic HR measurement approaches, is the lack of publicly available datasets recorded under realistic conditions. A notable exception is the MAHNOB-HCI dataset <ref type="bibr" target="#b19">[20]</ref>, a multimodal dataset for research on emotion recognition and implicit tagging, which also contains HR annotations. Importantly, an extensive evaluation of existing HR measurement methods on MAHNOB-HCI have been performed by Li et al. <ref type="bibr" target="#b16">[17]</ref>. However, the MAHNOB-HCI dataset suffers from some limitations, since the recording conditions are quite controlled: most of the video sequences do not contain spontaneous facial expressions, illumination changes or large target movements <ref type="bibr" target="#b16">[17]</ref>.</p><p>In this work, we tackle the aforementioned problems by introducing a novel approach for HR estimation from face videos and providing an extensive evaluation on two datasets: the MAHNOB-HCI, previously used for HR recognition research <ref type="bibr" target="#b16">[17]</ref>, and a spontaneous dataset with heart rate data and RGB videos (named MMSE-HR), which is a subset of the larger multimodal spontaneous emotion corpus (MMSE) <ref type="bibr" target="#b30">[31]</ref> specifically targeted to challenge HR estimation methods.</p><p>Inspired by previous methods, we track the face in a given video sequence, so to follow rigid head movements <ref type="bibr" target="#b16">[17]</ref>, and extract chrominance features <ref type="bibr" target="#b9">[10]</ref> to compensate for illumination variations. Importantly, most previous approaches preselect a face region of interest (ROI) that is kept constant through the entire HR estimation. However, the region containing useful features for HR estimation is a priori different for every frame since major appearance changes are spatially and temporally localized <ref type="figure">(Fig.1)</ref>. Therefore, we propose a principled data-driven approach to automatically detect the face parts useful for HR measurement, that is to estimate the time-varying mask of useful observations, selecting at each frame the relevant face regions from the chrominance features themselves.</p><p>Recent advances on matrix completion (MC) theory <ref type="bibr" target="#b10">[11]</ref> have shown the ability to recover missing entries of a matrix that is partially observed, i.e. masked. Up to the authors knowledge, we propose the first matrix completion-based learning algorithm able to self-adapt, that is to automatically select the useful observations, and call it self-adaptive matrix completion (SAMC). Intuitively, while learning the mask allows us to discard those face regions strongly affected by facial expressions or large movements, completing the matrix smooths out the smaller noise associated to the chrominance feature extraction procedure. The experiments we conducted on the MANHOB-HCI dataset clearly show that our method outperforms the state-of-the-art approaches for HR prediction. To further demonstrate the ability of our method to operate in challenging scenarios, we report a series of tests on the MMSE-HR dataset, where subjects show significant movements and facial expressions.</p><p>Thus, the contribution of this paper is three-fold:</p><p>• We present a novel approach to address the problem of HR estimation from face videos in realistic conditions. To cope with large facial variations due to spontaneous facial expressions and movements, we propose a principled framework to automatically discard the face regions corresponding to noisy features and only use the reliable ones for HR prediction. The region selection is addressed within a novel matrix completion-based optimization framework, called self-adaptive matrix completion, for which an efficient solver is proposed.</p><p>• Our approach is demonstrated to be more accurate than previous methods for average HR estimation on publicly available benchmarks. In addition, we report short-term analysis results to show the ability of our method to detect instantaneous heart rate.</p><p>• We perform extensive evaluation on the commonly used MAHNOB-HCI dataset and a spontaneous MMSE-HR dataset including 102 sequences of 40 subjects, moving and performing spontaneous facial expressions. As we show, this dataset is valuable for instantaneous HR estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In this section, we briefly review previous works on remote heart rate measurement and on matrix completion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">HR Estimation from Face Videos</head><p>Cardiac activity measurement is an essential tool to control the subjects' health and is actively used by medical practitioners. Conventional contact methods offer high accuracy of cardiac cycle. However, they require specific sensors to be attached to the human skin, be it a set of electrocardiogram (ECG) leads, a pulse oximiter, or the more recent fitness tracker. To avoid the use of invasive sensors, non-contact remote HR measurement from visual data has been proposed recently by computer vision researchers.</p><p>Verkruysse et al. <ref type="bibr" target="#b22">[23]</ref> showed that ambient light and a consumer camera can be used to reveal the cardio-vascular pulse wave and to remotely analyze the vital signs of a person. Poh et al. <ref type="bibr" target="#b17">[18]</ref> proposed to use blind source separation on color changes caused by heart activity to extract the HR signal from a face video. In <ref type="bibr" target="#b26">[27]</ref> an Eulerian magnification method is used to amplify subtle changes in a video stream and to visualize temporal dynamics of the blood flow. Balakrishnan et al. <ref type="bibr" target="#b3">[4]</ref> showed that subtle head motions are affected by cardiac activity, and these motions can be used to extract HR measurements from a video stream.</p><p>However, all these methods failed to address the problems of HR estimation in presence of facial expressions and subject's movements, despite their frequent presence in real-world applications. This limits the use of these approaches to laboratory settings. In <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b24">25]</ref> a chrominancebased method to relax motion constraints was introduced. However, this approach was tested on a few not-publiclyavailable sequences, making it hard to compare with.</p><p>Li et al. <ref type="bibr" target="#b16">[17]</ref> proposed an approach based on adaptive filtering to handle illumination and motion issues and they evaluated it on the publicly available MAHNOB-HCI dataset <ref type="bibr" target="#b19">[20]</ref>. However, although this work represents a valuable step towards remote HR measurement from visual data, it also shares several major limitations with the previous methods. The output of the method is the average HR, whereas to capture short-term phenomena (e.g. HR variations due to instantaneous emotions) the processing of smaller time intervals is required. A further limitation of <ref type="bibr" target="#b16">[17]</ref> is the MAHNOB-HCI dataset itself, since it is collected in a laboratory setting and the subjects are required to wear an invasive EEG measuring device on their head. Additionally, subjects perform neither large movements nor many spontaneous facial expressions.</p><p>In this work, we address the aforementioned limitations by proposing a novel method capable of predicting HR with higher accuracy than the state-of-the-art approaches and of robustly operating on short time sequences in order to detect the instantaneous HR. To our knowledge, while previous works <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b24">25]</ref> have acknowledged the importance of selecting parts of the signal to cope with noise and provide robust HR estimates, this paper is the first to tackle this problem within a principled optimization framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Matrix completion</head><p>Matrix completion <ref type="bibr" target="#b10">[11]</ref> approaches develop from the idea that an unknown low-rank matrix can be recovered from a small set of entries. This is done by solving an optimization problem, namely, a rank minimization problem subject to some data constraints arising from the small set of entries. Matrix completion has proved successful for many computer vision tasks, when data and labels are noisy or in the case of missing data, such as multi-label image classification <ref type="bibr" target="#b5">[6]</ref>, image retrieval and tagging <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b8">9]</ref>, manifold correspondence finding <ref type="bibr" target="#b15">[16]</ref>, head/body pose estimation <ref type="bibr" target="#b0">[1]</ref> and emotion recognition from abstract paintings <ref type="bibr" target="#b1">[2]</ref>. Most of these works extended the original MC framework by imposing task-specific constraints. For instance, in <ref type="bibr" target="#b8">[9]</ref> a MC problem is formulated adding a specific regularizer to address the ambiguous labeling problem. Very importantly, even if most computer-vision papers based on matrix completion are addressing classification tasks, therefore splitting the matrix to be completed between features and labels, MC techniques can be used in general, without any structural splitting. Indeed, in <ref type="bibr" target="#b14">[15]</ref> matrix completion is adopted to address the movie recommendation problem, where each column (row) represents a user (movie), and therefore each entry of the matrix shows the suitableness of a video for a user. In <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b14">15]</ref>, the MC problem is extended to take into account an underlying graph structure inducing a weighted relationship between the columns/rows of the matrix. In this paper, we were inspired by <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b0">1]</ref> in modeling the temporal smoothness of the HR signal. However, our method is essentially novel, since we are able to simultaneously recover the unknown low-rank matrix and the underlying data mask, corresponding to the most reliable observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">HR Estimation using SAMC</head><p>In this section we describe the proposed approach for HR estimation from face videos, that has four main phases as shown in <ref type="figure" target="#fig_0">Figure 2</ref>. Phase 1 is devoted to process face images so to extract face regions, that are used in phase 2 to compute chrominance features. Phase 3 consists in the joint estimation of the underlying low-rank feature matrix and the mask using SAMC. Finally, phase 4 computes the heart rate from the signal estimate provided by SAMC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Phases 1 &amp; 2: From Face Videos to Chrominance Features</head><p>Inspired by previous methods on remote HR estimation, we use Intraface 1 to localize and track 66 facial landmarks. Many approaches have been employed for face frontalisation <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b11">12]</ref>. However, in order to preserve the underlying blood flow signal, in the current study we define the facial region of interest (see <ref type="figure" target="#fig_0">Fig. 2</ref>-Phase 1), from which the HR will be estimated. The potential ROI is then warped to a rectangle using a piece-wise linear warping procedure, before dividing the potential ROI into a grid containing R regions.</p><p>The overall performance of the HR estimation method will strongly depend on the features extracted on each of the R sub-regions of the facial ROI. Ideally, we would select features that are robust to facial movements and expressions, while being discriminant enough to account for the subtle changes in skin color. Currently, the best features for HR estimation are the chrominance features, defined in <ref type="bibr" target="#b9">[10]</ref>. The chrominance features for HR estimation are derived from the RGB channels, as follows. For each pixel the chrominance signal C is computed as the linear combination of two signals  Overview of the proposed approach for HR estimation. During the first phase, we automatically detect a set of facial keypoints and use them to define a ROI. This region is then warped to a rectangular area and divided into a grid. For each small sub-region, chrominance features are computed (Phase 2). We then apply SAMC on the matrix of all feature observations to recover a smooth signal, while selecting from which sub-regions the signal is recovered (Phase 3). Welch's method <ref type="bibr" target="#b25">[26]</ref> is used to estimate the power spectral density and thus the HR frequency (Phase 4).</p><formula xml:id="formula_0">X f and Y f , i.e. C = X f − αY f , where α = σ(X f ) σ(Y f ) and σ(X f ), σ(Y f ) denote</formula><p>deviations of X f , Y f . The signals X f , Y f are band-passed filtered signals obtained respectively from the signals X and Y , where X =3 R n − 2G n , Y =1 .5R n + G n − 1.5B n and R n ,G n and B n are the normalized values of the individual color channels. The color combination coefficients to derive X and Y are computed using a skin-tone standardization approach (see <ref type="bibr" target="#b9">[10]</ref> for details). For each region r =1 ,...,R, the final chrominance features are computed averaging the values of the chrominance signals over all the pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Phase 3: Self-Adaptive Matrix Completion</head><p>The estimation of HR from the chrominance features is challenging for mainly two reasons. Firstly, the chrominance features associated to different facial regions are not fully synchronized. In other words, even if the output signals of many regions are synchronized between them (mainstream underlying heart signal), the signal of many other regions may not be in phase with the mainstream. Secondly, face movements and facial expressions induce strong perturbations in the chrominance features. These perturbations are typically local in space and time while large in intensity <ref type="figure">(Fig.1)</ref>. Therefore, we need to localize where these perturbations take place so not to use them in the HR estimation.</p><p>These two main difficulties are intuitively overcome by deriving a matrix completion technique embedding a selfadaptation strategy. On the one hand, since matrix completion problems are usually approached by reducing the matrix rank, the low-rank estimated matrix naturally groups the rows by their linear dependency. In our particular case, two rows are (near) linearly dependent if and only if the output signals they represent are synchronized. Therefore, the underlying HR signal is hypothesized to be in the vector subspace spanned by the largest group of linearly dependent rows of the estimated low-rank matrix.</p><p>On the other hand, the estimated low-rank matrix is enforced to resemble the observations. In previous MC approaches <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b15">16]</ref>, the non-observed part of the matrix consisted of the labels of the test set. Thus, the set of unknown matrix entries was fixed and known in advance. The HR estimation problem is slightly different since there are no missing observations, i.e. the matrix is fully observed. However, many of these observations are highly noisy, thus corrupting the estimation of the HR. Importantly, we do not know in advance which are the corrupted observations. This is why we believe that this problem naturally requires some form of adaptation, implying that the method selects the samples with which the learning is performed. Consequently, we name the proposed learning method selfadaptive matrix completion (SAMC). In order to formalize the self-adaptive matrix completion problem let us assume the existence of R regions where chrominance features are computed during T video frames. This provides a chrominance observations matrix C 2 R R⇥T . Ideally, in a scenario where we could trust all region features continuously, we would simply estimate the low-rank matrix that better approximates the matrix of observations C, by solving: min E ν rank(E)+kE − Ck 2 F , where ν is a regularization parameter. Unfortunately, minimizing the rank is a NP-hard problem, and traditionally a convex surrogate of the rank, the nuclear norm, is used <ref type="bibr" target="#b7">[8]</ref>:</p><formula xml:id="formula_1">min E νkEk ⇤ + kE − Ck 2 F .<label>(1)</label></formula><p>Another intrinsic property of the chrominance features is that, since the underlying reason of their oscillation is the internal functioning of the heart, we should enforce the estimated chrominance features (those of the low-rank estimated matrix) to be within the heart-rate's frequency range. Inspired by <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b0">1]</ref> we add a temporal smoothing term by means of a Laplacian matrix L:</p><formula xml:id="formula_2">min E νkEk ⇤ + kE − Ck 2 F + γ Tr(ELE &gt; ),<label>(2)</label></formula><p>where γ measures the weight of the temporal smoothing within the learning process. L should encode the relational information between the observations acquired at different instants, thus acting like a relaxed band-pass filter. Indeed, imposing that e r is band-pass filtered is equivalent to reduce ke r − e r Tk 2 = ke rT k 2 , where each column of T is a shifted replica of the band-pass normalized filter tap values so that the product e r T boils down to a convolution andT is a copy of T with zeros in the diagonal, since the bandpass filter is normalized. Imposing this for all R regions at once writes: Tr(ETT &gt; E &gt; ), and therefore L =TT &gt; . As previously discussed, the estimated matrix should not take into account the observed entries associated to large movements or spontaneous facial expressions. We model this by including a masking binary matrix M 2{0, 1} R⇥T in the previous equation as <ref type="bibr" target="#b5">[6]</ref>:</p><formula xml:id="formula_3">min E νkEk ⇤ + kM • (E − C)k 2 F + γ Tr(ELE &gt; ),<label>(3)</label></formula><p>where • stands for the element-wise (Hadamard) product and the entries of the matrix M are 1 if the corresponding entry in C has to be taken into account for the HR estimation and 0 otherwise. Importantly, while in the previous studies M was known in advance, in the present study we have to estimate it. We naturally interpret this as a form of adaptation since M is a observation-selection variable indicating from which observations should the method learn at each iteration. The masking matrix M should select the largest possible amount of samples that provide useful information for the estimation of the HR. Moreover, when available, it would be desirable to use a prior for the mask M, taking real values between 0 and 1, f M 2 [0, 1] R⇥T . The complete SAMC optimization problem writes:</p><formula xml:id="formula_4">min E,M νkEk ⇤ + kM • (E − C)k 2 F + γ Tr(ELE &gt; ) − βkMk 1 + µkM − f Mk 2 F ,<label>(4)</label></formula><p>The parameters β and µ regulate respectively the number of selected observations and the importance of prior information. In this paper the prior mask f M is defined as the negative exponential of the local standard deviation of the signal. Our intuition is that, if the signal has small local standard deviation, the chrominance variation within the region is due to the heart-rate and not to head movements or facial expressions, and therefore that matrix entry should be used to estimate the HR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Solving SAMC</head><p>The SAMC optimization problem in <ref type="formula" target="#formula_4">(4)</ref> is not jointly convex in E and M. Moreover, even in the case the masking matrix M was fixed, (4) would contain non-differential and differential terms and a direct optimization would be challenging. Instead, alternating methods have proven to be successful in solving (i) convex problems with nondifferential terms and (ii) marginally convex problems that are not jointly convex. More precisely, we derive an optimisation solver based on the alternating direction method of multipliers (ADMM) <ref type="bibr" target="#b4">[5]</ref>. In order to derive the associated ADMM method, we first define the augmented Lagrangian problem associated to <ref type="formula" target="#formula_4">(4)</ref>:</p><formula xml:id="formula_5">min E,F,M,Z νkEk ⇤ +kM•(F − C)k 2 F +γ Tr(FLF &gt; )−βkMk 1 + µkM − f Mk 2 F + hZ, E − Fi + ρ 2 kE − Fk 2 F ,<label>(5)</label></formula><p>where F is defined to split the terms of (4) that depend on E into those that are differential and those that are not. The variable Z represents the Lagrange multipliers constraining E to be equal to F, further regularized by the term kE−Fk 2 F . The ADMM solves the optimisation problem by alternating the direction of the optimisation while keeping the other directions fixed. Specifically, solving (5) requires alternating the following three steps until convergence: E/M-step With fixed F and Z the optimal value of E is obtained by solving:</p><formula xml:id="formula_6">min E νkEk ⇤ + ρ 2 kE − F + ρ −1 Zk 2 F .<label>(6)</label></formula><p>The solution of such problem is given by the shrinkage operator applied to F − ρ −1 Z, see <ref type="bibr" target="#b6">[7]</ref>. Formally, if we write the singular value decomposition of F − ρ −1 Z = UDV &gt; , the optimal value for E is:</p><formula xml:id="formula_7">E ⇤ = US ν ρ (D)V &gt; ,<label>(7)</label></formula><p>where S λ (x) = max(0,x− λ) is the soft-thresholding operator, applied element-wise to D in <ref type="bibr" target="#b6">(7)</ref>. The optimal value for M is obtained from the following optimisation problem:</p><formula xml:id="formula_8">min M kM • (F − C)k 2 F − βkMk 1 + µkM − f Mk 2 F ,<label>(8)</label></formula><p>which can be rewritten independently for each entry of M:</p><formula xml:id="formula_9">min mrt2{0,1} (f rt − o rt ) 2 m rt + µ(m rt − e m rt ) 2 − βm rt . (9)</formula><p>The solution is straightforward:</p><formula xml:id="formula_10">m ⇤ rt = ⇢ 1( f rt − o rt ) 2 + µ(1 − 2 e m rt ) &lt;β, 0 otherwise.<label>(10)</label></formula><p>Intuitively, this means that a chrominance feature is selected for learning if (i) the entry of the smoothed low-rank estimation F is close to the corresponding entry in C and (ii) that chrominance feature should be selected a priori. Remarkably, this criterion is a mixture of the a posteriori representation power and the a priori knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F-step</head><p>With fixed E, Z and M, the optimal value of F is obtained by solving the following optimisation problem:</p><formula xml:id="formula_11">min F kM•(F−C)k 2 F +γ Tr(FLF &gt; )+ ρ 2 kF−E−ρ −1 Zk 2 F . (11)</formula><p>Eq. 11 is a particular case of the problem solved in <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. Importantly, in our case there is no need to solve a linear system of dimension RT as in <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>, but we require to solve R linear systems of dimension T as in <ref type="bibr" target="#b0">[1]</ref>. From a numerical point of view this is quite advantageous, since larger linear systems tend to be numerically more unstable. More precisely, <ref type="bibr" target="#b10">(11)</ref> can be rewritten independently for each of the R rows of F:</p><formula xml:id="formula_12">min fr kM r (f r − o r )k 2 + γf r Lf &gt; r + ρ 2 kf r − e r − ρ −1 z r k 2 ,<label>(12)</label></formula><p>where lower-case bold letters denote rows of the respective matrices and M r = diag(m r ). The solution of the previous system is straightforward: <ref type="bibr" target="#b12">(13)</ref> where I T is the T -dimensional identity matrix.</p><formula xml:id="formula_13">f ⇤ r =(2M r +2γL + ρI T ) −1 (2M r o r + ρe r + z s ),</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Z-step</head><p>The optimal value of Z is taken from <ref type="bibr" target="#b4">[5]</ref>:</p><formula xml:id="formula_14">Z ⇤ = Z + ρ(E − F),<label>(14)</label></formula><p>where the right-hand side represent the current values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Phase 4: HR Estimation</head><p>Once the SAMC solver converges to an optimal solution for E, we can simply hypothesize that, since the main underlying signal is the one associated to the heart rate, the largest singular value of E, would encode the information associated to the sought signal. Therefore, we write the singular value decomposition of E = UDV &gt; , it is reasonable to take the first column of V, V 1 as the estimated underlying HR signal. Finally, the Welch's power spectral density estimation method <ref type="bibr" target="#b25">[26]</ref> is employed to obtain the frequency in V 1 with the largest energy f HR . For the instantaneous HR measurement to get f HR we follow <ref type="bibr" target="#b9">[10]</ref> and simply detect the highest peak in the Fourier domain of the estimated signal. The HR measured from the input video is then computed as H = 60f HR .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>We conducted experiments on two datasets: the publicly available MAHNOB-HCI dataset <ref type="bibr" target="#b19">[20]</ref> and the MMSE-HR dataset. As demonstrated by our experimental results, the latter dataset contains more challenging sequences, due to subjects' movements and facial expressions. The MAHNOB-HCI dataset is a multimodal dataset with 20 high resolution videos per subject. It contains 27 subjects (12 males and 15 females) in total, and each subject participated in two experiments: (i) emotion elicitation and (ii) implicit tagging. Following <ref type="bibr" target="#b16">[17]</ref>, in our experiments we used a 30 second interval (frames from 306 through 2135) of 527 sequences. To compute the ground truth heart rate for each video sequence we used the second channel (EXG2) of the corresponding ECG waveforms (see <ref type="bibr" target="#b19">[20]</ref>). The MMSE-HR dataset 2 is a subset of the MMSE database <ref type="bibr" target="#b30">[31]</ref> specifically targeted to challenge heart rate estimation algorithms. The MMSE-HR dataset includes 102 RGB videos and heart-rate data of 40 participants with diverse ethnic/racial ancestries. Two examples are given in <ref type="figure" target="#fig_1">Fig. 3</ref> (Note how the HR changes during the recording when each person experiences fear. This supports the value of the dataset for research on instantaneous HR estimation). The physiological data were collected by Biopac Mp150 data acquisition system 3 , including heart-rate, mean blood pressure, and other physiological signals, working at 1 kHz. All sensors were synchronized. More details regarding data collection and recording setup can be found in <ref type="bibr" target="#b30">[31]</ref>.</p><p>To compute the ground truth HR signal for both datasets we used a peak detection method from the MNE package 4 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Settings</head><p>To evaluate the performance of the proposed approach and compare it with previous methods, we consider five commonly used metrics in the literature on remote HR analysis <ref type="bibr" target="#b16">[17]</ref>. Specifically, we define H e (i)=H p (i) − H gt (i), i.e. the difference between the predicted heart rate H p (i) and the ground truth heart rate H gt (i) for the i-th video sequence. We report the mean M e and the standard deviation SD e of H e over all sequences. We also adopt the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>Average HR prediction. In the first series of experiments we compare the proposed approach with several state-of-the art methods for average HR prediction on the MAHNOB-HCI dataset. Specifically we consider the approaches described in <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b9">10]</ref>. Performance on MAHNOB-HCI is given in <ref type="table" target="#tab_1">Table 1</ref>. To perform a quantitative comparison, we have implemented the methods in <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b9">[10]</ref>  <ref type="bibr" target="#b4">5</ref> , since their code is not available, while the performance measures for <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b3">4]</ref> are taken from <ref type="bibr" target="#b16">[17]</ref>. It is evident that, while HR estimation on MAHNOB-HCI represents a challenging task for early methods, the more recent approaches, <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b9">[10]</ref>, achieve high accuracy. Moreover, our approach outperforms competing methods by a small margin. This can be explained by the fact that MAHNOB-HCI does not contain many sequences with subject's movements and facial expression changes, while SAMC has been designed to explicitly cope with the spatially localized and intense noise they generate.</p><p>To demonstrate the advantages of our method, we perform similar experiments on the more challenging sequences of the MMSE-HR dataset. Here, we only compare our method against the best-performing methods from <ref type="table" target="#tab_1">Table 1</ref>. <ref type="table">Table 2</ref> reports the results of our evaluation. On this difficult dataset, due to its capacity to select the most reliable chrominance features and ignore the noisy ones, the proposed SAMC achieves significantly higher accuracy than the state-of-the-art. Effect of self-adaptation. In order to show the benefits of adopting the proposed self-adaptation strategy, we provide results with a fixed binary mask M (i.e. without selfadaptation) and compare them to those obtained with selfadaptation in <ref type="table">Table 3</ref>. The first column corresponds to the percentile of the values of the prior f M used to construct the initial mask. More precisely, for a value p, the initial mask is 1 only in the entries corresponding to the p% regions with the lowest standard deviation. Therefore, p = 100% corresponds to an (initial) mask matrix of all 1's. Clearly, the  choice of p is crucial when the matrix is fixed, but almost irrelevant when there is self-adaptation. Also, self-adaptation systematically outperforms the fixed mask case. Finally, <ref type="figure" target="#fig_4">Fig. 4</ref> (left) shows the performance of the proposed approach at different values of parameters µ and γ for the experiments on the MMSE-HR dataset. As shown in the figure, very small and very large values of µ (indicating an increase and a reduction of the influence of the prior mask), correspond to a decrease of performance. Similarly, for the parameter γ, weighting the influence of the Laplacian term, a local optimum can be obtained for γ =0.01. <ref type="figure" target="#fig_4">Fig. 4 (right)</ref> shows similar behavior for σ, used to compute the prior mask as the negative entry-wise exponential of the matrix of standard deviations normalized by σ: f M = e (−S/σ) . Short-time HR estimation. To demonstrate the ability of our method to recognize instantaneous HR, we selected 20% of the recorded sequences where there is a very strong heart-rate variation. We split each sequence into nonoverlapping windows of length 4, 6, and 8 seconds and process each window independently with <ref type="bibr" target="#b9">[10]</ref> and SAMC, since the approach in <ref type="bibr" target="#b16">[17]</ref> is not suitable for instantaneous HR prediction. <ref type="table" target="#tab_3">Table 4</ref> shows the results of our short-time window analysis. The table supports the intuition that, the smaller the window, the more difficult is for a method to reliably estimate the HR. Importantly, SAMC consistently outperforms <ref type="bibr" target="#b9">[10]</ref> for all window lengths and produces reliable estimates starting from the 4-second windows.</p><p>To show that our method is able to follow the changes in subject's HR, we additionally report the predicted heart rate for three sequences of different length. <ref type="figure">Figure 5</ref> shows the results of three selected video sequences processed by our method. Note that although the method is not able to predict the exact HR for every window, providing the value close to the ground truth, a sudden increase/decrease is well localized in time. Running time. The proposed approach is fast, enabling real-time HR analysis. On average, phase 1 runs at 50 fps, while phase 2 runs at around 30 fps. Phase 3 and 4 have the smallest execution time, reaching 550 fps. Running times were measured using a single core implementation on a con-  <ref type="figure">Figure 5</ref>. Heart rate recognition results for three sequences, using window size of 4 seconds. Y -axis shows the interval over which the heart rate was computed. ventional laptop with an Intel Core i7-4702HQ processor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We presented a novel framework for remote HR estimation from visual data. At the core of our approach, there is a novel optimization framework, named self-adaptive matrix completion, which outputs the HR measurement while simultaneously selecting the most reliable face regions for robust HR estimation. This strategy permits to discard noisy features, due to spontaneous target's movements and facial expressions. As demonstrated by our experimental evaluation, the proposed approach provides accurate HR estimates and outperforms state-of-the-art methods not only in the case of long-time windows, but also for short-time analysis. Extensive experiments conducted on the MMSE-HR dataset support the value of the adopted self-adaption strategy for HR estimation. Future work guidelines include devising novel feature representations, in alternative to chrominance signals, to further improve the robustness to varying illumination conditions as well as exploiting the feasibility of combining the predicted HR measurements with visual features for spontaneous emotion classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgments</head><p>The material (dataset part) is based upon the work supported in part by the NSF under grants CNS-1205664 and CNS-1205195.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Overview of the proposed approach for HR estimation. During the first phase, we automatically detect a set of facial keypoints and use them to define a ROI. This region is then warped to a rectangular area and divided into a grid. For each small sub-region, chrominance features are computed (Phase 2). We then apply SAMC on the matrix of all feature observations to recover a smooth signal, while selecting from which sub-regions the signal is recovered (Phase 3). Welch's method [26] is used to estimate the power spectral density and thus the HR frequency (Phase 4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Two examples of video sequences from the MMSE-HR dataset where the subjects experience fear. For each subject two rows are shown. Top: the recorded RGB-video frames. Bottom: physiological data. Note how the heart rate (the blue line) increases when each subject experiences fear.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Root Mean Squared Error (RM SE), the mean of error-rate percentage M eRate = P N i=1 |He(i)| Hgt(i) and the Pearson's correlation ρ between signals H p = {H p (1),...,H p (N )} and H gt = {H gt (1),...,H gt (N )}, being N is the number of video sequences. In all our experiments the parameters of the proposed method have been selected by cross-validation on a subset of MMSE-HR and set to ν =0.0357, γ =0.01, µ =0 .0011 and β =0 .0005. Importantly, these parameters were used throughout all our experiments for the two datasets, supporting the generalization ability of SAMC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Left: performance at varying values of the γ and µ. Right: RMSE dependency on σs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>the standard 2. Feature Extraction</figDesc><table>Feature 
Extraction 

Region 1 
Region 2 

Region R 

... 

... 

ROI 
extraction 

ROI 
Warping 

1. Face Region Extraction 
3. Self-Adaptive Matrix Completion 

Observation matrix 
Low-rank matrix 

Prior mask 

SAMC 

Estimated Mask 

0 
1 
2 
3 
4 
5 
6 

Frequency, Hz 

HR Frequency 

Signal estimated using SAMC 

Magnitude 

Power spectral 
density estimation 

4. Heart Rate Estimation 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 .</head><label>1</label><figDesc>Average HR prediction: comparison among different methods on MAHNOB-HCI dataset (best performance in bold).</figDesc><table>Method 
M e (SD e ) 
RM SE M eRate 
ρ 

Poh et al. [18] 
-8.95 (24.3) 
25.9 
25.0% 0.08 
Poh et al. [19] 
2.04 (13.5) 
13.6 
13.2% 0.36 
Balakrishnan et al. [4] -14.4(15.2) 
21.0 
20.7% 0.11 
Li et al. [17] 
-3.30 (6.88) 
7.62 
6.87% 0.81 
De Haan et al. [10] 
4.62 (6.50) 
6.52 
6.39% 0.82 

SAMC 
3.19 (5.81) 
6.23 
5.93% 0.83 

Table 2. Average HR prediction: comparison among different 
methods on MMSE-HR (best performance in bold). 

Method 
M e (SD e ) 
RM SE M eRate 
ρ 

Li et al. [17] 
11.56 (20.02) 
19.95 
14.64% 0.38 
De Haan et al. [10] 9.41 (14.08) 
13.97 
12.22% 0.55 

SAMC 
7.61 (12.24) 
11.37 
10.84% 0.71 

Table 3. Self-adapting (SA) vs. non-adapting (NA) MC. 

pM e (SD e ) 
RM SE M eRate 
ρ 

SA 
20 
8.13 (12.08) 
12.13 
10.74 
0.68 
40-100 8.22 (12.24) 
12.23 
10.84 
0.67 

NA 

20 
55.39 (36.86) 
65.99 
68.21 
0.08 
40 
35.90 (41.29) 
51.47 
44.76 
0.16 
60 
22.40 (33.79) 
37.06 
27.91 
0.17 
80 
9.41 (14.53) 
14.63 
11.91 
0.49 
100 
10.05 (15.23) 
15.13 
12.98 
0.47 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>Heart rate, bpm[0:4] [4:8] [8:12] [12:16] [16:20] [20:24] [24:28] [28:32] [32:36] [36:40] [40:44] [44:48] [48:52] [52:56] [56:60]</figDesc><table>Time interval, seconds 

60 

70 

80 

90 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 4 .</head><label>4</label><figDesc>Short-time window analysis. Results for three windows sizes are reported: 4, 6, and 8 seconds.</figDesc><table>Method 
M e (SD e ) 
RM SE M eRate 
ρ 

4s 
De Haan et al. [10] -1.85 (15.77) 
15.83 
9.92% 0.67 
SAMC 
2.12 (11.51) 
11.66 
9.15% 0.78 

6s 
De Haan et al. [10] -2.21 (19.21) 
19.27 
11.81% 0.33 
SAMC 
0.32 (8.29) 
8.27 
7.30% 0.80 

8s 
De Haan et al. [10] 0.81 (11.49) 
11.46 
8.60% 0.63 
SAMC 
1.62 (9.67) 
9.76 
7.52% 0.71 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.humansensing.cs.cmu.edu/intraface</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The MMSE-HR is included in the full dataset (MMSE)<ref type="bibr" target="#b30">[31]</ref> which will be made available to the research community through the Binghamton University</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://www.biopac.com/ 4 http://martinos.org/mne/stable/index.html<ref type="bibr" target="#b4">5</ref> We also reimplemented the more recent method based on chrominance features in<ref type="bibr" target="#b24">[25]</ref>. Unfortunately, perhaps due to the fact that the method is exhaustively described, we obtained worse results than those we obtained with<ref type="bibr" target="#b9">[10]</ref>. Therefore we choose to report our results using<ref type="bibr" target="#b9">[10]</ref>.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Analyzing free-standing conversational groups: A multimodal approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Alameda-Pineda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Lanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Recogniting emotions from abstract paintings using non-linear matrix completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Alameda-Pineda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robust discriminative response map fitting with constrained local models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Asthana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Detecting pulse from head motions in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peleato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eckstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Matrix completion for weakly-supervised multi-label image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A singular value thresholding algorithm for matrix completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-F</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1956" to="1982" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exact matrix completion via convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of Computational mathematics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="717" to="772" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Matrix completion for resolving label ambiguity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Robust pulse rate from chrominance-based rPPG</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>De Haan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jeanne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transaction on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2878" to="2886" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Transduction with matrix completion: Three birds with one stone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Effective face frontalization in unconstrained images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Enbar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dense 3D Face Alignment from 2D Videos in Real-Time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FG</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Pose-Invariant 3D Face Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jourabloo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Matrix completion on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kalofolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshops</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Functional correspondence by matrix completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kovnatsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Remote Heart Rate Measurement From Face Videos Under Realistic Situations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Non-contact, automated cardiac pulse measurements using video imaging and blind source separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Z</forename><surname>Poh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Mcduff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optics express</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="10762" to="10774" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Advancements in noncontact, multiparameter physiological measurements using a webcam</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z</forename><surname>Poh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Mcduff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A multimodal database for affect recognition and implicit tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Soleymani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lichtenauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transaction on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Regressing a 3D face shape from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tulyakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Revealing real-time emotional responses: a personalized assessment based on heartbeat dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Valenza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Citi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lanatá</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Scilingo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barbieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Remote plethysmographic imaging using ambient light</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Verkruysse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">O</forename><surname>Svaasand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Nelson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Optics Express</publisher>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">21434</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Recurrent face aging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Exploiting Spatial Redundancy of Image Sensor for Motion Robust rPPG</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Stuijk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Haan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The use of fast fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Welch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio and Electroacoustics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Eulerian video magnification for revealing subtle changes in the world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Tag completion for image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="716" to="727" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Supervised descent method and its applications to face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Robust efficient estimation of heart rate pulse from video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Rohde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomedical optics express</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1124" to="1159" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multimodal spontaneous emotion corpus for human behavior analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Girard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Ciftci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Canavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
