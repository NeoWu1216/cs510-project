<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficient Coarse-to-Fine PatchMatch for Large Displacement Optical Flow</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinlin</forename><surname>Hu</surname></persName>
							<email>huyinlin@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Xidian University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Song</surname></persName>
							<email>rsong@xidian.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Xidian University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Shanghai Institute of Technical Physics</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunsong</forename><surname>Li</surname></persName>
							<email>ysli@mail.xidian.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Xidian University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Efficient Coarse-to-Fine PatchMatch for Large Displacement Optical Flow</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As a key component in many computer vision systems, optical flow estimation, especially with large displacements, remains an open problem. In this paper we present a simple but powerful matching method works in a coarseto-fine scheme for optical flow estimation. Inspired by the nearest neighbor field (NNF) algorithms, our approach, called CPM (Coarse-to-fine PatchMatch), blends an efficient random search strategy with the coarse-to-fine scheme for optical flow problem. Unlike existing NNF techniques, which is efficient but the results is often too noisy for optical flow caused by the lack of global regularization, we propose a propagation step with constrained random search radius between adjacent levels on the hierarchical architecture. The resulting correspondences enjoys a built-in smoothing effect, which is more suited for optical flow estimation than NNF techniques. Furthermore, our approach can also capture the tiny structures with large motions which is a problem for traditional coarse-to-fine optical flow algorithms. Interpolated by an edge-preserving interpolation method (EpicFlow), our method outperforms the state of the art on MPI-Sintel and KITTI, and runs much faster than the competing methods. * Corresponding author (a) EpicFlow [24] (b) CPM-Flow (c) MDPFlow2 [29] (d) Ground truth</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Optical flow has traditionally been, and continues to be, one of the most fundamental components in many vision tasks. There has been abundant literature on this topic, while obtaining a reliable optical flow for real-world videos remains a challenging problem caused mainly by motion discontinuities, large displacements, and occlusions.</p><p>Since the pioneering work by Horn and Schunck <ref type="bibr" target="#b10">[11]</ref> who formulated the optical flow estimation as a problem of energy minimization, many effective approaches have emerged for improving the performance with complex motions <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b28">29]</ref>. Though combined with a coarse-to-fine scheme, such approaches still often failed to estimate large displacements introduced by fast motion, which is caused by the propagation of errors from coarser levels to the finest level, especially in the case of tiny structures with large motions (see <ref type="figure" target="#fig_0">Figure 1</ref>(c)).</p><p>The visual similarity between two image regions is the most important clue for large optical flow estimation. Recently, optical flow interpolated from sparse descriptor matching correspondences directly has shown great success for large displacements, especially with significant occlusions <ref type="bibr" target="#b23">[24]</ref>. While the results is mainly constrained by the efficiency and accuracy of the matching techniques.</p><p>In contrast, as a core component in image editing and scene correspondence <ref type="bibr" target="#b17">[18]</ref>, the nearest neighbor field (NN-F) is closely related to optical flow estimation. The objective of NNF computation is to find one or more nearest (visually similar) neighbors for every patch in a given image against another image. The main challenge in this procedure is the computational complexity. Through the seminal work called PatchMatch <ref type="bibr" target="#b3">[4]</ref> and the improved methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b9">10]</ref>, the efficiency of computing NNF has advanced remarkably. The core idea behind this boost is random search and propagation between neighbors. While with a different objective from optical flow estimation, the computed NNF is often We can see that the response maps with larger patch size are more discriminative.</p><p>very noisy from the viewpoint of motion, especially in the criteria of edge preservation and spatial smoothness for evaluating an optical flow results, which is mainly caused by the lack of global regularization.</p><p>In this study, we propose a matching method combining a random search strategy with a coarse-to-fine scheme for optical flow with large displacements. A key observation is that matching correspondences with larger patch size are often more discriminative (see <ref type="figure" target="#fig_1">Figure 2</ref>). After the construction of the pyramids, we can use the matching correspondences from higher levels of the pyramids as a guidance for the matching process on lower levels. While as in DeepMatching <ref type="bibr" target="#b26">[27]</ref>, constructing the response maps of each reference patch on the target image at each level of the pyramid is time-consuming. We introduce a propagation procedure between the adjacent levels from top to bottom, which avoids the construction of the whole response maps. With random search strategy like in PatchMatch <ref type="bibr" target="#b3">[4]</ref> on each level, our approach, CPM (Coarse-to-fine Patch-Match), interpolated using EpicFlow <ref type="bibr" target="#b23">[24]</ref> outperforms the original EpicFlow and also most state of the art (see <ref type="figure" target="#fig_0">Figure  1</ref>).</p><p>We make the following contributions: 1) We propose CPM matching, a novel coarse-to-fine matching scheme based on combination of random search and propagation between hierarchical levels. We show that it is robust to larger displacements and more suited for optical flow compared with NNF methods. 2) We propose a fast approximate structure for the matching process, which avoids finding the matching of every pixels and leads to a significant speed-up with controllable accuracy. 3) We show the effectiveness and efficiency of our matching approach by achieving state-of-the-art flow accuracy but running much faster than other competing methods on MPI-Sintel <ref type="bibr" target="#b5">[6]</ref> and KITTI <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>We do not review the entire literature on optical flow and only discuss the related literature. We refer to publications like <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b1">2]</ref> for a detailed overview of optical flow methods based on the classic variational minimization framework first proposed in <ref type="bibr" target="#b10">[11]</ref>.</p><p>Our method is closely related to NNF estimation. The efficiency of computing NNF has advanced remarkably through the work <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b9">10]</ref>, while the results is often too noisy from the viewpoint of motion. Nevertheless, many efforts have been made to estimate the optical flow based on the NNF: Chen et al. <ref type="bibr" target="#b6">[7]</ref> used the computed NNF as a hint for motion segmentation before variational optimization. Bao et al. <ref type="bibr" target="#b2">[3]</ref> adapted the PatchMatch algorithm to optical flow using an edge-preserving patch-matching measurement. However, they still often failed in the case of large displacements, especially with significant occlusions. Bailer et al. <ref type="bibr" target="#b0">[1]</ref> proposed a similar pipeline to ours to handle the noisiness of NNF. However, their method relies on a dedicated hierarchical structure and many complicated techniques for ambiguity handling.</p><p>Also inspired by PatchMatch <ref type="bibr" target="#b3">[4]</ref>, Li et al. <ref type="bibr" target="#b16">[17]</ref> proposed a PatchMatch belief propagation to estimate the optical flow which was formulated as a labeling problem. Yang et al. <ref type="bibr" target="#b29">[30]</ref> proposed a piecewise parametric model for optical flow estimation. In contrast, we tackle the optical flow problem through a nonparametric matching.</p><p>As an important milestone regarding the integration of matching and optical flow, Brox and Malik <ref type="bibr" target="#b4">[5]</ref> introduced a descriptor matching term to the classic variational minimization framework of optical flow. Furthermore, Xu et al. <ref type="bibr" target="#b28">[29]</ref> proposed an extended coarse-to-fine framework that integrates matching to refine the flow at each level. However, due to the sparsity of the matching and the requirement of accurate initialization of the variational minimization, they still usually fail in the case of small details with motion larger than its own scale. To handle the sparsity of descriptor matching, Leordeanu et al. <ref type="bibr" target="#b15">[16]</ref> extended sparse matching to dense matching with a locally affine constraint. For efficiency, Wulff et al. <ref type="bibr" target="#b27">[28]</ref> introduced a basis of flow, and obtained the flow directly from the combination of the basis of the flow infered from a sparse descriptor matching. However, the quality is not satisfactory. Revaud et al. <ref type="bibr" target="#b23">[24]</ref> introduced an edge-preserving interpolation framework for optical flow based on a matching algorithm termed Deep-Matching <ref type="bibr" target="#b26">[27]</ref>. However, the interpolation results is mainly constrained by the efficiency of DeepMatching. Closely related to our method, Kim et al. <ref type="bibr" target="#b13">[14]</ref> and Hur et al. <ref type="bibr" target="#b11">[12]</ref> also investigated hierarchical matching, but their methods requires inexact inference using loopy belief propagation.  . Overview of the proposed CPM algorithm. Given two images, we construct the pyramids and process from top to bottom. On each level, the initial matching correspondences is propagated with random search after a fixed number of times, and the results of each level is used as a initialization of the next lower level. The results after the propagation on the finest level is our matching results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Coarse-to-fine PatchMatch</head><p>In this section, we present our matching framework, CP-M, and discuss its main features. Our matching method builds upon a hierarchical architecture, and works in a coarse-to-fine (top-down) scheme. An overview of CPM Matching is given in <ref type="figure" target="#fig_3">Figure 3</ref>. We first detail the matching procedure on one level of the pyramid in Section 3.1, and then describe the hierarchical structures of our approach as well as the propagation step between the levels in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Basic Matching</head><p>Considering the nature of smoothness of optical flow compared with the NNF, we define our goal of matching is to find the best correspondence of some seeds rather than every pixel of the image for efficiency. Formally, given two images I 1 , I 2 ⊂ R 2 and a collection of seeds S = {s m } at position {p(s m )}, our goal is to determine the flow of each</p><formula xml:id="formula_0">seed f (s m ) = M(p(s m ))−p(s m ) ∈ R 2 , where M(p(s m ))</formula><p>is the corresponding matching position in I 2 for seed s m in I 1 . In our method, the seeds are the cross points of the regular image grid with a spacing of d pixels. Then there's only one seed in every d × d non-overlapping block. We will show that this fast approximation results in a significant speed-up with controllable accuracy.</p><p>Adopting the regular image grid, we obtain a default neighbor system according to the spatially adjacency of the seeds on the image grid. Like PatchMatch, neighborhood propagation and random search is performed iteratively in an interleaved manner after some flow initialization of each seed (detailed in Section 3.2).</p><p>Seeds are examined in scan order on odd iterations and in reverse scan order on even iterations. For a current seed s m , we denote its set of spatially adjacent seed neighbors that is already examined in current iteration as N m . Flow values are propagated from neighbor seeds to current seed if they have already been examined in current iteration. That is</p><formula xml:id="formula_1">f (s m ) = arg min f (si) (C(f (s i ))), s i ∈ {s m } ∪ N m<label>(1)</label></formula><p>where C(f (·)) denote the match cost between patch centered at p(s m ) in I 1 and patch centered at p(s m ) + f (·) in I 2 . We will discuss the computation of match cost in Section 3.3.</p><p>After the preceding propagation step, a random search as in PatchMatch <ref type="bibr" target="#b3">[4]</ref> is performed for the current seed s m . We attempt to improve f (s m ) by testing some candidate flow around the current best flow. As in <ref type="bibr" target="#b3">[4]</ref>, a sequence of random flow sampled around the current best flow f (s m ) of each seed s m is evaluated at an exponentially decreasing scope started from a maximum search radius. The ratio α between the two consecutive search scopes is fixed to 1/2.</p><p>Let n the number of iteration numbers. After n times of iteration, we stop our matching process. In practice a fixed iteration number works well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Coarse-to-fine Scheme</head><p>Our basic matching is similar to PatchMatch <ref type="bibr" target="#b3">[4]</ref> which is very noisy without global regularization. Similarly, our basic matching contains many outliers arising from the ambiguity of small patches. A common way to handle the ambiguity of small patches is increasing the size of the patches, while this often leads to less accurate matches.</p><p>We introduce a simple but powerful hierarchical architecture with propagation from top to bottom to handle this problem. First, we construct a pyramid with k levels for both I 1 and I 2 with a downsampling factor η (in our experiments, we fix η = 0.5). We denote the lth level of pyramid of</p><formula xml:id="formula_2">I i as I l i , i ∈ {1, 2}, l ∈ {0, 1, . . . , k − 1}.</formula><p>The bottom level of the pyramids I 0 1 and I 0 2 are the raw images. Our goal now is to find the matches of every seeds in I 0 1 against I 0 2 . We construct seeds on each level, and we define {s l } the seeds at position {p(s l )} on the lth level as the downscaled version from the raw seeds in I 0 1 , that is:</p><formula xml:id="formula_3">{p(s l )} = η · {p(s l−1 )}, l ≥ 1 (2)</formula><p>The seeds on each level preserve the same neighboring relation as the finest level, and the number of seeds is the same on each level. Note that, in our method we do not introduce any seed with sub-pixel accuracy. The position of the seeds on each level is always truncated to the nearest integers. Then there will be some seeds with same positions on high levels when d * η k−1 &lt; 1. With many seeds duplicated, the propagation with random search is performed more extensively on the coarser levels with a low resolution. This is an important feature that can guarantee the robustness of matching results on high levels. After the construction of the pyramid and the generation of the seeds in each level, we perform the propagation with random search on each level and propagate the flow of each seed from top to bottom on the pyramid. We first set the flow of the seeds {s k−1 } on the top level as random flow. Then a propagation with random search within the maximum image dimension on this level is performed iteratively. The obtained flow {f (s k−1 )} serve as an initialization of the seeds {s k−2 } on the next level I k−2 , and likewise the computed flow of the seeds in each level always serves as a initialization of the seeds on the next level:</p><formula xml:id="formula_4">{f (s l )} = 1 η · {f (s l+1 )}, l &lt; k − 1<label>(3)</label></formula><p>For the seeds on level l &lt; k − 1, we first initialize the flow of the seeds from higher levels as <ref type="bibr">Equation 3</ref>, and then a propagation with random search within a small search radius is performed iteratively to obtain the flow of the seeds on each level. We define r as the search radius of every pyramid level except the top level which has a search radius of the maximum image dimension.</p><p>The secret is to constrain r within a small range. This is the most important step in processing the lower levels. The expansive search radius on the coarsest level together with many duplicated seeds can help us to find a rough global optimal initialization. In contrast, on the lower levels, a small search radius around the propagated matching is very helpful for the smoothness of the final matching. It can also help us to avoid finding a poor local optimum far from the propagated matching. While, we find that a too small search radius on lower levels is vulnerable in the case of tiny structures with large motions. This is mainly caused by the failure of recovering the true matching of the tiny structures which is vanished on higher levels. With a proper r, we can find the matching of tiny structures as depicted in <ref type="figure" target="#fig_4">Figure 4</ref>. A quantitative analysis of the impact of search radius will be discussed in Section 4.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Cost Computation</head><p>As an effective feature descriptor, dense SIFT flow <ref type="bibr" target="#b17">[18]</ref> has show prominent performance demonstrated in <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b30">31]</ref>. We choose our patch-based matching cost to be a sum of the absolute difference over all the 128 dimensions of the SIFT flow at the matching points. We use the online code to compute the SIFT feature for every pixel on each hierarchical level 1 . Note that, we use the entire 128 dimensions for matching, and the SIFT feature is computed for every pixel on all hierarchical levels with the same patch size 8 × 8 in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Outlier Handling</head><p>As in <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b24">25]</ref>, a forward-backward consistency check is performed to detect the occlusions and remove the outliers. While, considering the effect that the matching results is more discriminative and also more robust on higher levels, we perform the consistency check on multi levels of the pyramid simultaneously other than the only check on the finest level.</p><p>Similar to <ref type="bibr" target="#b0">[1]</ref>, only the validation of the matching correspondences on the two finest levels is checked. With backward flow interpolated from matching correspondences linearly, we let the error threshold ǫ of the consistency check equal to the grid spacing d, and the coarser matches are all upscaled to the finest resolution before the consistency check. The matches larger than 400 pixels are also removed. The overall procedure is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we evaluate our matching method on three optical flow datasets: MPI-Sintel <ref type="bibr" target="#b5">[6]</ref>, Middlebury <ref type="bibr" target="#b1">[2]</ref> and KITTI <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21]</ref>. To fill the gaps created by outlier handling we use the EpicFlow <ref type="bibr" target="#b23">[24]</ref> to interpolate our matching correspondences to a dense optical flow (termed as CPM-Flow).</p><p>We optimize the parameters of our method on a subset of the training set of the MPI-Sintel dataset. Then we use the same constant parameter settings to generate our matching results for all datasets for evaluation: {d, r, k, n} = {3, 4, 5, 6}. This demonstrates the robustness of our method. We use the online code with default parameters used in EpicFlow <ref type="bibr" target="#b23">[24]</ref> for interpolation 2 .</p><p>All algorithms were run on an Intel Core i7 3.5GHz CPU with a single-core implementation. On average, our matching method including interpolation (EpicFlow) requires only 4.3 seconds for one color image pair (1024 × 436) from the MPI-Sintel training set. In detail, SIFT flow computation takes 0.7s, coarse-to-fine matching (including forward-backward consistency check) 0.6s, and interpolation (EpicFlow) 3s. We can observe that 70% of the time is spent on interpolation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">MPI-Sintel Database Experiments</head><p>MPI-Sintel dataset <ref type="bibr" target="#b5">[6]</ref> is a challenging evaluation benchmark based on an animated movie and contains many large motions. It consists of two versions: clean and final. Compared to the clean version with realistic illuminations and reflections, the final version adds rendering effects like motion, defocus blurs and atmospheric effects.</p><p>On the MPI-Sintel test set, CPM-Flow currently ranks 1st on the clean version and 2nd on the final version measured in the average endpoint error (AEE) <ref type="bibr" target="#b1">[2]</ref>. <ref type="table">Table 1</ref>  marizes the main results, and our method outperforms all published methods on the clean version, and we just missed the best approach by 0.15 on the final version but runs much faster. Note that it performs especially well on the occluded areas, thanks to the use of multi-level consistency check in the outlier handling stage and the edge-preserving interpolation. <ref type="figure">Figure 7</ref> shows a comparison to two state-of-the-art methods. One using an extended coarse-to-fine scheme (MDPFlow2 <ref type="bibr" target="#b28">[29]</ref>) and the other is a modern method interpolated from matching correspondences (EpicFlow <ref type="bibr" target="#b23">[24]</ref>). Similar to EpicFlow <ref type="bibr" target="#b23">[24]</ref>, CPM-Flow benefits from the interpolation to produce sharp motion boundaries and correct estimation on occluded areas. While, note how tiny structures are captured by CPM-Flow. Even small details, like the tail of the monster in the middle column and the limbs of the character in the right column, are captured.</p><p>Comparison of different matching methods. We compare our matching method with some state-of-the-art matching techniques, and also evaluate the performance of dense optical flow interpolated from these matches (using EpicFlow <ref type="bibr" target="#b23">[24]</ref>).</p><p>We first compare our matching method with the following matching algorithms: sparse SIFT keypoints <ref type="bibr" target="#b7">[8]</ref> matched with FLANN <ref type="bibr" target="#b19">[20]</ref> (referred to as SIFT-NN) 3 , Kdtree PatchMatch <ref type="bibr" target="#b9">[10]</ref> (KPM) <ref type="bibr" target="#b3">4</ref> and DeepMatching <ref type="bibr" target="#b26">[27]</ref> (D-M) <ref type="bibr" target="#b4">5</ref> . Considering different matching methods often produce matches at different locations, we use a comparison method similar to <ref type="bibr" target="#b26">[27]</ref> for fair matching comparison. After assign-CPM DM <ref type="bibr" target="#b26">[27]</ref> KPM <ref type="bibr" target="#b9">[10]</ref> SIFT <ref type="bibr" target="#b7">[8]</ref>  <ref type="figure">Figure 5</ref>. Comparison of different matching methods. The first row is the mean of two consecutive images (left) and the ground truth (right). From the second row, each row shows the matching results (left) and the dense flow results (right) from top to bottom: SIFT-NN <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b19">20]</ref>, KPM <ref type="bibr" target="#b9">[10]</ref>, DM <ref type="bibr" target="#b26">[27]</ref> and our CPM method. The dense flow results are all interpolated from the matching correspondences using EpicFlow <ref type="bibr" target="#b23">[24]</ref>.</p><p>ing each point a fixed grid with a spacing of 10 pixels the nearest neighbor match, density is defined as the percentage of points with at least one match in the neighborhood of 10 × 10, and precision is the percentage of those matches with an error below 10 pixels.</p><p>Quantitative results are listed in <ref type="table">Table 2</ref>, and qualitative results in Figures 5. As we can see that, the matching results produced by SIFT is too sparse to obtain a reasonable dense flow after interpolation. To handle the noisiness of KPM which is a dense NNF technique, we perform a forwardbackward consistency check before the interpolation. Note that, our matching method can produce comparable matching results with DeepMatching <ref type="bibr" target="#b26">[27]</ref> but runs much faster. Furthermore, as <ref type="table">Table 2</ref> shows, after interpolation, the obtained dense flow from our matching method is more accurate than that from DeepMatching.</p><p>The main reason why our CPM can outperform Deep-Matching is that CPM can produce more matches than DeepMatching by default. Note that DeepMatching using the default parameters produces only about 5K matches for one 1024 × 436 image pair, while CPM can produce about 40K matches (grid spacing d = 3). Furthermore, the final flow is interpolated from these matches, and more matches are preferable under the condition of similar density and precision. We think DeepMatching can obtain similar qual-  ity as CPM if it can produce more matches by adjusting its default parameters, but at the expense of even worse efficiency.</p><p>Parameter sensitivity analysis. In order to get a better understanding of the robustness and scalability of CPM-Flow, we evaluate the impact of different parameter settings of our matching approach to the flow interpolated from the matching correspondences. After obtaining the optimized parameters as reported in Section 4 on a subset (20%) of the clean version training set of the MPI-Sintel dataset, we systematically vary the parameter setting each by one and report the AEE on the final version of the training set. <ref type="figure" target="#fig_6">Figure 6</ref> summarizes the results.</p><p>We also report the average running time of our matching method with different grid spacing d. As <ref type="figure" target="#fig_6">Figure 6(a)</ref> shows, a small grid spacing clearly improves the performance, which is contributed by the more extensive search on each level of the pyramid. While a small grid spacing leads to a high computation complexity, especially when there is no spacing (d = 1). We find that d = 3 hardly MDPFlow2 <ref type="bibr" target="#b28">[29]</ref> EpicFlow <ref type="bibr" target="#b23">[24]</ref> CPM-Flow Ground Truth Images <ref type="figure">Figure 7</ref>. Example of our results on MPI-Sintel. Each column shows from top to bottom: mean of two consecutive images, ground truth, CPM-Flow and 2 state-of-the-art methods (EpicFlow <ref type="bibr" target="#b23">[24]</ref> and MDPFlow2 <ref type="bibr" target="#b28">[29]</ref>). CPM-Flow is able to capture thin moving objects like the tail of the monster (middle column) and the limbs of the character (right column).</p><p>impairs the quality but leads to a significant speed-up. <ref type="figure" target="#fig_6">Figure 6</ref>(b) studies the effect of our method with different search radius r. We can see that with the increase of r, the flow shows a clear trend of quality deterioration, which is caused by the more outliers introduced by larger search radius. While we find that a too small r(&lt; 4) also results in quality deterioration. This is mainly caused by that the too small r will cause the match correspondences to be too smooth, and make it fails to recover the matches of small parts which is vanished on higher levels.</p><p>Next, we evaluate the effect of our hierarchical method with different number of hierarchical levels k . As we can see in <ref type="figure" target="#fig_6">Figure 6</ref>(c), when k = 1 (single-scale PatchMatch), the method performs poorly, mainly caused by the local ambiguity of patches without any guidance. As k increase, the quality rises contributed by the propagation from high levels which is more discriminative. This confirms the importance of the multi-scale matching strategy. However, the quality will be impaired by too more levels (k &gt; 5), due to the failure of recovering small details.</p><p>For the iteration numbers n, a larger n always leads to a more accurate matching, while at the price of more running time. We find that after n = 6 times of iterations our matching method has almost converged, and it obtains limited gain in accuracy with even larger n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Middlebury Database Experiments</head><p>Middlebury dataset <ref type="bibr" target="#b1">[2]</ref> is a classical optical flow benchmark. It contains complex motions for accurate optical flow estimation, while no large displacements. On Middlebury, our method obtains an average AEE of 0.368 and performs slightly better than EpicFlow (0.393). Like EpicFlow <ref type="bibr" target="#b23">[24]</ref>, the benefits of our matching method on Middlebury are limited due to the absence of large displacements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">KITTI Database Experiments</head><p>KITTI dataset <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21]</ref>   <ref type="bibr" target="#b26">[27]</ref> 7.22% 17.79% 1.5 5.8 17s EpicFlow <ref type="bibr" target="#b23">[24]</ref> 7.88% 17.08% 1.5 3.8 15s TF+OFM <ref type="bibr" target="#b12">[13]</ref> 10.22% 18.46% 2.0 5.0 350s <ref type="table">Table 3</ref>. Results on KITTI2012 test set. AEE-Noc is the AEE on non-occluded areas. Out-Noc3 (resp. Out-All3) is the percentage of pixels with flow error above 3 pixels on non-occluded areas (resp. all pixels). * Runtime measured on a powerful GPU. KITTI dataset consists of two versions: KITTI2012 <ref type="bibr" target="#b8">[9]</ref> and KITTI2015 <ref type="bibr" target="#b20">[21]</ref>. <ref type="table">Table 3</ref> compares our method to state-of-the-art methods that do not use epipolar geometry or stereo vison on the KITTI2012 dataset. Note that we use the same matching parameters for both KITTI and MPI-Sintel. Our method clearly outperforms the original EpicFlow <ref type="bibr" target="#b23">[24]</ref> as well as most other methods. As can be seen, in addition to the efficiency, our method just missed the best approach by 0.03% in Out-Noc3 and performs best in terms of AEE on nonoccluded areas. We also evaluate our method on the newly emerged KITTI2015 dataset. As <ref type="table">Table 4</ref> shows, our method outperforms EpicFlow and is 40+ times faster than the 1st.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We present an efficient coarse-to-fine matching framework for optical flow estimation. On the basis of the observation that the matching results is more discriminative on higher pyramidal levels and the optical flow is smooth spatially, we combine an efficient random search with the coarse-to-fine scheme on a sparse image grid structure for optical flow. The evaluation on modern datasets shows that our approach is capable of providing highly accurate optical flow for large displacements and is more efficient than state-of-the-art methods with similar quality. For our future work, we are interested in the parallelization of our match-ing framework in the GPU for real-time processing. Exploring the proposed matching framework to facilitate other tasks is also an interesting research direction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Comparison of state-of-the-art flow methods. In addition to the sharp motion boundaries which is similar to EpicFlow, our CPM-Flow can survive in the case of tiny structures with large motions (like the leg of the character and the bar of the weapon) which is usually a problem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Response maps of some reference patches on the target image with different patch size. Left column consists of the two consecutive images and the zoomed version from top to bottom. Right column is the responses of the patches in the left-bottom with size 4 × 4, 8 × 8 and 32 × 32 from top to bottom respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3</head><label>3</label><figDesc>Figure 3. Overview of the proposed CPM algorithm. Given two images, we construct the pyramids and process from top to bottom. On each level, the initial matching correspondences is propagated with random search after a fixed number of times, and the results of each level is used as a initialization of the next lower level. The results after the propagation on the finest level is our matching results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Example of our coarse-to-fine matching. Left column shows the matching results on different levels from coarse to fine (from top to bottom), and right column shows from top to bottom: mean of the consecutive images, ground truth and the matching results after outlier handling. We can see that, as the matching gets finer, it can recover the matching of the weapon which is vanished on higher levels. Matching correspondences are shown as small colored patches centered at the matching points (color coded as in<ref type="bibr" target="#b1">[2]</ref>).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 1 :</head><label>1</label><figDesc>Coarse-to-fine PatchMatch Algorithm Input: a pair of images I 1 , I 2 , a seed set S ∈ I 1 Output: matching correspondences M of S Construct the image pyramids I l i and seeds {s l }, i ∈ {1, 2}, l ∈ {0, 1, . . . , k − 1} for seeds {s l } from {s k−1 } to {s 0 } do if l = k − 1 then random initialization search within the maximum image dimension else initialization according to Eqn. 3 search within radius r Outlier handling according to Sec. 3.4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Parameter sensitivity analysis. Note that, AEE is reported on the final version of the MPI-Sintel training set, and interpolation time is not included in the reported time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>sum-2 http://lear.inrialpes.fr/src/epicflow/ Table 1. Results on MPI-Sintel test set. AEE-Noc (resp. AEE-Occ) is the AEE on non-occluded areas (resp. occluded areas).</figDesc><table>Method 
AEE 
All 

AEE 
Noc 

AEE 
Occ 

Time 

Clean Set 

CPM-Flow 
3.557 1.189 22.889 
4.3s 
DiscreteFlow[22] 3.567 1.108 23.626 ∼180s 
FlowFields[1] 
3.748 1.056 25.700 
18s 
EpicFlow[24] 
4.115 1.360 26.595 
16.4s 
PH-Flow[30] 
4.388 1.714 26.202 ∼800s 
DeepFlow[27] 
5.377 1.771 34.751 
19s 
PCALayers[28] 5.730 2.455 32.468 
3.2s 

Final Set 

FlowFields[1] 
5.810 2.621 31.799 
18s 
CPM-Flow 
5.960 2.990 30.177 
4.3s 
DiscreteFlow[22] 6.077 2.937 31.685 ∼180s 
EpicFlow[24] 
6.285 3.060 32.564 
16.4s 
TF+OFM[13] 
6.727 3.388 33.929 ∼400s 
Classic+NLP[26] 8.291 4.287 40.925 ∼800s 
MDPFlow2[29] 8.445 4.150 43.430 ∼700s 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>was created from a driving platform and contains images of city streets. It contains complex lighting conditions and large displacements. Note that the 79% 13.70% 1.3 3.2 4.2s NLTGV-SC[23] 5.93% 11.96% 1.6 3.8 16s * DiscreteFlow[22] 6.23% 16.63% 1.3 3.6 180s DeepFlow</figDesc><table>Method 

Out 
Noc3 

Out 
All3 

AEE 
Noc 

AEE 
All 

Time 

PH-Flow[30] 
5.76% 10.57% 1.3 2.9 800s 
FlowFields[1] 
5.77% 14.01% 1.4 3.5 
23s 
CPM-Flow 
5.</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>Table 4. Results on KITTI2015 test set. Fl-bg (resp. Fl-fg) is the percentage of outliers averaged only over background regions (resp. foreground regions).</figDesc><table>Method 
Fl-all 
Fl-bg 
Fl-fg Time 

DiscreteFlow[22] 22.38% 21.53% 26.68% 180s 
CPM-Flow 
23.23% 22.32% 27.79% 4.2s 
EpicFlow[24] 
27.10% 25.81% 33.56% 
15s 
DeepFlow[27] 
29.18% 27.96% 35.28% 
17s 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://people.csail.mit.edu/celiu/SIFTflow/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/Itseez/opencv 4 http://j0sh.github.io/thesis/kdtree/ 5 http://lear.inrialpes.fr/src/deepmatching/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Flow Fields: Dense correspondence fields for highly accurate large displacement optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bailer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Taetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stricker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A database and evaluation methodology for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast edge-preserving patchmatch for large displacement optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Goldman. PatchMatch: A randomized correspondence algorithm for structural image editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGGRAGH</title>
		<meeting>of ACM SIGGRAGH</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large displacement optical flow: Descriptor matching in variational motion estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A naturalistic open source movie for optical flow evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Large displacement optical flow from nearest neighbor fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Distinctive image features from scale-invariant keypoints. IJCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Are we ready for autonomous driving? the kitti vision benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Computing nearest-neighbor fields via propagationassisted kd-trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Determining optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K P</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">G</forename><surname>Schunck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generalized deformable spatial pyramid: Geometry-preserving dense correspondence estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Optical flow with geometric occlusion estimation and fusion of multiple frames. Energy Minimization Methods in Computer Vision and Pattern Recognition (EMMCVPR)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deformable spatial pyramid matching for fast dense correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Coherency sensitive hashing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Korman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Locally affine sparse-to-dense matching for motion and occlusion estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Leordeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SPM-BP: Sped-up patchmatch belief propagation for continuous M-RFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">SIFT Flow: Dense correspondence across scenes and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">PatchMatch Filter: Efficient edge-aware filtering meets randomized search for fast correspondence field estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fast approximate nearest neighbors with automatic algorithm configuration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision Theory and Applications</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Object scene flow for autonomous vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Discrete optimization for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Heipke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition (GCPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Non-local total generalized variation for optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranftl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bredies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">EpicFlow: Edge-preserving interpolation of correspondences for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fast cost-volume filtering for visual correspondence and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hosni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bleyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gelautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A quantitative analysis of current practices in optical flow estimation and the principles behind them. IJCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">DeepFlow: Large displacement optical flow with deep matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient sparse-to-dense optical flow estimation using a learned basis and layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Motion detail preserving optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsushita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dense, accurate optical flow estimation with piecewise parametric model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Patch-Cut: Data-driven object segmentation via local shape transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
