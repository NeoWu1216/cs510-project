<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/c/Users/pc/Desktop/cs510_proj/grobid-0.5.6/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Motion from Structure (MfS): Searching for 3D Objects in Cluttered Point Trajectories</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayakorn</forename><surname>Vongkulbhisal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Cabral</surname></persName>
							<email>rcabral@cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>De La Torre</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><forename type="middle">P</forename><surname>Costeira</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename><surname>Isr -Instituto</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Superior</forename><surname>Técnico</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Portugal</roleName><surname>Lisboa</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Motion from Structure (MfS): Searching for 3D Objects in Cluttered Point Trajectories</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.5.6" ident="GROBID" when="2019-12-02T16:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Object detection has been a long standing problem in computer vision, and state-of-the-art approaches rely on the use of sophisticated features and/or classifiers. However, these learning-based approaches heavily depend on the quality and quantity of labeled data, and do not generalize well to extreme poses or textureless objects.</p><p>In this work, we explore the use of 3D shape models to detect objects in videos in an unsupervised manner. We call this problem Motion from Structure (MfS): given a set of point trajectories and a 3D model of the object of interest, find a subset of trajectories that correspond to the 3D model and estimate its alignment (i.e., compute the motion matrix). MfS is related to Structure from Motion (SfM) and motion segmentation problems: unlike SfM, the structure of the object is known but the correspondence between the trajectories and the object is unknown; unlike motion segmentation, the MfS problem incorporates 3D structure, providing robustness to tracking mismatches and outliers. Experiments illustrate how our MfS algorithm outperforms alternative approaches in both synthetic data and real videos extracted from YouTube.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Object detection is one of the most common tasks that humans perform. We are constantly looking and detecting people, roads, chairs or automobiles. Yet, much of how we perceive objects so accurately and with so little apparent effort remains a mystery. Although much progress has been done in the last few years, we are still far away from developing algorithms that can match human performance. Most previous efforts in the area of object detection have emphasized 2D approaches on different types of features and classifiers. Features have included shape (e.g. contours) and/or appearance descriptors (e.g., SIFT, deep learning features). Classifiers have included Support Vector Machines (SVM), <ref type="bibr">Figure 1</ref>. Motion from Structure (MfS) problem: Given a set of point trajectories (a) and a 3D model of an object (b), find a subset of trajectories that are aligned with the model. Our approach splits this combinatorial problem in two parts. First, we reduce potential candidate matching points by finding trajectories that compose the convex hull of objects (red squares in (c)). Second, a subset of the remaining trajectories are aligned with the 3D model (d).</p><p>Boosting or Gaussian Processes. While 2D approaches are fast and have been shown to scale well to a large number of objects, they typically depend heavily on texture regions, lack robustness to viewpoints and incorporate video information in a heuristic manner. Surprisingly, little attention has been paid to the problem of 3D object detection, especially since acquiring 3D models has become more accessible due to the ubiquity of RGBD cameras and crowdsourced repositories such as 3D Warehouse <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b28">29]</ref>.</p><p>To address the limitations of 2D approaches for detection, this paper proposes a new problem that we call Motion from Structure (MfS). Given a set of point trajectories containing multiple objects and a 3D model of an object (i.e., a point cloud), MfS finds a subset of trajectories that are wellaligned (i.e., via motion matrix) with the 3D model. Con-sider <ref type="figure">Fig. 1; Fig. 1a</ref> shows the point trajectories and <ref type="figure">Fig. 1b</ref> plots several 3D views of the object of interest to detect. The goal of MfS is to solve the alignment between the 3D model and its trajectories (see <ref type="figure">Fig. 1d</ref>). MfS differs from 2D approaches to object detection in several aspects. First, MfS provides a natural framework to incorporate geometry into object detection in video. It computes the motion using a 3D model, which makes it more robust to strong viewpoint changes. Second, the MfS problem is unsupervised and there is no need for expensive and error-prone labeling process. Finally, in contrast to image-based approaches which rely on similar appearance, MfS allows 3D models to be aligned to objects with the same shape while having no similarity in textures.</p><p>The main challenge of MfS lies in the lack of discriminative features (i.e., it is an unsupervised method without any appearance features) to solve for correspondence between trajectories and the queried model. Recall that most detection problems <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b35">36]</ref> use supervised detectors for parts of the objects. Since the number of trajectories can be significantly larger than the number of vertices representing the object, the problem is NP-hard in general. To alleviate the combinatorial problem, we proposed a two-step approach to the MfS problem: (1) Reducing the number of trajectories by considering only the tracked points in the convex hull of an object (see red squares in <ref type="figure">Fig. 1c</ref>). This provides a compact representation of objects in the scene. (2) Aligning the remaining tracks with the 3D model via a guided sampling approach (see <ref type="figure">Fig. 1d</ref>).</p><p>The MfS problem is related to two well-known problems in computer vision: Structure from Motion (SfM) and motion segmentation (MSeg). Similar to SfM, the MfS problem starts from point trajectories, but, unlike SfM, in MfS a 3D model of the object of interest is given. However, in the MfS problem the point trajectories that correspond to the 3D object are unknown. MfS is able to find not only the subset of trajectories corresponding to the object, but also its alignment (i.e., the motion matrix). MfS also relates to the MSeg problem that performs grouping of trajectories corresponding to the same rigid object. MSeg may seem to be an intuitive approach to solve the MfS problem: we could use MSeg methods to group trajectories into objects, and then fit the 3D model to each set of points, and select the one with less error. However, each of these steps is prone to errors by itself, and as we will show in experimental validation, MSeg-based algorithms may lead to worse solutions for MfS than our approach. Moreover, in MSeg the number of clusters needs to be known a priori and they are susceptoble to outliers which are typically present due to background motion, camera blur, and noise. On the other hand, our approach does not perform clustering or 3D reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Our work has a direct connection to Structure from Motion (SfM) and Motion Segmentation (MSeg). In this section, we briefly review these two problems and other works that perform partial matching and pose estimation.</p><p>Structure from Motion (SfM) Let W ∈ R 2F ×n (see notation 1 ) be a matrix containing n feature tracks of an object in F image frames. Tomasi and Kanade <ref type="bibr" target="#b24">[25]</ref> showed that under an orthographic camera model W lies in a four dimensional subspace, leading to the factorization</p><formula xml:id="formula_0">W = MS,<label>(1)</label></formula><p>where M ∈ R 2F ×4 is the F -frame motion matrix and S ∈ R 4×n contains 3D homogeneous coordinates of the vertices. This factorization relates feature tracks in a sequence of 2D images to its 3D reconstruction. Since this factorization was first proposed, it has been extended to handle different camera models, articulated and non-rigid objects, outlier handling, missing data, and other feature types <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b27">28]</ref>. Motion Segmentation (MSeg) Given a matrix W containing tracks of multiple objects, the goal of MSeg is to group the tracks of different objects. Since the tracks of each object lie in a low dimensional subspace <ref type="bibr" target="#b24">[25]</ref>, subspace clustering techniques have been proposed as a solution to MSeg. Previous works in this direction include the use of shape interaction matrix <ref type="bibr" target="#b3">[4]</ref>, generalized principal component analysis <ref type="bibr" target="#b29">[30]</ref>, and principal subspace angles <ref type="bibr" target="#b30">[31]</ref>, with extensions to handle articulated and nonrigid objects, and also segmentation of dense trajectories <ref type="bibr" target="#b32">[33]</ref>. Recent approaches such as sparse subspace clustering <ref type="bibr" target="#b5">[6]</ref> and low rank representation <ref type="bibr" target="#b14">[15]</ref> impose sparsity or low rank priors to recover the affinity matrix in a convex formulation. However, MSeg only clusters tracks into groups with low dimensional subspaces, and it is not clear how to incorporate 3D models of objects as additional information.</p><p>Track-based information processing Beyond reconstruction and MSeg, feature tracks have also been used for other higher level computer vision tasks, such as foreground object segmentation <ref type="bibr" target="#b23">[24]</ref>, action recognition <ref type="bibr" target="#b16">[17]</ref>, object detection <ref type="bibr" target="#b34">[35]</ref>, and object recognition <ref type="bibr" target="#b18">[19]</ref>. However, most of the approaches to detection and recognition still require classifiers to be learned from training data, which have to be manually labeled and can be laborous to obtain.</p><p>Correspondence and pose estimation Instead of using labeled data, 3D models provide compact representations of an object's shapes. To incorporate 3D models for object detection or recognition, pose estimation must be performed to align the models to the images. In the case of single images, several works utilize both appearance features (e.g. SIFT) and 3D shape as input <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b36">37]</ref>. These approaches require the correspondence between appearance features of 3D models and the images to be established prior to estimating pose. However, without appearance features, there is much less cue for obtaining the correspondence, and hence both correspondence and pose must be solved simultaneously <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18]</ref>.</p><p>In the case of videos, motion can be used to provide information to solve for pose and correspondence. Toshev et al. <ref type="bibr" target="#b26">[27]</ref> proposed to synthesize different views from 3D models and match their silhouettes to a moving object segmented from a video. On the other hand, we aim to directly align 3D point clouds to feature tracks from videos using the subspace relation as in <ref type="bibr" target="#b0">(1)</ref>. When the number of tracks is the same as that of the model vertices, the correspondence can be obtained by permuting the nullspace of the shape matrix to match with the track matrix <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16]</ref>. However, there is no obvious way to extend these approaches to deal with extra tracks from videos. To deal with such cases, <ref type="bibr" target="#b33">[34]</ref> included texture features as input and sought the correspondence that minimizes the nuclear norm of the selected tracks and features.</p><p>Recently, Zhou and De la Torre <ref type="bibr" target="#b35">[36]</ref> proposed a method to select a subset of trajectories that aligns body configurations with a motion capture data. However, the selection of trajectories uses supervised information. Our work tackles MfS by reducing the candidate for matching to the convex hull of objects. Although the idea of using convex hulls has been used in image registration <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b31">32]</ref>, their focus was on registering two sets of 2D point clouds whereas we register the 3D structure by observing 2D tracks from videos.</p><p>Despite the name resemblance, we note that our problem is different from <ref type="bibr" target="#b13">[14]</ref>, which proposed a large-scale 3D reconstruction approach for rolling-shutter cameras, while our goal is to register 3D models onto 2D tracks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Motion from Structure Problem</head><p>The motion from structure (MfS) problem can be stated as follows. Given a measurement matrix</p><formula xml:id="formula_1">W =      x 1 1 x 1 2 · · · x 1 n x 2 1 x 2 2 · · · x 2 n . . . . . . . . . . . . x F 1 x F 2 · · · x F n      ∈ R 2F ×n ,<label>(2)</label></formula><p>where x f i ∈ R 2 is the 2D coordinate of the i th feature track in frame f , and a shape matrix S ∈ R 4×m containing m 3D vertices of an object of interest, find the subset of tracks in W that belongs to the object. MfS is different from MSeg as it does not require tracks to be clustered into groups beforehand, but rather finds a partial permutation matrix P ∈ {0, 1} n×m and a motion matrix M ∈ R 2F ×4 that aligns a given 3D object to a subset of tracks. Assuming no noise and no missing data, the relationship between W, P, and S is given by</p><formula xml:id="formula_2">WP = MS.<label>(3)</label></formula><p>Assuming that the motion is scaled orthographic, we can expand M as:</p><formula xml:id="formula_3">M =     α 1 M 1 b 1 . . . . . . α F M F b F     ,<label>(4)</label></formula><p>where</p><formula xml:id="formula_4">M f ∈ R 2×3 , b f ∈ R 2</formula><p>, and α f ∈ R are rotation, translation, and scaling components in frame f .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem Analysis</head><p>In this section, we analyze the challenges of the MfS problem.</p><p>Complexity due to large number of tracks: The objects in general videos typically contain complex texture resulting in large number of additional tracks (besides the tracks belonging to the 3D object of interest). Since we only use the shape of the object, MfS problem is formulated as a combinatorial problem, with increasing complexity with the number of trajectories.</p><p>Lack of appearance features: The lack of appearance features (e.g. SIFT) causes each track to be indistinct from others, and prevents us from obtaining putative matches between them and the 3D model. This difference sets MfS apart from general pose estimation problems where distinctive appearance features play a significant role as an initialization to obtain pose. Without these putative matching, pose estimation is in general an ill-posed problem as it is not clear how to obtain the alignment.</p><p>Self-occlusion of 3D model: Generally, a 3D object in a real scene is subject to self-occlusion. This means not all vertices of S in <ref type="formula" target="#formula_2">(3)</ref> should be matched to the tracks. Since spurious matches can easily lead to a bad alignments, how to handle self-occlusion is an important issue that needs to be addressed.</p><p>Coherent motion trajectories: Although the tracks are indistinct, coherent motion of tracks from the same objects allows their tracks to be clustered into groups (e.g. by MSeg). In addition, they also encode information about the shape of each object (e.g. as in <ref type="formula" target="#formula_0">(1)</ref>). These two properties provide enough structure for us to solve the MfS problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Solving MfS</head><p>In order to tackle MfS, we make two assumptions: (1) the target objects have independent motion from other ob-jects in the scene, and (2) the camera model is scaled orthographic. These assumptions can well approximate typical scenes and are generally adopted in solving MSeg <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b14">15]</ref>. However, MfS is different as it does not require all tracks to be clustered into groups, but rather selecting tracks belonging to a given shape. To this end, we propose a two-step approach. In the first step, we solve a convex optimization problem to select a subset of special tracks constituting the convex hulls of moving objects. We call these tracks Support Tracks (STs). Since STs constitute convex hull of objects, they are more likely to be matched to the target shape. Selecting STs before matching results in the reduction of both false matches and complexity of the problem. In the second step, we align the 3D model to STs using a guided sampling procedure, where the selected STs are more likely to come from the same object. The following section provides details on the cost function and the algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">What is a good alignment?</head><p>Defining a good metric for alignment is critical for MfS, especially since the vertices in the given 3D model may not exactly match the tracks of the target object. Rather than solving for both P and M in <ref type="formula" target="#formula_2">(3)</ref>, we say that an alignment is good when there exists a matrix M such that the convex hulls 2 of back-projection of S and all tracks that undergo the same motion 3 are similar (see <ref type="figure" target="#fig_0">Fig. 2</ref>):</p><formula xml:id="formula_5">π f (W M ) ∼ π f (MS),<label>(5)</label></formula><p>where π f (·) returns the convex hull in frame f of the input track matrix, and W M is a matrix containing columns of W that lie in span(M). Specifically, we use the intersectionover-union (IoU) between π f (W M ) and π f (MS) to measure alignment. This leads to the following optimization problem:</p><formula xml:id="formula_6">max M F f =1 Area(π f (W M ) ∩ π f (MS)) Area(conv(π f (W M ) ∪ π f (MS))) ,<label>(6)</label></formula><p>subject</p><formula xml:id="formula_7">to M f M f ⊤ = I 2 , f = 1, . . . , F,</formula><p>where the relation between M f and M is given in <ref type="formula" target="#formula_3">(4)</ref>, conv(·) returns convex hull of the input set, and Area(·) returns the area of the input convex hull. The cost function in (6) possesses many desirable properties, namely it (1) uses motion and shape to measure alignment, (2) is insensitive to self-occlusion of the 3D model since alignment is measured based on regions, and (3) takes into account coherent motion of tracks. Note that P is not included in (6), but it can be recovered after obtaining M.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bad alignment</head><p>Good alignment Solving (6) requires estimating motion M, which involves sampling 4 matches between tracks from W and vertices of S. However, the total number of candidate pairs is in the order of O(n 4 k 4 ), while the number of correct pairs can be significantly smaller. In the next section, we propose an approach to identify special tracks constituting visible part of objects' convex hull by using convex optimization. We refer to these tracks as support tracks (STs). Selecting STs as candidates for matching helps reduce problem complexity, while also retain useful tracks that are more likely to match to a given shape.</p><formula xml:id="formula_8">π f (MS) π f (W M ) π f (W M ) ∩ π f (MS) conv(π f (W M ) ∪ π f (MS))</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Identifying support tracks (STs)</head><p>To identify STs in W, we exploit the idea that such tracks cannot be represented by convex combinations of tracks of the same object. Inspired by sparse subspace clustering (SSC) <ref type="bibr" target="#b5">[6]</ref>, we formulate the identification of STs and non-STs as</p><formula xml:id="formula_9">min C,E tr (C) + µf (E)<label>(7)</label></formula><p>subject to E = W − WC,</p><formula xml:id="formula_10">1 ⊤ n C = 1 n , C ≥ 0 n×n ,</formula><p>where C ∈ R n×n is the matrix containing coefficients for representing each track as a convex combination of others, and E ∈ R 2F ×n allows for errors. The error function f (·) can be ℓ 1 norm, ℓ 2,1 norm, or squared Frobenius norm. The intuition of (7) is akin to the self-expressiveness property in <ref type="bibr" target="#b5">[6]</ref>, which states that each vector in a subspace can be represented as a linear combination of others in the same subspace. By using convex combination rather than linear, STs can be identified as tracks that cannot be represented by other tracks in the same subspace. <ref type="figure">Fig. 3</ref> illustrates the idea behind <ref type="formula" target="#formula_9">(7)</ref>. There are three subtle but non-trivial differences between (7) and SSC, in both the tasks they try to accomplish and the  <ref type="figure">Figure 3</ref>. (Left) Since tracks (yellow circles) of independently moving objects lie in independent subspaces, any tracks that cannot be expressed as a convex combination of other tracks are considered STs (red squares) that constitute the convex hull of objects (see <ref type="figure">Fig. 1c</ref>). (Right) By solving <ref type="formula" target="#formula_9">(7)</ref>, these STs induce 1's in the diagonal of C.</p><p>variables involved. First, SSC was proposed to perform subspace clustering, where spectral clustering is performed on C to obtain the clusters. On the contrary, our formulation focuses on both C and E, which encode the information for distinguishing STs from non-STs. Second, C is nonnegative and its columns sum to 1, which makes them convex combination coefficients instead of linear ones. As C is nonnegative, C 1 in SSC's objective function becomes a constant value n, and thus can removed. Lastly, we penalize tr(C) as opposed to restricting diag(C) = 0 n . We show in Theorem 1 that at the global optimum diag(C) can be evaluated as a binary vector and provides information on whether a track is a ST or not.</p><p>Theorem 1. Let C * and E * be the optimal solutions of (7), andÊ be the optimal solution of variable E of (7) with diag(C) = 0 n as an additional constraint. The relation between c * ii , µ, and f (ê i ) for any i can be stated as follows:</p><formula xml:id="formula_11">c * ii ∈      {0} f (ê i ) &lt; µ −1 , [0, 1] f (ê i ) = µ −1 , {1} otherwise.<label>(8)</label></formula><p>Proof. It can be seen that <ref type="formula" target="#formula_9">(7)</ref> can be column-wise separated. For each column i, the objective is a tradeoff between c ii and µf (ê i ). If µf (ê i ) &gt; 1 then it would cost less to set c * ii = 1 with e * i = 0 2F . On the other hand, if µf (ê i ) &lt; 1 then setting c * ii = 0 and e * i =ê i would cost less. Finally, if µf (ê i ) = 1, then the cost can be kept constant at 1 by letting c * ii be any values in</p><formula xml:id="formula_12">[0, 1] while f (e i ) = (1 − c * ii )f (ê i ).</formula><p>Corollary 2. For any µ, there exists an optimal solution of (7) where diag(C * ) is a binary vector.</p><p>In Theorem 1,ê i is the error of representing w i with a convex combination of strictly other columns than w i . We can see that µ acts as a threshold for determining the value of c * ii . Specifically, if the error f (ê i ) is larger than µ −1 , it would cost less to represent w i by itself, resulting in</p><formula xml:id="formula_13">c * ii = 1.</formula><p>On the other hand, if the error is smaller than µ −1 , then it costs less for w i to be represented by other columns, resulting in c * ii = 0. For our problem, this implies that w i with c * ii = 1 is a ST, while w i with c * ii = 0 is not. By noting that µ is simply a threshold value, we can solve <ref type="bibr" target="#b6">(7)</ref> for all values of µ in a single optimization run. This is done by solving <ref type="formula" target="#formula_9">(7)</ref> with diag(C) = 0 n as an additional constraint to obtainÊ. Since c * ii = 1 and e * i = 0 2F for all i with f (ê i ) &gt; µ −1 , determining the order of tracks that gradually become STs as µ increases is equivalent to sorting f (ê i ) in a descending order. Thus, instead of setting the value µ, we can specify the number of desired STs p by selecting p tracks with highest f (ê i ).</p><p>After obtaining STs, we proceed to estimate motion matrix. To do so, we need to sample 4 STs and match them to 4 vertices from S. Although the number of tracks is reduced from n to p, the total number of matches can still be very large. To increase the likelihood of selecting good matches, it would be beneficial to sample 4 STs that are more likely to come from the same object instead of uniform sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Guided Sampling</head><p>We propose to sequentially sample STs using random walk strategy, where the transition probability of sampling ST i after ST j depends on how likely they are from the same object. In this work, we measure this value by representing each non-ST as a convex combination of only STs 4 , and counting the number of non-STs that each pair of STs mutually represent.</p><p>To represent all non-STs by only STs, we leverage on the structure of C * obtained from previous section; the constraints of (7) enforces C * to be a stochastic matrix with p ones in its diagonal. In essence, C * is a transition matrix of an absorbing Markov chain with p absorbing nodes corresponding to the p STs. From the Markov chain theory <ref type="bibr" target="#b8">[9]</ref>, the limiting matrix of C * :</p><formula xml:id="formula_14">C = lim t→∞ (C * ) t ,<label>(9)</label></formula><p>can be interpreted as convex coefficients of representing non-STs by only STs. Let d ik = I(ĉ i ′ k &gt; 0) where i ′ is the index of ST i in the original W, and I(·) is the indicator function which returns 1 if the argument is true and 0 otherwise. We calculate transition probability of sampling ST j after ST i using Jaccard similarity:</p><formula xml:id="formula_15">Pr(i → j) = 1 zi n k=1 min(d ik ,d jk ) n k=1 max(d ik ,d jk ) ; i = j, 0 ; i = j,<label>(10)</label></formula><p>where z i is a normalization factor. Note that Pr(i → j) is not equal to Pr(j → i). For the 3D model, 4 vertices are uniformly sampled to match the 4 sampled STs without any special procedure. Given 4 matches between tracks and 3D vertices, we first estimate affine transformation between them, then project the rotation part of each frame to the Stiefel manifold (see supplementary material for more detail). The M that maximizes (6) can be used to recover P in (3) by selecting closest tracks in W to MS.</p><p>The algorithm for MfS is summarized in Alg. (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Motion from Structure</head><p>Input: W, S, λ 0 , µ, nIter Output: P, M</p><p>Step 1: Identifying STs 1: Compute C and E with (7) 2: Select columns of W indicated by diag(C) = 1 as STs</p><p>Step 2: Guided Sampling 3: ComputeĈ with (9) 4: Compute transition matrix with (10) 5: for i = 1 to nIter do <ref type="bibr">6:</ref> Uniformly sample a ST <ref type="bibr">7:</ref> Use guided sampling to obtain another 3 STs </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Implementation details</head><p>This section provides the implementation details for each step of our algorithm.</p><p>Identifying STs: We use ℓ 1 norm as the error function f (·) in <ref type="bibr" target="#b6">(7)</ref>. The optimization problem is solved using Gurobi optimizer <ref type="bibr" target="#b9">[10]</ref>.</p><p>Guided sampling: In (9), rather than using eigendecomposition to computeĈ, we perform 1000 rounds of power iterations on C * , which results in a similarĈ while being faster than eigendecomposition. To calculate d i,k , it is likely that mostĉ i ′ k will not be zero. Instead, we set the threshold in I(·) to 2/p, where p is the number of STs. During the sampling, we perform two steps of random walk before selecting a ST, and allow the walker to restart at any sampled STs with equal probability <ref type="bibr" target="#b25">[26]</ref>. We prevent the sampled STs from being resampled by setting Pr(i → j) to 0 for all sampled STs j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We evaluated our algorithm on synthetic data and real videos downloaded from YouTube. Recall that MfS is a new problem, and there is no existing baseline algorithm. Hence, we constructed two baselines to compare our algorithm against. (a) All-R: This baseline approach directly samples 4 tracks and 3D vertices uniformly to form the matches required for estimating M. (b) ST-R: For this approach, we use (7) to first identify STs, then uniformly sample 4 track-vertex pairs. We refer to our ST selection and guided sampling as STGS-R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Synthetic data</head><p>In this section, we used synthetic data to quantitatively evaluate the performance of our approach (see <ref type="figure" target="#fig_3">Fig. 4a</ref>). We generated a set of 15-frame tracks with three moving shapes: a cube (8 corners), a double pyramid (6 corners), and a cuboid (8 corners). A number of internal vertices (IVs) were generated randomly inside each shape to imitate non-STs. For each shape, we generated a motion matrix M gt comprising rotation, translation, and scaling. 200 additional tracks are generated as background tracks. We added a single random translation to all tracks to simulate camera motion, and perturbed each track with Gaussian noise. To model outliers, we set the background tracks to follow the first shape that comes close to them. This is to imitate real scenarios when parts of background got occluded by moving objects, causing background tracks to follow foreground objects instead.</p><p>We evaluated our algorithm in two situations. First, we tested the robustness of our MfS against the density of tracks for each object with varying IVs for each object from 20 to 100 (corners inclusive). Second, we randomly removed tracks belonging to the corner of each shape with probability from 0 to 100 percent to imitate the situations where corner vertices may not be tracked. In the second case, we set the number of IVs to 100. The simulation was repeated 100 rounds for each setting. In all experiments, we selected 10% and 20% of tracks as STs for ST-R and STGS-R and sampled track-vectex pairs 5 × 10 4 time on each set of STs, while we sampled 1 × 10 5 times for All-R. The sample that yielded the highest cost in <ref type="bibr" target="#b5">(6)</ref> was returned as the result of each algorithm.</p><p>We used three metrics to measure performance. The first metric is IoU between the projections due to M and M gt , defined as:</p><formula xml:id="formula_16">IoU = F f =1 Area(π f (M gt S) ∩ π f (MS)) Area(conv(π f (M gt S) ∪ π f (MS)))</formula><p>.</p><p>The second metric is segmentation precision, defined as the number of correctly selected tracks against the total number of selected tracks (i.e. number of rows of W M ). The last metric is segmentation recall, defined as the number of correctly selected tracks against the number of tracks of the correct objects.   <ref type="figure" target="#fig_3">4</ref> shows the result of the synthetic experiment. The performance of All-R is very low, implying that randomly selecting matches is not a good approach to MfS. This is due to the challenging nature of the MfS that the ratio of good matches against all matches is very low. Improvements due to ST selection and guided sampling can be seen by the performance gaps between the three algorithms. STGS-R performs very well regardless of the number of IVs. On the other hand, since the shapes are similar, removing corners caused the performance to drop. In real cases, we would expect at least 50% of corners to be present, in which the performance is still in the acceptable range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Real videos</head><p>In this section, we provide qualitative evaluation of our approach using videos collected by us and videos downloaded from YouTube (see <ref type="figure" target="#fig_5">Fig. 5</ref>). The videos are 10 to 97 frames long, and are extremely challenging since they contain multiple moving objects, camera motion, zoom changes, and perspective effects. These geometric changes cause the scenes to be very dynamic and difficult to track features over long periods of time. We detected the feature points using Shi-Tomasi feature detector <ref type="bibr" target="#b22">[23]</ref> and used Lucas-Kanade tracker <ref type="bibr" target="#b1">[2]</ref> to track, resulting in 490 to 1014 tracks for each video (see Col. 3, <ref type="figure" target="#fig_5">Fig. 5</ref>). Note that there are multiple outlier tracks caused by features corresponding to the occlusion boundary. We downloaded 3D models that approximate target objects from <ref type="bibr" target="#b28">[29]</ref>, and generated the shape matrix by manually selecting 8 to 18 vertices that represent well the convex hull of each 3D model (see Col. 2, <ref type="figure" target="#fig_5">Fig. 5</ref>). For the algorithm settings, we selected 10% of tracks as STs, and sampled 1 × 10 6 track-vertex pairs for all algorithms.</p><p>Col. 4 and 5 of <ref type="figure" target="#fig_5">Fig. 5</ref>, respectively, show the selected STs and alignment results for the real videos experiment. We encourage the readers to see the results in the supplementary material to appreciate the difficulty of the data. As can be seen in Col. 4 of <ref type="figure" target="#fig_5">Fig. 5</ref>, our ST selection can reliably select tracks on the convex hull of objects, which significantly reduced the complexity of the problem. This strategy combined with guided sampling and the appropriate cost function in (6) effectively allows to solve for the correspondence between the 3D models and trajectories. With only a few vertices representing convex hulls of objects, our MfS algorithm can correctly find an alignment under self occlusion without knowing which vertices are occluded. It also can handle different camera motion effects, and imprecise 3D models <ref type="figure" target="#fig_5">(Fig. 5</ref>, different models of harrier (row 2) and cars (row 5)). Due to space restriction, we include in the supplementary document additional results with comparison to baselines, and several examples where MSeg-based approaches cannot solve this problem. It is important to remind the reader that MfS is a different problem from MSeg, but we use MSeg as baseline since the problems are related.</p><p>While the method has worked well in most of the sequences that we have tried, the last row of <ref type="figure" target="#fig_5">Fig. 5</ref> shows a failure case of our algorithm. In this case, the camera was panning from left to right, allowing only a portion of the background to be fully tracked. Rather than aligning to one of the cars, the 3D model is aligned to the background tracks because they coincidentally form a rectangular shape similar to the top view of the car's 3D model. In such cases, only tracks may not provide enough information to obtain the correct result. Additional information, such as expected </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>This paper proposes a new problem, Motion from Structure (MfS), where a given 3D model is aligned in an unsupervised manner to tracks in video. A two-step approach is proposed where convex hulls of objects are discovered in the first step, then guided sampling is performed for alignment in the second step. Our approach does not require the segmentation and 3D reconstruction of objects, and thus allows for bypassing their drawbacks. We tested our approach on synthetic data and real videos, and showed that it outperformed baseline approaches.</p><p>One limitation of using convex hulls for alignment is that the convex hull of some objects may be symmetric, which may lead to incorrect alignment due to oversimplification of shapes. We also notice that some corners were not iden-tified as STs. This occurs due to (1) close proximity between tracks allowing them to well represent each other, and (2) violation of independent subspace assumption. Further improvements also include incorporating other information (e.g. orientation), and handling incomplete tracks (i.e. missing data). We will address these issues in future works.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Example of good and bad alignments from a frame f . The yellow dots are coherent tracks. The convex hulls shown are of W M (yellow), MS (green), their intersection (red), and union (blue). An alignment is good when the ratio between intersection and union is high. (Best viewed in color.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>if it has highest value in (6) 11: end for 12: Compute P by selecting tracks closest to MS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Synthetic experiment. (a) A synthetic scene comprising tracks from a cube (red), a double pyramid (blue), a cuboid (green) and background (gray). Outlier tracks are shown in dark gray. The performance was measured by varying (b) number of internal vertices, and (c) probability of having each corner track removed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.</head><label></label><figDesc>Fig. 4 shows the result of the synthetic experiment. The performance of All-R is very low, implying that randomly selecting matches is not a good approach to MfS. This is due to the challenging nature of the MfS that the ratio of good matches against all matches is very low. Improvements due to ST selection and guided sampling can be seen by the performance gaps between the three algorithms. STGS-R performs very well regardless of the number of IVs. On the other hand, since the shapes are similar, removing corners caused the performance to drop. In real cases, we would expect at least 50% of corners to be present, in which the performance is still in the acceptable range.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Results from a real video experiment. Column 1: First frame of the videos. Column 2: 3D models with the vertices represented by S shown in dark green dots. Column 3: Tracks are shown with yellow lines. Recall that we only use tracks and 3D models as input, not the images. Column 4: Selected STs. Column 5: Results of alignment by backprojecting 3D models to the video. The STs in this frame are shown in red points. We reduce the image intensity of columns 3 to 5 for visualization purpose. (Best viewed in color.) orientation (e.g. wheels should point down), can be incorporated to reject wrong solutions during estimation of M.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Bold capital letters denote a matrix X, bold lower-case letters a column vector x. x i represents the i th column of the matrix X. x ij denotes the scalar in the i th row and j th column of the matrix X. All non-bold letters represent scalars. 1 m×n , 0 m×n ∈ R m×n are matrices of ones and zeros. In ∈ R n×n is an identity matrix. diag(X) and tr(X) denotes the vector of diagonal entries and the trace of matrix X, respectively.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In general, other types of region can be used. However, since we are given point clouds without any relation between the vertices, convex hull provides the most detailed description of the region.<ref type="bibr" target="#b2">3</ref> We say a group of tracks undergoes the same motion when there is a motion matrix M that can well explain them (see<ref type="bibr" target="#b0">(1)</ref>).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">By independent motion assumption, STs should represent only non-STs in the same subspace.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was partially supported by Fundação para a Ciência e a Tecnologia (project FCT [UID/EEA/50009/2013] and a PhD grant from the Carnegie Mellon-Portugal program).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Trajectory space: A dual representation for nonrigid structure from motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Akhter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1442" to="1456" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Lucas-Kanade 20 years on: A unifying framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="255" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Object recognition and full pose registration from a single image for robotic manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Collet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Srinivasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ferguson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A multibody factorization method for independently moving objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="159" to="179" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">SoftPOSIT: Simultaneous pose and correspondence determination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dementhon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duraiswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Samet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="259" to="284" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Sparse subspace clustering: Algorithm, theory, and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>TPAMI</publisher>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Object detection with discriminatively trained part-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Point pattern matching using convex hull edges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goshtasby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Stockman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Man, and Cybernatics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="631" to="637" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
	<note>IEEE Trans. Systems</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Introduction to Probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Grinstead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Snell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>American Mathematical Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Gurobi Optimization Inc. Gurobi optimizer reference manual</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">3D object recognition based on canonical angles between shape subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Igarashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Linear fitting with missing data for structure-from-motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="206" to="2012" />
		</imprint>
		<respStmt>
			<orgName>CVIU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robust L1 norm factorization in the presence of outliers and missing data by alternative convex programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Street view motion-from-structure-from-motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Roseborough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Robust recovery of subspace structures by low-rank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>TPAMI</publisher>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Subspace matching: Unique solution to point matching with geometric constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stošić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Costeira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Trajectons: Action recognition through the motion analysis of tracked features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Matikainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pose priors for simultaneously solving alignment and correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Moreno-Noguer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Seeing the objects behind the dots: Recognition in videos from a moving camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="71" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A factorization method for affine structure from line correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Data-driven scene understanding from 3D models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">3D generic object categorization, localization and pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Good features to track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Moving foreground object detection via robust sift trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Y M</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Communication and Image Representation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="232" to="243" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Shape and motion from image streams under orthography: a factorization method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fast random walk with restart and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Shapebased object recognition in videos using 3d synthetic object models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Makadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Articulated structure from motion by factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tresadern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<ptr target="http://3dwarehouse.sketchup.com/.1,7" />
		<title level="m">Trimble Navigation Ltd. 3D warehouse</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Generalized principal component analysis (GPCA)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>TPAMI</publisher>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1945" to="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A factorization-based approach for articulated non-rigid shape, motion and kinematic chain recovery from video. TPAMI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="865" to="877" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Points matching via iterative convex hull vertices pairing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Machine Learning and Cybernatics</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multibody factorization with uncertainty: Revisiting motion consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Machline</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="41" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Finding correspondence from multiple images via sparse and lowrank decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Object detection in surveillance video from dense trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khodabandeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MVA</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Spatio-temporal matching for human detection in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Detailed 3D representations for object recognition and modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z</forename><surname>Zia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2608" to="2623" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
